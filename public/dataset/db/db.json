{
  "name": "데이터베이스",
  "description": "데이터베이스 핵심 개념 및 면접 질문",
  "cards": [
    {
      "question": "Key (기본키, 후보키, 슈퍼키 등등...) 에 대해 설명해 주세요.",
      "answer": "**슈퍼키(Super Key)**: 테이블에서 각 행을 유일하게 식별할 수 있는 속성 또는 속성의 집합입니다. 중복을 허용하지 않지만, 최소성을 만족하지 않아도 됩니다.\n\n**후보키(Candidate Key)**: 슈퍼키 중에서 최소성을 만족하는 키입니다. 즉, 불필요한 속성이 없는 최소한의 슈퍼키입니다.\n\n**기본키(Primary Key)**: 후보키 중에서 선택된 메인 키로, 테이블의 각 행을 고유하게 식별합니다. NULL 값을 가질 수 없고, 중복되지 않습니다.\n\n**대체키(Alternate Key)**: 후보키 중 기본키로 선택되지 않은 나머지 키들입니다.\n\n**외래키(Foreign Key)**: 다른 테이블의 기본키를 참조하는 키로, 테이블 간의 관계를 나타냅니다.",
      "type": "essay",
      "tags": ["데이터베이스", "Key", "기본키", "후보키"]
    },
    {
      "question": "기본키는 수정이 가능한가요?",
      "answer": "기술적으로는 가능하지만, **권장하지 않습니다**.\n\n기본키를 수정하면:\n1. 외래키로 참조하는 다른 테이블과의 관계가 깨질 수 있습니다\n2. 인덱스 재구성으로 성능 저하가 발생합니다\n3. 데이터 정합성 문제가 생길 수 있습니다\n4. 클러스터드 인덱스를 사용하는 경우 물리적 저장 순서가 변경되어 큰 오버헤드가 발생합니다\n\n따라서 기본키는 **불변(immutable)**하게 설계하는 것이 좋고, 수정이 필요한 경우 대리키(surrogate key)인 auto_increment나 UUID를 사용하는 것이 일반적입니다.",
      "type": "essay",
      "tags": ["데이터베이스", "기본키", "설계"]
    },
    {
      "question": "사실 MySQL의 경우, 기본키를 설정하지 않아도 테이블이 만들어집니다. 어떻게 이게 가능한 걸까요?",
      "answer": "MySQL(InnoDB)은 기본키를 명시하지 않으면 내부적으로 숨겨진 기본키를 자동 생성합니다:\n\n1. 먼저 UNIQUE NOT NULL 컬럼이 있으면 그것을 기본키로 사용\n2. 없으면 내부적으로 6바이트 숨겨진 rowid를 자동 생성하여 기본키로 사용\n\nInnoDB는 **클러스터드 인덱스** 구조를 사용하므로 반드시 기본키가 필요하기 때문입니다. 모든 데이터는 기본키 순서로 물리적으로 저장됩니다.\n\n하지만 명시적으로 기본키를 지정하는 것이 성능과 관리 측면에서 훨씬 좋습니다. 숨겨진 rowid는 사용자가 제어할 수 없고, 쿼리 최적화에도 활용할 수 없기 때문입니다.",
      "type": "essay",
      "tags": ["MySQL", "InnoDB", "기본키", "클러스터드 인덱스"]
    },
    {
      "question": "외래키 값은 NULL이 들어올 수 있나요?",
      "answer": "**네, 가능합니다.** 외래키는 NULL 값을 허용할 수 있습니다.\n\n외래키가 NULL이라는 것은 \"참조하는 대상이 없다\"는 의미로, 관계가 선택적(optional)일 때 사용됩니다.\n\n예시:\n- 직원 테이블에서 부서ID(외래키)가 NULL → 아직 부서가 배정되지 않은 직원\n- 주문 테이블에서 쿠폰ID(외래키)가 NULL → 쿠폰을 사용하지 않은 주문\n\n반대로 외래키를 NOT NULL로 설정하면 반드시 참조 관계가 있어야 하므로 필수 관계(mandatory)를 표현할 수 있습니다.",
      "type": "essay",
      "tags": ["외래키", "NULL", "참조 무결성"]
    },
    {
      "question": "어떤 칼럼의 정의에 UNIQUE 키워드가 붙는다고 가정해 봅시다. 이 칼럼을 활용한 쿼리의 성능은 그렇지 않은 것과 비교해서 어떻게 다를까요?",
      "answer": "UNIQUE 제약조건이 있는 컬럼은 **자동으로 인덱스가 생성**되므로 조회 성능이 크게 향상됩니다.\n\n**성능 차이:**\n- UNIQUE 컬럼: O(log N) - 인덱스를 통한 빠른 검색\n- 일반 컬럼: O(N) - Full Table Scan\n\n**예시:**\n```sql\n-- email에 UNIQUE 제약조건이 있는 경우\nSELECT * FROM users WHERE email = 'test@example.com';\n-- → 인덱스 스캔으로 매우 빠름\n\n-- name에 제약조건이 없는 경우  \nSELECT * FROM users WHERE name = '홍길동';\n-- → 전체 테이블 스캔으로 느림\n```\n\n단, INSERT/UPDATE 시에는 중복 검사를 위한 오버헤드가 있으나, 조회 성능 향상이 훨씬 큽니다.",
      "type": "essay",
      "tags": ["UNIQUE", "인덱스", "성능", "쿼리 최적화"]
    },
    {
      "question": "RDB와 NoSQL의 차이에 대해 설명해 주세요.",
      "answer": "**RDB (Relational Database):**\n- 정형화된 스키마 구조 (테이블, 행, 열)\n- ACID 트랜잭션 보장\n- SQL 쿼리 언어 사용\n- 관계(JOIN)를 통한 데이터 연결\n- 수직적 확장(Scale-up)에 유리\n- 예: MySQL, PostgreSQL, Oracle\n\n**NoSQL (Not Only SQL):**\n- 유연한 스키마 또는 스키마리스\n- BASE 속성 (Basically Available, Soft state, Eventually consistent)\n- 다양한 데이터 모델 (Key-Value, Document, Column-family, Graph)\n- 수평적 확장(Scale-out)에 유리\n- 빠른 읽기/쓰기 성능\n- 예: MongoDB, Redis, Cassandra, DynamoDB\n\n**선택 기준:**\n- 데이터 정합성이 중요 → RDB\n- 대용량 트래픽, 빠른 응답 → NoSQL\n- 복잡한 관계 쿼리 → RDB\n- 유연한 스키마 필요 → NoSQL",
      "type": "essay",
      "tags": ["RDB", "NoSQL", "데이터베이스", "비교"]
    },
    {
      "question": "NoSQL의 강점과, 약점이 무엇인가요?",
      "answer": "**강점:**\n1. **유연한 스키마**: 스키마 변경이 자유로워 빠른 개발 가능\n2. **수평적 확장**: 서버 추가로 쉽게 확장 가능 (샤딩)\n3. **높은 성능**: 대용량 데이터 읽기/쓰기에 최적화\n4. **다양한 데이터 모델**: 비정형 데이터 저장에 유리\n5. **가용성**: 분산 환경에서 높은 가용성 제공\n\n**약점:**\n1. **데이터 정합성**: ACID 보장이 약하거나 없음 (Eventually Consistent)\n2. **복잡한 쿼리**: JOIN이 없거나 제한적이어서 복잡한 관계 쿼리가 어려움\n3. **표준화 부족**: 각 NoSQL마다 쿼리 언어와 방식이 다름\n4. **트랜잭션 제한**: 다중 문서/컬렉션 간 트랜잭션이 제한적\n5. **학습 곡선**: RDB에 익숙한 개발자에게는 새로운 개념 학습 필요\n6. **데이터 중복**: 역정규화로 인한 저장 공간 낭비 가능",
      "type": "essay",
      "tags": ["NoSQL", "장단점", "설계"]
    },
    {
      "question": "RDB의 어떠한 특징 때문에 NoSQL에 비해 부하가 많이 걸릴 \"수\" 있을까요?",
      "answer": "**주의**: 무조건 NoSQL이 RDB보다 빠른 것은 아닙니다!\n\n**RDB에서 부하가 걸릴 수 있는 상황:**\n\n1. **복잡한 JOIN 연산**\n   - 여러 테이블을 조인할 때 많은 연산 필요\n   - NoSQL은 역정규화로 한 문서에 모든 데이터 저장\n\n2. **트랜잭션 오버헤드**\n   - ACID 보장을 위한 Lock, MVCC 등의 메커니즘\n   - NoSQL은 트랜잭션이 제한적이거나 없음\n\n3. **수직적 확장의 한계**\n   - 단일 서버 성능 한계에 도달\n   - NoSQL은 수평 확장이 쉬움\n\n4. **정규화로 인한 쿼리 복잡도**\n   - 정규화된 테이블은 여러 번 조회 필요\n   - NoSQL은 역정규화로 한 번에 조회\n\n**하지만:**\n- 인덱스가 잘 설계된 RDB는 매우 빠름\n- 복잡한 쿼리나 집계 연산은 RDB가 오히려 유리\n- 데이터 정합성이 중요한 경우 RDB의 트랜잭션이 필수",
      "type": "essay",
      "tags": ["RDB", "NoSQL", "성능", "비교"]
    },
    {
      "question": "NoSQL을 활용한 경험이 있나요? 있다면, 왜 RDB를 선택하지 않고 해당 DB를 선택했는지 설명해 주세요.",
      "answer": "**Redis 사용 경험:**\n\n**선택 이유:**\n1. **캐싱 레이어**: RDB 조회 성능 개선을 위한 캐시\n2. **빠른 응답 속도**: 인메모리 DB로 밀리초 단위 응답\n3. **세션 저장소**: 분산 환경에서 세션 공유\n4. **실시간 랭킹**: Sorted Set을 이용한 실시간 리더보드\n\n**MongoDB 사용 경험:**\n\n**선택 이유:**\n1. **유연한 스키마**: 자주 변경되는 제품 속성 저장\n2. **빠른 개발**: 스키마 변경 없이 필드 추가 가능\n3. **JSON 형태**: REST API와 자연스러운 연동\n4. **로그 데이터**: 비정형 로그를 유연하게 저장\n\n**결론:**\nNoSQL은 RDB를 **대체**하는 것이 아니라 **보완**하는 관계입니다. 각 DB의 강점을 살려 적재적소에 사용하는 것이 중요합니다 (Polyglot Persistence).",
      "type": "essay",
      "tags": ["NoSQL", "Redis", "MongoDB", "실무 경험"]
    },
    {
      "question": "트랜잭션이 무엇이고, ACID 원칙에 대해 설명해 주세요.",
      "answer": "**트랜잭션(Transaction):**\n데이터베이스의 상태를 변화시키는 하나의 논리적 작업 단위입니다. All or Nothing 원칙으로, 모두 성공하거나 모두 실패해야 합니다.\n\n**ACID 원칙:**\n\n**1. Atomicity (원자성)**\n- 트랜잭션의 모든 연산이 완전히 수행되거나 전혀 수행되지 않아야 함\n- 예: 계좌 이체 시 출금과 입금이 모두 성공하거나 모두 실패\n\n**2. Consistency (일관성)**\n- 트랜잭션 실행 전후에 데이터베이스가 일관된 상태를 유지해야 함\n- 모든 제약조건(FK, UNIQUE 등)을 만족해야 함\n\n**3. Isolation (격리성)**\n- 여러 트랜잭션이 동시에 실행될 때 서로 간섭하지 않아야 함\n- 각 트랜잭션은 독립적으로 실행되는 것처럼 보여야 함\n\n**4. Durability (지속성)**\n- 트랜잭션이 성공적으로 완료되면 그 결과는 영구적으로 반영되어야 함\n- 시스템 장애가 발생해도 결과가 보존됨",
      "type": "essay",
      "tags": ["트랜잭션", "ACID", "데이터베이스"]
    },
    {
      "question": "ACID 원칙 중, Durability를 DBMS는 어떻게 보장하나요?",
      "answer": "DBMS는 **WAL(Write-Ahead Logging)** 기법으로 Durability를 보장합니다.\n\n**WAL 동작 방식:**\n1. **데이터 변경 전 로그 기록**: 실제 데이터를 변경하기 전에 Redo 로그에 변경 내용을 먼저 기록\n2. **로그를 디스크에 flush**: 로그를 안전하게 디스크에 저장\n3. **COMMIT**: 로그가 안전하게 저장되면 트랜잭션 커밋\n4. **실제 데이터 변경**: 나중에 실제 데이터 파일 변경 (지연 쓰기)\n\n**장애 복구:**\n- **시스템 장애 시**: Redo 로그를 이용해 커밋된 트랜잭션 재실행\n- **미완료 트랜잭션**: Undo 로그를 이용해 롤백\n\n**MySQL InnoDB 예시:**\n- **Redo Log**: 커밋된 변경사항 저장 (복구용)\n- **Undo Log**: 롤백 및 MVCC용\n- **Double Write Buffer**: 데이터 페이지 손상 방지\n\n이를 통해 COMMIT된 트랜잭션은 시스템 장애에도 반드시 복구됩니다.",
      "type": "essay",
      "tags": ["ACID", "Durability", "WAL", "MySQL"]
    },
    {
      "question": "트랜잭션을 사용해 본 경험이 있나요? 어떤 경우에 사용할 수 있나요?",
      "answer": "**트랜잭션 사용 경험:**\n\n**1. 금융 거래 (계좌 이체)**\n```sql\nSTART TRANSACTION;\nUPDATE accounts SET balance = balance - 10000 WHERE id = 1;\nUPDATE accounts SET balance = balance + 10000 WHERE id = 2;\nCOMMIT;\n```\n- 출금과 입금이 모두 성공해야 함\n\n**2. 주문 처리**\n```sql\nSTART TRANSACTION;\nINSERT INTO orders (user_id, total) VALUES (1, 50000);\nUPDATE products SET stock = stock - 1 WHERE id = 10;\nINSERT INTO order_items (order_id, product_id) VALUES (LAST_INSERT_ID(), 10);\nCOMMIT;\n```\n- 주문 생성, 재고 감소, 주문 상세가 원자적으로 처리\n\n**3. 회원 가입**\n```sql\nSTART TRANSACTION;\nINSERT INTO users (email, name) VALUES ('test@example.com', '홍길동');\nINSERT INTO user_profiles (user_id, phone) VALUES (LAST_INSERT_ID(), '010-1234-5678');\nCOMMIT;\n```\n- 사용자와 프로필이 함께 생성\n\n**사용해야 하는 경우:**\n- 여러 테이블에 걸친 데이터 변경\n- 데이터 정합성이 중요한 비즈니스 로직\n- 실패 시 전체 롤백이 필요한 작업",
      "type": "essay",
      "tags": ["트랜잭션", "실무", "SQL"]
    },
    {
      "question": "읽기에는 트랜잭션을 걸지 않아도 될까요?",
      "answer": "**상황에 따라 다릅니다.** 읽기 작업에도 트랜잭션이 필요한 경우가 많습니다.\n\n**트랜잭션이 필요한 읽기:**\n\n**1. 일관된 읽기 (Consistent Read)**\n```sql\nSTART TRANSACTION;\nSELECT balance FROM accounts WHERE id = 1;\nSELECT balance FROM accounts WHERE id = 2;\nCOMMIT;\n```\n- 두 계좌의 잔액을 동일 시점에서 조회\n- 중간에 다른 트랜잭션의 변경이 반영되면 안 됨\n\n**2. Phantom Read 방지**\n```sql\nSTART TRANSACTION;\nSELECT COUNT(*) FROM orders WHERE status = 'PENDING';\n-- 집계 후 관련 작업 수행\nCOMMIT;\n```\n- 집계와 후속 작업 사이에 새로운 데이터가 삽입되면 안 됨\n\n**3. 읽기 후 쓰기**\n```sql\nSTART TRANSACTION;\nSELECT stock FROM products WHERE id = 1 FOR UPDATE;\n-- 재고 확인 후 주문 처리\nUPDATE products SET stock = stock - 1 WHERE id = 1;\nCOMMIT;\n```\n- 읽은 값을 기반으로 쓰기를 할 때 Lock 필요\n\n**트랜잭션 없이 읽기:**\n- 단순 조회만 하는 경우\n- 데이터 일관성이 중요하지 않은 경우\n- Auto-commit 모드에서 단일 SELECT",
      "type": "essay",
      "tags": ["트랜잭션", "읽기", "격리 수준"]
    },
    {
      "question": "트랜잭션 격리 레벨에 대해 설명해 주세요.",
      "answer": "트랜잭션 격리 레벨은 동시성 제어를 위해 **얼마나 엄격하게 격리할지** 결정합니다.\n\n**4가지 격리 레벨 (낮음 → 높음):**\n\n**1. READ UNCOMMITTED**\n- 커밋되지 않은 데이터 읽기 가능 (Dirty Read)\n- 동시성 최고, 정합성 최저\n- 거의 사용하지 않음\n\n**2. READ COMMITTED** ⭐ (Oracle, PostgreSQL 기본값)\n- 커밋된 데이터만 읽기\n- Dirty Read 방지\n- Non-repeatable Read 발생 가능\n- 실무에서 가장 많이 사용\n\n**3. REPEATABLE READ** ⭐ (MySQL InnoDB 기본값)\n- 트랜잭션 내에서 같은 쿼리는 항상 같은 결과\n- Non-repeatable Read 방지\n- Phantom Read 발생 가능 (MySQL은 MVCC로 방지)\n\n**4. SERIALIZABLE**\n- 완전한 격리, 트랜잭션 순차 실행\n- 모든 이상 현상 방지\n- 동시성 최저, 정합성 최고\n\n**이상 현상:**\n- **Dirty Read**: 커밋 안 된 데이터 읽기\n- **Non-repeatable Read**: 같은 데이터를 다시 읽었을 때 값이 다름\n- **Phantom Read**: 같은 쿼리 재실행 시 행이 추가/삭제됨",
      "type": "essay",
      "tags": ["격리 수준", "트랜잭션", "동시성"]
    },
    {
      "question": "모든 DBMS가 4개의 레벨을 모두 구현하고 있나요? 그렇지 않다면 그 이유는 무엇일까요?",
      "answer": "**아니오**, 모든 DBMS가 4개 레벨을 동일하게 구현하지는 않습니다.\n\n**MySQL InnoDB:**\n- REPEATABLE READ에서 Phantom Read도 방지 (MVCC 덕분)\n- 표준 REPEATABLE READ보다 더 강력\n\n**Oracle:**\n- READ UNCOMMITTED 미지원\n- READ COMMITTED와 SERIALIZABLE만 지원\n- REPEATABLE READ는 SERIALIZABLE로 처리\n\n**PostgreSQL:**\n- READ UNCOMMITTED를 지원하지만 실제로는 READ COMMITTED처럼 동작\n- REPEATABLE READ가 Phantom Read도 방지 (SSI 사용)\n\n**이유:**\n\n1. **구현 메커니즘 차이**\n   - MVCC vs Lock 기반\n   - 각 DBMS의 아키텍처에 따라 구현 방식이 다름\n\n2. **성능 최적화**\n   - 특정 격리 레벨이 해당 DBMS에서 비효율적일 수 있음\n   - 더 나은 대안이 있는 경우 제외\n\n3. **실용성**\n   - READ UNCOMMITTED는 실무에서 거의 사용하지 않음\n   - 지원하지 않아도 문제가 없음\n\n**결론**: 표준은 있지만, 각 DBMS는 자신의 아키텍처에 맞게 최적화된 격리 레벨을 제공합니다.",
      "type": "essay",
      "tags": ["격리 수준", "DBMS", "MVCC"]
    },
    {
      "question": "만약 MySQL을 사용하고 있다면, (InnoDB 기준) Undo 영역과 Redo 영역에 대해 설명해 주세요.",
      "answer": "**Undo 영역 (Undo Log):**\n\n**목적:**\n1. **롤백**: 트랜잭션 실패 시 이전 상태로 복구\n2. **MVCC**: 동시성 제어를 위한 이전 버전 데이터 제공\n\n**동작:**\n- 데이터 변경 전 이전 값을 Undo 로그에 저장\n- 다른 트랜잭션이 변경 전 데이터를 읽을 수 있게 함 (Snapshot)\n- COMMIT 후에도 MVCC를 위해 일정 시간 유지\n- Purge Thread가 주기적으로 정리\n\n**위치:** 시스템 테이블스페이스 또는 Undo 테이블스페이스\n\n---\n\n**Redo 영역 (Redo Log):**\n\n**목적:**\n1. **Durability 보장**: 장애 복구 시 커밋된 트랜잭션 재실행\n2. **성능 향상**: 디스크 쓰기를 순차적으로 처리\n\n**동작:**\n- 데이터 변경 시 Redo 로그에 먼저 기록 (WAL)\n- Circular 방식으로 재사용 (ib_logfile0, ib_logfile1)\n- COMMIT 시 Redo 로그만 디스크에 flush\n- 실제 데이터 파일은 나중에 천천히 기록 (지연 쓰기)\n\n**장애 복구:**\n- Redo 로그를 이용해 커밋된 변경사항 재실행\n- Undo 로그를 이용해 미완료 트랜잭션 롤백\n\n**차이점:**\n- Undo: 변경 **전** 값, 롤백/MVCC용\n- Redo: 변경 **후** 값, 복구용",
      "type": "essay",
      "tags": ["MySQL", "InnoDB", "Undo", "Redo", "WAL"]
    },
    {
      "question": "그런데, 스토리지 엔진이 정확히 무엇을 하는 건가요?",
      "answer": "**스토리지 엔진(Storage Engine):**\n\n데이터베이스에서 **데이터를 물리적으로 저장하고 조회**하는 역할을 담당하는 컴포넌트입니다.\n\n**주요 역할:**\n\n1. **데이터 저장/조회**\n   - 디스크에 데이터를 어떻게 저장할지 결정\n   - INSERT, SELECT, UPDATE, DELETE 처리\n\n2. **인덱스 관리**\n   - B-Tree, Hash 등 인덱스 구조 구현\n   - 인덱스를 통한 빠른 검색\n\n3. **트랜잭션 처리**\n   - ACID 속성 구현 (엔진에 따라 다름)\n   - Lock, MVCC 등 동시성 제어\n\n4. **버퍼 관리**\n   - 메모리 캐시 관리 (Buffer Pool)\n   - 디스크 I/O 최적화\n\n**MySQL 스토리지 엔진 예시:**\n\n**InnoDB** (기본, 권장)\n- 트랜잭션 지원 (ACID)\n- 외래키 지원\n- MVCC 동시성 제어\n- 크래시 복구\n- 클러스터드 인덱스\n\n**MyISAM** (구형, 비권장)\n- 트랜잭션 미지원\n- 테이블 레벨 Lock\n- 빠른 SELECT (단순 조회)\n- 전문 검색(Full-text) 지원\n\n**Memory**\n- 인메모리 저장\n- 임시 테이블용\n- 서버 재시작 시 데이터 손실\n\n**비유:**\n스토리지 엔진은 자동차의 엔진과 같습니다. 같은 차체(MySQL)에 다른 엔진(InnoDB, MyISAM)을 장착할 수 있고, 각 엔진마다 성능과 특성이 다릅니다.",
      "type": "essay",
      "tags": ["스토리지 엔진", "MySQL", "InnoDB", "MyISAM"]
    },
    {
      "question": "인덱스가 무엇이고, 언제 사용하는지 설명해 주세요.",
      "answer": "**인덱스(Index):**\n\n책의 목차처럼 데이터를 빠르게 찾기 위한 **별도의 자료구조**입니다. 주로 B-Tree 구조를 사용합니다.\n\n**동작 원리:**\n```\n인덱스 없이: O(N) - 전체 스캔\n인덱스 사용: O(log N) - 트리 탐색\n```\n\n**언제 사용하나요:**\n\n**1. WHERE 절에 자주 사용되는 컬럼**\n```sql\nSELECT * FROM users WHERE email = 'test@example.com';\n-- email에 인덱스가 있으면 빠름\n```\n\n**2. JOIN 조건에 사용되는 컬럼**\n```sql\nSELECT * FROM orders o JOIN users u ON o.user_id = u.id;\n-- user_id에 인덱스 필요\n```\n\n**3. ORDER BY, GROUP BY에 사용되는 컬럼**\n```sql\nSELECT * FROM products ORDER BY created_at DESC;\n-- created_at에 인덱스가 있으면 정렬 생략 가능\n```\n\n**4. MIN, MAX 등 집계 함수**\n```sql\nSELECT MAX(price) FROM products;\n-- price 인덱스가 있으면 즉시 조회\n```\n\n**인덱스를 사용하지 말아야 할 때:**\n- 테이블 크기가 작을 때 (수백 건 이하)\n- 카디널리티가 낮을 때 (성별, boolean 등)\n- 데이터 변경(INSERT/UPDATE/DELETE)이 매우 빈번할 때\n- 해당 컬럼을 거의 조회하지 않을 때",
      "type": "essay",
      "tags": ["인덱스", "성능", "쿼리 최적화"]
    },
    {
      "question": "일반적으로 인덱스는 수정이 잦은 테이블에선 사용하지 않기를 권합니다. 왜 그럴까요?",
      "answer": "인덱스는 조회 성능은 향상시키지만, **데이터 수정 시 오버헤드**가 발생하기 때문입니다.\n\n**INSERT 시:**\n1. 실제 테이블에 데이터 삽입\n2. 모든 인덱스에도 새로운 항목 추가\n3. B-Tree 리밸런싱 발생 가능\n\n**UPDATE 시:**\n1. 인덱스 컬럼이 변경되면 인덱스에서 삭제 후 재삽입\n2. 여러 인덱스가 있으면 각각 업데이트\n3. 페이지 분할(Page Split) 발생 가능\n\n**DELETE 시:**\n1. 모든 인덱스에서 해당 항목 삭제\n2. 인덱스 재구성\n\n**성능 저하 예시:**\n```sql\n-- 인덱스 5개가 있는 테이블\nINSERT INTO logs (message, level, timestamp, user_id, ip) \nVALUES (...);\n-- 실제로는 6번의 쓰기 발생 (테이블 1 + 인덱스 5)\n```\n\n**해결책:**\n- 꼭 필요한 인덱스만 생성\n- 배치 작업 시 인덱스 임시 삭제 후 재생성\n- 파티셔닝 활용\n- 로그성 데이터는 NoSQL 고려\n\n**결론:**\n인덱스는 **조회:수정 비율**을 고려해서 생성해야 합니다. 조회가 많으면 인덱스 유리, 수정이 많으면 인덱스 불리합니다.",
      "type": "essay",
      "tags": ["인덱스", "성능", "트레이드오프"]
    },
    {
      "question": "앞 꼬리질문에 대해, 그렇다면 인덱스에서 사용하지 않겠다고 선택한 값은 위 정책을 그대로 따라가나요?",
      "answer": "아니오, **커버링 인덱스(Covering Index)**를 사용하면 다릅니다.\n\n**커버링 인덱스란:**\n쿼리에 필요한 모든 컬럼을 인덱스에 포함시켜 테이블 접근 없이 인덱스만으로 쿼리를 처리하는 기법입니다.\n\n**예시:**\n```sql\n-- 인덱스: (user_id, created_at, status)\nCREATE INDEX idx_orders ON orders(user_id, created_at, status);\n\n-- 이 쿼리는 테이블 접근 없이 인덱스만 사용\nSELECT created_at, status \nFROM orders \nWHERE user_id = 123;\n-- → 매우 빠름 (Using index)\n\n-- 이 쿼리는 테이블 접근 필요\nSELECT created_at, status, total_amount \nFROM orders \nWHERE user_id = 123;\n-- → total_amount가 인덱스에 없어서 테이블 조회 필요\n```\n\n**장점:**\n- 디스크 I/O 감소 (테이블 접근 불필요)\n- 매우 빠른 조회 성능\n\n**단점:**\n- 인덱스 크기 증가\n- INSERT/UPDATE 시 오버헤드 증가\n\n**MySQL 실행 계획에서 확인:**\n```sql\nEXPLAIN SELECT ...;\n-- Extra: Using index  → 커버링 인덱스 사용\n-- Extra: Using index condition → 인덱스 + 테이블 조회\n```\n\n**결론:**\n인덱스에 포함된 컬럼은 조회 시 테이블 접근이 필요 없어 매우 빠르지만, 수정 시 오버헤드는 여전히 존재합니다.",
      "type": "essay",
      "tags": ["인덱스", "커버링 인덱스", "쿼리 최적화"]
    },
    {
      "question": "ORDER BY/GROUP BY 연산의 동작 과정을 인덱스의 존재여부와 연관지어서 설명해 주세요.",
      "answer": "**인덱스가 있는 경우:**\n\n**ORDER BY:**\n```sql\n-- created_at에 인덱스가 있는 경우\nSELECT * FROM orders ORDER BY created_at DESC;\n```\n- 인덱스는 이미 정렬되어 있음 (B-Tree 구조)\n- 정렬 과정 생략 (Using index)\n- 매우 빠른 실행\n\n**GROUP BY:**\n```sql\n-- user_id에 인덱스가 있는 경우\nSELECT user_id, COUNT(*) FROM orders GROUP BY user_id;\n```\n- 인덱스가 정렬되어 있어 그룹화가 쉬움\n- 인덱스 스캔만으로 처리 가능\n\n---\n\n**인덱스가 없는 경우:**\n\n**ORDER BY:**\n```sql\nSELECT * FROM orders ORDER BY created_at DESC;\n```\n1. **Full Table Scan**: 모든 행 읽기\n2. **Filesort**: 메모리 또는 디스크에서 정렬\n3. 결과 반환\n\n**Filesort 과정:**\n- 데이터가 sort_buffer_size에 들어가면 메모리 정렬 (빠름)\n- 크면 디스크 임시 파일 사용 (느림)\n- Extra: Using filesort → 성능 저하 신호\n\n**GROUP BY:**\n```sql\nSELECT user_id, COUNT(*) FROM orders GROUP BY user_id;\n```\n1. **Full Table Scan**: 모든 행 읽기\n2. **Temporary Table**: 임시 테이블 생성\n3. **Grouping**: 그룹화 및 집계\n4. Extra: Using temporary; Using filesort\n\n---\n\n**복합 인덱스 활용:**\n```sql\n-- 인덱스: (user_id, created_at)\nSELECT * FROM orders \nWHERE user_id = 123 \nORDER BY created_at DESC;\n-- → 완벽하게 인덱스 활용 (WHERE + ORDER BY)\n\n-- 인덱스: (created_at, user_id)\nSELECT * FROM orders \nWHERE user_id = 123 \nORDER BY created_at DESC;\n-- → 인덱스 일부만 사용, filesort 발생 가능\n```\n\n**결론:**\n- 인덱스 O: 정렬 생략, 빠름\n- 인덱스 X: Filesort/Temporary Table, 느림",
      "type": "essay",
      "tags": ["인덱스", "ORDER BY", "GROUP BY", "Filesort"]
    },
    {
      "question": "기본키는 인덱스라고 할 수 있을까요? 그렇지 않다면, 인덱스와 기본키는 어떤 차이가 있나요?",
      "answer": "**네, 기본키는 자동으로 인덱스입니다.**\n\n기본키를 생성하면 DBMS는 자동으로 **Unique 인덱스**를 생성합니다.\n\n**차이점:**\n\n**기본키 (Primary Key):**\n- **목적**: 각 행을 고유하게 식별\n- **제약조건**: NOT NULL + UNIQUE\n- **개수**: 테이블당 1개만 가능\n- **자동 생성**: 인덱스 자동 생성\n- **클러스터드 인덱스**: MySQL InnoDB에서는 클러스터드 인덱스로 생성 (데이터와 함께 저장)\n- **의미**: 논리적인 개념 (비즈니스 의미)\n\n**인덱스 (Index):**\n- **목적**: 조회 성능 향상\n- **제약조건**: 없음 (NULL 허용 가능)\n- **개수**: 테이블당 여러 개 가능\n- **수동 생성**: 명시적으로 생성 필요\n- **논클러스터드**: 일반적으로 논클러스터드 인덱스 (별도 저장)\n- **의미**: 물리적인 개념 (성능 최적화)\n\n**예시:**\n```sql\n-- 기본키 생성 → 자동으로 인덱스 생성됨\nCREATE TABLE users (\n    id INT PRIMARY KEY,  -- 자동 인덱스\n    email VARCHAR(255) UNIQUE,  -- 자동 인덱스\n    name VARCHAR(100),\n    INDEX idx_name (name)  -- 수동 인덱스\n);\n```\n\n**MySQL에서 확인:**\n```sql\nSHOW INDEX FROM users;\n-- Key_name: PRIMARY → 기본키 인덱스\n-- Key_name: idx_name → 일반 인덱스\n```\n\n**결론:**\n모든 기본키는 인덱스이지만, 모든 인덱스가 기본키는 아닙니다. 기본키는 데이터 무결성을 위한 **논리적 제약**이고, 인덱스는 **물리적 최적화** 수단입니다.",
      "type": "essay",
      "tags": ["기본키", "인덱스", "차이점"]
    },
    {
      "question": "그렇다면 외래키는요?",
      "answer": "**외래키는 자동으로 인덱스가 생성되지 않는 경우가 많습니다.** (DBMS마다 다름)\n\n**DBMS별 차이:**\n\n**MySQL InnoDB:**\n- 외래키 생성 시 **자동으로 인덱스 생성** (없는 경우)\n- 이미 해당 컬럼에 인덱스가 있으면 재사용\n\n```sql\nCREATE TABLE orders (\n    id INT PRIMARY KEY,\n    user_id INT,\n    FOREIGN KEY (user_id) REFERENCES users(id)\n);\n-- user_id에 자동으로 인덱스 생성됨\n```\n\n**PostgreSQL:**\n- 외래키 생성 시 **자동 인덱스 생성 안 됨**\n- 수동으로 인덱스를 생성해야 함\n\n```sql\nCREATE TABLE orders (\n    id INT PRIMARY KEY,\n    user_id INT,\n    FOREIGN KEY (user_id) REFERENCES users(id)\n);\n-- 인덱스 수동 생성 권장\nCREATE INDEX idx_orders_user_id ON orders(user_id);\n```\n\n**Oracle:**\n- 외래키에 자동 인덱스 생성 안 됨\n- 수동 생성 필요\n\n---\n\n**왜 외래키에 인덱스가 필요한가?**\n\n**1. JOIN 성능:**\n```sql\nSELECT * FROM orders o \nJOIN users u ON o.user_id = u.id;\n-- user_id에 인덱스가 없으면 매우 느림\n```\n\n**2. 부모 테이블 삭제 시:**\n```sql\nDELETE FROM users WHERE id = 123;\n-- 자식 테이블(orders)에서 user_id=123인 행 확인\n-- 인덱스 없으면 Full Table Scan\n```\n\n**3. Lock 경합 감소:**\n- 외래키 제약 검사 시 인덱스가 없으면 테이블 Lock 발생 가능\n\n**결론:**\n- MySQL: 외래키 생성 시 자동 인덱스\n- PostgreSQL/Oracle: 수동으로 인덱스 생성 권장\n- **항상 외래키 컬럼에는 인덱스를 생성하는 것이 좋습니다**",
      "type": "essay",
      "tags": ["외래키", "인덱스", "MySQL", "PostgreSQL"]
    },
    {
      "question": "인덱스가 데이터의 물리적 저장에도 영향을 미치나요? 그렇지 않다면, 데이터는 어떤 순서로 물리적으로 저장되나요?",
      "answer": "**클러스터드 인덱스**는 물리적 저장 순서에 영향을 미칩니다.\n\n**클러스터드 인덱스 (Clustered Index):**\n- 테이블당 1개만 존재\n- 데이터가 인덱스 키 순서로 **물리적으로 정렬**되어 저장\n- MySQL InnoDB에서는 **기본키가 클러스터드 인덱스**\n\n```\n기본키 순서: 1, 3, 5, 7, 9\n→ 디스크에도 1, 3, 5, 7, 9 순서로 저장\n```\n\n**장점:**\n- 범위 검색(BETWEEN, >, <)에 매우 빠름\n- ORDER BY 성능 향상\n\n**단점:**\n- INSERT 시 중간 삽입으로 페이지 분할 발생 가능\n- 순차적이지 않은 키(UUID)는 성능 저하\n\n---\n\n**논클러스터드 인덱스 (Non-Clustered Index):**\n- 테이블당 여러 개 가능\n- 별도의 공간에 인덱스 저장\n- 실제 데이터 위치를 가리키는 포인터 저장\n- **데이터의 물리적 저장 순서에 영향 없음**\n\n**MySQL InnoDB:**\n- 기본키: 클러스터드 인덱스\n- 세컨더리 인덱스: 논클러스터드 (기본키 값을 포인터로 사용)\n\n**SQL Server:**\n- 클러스터드/논클러스터드 모두 명시적 선택 가능\n\n**결론:**\n기본키(클러스터드 인덱스)는 물리적 저장 순서를 결정하고, 일반 인덱스는 영향을 주지 않습니다.",
      "type": "essay",
      "tags": ["인덱스", "클러스터드 인덱스", "물리적 저장"]
    },
    {
      "question": "우리가 아는 RDB가 아닌 NoSQL (ex. Redis, MongoDB 등)는 인덱스를 갖고 있나요? 만약 있다면, RDB의 인덱스와는 어떤 차이가 있을까요?",
      "answer": "**네, NoSQL도 인덱스를 가지고 있습니다.** 하지만 구현 방식과 특성이 다릅니다.\n\n**MongoDB:**\n\n**인덱스 타입:**\n- Single Field Index: 단일 필드 인덱스\n- Compound Index: 복합 인덱스\n- Multikey Index: 배열 필드 인덱스\n- Text Index: 전문 검색\n- Geospatial Index: 위치 기반 검색\n- Hashed Index: 해시 기반 샤딩용\n\n```javascript\n// MongoDB 인덱스 생성\ndb.users.createIndex({ email: 1 })  // 오름차순\ndb.users.createIndex({ name: 1, age: -1 })  // 복합\ndb.users.createIndex({ tags: 1 })  // 배열 인덱스\n```\n\n**RDB와의 차이:**\n- 스키마리스 환경에서 동작\n- JSON 문서의 중첩 필드도 인덱싱 가능\n- 배열 요소 각각에 인덱스 생성 가능\n\n---\n\n**Redis:**\n\n**인덱스 방식:**\n- 전통적인 인덱스는 없음\n- **데이터 구조 자체가 인덱스** 역할\n- Sorted Set: O(log N) 검색\n- Hash: O(1) 검색\n- Secondary Index: RediSearch 모듈 사용\n\n```redis\n# Sorted Set을 인덱스처럼 사용\nZADD user:scores 100 \"user:1\"\nZADD user:scores 200 \"user:2\"\nZRANGE user:scores 0 10  # 상위 10명\n```\n\n---\n\n**Cassandra:**\n- Primary Key: 파티션 키 + 클러스터링 키\n- Secondary Index: 글로벌 인덱스 (성능 주의)\n- Materialized View: 인덱스 대체\n\n**주요 차이점:**\n1. **구조**: RDB는 B-Tree, NoSQL은 다양 (Hash, LSM-Tree 등)\n2. **유연성**: NoSQL은 동적 필드 인덱싱 가능\n3. **분산**: NoSQL 인덱스는 샤딩 환경 고려\n4. **트레이드오프**: NoSQL은 일관성보다 성능/확장성 우선",
      "type": "essay",
      "tags": ["NoSQL", "인덱스", "MongoDB", "Redis"]
    },
    {
      "question": "(A, B) 와 같은 방식으로 인덱스를 설정한 테이블에서, A 조건 없이 B 조건만 사용하여 쿼리를 요청했습니다. 해당 쿼리는 인덱스를 탈까요?",
      "answer": "**아니오, 인덱스를 타지 못합니다.** (일반적으로)\n\n**복합 인덱스의 원칙: 최

좌 우선(Leftmost Prefix)**\n\n```sql\n-- 인덱스: (A, B)\nCREATE INDEX idx_ab ON table (A, B);\n```\n\n**인덱스 사용 여부:**\n\n```sql\n-- ✅ 인덱스 사용 (A만)\nSELECT * FROM table WHERE A = 1;\n\n-- ✅ 인덱스 사용 (A, B 모두)\nSELECT * FROM table WHERE A = 1 AND B = 2;\n\n-- ❌ 인덱스 사용 불가 (B만)\nSELECT * FROM table WHERE B = 2;\n-- → Full Table Scan\n\n-- ✅ 인덱스 부분 사용 (A만 사용, B는 필터)\nSELECT * FROM table WHERE A = 1 AND B > 2;\n```\n\n**이유:**\n\n복합 인덱스 (A, B)는 내부적으로 **A로 먼저 정렬, 같은 A 내에서 B로 정렬**됩니다.\n\n```\n인덱스 구조:\n(A=1, B=1) → (A=1, B=2) → (A=1, B=3)\n(A=2, B=1) → (A=2, B=5) → (A=2, B=9)\n(A=3, B=2) → (A=3, B=4)\n```\n\nB=2를 찾으려면:\n- A 값이 없으면 모든 A를 스캔해야 함\n- 인덱스의 의미가 없음\n\n**해결책:**\n\n1. **인덱스 순서 변경:**\n```sql\nCREATE INDEX idx_ba ON table (B, A);\n-- B만 검색하는 쿼리가 많다면\n```\n\n2. **별도 인덱스 추가:**\n```sql\nCREATE INDEX idx_b ON table (B);\n```\n\n3. **Index Skip Scan** (Oracle, MySQL 8.0.13+):\n- 일부 DBMS는 최적화로 인덱스를 부분적으로 활용\n- 하지만 성능은 Full Table Scan에 가까움\n\n**결론:**\n복합 인덱스는 **왼쪽부터 순서대로** 사용해야 효과적입니다.",
      "type": "essay",
      "tags": ["복합 인덱스", "Leftmost Prefix", "쿼리 최적화"]
    },
    {
      "question": "RDBMS, NoSQL에서의 클러스터링/레플리케이션 방식에 대해 설명해 주세요.",
      "answer": "**레플리케이션 (Replication):**\n\n데이터를 **여러 서버에 복사**하여 가용성과 읽기 성능을 향상시키는 기법입니다.\n\n**RDBMS (MySQL 예시):**\n\n**Master-Slave 구조:**\n- Master: 쓰기 작업 담당\n- Slave: Master 데이터 복제, 읽기 작업 담당\n- Binary Log를 통한 비동기 복제\n\n**장점:**\n- 읽기 성능 향상 (Load Balancing)\n- 장애 복구 (Failover)\n\n**단점:**\n- 쓰기는 Master만 가능 (확장 한계)\n- 복제 지연(Replication Lag) 발생 가능\n\n**NoSQL (MongoDB 예시):**\n\n**Replica Set:**\n- Primary: 쓰기 담당\n- Secondary: 복제본, 읽기 가능\n- 자동 Failover (Primary 장애 시 Secondary가 승격)\n\n```javascript\n// Read Preference 설정\ndb.collection.find().readPref('secondary')\n```\n\n---\n\n**클러스터링 / 샤딩 (Sharding):**\n\n데이터를 **여러 서버에 분산 저장**하여 쓰기 성능과 저장 용량을 확장하는 기법입니다.\n\n**RDBMS:**\n\n**수평 분할(Horizontal Partitioning / Sharding):**\n```sql\n-- User ID 기준으로 분할\nShard 1: user_id 1-1000000\nShard 2: user_id 1000001-2000000\nShard 3: user_id 2000001-3000000\n```\n\n**어려운 점:**\n- 수동 구현 필요 (애플리케이션 레벨)\n- JOIN이 어려움 (여러 샤드에 걸친 쿼리)\n- 트랜잭션 복잡\n\n**NoSQL (MongoDB):**\n\n**자동 샤딩:**\n- Shard Key 기반 자동 분산\n- Config Server가 메타데이터 관리\n- Mongos가 라우팅\n\n```javascript\n// Shard Key 설정\nsh.shardCollection(\"mydb.users\", { \"user_id\": 1 })\n```\n\n**장점:**\n- 자동 데이터 분산\n- 쉬운 확장 (서버 추가)\n\n**결론:**\n- **레플리케이션**: 읽기 성능, 가용성 향상\n- **샤딩**: 쓰기 성능, 저장 용량 확장\n- **조합 사용**: 각 샤드를 레플리케이션",
      "type": "essay",
      "tags": ["레플리케이션", "샤딩", "클러스터링", "분산 시스템"]
    },
    {
      "question": "분산 환경에선, 트랜잭션을 어떻게 관리할 수 있을까요?",
      "answer": "분산 환경에서는 **2PC, Saga, TCC** 등의 패턴을 사용합니다.\n\n**1. 2PC (Two-Phase Commit)**\n\n**단계:**\n1. **Prepare Phase**: 모든 참여자에게 커밋 가능 여부 확인\n2. **Commit Phase**: 모두 OK면 커밋, 하나라도 NO면 롤백\n\n**장점:**\n- ACID 보장\n- 강한 일관성\n\n**단점:**\n- Coordinator 장애 시 블로킹\n- 성능 저하 (동기 방식)\n- 확장성 제한\n\n---\n\n**2. Saga Pattern** ⭐ (마이크로서비스에서 많이 사용)\n\n**핵심 개념:**\n- 여러 개의 로컬 트랜잭션으로 분리\n- 각 단계마다 **보상 트랜잭션(Compensating Transaction)** 정의\n- 실패 시 역순으로 보상 트랜잭션 실행\n\n**예시: 주문 프로세스**\n```\n1. 주문 생성 → [보상: 주문 취소]\n2. 결제 처리 → [보상: 결제 환불]\n3. 재고 차감 → [보상: 재고 복구]\n4. 배송 시작 → [보상: 배송 취소]\n```\n\n**구현 방식:**\n\n**Choreography (이벤트 기반):**\n```java\n// 주문 서비스\norderCreated → publishEvent(\"OrderCreated\")\n\n// 결제 서비스\nonEvent(\"OrderCreated\") → processPayment()\npaymentSuccess → publishEvent(\"PaymentCompleted\")\n\n// 재고 서비스  \nonEvent(\"PaymentCompleted\") → decreaseStock()\n```\n\n**Orchestration (중앙 조정):**\n```java\n// Saga Orchestrator\npublic class OrderSaga {\n    execute() {\n        createOrder();\n        try {\n            processPayment();\n            decreaseStock();\n            startDelivery();\n        } catch (Exception e) {\n            // 보상 트랜잭션 실행\n            rollbackDelivery();\n            rollbackStock();\n            rollbackPayment();\n            rollbackOrder();\n        }\n    }\n}\n```\n\n**장점:**\n- 높은 확장성\n- 각 서비스 독립적\n\n**단점:**\n- 일시적 불일치 허용\n- 복잡한 구현\n\n---\n\n**3. TCC (Try-Confirm-Cancel)**\n\n**단계:**\n1. **Try**: 리소스 예약\n2. **Confirm**: 최종 확정\n3. **Cancel**: 취소/롤백\n\n**결론:**\n- 강한 일관성 필요: 2PC\n- 확장성 중요: Saga\n- 마이크로서비스: Saga Pattern이 대세",
      "type": "essay",
      "tags": ["분산 트랜잭션", "Saga", "2PC", "마이크로서비스"]
    },
    {
      "question": "슬레이브 데이터 동기화 전 까지의 데이터 정합성을 지키는 방법은 무엇이 있을까요?",
      "answer": "**레플리케이션 지연(Replication Lag)** 문제를 해결하는 방법들입니다.\n\n**문제 상황:**\n```java\n// Master에 쓰기\ninsertUser(user);\n\n// 즉시 Slave에서 읽기\nUser user = selectUser(userId);  // NULL! (아직 복제 안 됨)\n```\n\n---\n\n**해결 방법:**\n\n**1. Read Your Writes (자신이 쓴 데이터는 읽기 보장)**\n\n```java\n// 쓰기 직후에는 Master에서 읽기\npublic User createAndGetUser(User user) {\n    masterDB.insert(user);  // Master 쓰기\n    return masterDB.select(user.getId());  // Master 읽기\n}\n\n// 시간이 지난 후에는 Slave 읽기\npublic User getUser(Long userId) {\n    return slaveDB.select(userId);  // Slave 읽기\n}\n```\n\n**2. Session Sticky (세션 고정)**\n\n```java\n// 같은 사용자는 항상 같은 Slave로 라우팅\nString slaveKey = userId % slaveCount;\nreturn slaves.get(slaveKey).select(userId);\n```\n\n**3. Semi-Synchronous Replication (준동기 복제)**\n\n```sql\n-- MySQL 설정\nSET GLOBAL rpl_semi_sync_master_enabled = 1;\n```\n\n- Master는 최소 1개의 Slave가 받았음을 확인 후 COMMIT\n- 성능은 떨어지지만 데이터 정합성 향상\n\n**4. 버전/타임스탬프 확인**\n\n```java\n// Master 쓰기 후 버전 반환\nlong version = masterDB.insert(user);\n\n// Slave에서 읽을 때 버전 확인\nwhile (true) {\n    User user = slaveDB.select(userId);\n    if (user.getVersion() >= version) {\n        return user;  // 복제 완료\n    }\n    Thread.sleep(100);  // 재시도\n}\n```\n\n**5. 중요한 쿼리는 Master에서**\n\n```java\n@Transactional(readOnly = false)  // Master\npublic void updateBalance(Long userId, BigDecimal amount) {\n    // 잔액 조회도 Master에서\n    Balance balance = masterDB.getBalance(userId);\n    balance.add(amount);\n    masterDB.update(balance);\n}\n\n@Transactional(readOnly = true)  // Slave\npublic List<Order> getOrderHistory(Long userId) {\n    return slaveDB.getOrders(userId);\n}\n```\n\n**6. 애플리케이션 레벨 캐시**\n\n```java\n// Redis 등에 쓰기 즉시 캐시\nmasterDB.insert(user);\nredis.set(\"user:\" + userId, user, 60);  // 1분 캐시\n\n// 읽기는 캐시 우선\nUser user = redis.get(\"user:\" + userId);\nif (user == null) {\n    user = slaveDB.select(userId);\n}\n```\n\n**결론:**\n- 쓰기 직후 읽기: Master 사용\n- 중요 트랜잭션: Master 사용\n- 일반 읽기: Slave 사용\n- 캐시 활용",
      "type": "essay",
      "tags": ["레플리케이션", "정합성", "Replication Lag", "Master-Slave"]
    },
    {
      "question": "트랜잭션 상황에서의 Deadlock 상황과, 이를 해결하기 위한 방법에 대해 설명해 주세요.",
      "answer": "**Deadlock (교착 상태):**\n\n두 개 이상의 트랜잭션이 서로가 보유한 Lock을 기다리며 무한 대기하는 상황입니다.\n\n**발생 예시:**\n\n```sql\n-- Transaction 1\nSTART TRANSACTION;\nUPDATE accounts SET balance = balance - 100 WHERE id = 1;  -- Lock A\n-- 대기...\nUPDATE accounts SET balance = balance + 100 WHERE id = 2;  -- Lock B 대기\n\n-- Transaction 2\nSTART TRANSACTION;\nUPDATE accounts SET balance = balance - 50 WHERE id = 2;   -- Lock B\n-- 대기...\nUPDATE accounts SET balance = balance + 50 WHERE id = 1;   -- Lock A 대기\n\n-- Deadlock 발생!\n```\n\n**교착 상태 조건 (4가지 모두 만족 시 발생):**\n1. **Mutual Exclusion**: 자원을 독점적으로 사용\n2. **Hold and Wait**: 자원을 보유한 채 다른 자원 대기\n3. **No Preemption**: 강제로 자원을 빼앗을 수 없음\n4. **Circular Wait**: 순환 대기 발생\n\n---\n\n**해결 방법:**\n\n**1. 데드락 방지 (Prevention)**\n\n**Lock 순서 통일:**\n```java\n// ❌ 나쁜 예 - 순서가 다름\nvoid transfer1() {\n    lock(accountA);  // A → B\n    lock(accountB);\n}\n\nvoid transfer2() {\n    lock(accountB);  // B → A (Deadlock!)\n    lock(accountA);\n}\n\n// ✅ 좋은 예 - 항상 ID 작은 것부터\nvoid transfer(Account from, Account to) {\n    Account first = from.id < to.id ? from : to;\n    Account second = from.id < to.id ? to : from;\n    \n    lock(first);\n    lock(second);\n    // 처리\n    unlock(second);\n    unlock(first);\n}\n```\n\n**타임아웃 설정:**\n```sql\n-- MySQL\nSET innodb_lock_wait_timeout = 50;  -- 50초 후 타임아웃\n\n-- PostgreSQL\nSET lock_timeout = '5s';\n```\n\n**2. 데드락 회피 (Avoidance)**\n\n**낙관적 락 (Optimistic Lock):**\n```sql\n-- 버전 기반\nUPDATE accounts \nSET balance = balance - 100, version = version + 1\nWHERE id = 1 AND version = 5;\n-- 영향받은 행이 0이면 재시도\n```\n\n**3. 데드락 탐지 및 복구 (Detection & Recovery)**\n\n**DBMS 자동 탐지:**\n- MySQL은 데드락을 자동으로 감지\n- 하나의 트랜잭션을 롤백 (보통 더 적은 작업을 한 쪽)\n\n```sql\n-- 데드락 정보 확인\nSHOW ENGINE INNODB STATUS;\n\n-- 데드락 로그\n------------------------\nLATEST DETECTED DEADLOCK\n------------------------\n```\n\n**애플리케이션 레벨 재시도:**\n```java\n@Retryable(value = DeadlockLoserDataAccessException.class, \n           maxAttempts = 3)\npublic void transfer(Long fromId, Long toId, BigDecimal amount) {\n    // 트랜잭션 로직\n}\n```\n\n**4. 트랜잭션 최소화**\n\n```java\n// ❌ 나쁜 예 - 긴 트랜잭션\n@Transactional\npublic void processOrder() {\n    calculatePrice();  // 오래 걸림\n    validateStock();   // 오래 걸림\n    updateDB();        // Lock 오래 유지\n}\n\n// ✅ 좋은 예 - 짧은 트랜잭션\npublic void processOrder() {\n    BigDecimal price = calculatePrice();  // 트랜잭션 밖\n    boolean valid = validateStock();       // 트랜잭션 밖\n    \n    updateDBWithTransaction(price);  // 최소한만 트랜잭션\n}\n```\n\n**결론:**\n- Lock 순서 통일이 가장 효과적\n- 트랜잭션을 짧게 유지\n- 타임아웃과 재시도 메커니즘 구현",
      "type": "essay",
      "tags": ["Deadlock", "교착상태", "Lock", "트랜잭션"]
    },
    {
      "question": "방식은 무엇인가요? 만약 본인이 DB를 분산해서 관리해야 한다면, 레플리케이션 방식과 샤딩 방식 중 어떤 것을 사용할 것 같나요?",
      "answer": "**레플리케이션 vs 샤딩 비교:**\n\n**레플리케이션 (Replication):**\n\n**특징:**\n- 같은 데이터를 여러 서버에 복사\n- Master-Slave 구조\n- 읽기 성능 향상 (Slave 추가)\n- 가용성 향상 (Failover)\n\n**장점:**\n- 구현이 비교적 간단\n- 읽기 부하 분산\n- 데이터 백업 효과\n\n**단점:**\n- 쓰기는 Master만 (쓰기 확장 불가)\n- 모든 서버가 전체 데이터 보유 (저장 용량 문제)\n- 복제 지연 발생 가능\n\n**사용 사례:**\n- 읽기가 많고 쓰기가 적은 서비스\n- 뉴스, 블로그, 검색\n\n---\n\n**샤딩 (Sharding):**\n\n**특징:**\n- 데이터를 여러 서버에 분산 저장\n- 각 서버가 데이터의 일부만 보유\n- 쓰기/읽기 모두 분산\n\n**장점:**\n- 쓰기 성능 확장 가능\n- 저장 용량 확장\n- 진정한 수평 확장\n\n**단점:**\n- 구현 복잡\n- JOIN 어려움\n- 트랜잭션 복잡\n- 샤드 키 선택이 중요\n\n**사용 사례:**\n- 대용량 쓰기가 발생하는 서비스\n- SNS, IoT 로그, 게임\n\n---\n\n**선택 기준:**\n\n```java\n// 읽기:쓰기 = 9:1 (읽기 중심)\nif (readHeavy && writeLight) {\n    return \"레플리케이션\";\n}\n\n// 읽기:쓰기 = 5:5 (쓰기도 많음)\nif (writeHeavy || dataSize > serverCapacity) {\n    return \"샤딩\";\n}\n\n// 최고 성능 필요\nif (needMaxPerformance) {\n    return \"샤딩 + 레플리케이션 조합\";\n}\n```\n\n**조합 사용 (샤딩 + 레플리케이션):**\n```\nShard 1: Master + Slave1 + Slave2\nShard 2: Master + Slave1 + Slave2  \nShard 3: Master + Slave1 + Slave2\n```\n\n**결론:**\n- 읽기 중심: 레플리케이션\n- 쓰기 중심/대용량: 샤딩\n- 실무에서는 둘을 조합하여 사용",
      "type": "essay",
      "tags": ["레플리케이션", "샤딩", "분산 시스템", "확장성"]
    },
    {
      "question": "정규화가 무엇인가요?",
      "answer": "**정규화(Normalization):**\n\n데이터베이스 설계 시 **중복을 최소화**하고 **데이터 무결성**을 유지하기 위해 테이블을 분리하는 과정입니다.\n\n**목적:**\n1. 데이터 중복 제거\n2. 이상 현상(Anomaly) 방지\n3. 데이터 일관성 유지\n4. 저장 공간 절약\n\n**정규화 단계:**\n\n**제1정규형 (1NF):**\n- 모든 속성이 **원자값**(Atomic Value)을 가져야 함\n- 반복 그룹 제거\n\n```sql\n-- ❌ 1NF 위반\nCREATE TABLE students (\n    id INT,\n    name VARCHAR(100),\n    hobbies VARCHAR(200)  -- '독서, 영화, 운동' (원자값 아님)\n);\n\n-- ✅ 1NF 만족\nCREATE TABLE students (\n    id INT,\n    name VARCHAR(100)\n);\n\nCREATE TABLE student_hobbies (\n    student_id INT,\n    hobby VARCHAR(100)\n);\n```\n\n**제2정규형 (2NF):**\n- 1NF 만족 + **부분 함수 종속 제거**\n- 기본키의 일부에만 종속된 속성 제거\n\n**제3정규형 (3NF):**\n- 2NF 만족 + **이행적 함수 종속 제거**\n- 기본키가 아닌 속성에 종속된 속성 제거\n\n**BCNF (Boyce-Codd Normal Form):**\n- 3NF의 강화 버전\n- 모든 결정자가 후보키여야 함\n\n**실무에서:**\n- 보통 3NF까지만 진행\n- BCNF는 특수한 경우에만\n- 성능을 위해 의도적으로 역정규화하기도 함",
      "type": "essay",
      "tags": ["정규화", "데이터베이스 설계", "1NF", "2NF", "3NF"]
    },
    {
      "question": "정규화를 하지 않을 경우, 발생할 수 있는 이상현상에 대해 설명해 주세요.",
      "answer": "정규화를 하지 않으면 **데이터 이상(Anomaly)** 현상이 발생합니다.\n\n**비정규화 테이블 예시:**\n\n```sql\nCREATE TABLE orders (\n    order_id INT,\n    product_name VARCHAR(100),\n    price DECIMAL(10,2),\n    customer_name VARCHAR(100),\n    customer_address VARCHAR(200)\n);\n\n-- 데이터\n| order_id | product_name | price | customer_name | customer_address |\n|----------|--------------|-------|---------------|------------------|\n| 1        | 노트북       | 1000  | 홍길동        | 서울시 강남구    |\n| 2        | 마우스       | 30    | 홍길동        | 서울시 강남구    |\n| 3        | 키보드       | 50    | 김철수        | 부산시 해운대구  |\n```\n\n---\n\n**1. 삽입 이상 (Insertion Anomaly)**\n\n신규 고객 정보를 저장하려고 하는데, 주문이 없으면 저장할 수 없습니다.\n\n```sql\n-- 주문 없이 고객만 등록 불가\nINSERT INTO orders (customer_name, customer_address) \nVALUES ('이영희', '대구시 수성구');\n-- order_id와 product_name이 NULL이 됨 (의미 없는 데이터)\n```\n\n---\n\n**2. 삭제 이상 (Deletion Anomaly)**\n\n주문을 삭제하면 고객 정보까지 함께 삭제됩니다.\n\n```sql\n-- 김철수의 주문(order_id=3)을 삭제\nDELETE FROM orders WHERE order_id = 3;\n-- 김철수의 고객 정보까지 삭제됨!\n```\n\n---\n\n**3. 갱신 이상 (Update Anomaly)**\n\n고객 주소를 변경할 때 여러 행을 모두 수정해야 하고, 일부만 수정하면 데이터 불일치가 발생합니다.\n\n```sql\n-- 홍길동의 주소를 변경\nUPDATE orders \nSET customer_address = '서울시 서초구' \nWHERE customer_name = '홍길동';\n\n-- 만약 일부만 수정되면?\n| order_id | customer_name | customer_address |\n|----------|---------------|------------------|\n| 1        | 홍길동        | 서울시 서초구    |  ← 수정됨\n| 2        | 홍길동        | 서울시 강남구    |  ← 수정 안 됨 (불일치!)\n```\n\n---\n\n**정규화로 해결:**\n\n```sql\n-- 고객 테이블\nCREATE TABLE customers (\n    customer_id INT PRIMARY KEY,\n    name VARCHAR(100),\n    address VARCHAR(200)\n);\n\n-- 주문 테이블\nCREATE TABLE orders (\n    order_id INT PRIMARY KEY,\n    customer_id INT,\n    product_name VARCHAR(100),\n    price DECIMAL(10,2),\n    FOREIGN KEY (customer_id) REFERENCES customers(customer_id)\n);\n```\n\n**결과:**\n- 삽입 이상: 고객을 주문 없이 등록 가능\n- 삭제 이상: 주문 삭제해도 고객 정보 유지\n- 갱신 이상: 고객 주소는 한 곳만 수정하면 됨",
      "type": "essay",
      "tags": ["정규화", "이상현상", "Anomaly", "데이터 무결성"]
    },
    {
      "question": "각 정규화에 대해, 그 정규화가 진행되기 전/후의 테이블의 변화에 대해 설명해 주세요.",
      "answer": "**제1정규형 (1NF): 원자값 만족**\n\n**변화 전:**\n```sql\nCREATE TABLE students (\n    student_id INT,\n    name VARCHAR(100),\n    phone VARCHAR(200)  -- '010-1111-1111, 010-2222-2222'\n);\n\n| student_id | name   | phone                          |\n|------------|--------|--------------------------------|\n| 1          | 홍길동 | 010-1111-1111, 010-2222-2222  |\n```\n\n**문제:** 전화번호가 원자값이 아님 (여러 값 포함)\n\n**변화 후:**\n```sql\nCREATE TABLE students (\n    student_id INT,\n    name VARCHAR(100)\n);\n\nCREATE TABLE student_phones (\n    student_id INT,\n    phone VARCHAR(20),\n    PRIMARY KEY (student_id, phone)\n);\n\n-- students 테이블\n| student_id | name   |\n|------------|--------|\n| 1          | 홍길동 |\n\n-- student_phones 테이블\n| student_id | phone         |\n|------------|---------------|\n| 1          | 010-1111-1111 |\n| 1          | 010-2222-2222 |\n```\n\n---\n\n**제2정규형 (2NF): 부분 함수 종속 제거**\n\n**변화 전:**\n```sql\nCREATE TABLE order_details (\n    order_id INT,\n    product_id INT,\n    product_name VARCHAR(100),  -- product_id에만 종속\n    product_price DECIMAL(10,2), -- product_id에만 종속\n    quantity INT,\n    PRIMARY KEY (order_id, product_id)\n);\n\n| order_id | product_id | product_name | product_price | quantity |\n|----------|------------|--------------|---------------|---------|\n| 1        | 101        | 노트북       | 1000          | 2       |\n| 1        | 102        | 마우스       | 30            | 1       |\n| 2        | 101        | 노트북       | 1000          | 1       |\n```\n\n**문제:** product_name, product_price는 (order_id, product_id) 전체가 아닌 product_id에만 종속\n\n**변화 후:**\n```sql\n-- 상품 테이블\nCREATE TABLE products (\n    product_id INT PRIMARY KEY,\n    product_name VARCHAR(100),\n    price DECIMAL(10,2)\n);\n\n-- 주문 상세 테이블\nCREATE TABLE order_details (\n    order_id INT,\n    product_id INT,\n    quantity INT,\n    PRIMARY KEY (order_id, product_id),\n    FOREIGN KEY (product_id) REFERENCES products(product_id)\n);\n\n-- products 테이블\n| product_id | product_name | price |\n|------------|--------------|-------|\n| 101        | 노트북       | 1000  |\n| 102        | 마우스       | 30    |\n\n-- order_details 테이블\n| order_id | product_id | quantity |\n|----------|------------|---------|\n| 1        | 101        | 2       |\n| 1        | 102        | 1       |\n| 2        | 101        | 1       |\n```\n\n---\n\n**제3정규형 (3NF): 이행적 함수 종속 제거**\n\n**변화 전:**\n```sql\nCREATE TABLE employees (\n    emp_id INT PRIMARY KEY,\n    emp_name VARCHAR(100),\n    dept_id INT,\n    dept_name VARCHAR(100),  -- dept_id를 통해 emp_id에 이행적 종속\n    dept_location VARCHAR(100) -- dept_id를 통해 emp_id에 이행적 종속\n);\n\n| emp_id | emp_name | dept_id | dept_name | dept_location |\n|--------|----------|---------|-----------|---------------|\n| 1      | 홍길동   | 10      | 개발팀    | 3층           |\n| 2      | 김철수   | 10      | 개발팀    | 3층           |\n| 3      | 이영희   | 20      | 마케팅팀  | 2층           |\n```\n\n**문제:** \n- emp_id → dept_id → dept_name (이행적 종속)\n- emp_id → dept_id → dept_location (이행적 종속)\n\n**변화 후:**\n```sql\n-- 부서 테이블\nCREATE TABLE departments (\n    dept_id INT PRIMARY KEY,\n    dept_name VARCHAR(100),\n    location VARCHAR(100)\n);\n\n-- 직원 테이블\nCREATE TABLE employees (\n    emp_id INT PRIMARY KEY,\n    emp_name VARCHAR(100),\n    dept_id INT,\n    FOREIGN KEY (dept_id) REFERENCES departments(dept_id)\n);\n\n-- departments 테이블\n| dept_id | dept_name | location |\n|---------|-----------|----------|\n| 10      | 개발팀    | 3층      |\n| 20      | 마케팅팀  | 2층      |\n\n-- employees 테이블\n| emp_id | emp_name | dept_id |\n|--------|----------|---------|\n| 1      | 홍길동   | 10      |\n| 2      | 김철수   | 10      |\n| 3      | 이영희   | 20      |\n```\n\n**효과:**\n- 중복 제거: 부서 정보가 한 곳에만 존재\n- 갱신 이상 방지: 부서명 변경 시 한 곳만 수정\n- 데이터 일관성 향상",
      "type": "essay",
      "tags": ["정규화", "1NF", "2NF", "3NF", "테이블 설계"]
    },
    {
      "question": "정규화가 무조건 좋은가요? 그렇지 않다면, 어떤 상황에서 역정규화를 하는게 좋은지 설명해 주세요.",
      "answer": "**아니오**, 정규화가 항상 좋은 것은 아닙니다.\n\n**정규화의 단점:**\n\n**1. 조인 성능 저하**\n```sql\n-- 정규화된 테이블 (3개 조인 필요)\nSELECT e.emp_name, d.dept_name, c.city_name\nFROM employees e\nJOIN departments d ON e.dept_id = d.dept_id\nJOIN cities c ON d.city_id = c.city_id\nWHERE e.emp_id = 1;\n-- 3개 테이블 조인 → 느림\n```\n\n**2. 쿼리 복잡도 증가**\n- 여러 테이블을 조인해야 원하는 데이터 조회\n- 개발 복잡도 증가\n\n**3. 읽기 성능 저하**\n- 디스크 I/O 증가\n- 인덱스 탐색 횟수 증가\n\n---\n\n**역정규화(Denormalization)가 필요한 경우:**\n\n**1. 조회 성능이 중요한 경우**\n\n```sql\n-- ❌ 정규화 (매번 조인)\nSELECT o.order_id, c.name, c.email, c.address\nFROM orders o\nJOIN customers c ON o.customer_id = c.customer_id;\n\n-- ✅ 역정규화 (조인 없이 바로 조회)\nCREATE TABLE orders (\n    order_id INT,\n    customer_id INT,\n    customer_name VARCHAR(100),  -- 중복 저장\n    customer_email VARCHAR(100), -- 중복 저장\n    product_name VARCHAR(100)\n);\n\nSELECT * FROM orders WHERE order_id = 1;\n-- 조인 없이 바로 조회 → 빠름\n```\n\n**2. 읽기:쓰기 비율이 높은 경우**\n\n```\n읽기 1000번 : 쓰기 1번\n→ 조인 1000번보다 중복 데이터 갱신 1번이 낫다\n```\n\n**3. 집계 쿼리가 빈번한 경우**\n\n```sql\n-- 정규화: 매번 집계\nSELECT user_id, COUNT(*) as order_count, SUM(total) as total_amount\nFROM orders\nGROUP BY user_id;\n\n-- 역정규화: 미리 계산된 값 저장\nCREATE TABLE users (\n    user_id INT,\n    name VARCHAR(100),\n    total_orders INT,      -- 미리 계산\n    total_amount DECIMAL   -- 미리 계산\n);\n\nSELECT total_orders, total_amount FROM users WHERE user_id = 1;\n-- 즉시 조회, 집계 불필요\n```\n\n**4. 이력성 데이터 보존**\n\n```sql\n-- 주문 당시의 상품 가격 저장 (나중에 상품 가격이 변경되어도 주문 시점 가격 유지)\nCREATE TABLE orders (\n    order_id INT,\n    product_id INT,\n    product_name VARCHAR(100),  -- 주문 당시 이름\n    price DECIMAL(10,2)         -- 주문 당시 가격 (역정규화)\n);\n```\n\n**5. 캐시 테이블**\n\n```sql\n-- 복잡한 집계를 미리 계산해서 저장\nCREATE TABLE daily_sales_summary (\n    sale_date DATE,\n    total_sales DECIMAL,\n    order_count INT,\n    avg_order_value DECIMAL\n);\n-- 매일 배치로 갱신\n```\n\n---\n\n**역정규화 시 주의사항:**\n\n**1. 데이터 동기화**\n```java\n// 고객 정보 변경 시 주문 테이블도 함께 갱신\n@Transactional\npublic void updateCustomer(Customer customer) {\n    customerRepository.update(customer);\n    orderRepository.updateCustomerInfo(customer);  // 역정규화된 데이터 갱신\n}\n```\n\n**2. 저장 공간 증가**\n- 중복 데이터로 인한 디스크 사용량 증가\n\n**3. 갱신 비용 증가**\n- 여러 곳의 중복 데이터를 모두 갱신해야 함\n\n---\n\n**결론:**\n\n| 상황 | 선택 |\n|------|------|\n| 데이터 무결성 중요 | 정규화 |\n| 조회 성능 중요, 읽기 많음 | 역정규화 |\n| 트랜잭션 많음 | 정규화 |\n| 분석/리포팅 위주 | 역정규화 |\n\n**실무에서는 적절한 균형을 찾는 것이 중요합니다.**",
      "type": "essay",
      "tags": ["역정규화", "정규화", "성능 최적화", "트레이드오프"]
    },
    {
      "question": "View가 무엇이고, 언제 사용할 수 있나요?",
      "answer": "**View (뷰):**\n\n하나 이상의 테이블로부터 유도된 **가상 테이블**입니다. 실제 데이터를 저장하지 않고, SELECT 쿼리만 저장합니다.\n\n**생성 예시:**\n```sql\n-- 복잡한 조인을 View로 만들기\nCREATE VIEW employee_details AS\nSELECT \n    e.emp_id,\n    e.emp_name,\n    e.salary,\n    d.dept_name,\n    d.location\nFROM employees e\nJOIN departments d ON e.dept_id = d.dept_id;\n\n-- 사용\nSELECT * FROM employee_details WHERE emp_id = 1;\n-- 실제로는 조인 쿼리가 실행됨\n```\n\n---\n\n**언제 사용하나요:**\n\n**1. 복잡한 쿼리 단순화**\n\n```sql\n-- 매번 복잡한 쿼리를 작성하는 대신\nSELECT u.name, COUNT(o.order_id) as order_count\nFROM users u\nLEFT JOIN orders o ON u.user_id = o.user_id\nWHERE o.status = 'completed'\nGROUP BY u.user_id;\n\n-- View로 만들어서 간단히\nCREATE VIEW user_order_stats AS\nSELECT u.user_id, u.name, COUNT(o.order_id) as order_count\nFROM users u\nLEFT JOIN orders o ON u.user_id = o.user_id\nWHERE o.status = 'completed'\nGROUP BY u.user_id;\n\nSELECT * FROM user_order_stats;\n```\n\n**2. 보안 및 접근 제어**\n\n```sql\n-- 민감한 정보를 숨긴 View\nCREATE VIEW public_employees AS\nSELECT \n    emp_id,\n    emp_name,\n    dept_id\n    -- salary, ssn 등 민감 정보 제외\nFROM employees;\n\n-- 외부 사용자에게는 View만 접근 권한 부여\nGRANT SELECT ON public_employees TO external_user;\n```\n\n**3. 논리적 데이터 독립성**\n\n```sql\n-- 테이블 구조가 변경되어도 View는 그대로 유지\nCREATE VIEW customer_info AS\nSELECT \n    customer_id,\n    CONCAT(first_name, ' ', last_name) as full_name,  -- 2개 컬럼을 합침\n    email\nFROM customers;\n\n-- 애플리케이션은 View를 사용\n-- 테이블 구조가 바뀌어도 View만 수정하면 됨\n```\n\n**4. 특정 데이터만 표시**\n\n```sql\n-- 활성 사용자만 보이는 View\nCREATE VIEW active_users AS\nSELECT * FROM users\nWHERE status = 'active' AND deleted_at IS NULL;\n\nSELECT * FROM active_users;\n-- 자동으로 활성 사용자만 조회\n```\n\n**5. 다양한 관점 제공**\n\n```sql\n-- 부서별 통계 View\nCREATE VIEW dept_statistics AS\nSELECT \n    d.dept_id,\n    d.dept_name,\n    COUNT(e.emp_id) as emp_count,\n    AVG(e.salary) as avg_salary\nFROM departments d\nLEFT JOIN employees e ON d.dept_id = e.dept_id\nGROUP BY d.dept_id;\n```\n\n---\n\n**View의 장점:**\n1. 쿼리 재사용성\n2. 데이터 보안\n3. 복잡성 감소\n4. 논리적 독립성\n\n**View의 단점:**\n1. 성능 저하 가능 (복잡한 View)\n2. 인덱스 사용 제한\n3. 수정 제약 (일부 View는 UPDATE 불가)\n\n**Materialized View (실체화된 뷰):**\n```sql\n-- PostgreSQL\nCREATE MATERIALIZED VIEW sales_summary AS\nSELECT product_id, SUM(amount) as total_sales\nFROM sales\nGROUP BY product_id;\n\n-- 실제 데이터를 저장하므로 빠름\n-- 주기적으로 갱신 필요\nREFRESH MATERIALIZED VIEW sales_summary;\n```\n\n**결론:**\nView는 복잡한 쿼리를 단순화하고, 보안을 강화하며, 데이터 독립성을 제공하는 유용한 도구입니다.",
      "type": "essay",
      "tags": ["View", "가상 테이블", "SQL", "데이터베이스"]
    },
    {
      "question": "그렇다면, View의 값을 수정해도 실제 테이블에는 반영되지 않나요?",
      "answer": "**경우에 따라 다릅니다.** View를 통한 수정이 실제 테이블에 반영될 수도 있고, 안 될 수도 있습니다.\n\n**수정 가능한 View (Updatable View):**\n\n**조건:**\n1. 단일 테이블에서 생성된 View\n2. DISTINCT, GROUP BY, HAVING 없음\n3. 집계 함수 없음\n4. UNION 없음\n5. 서브쿼리 없음 (일부 DBMS)\n\n**예시:**\n```sql\n-- 단순 View 생성\nCREATE VIEW active_users AS\nSELECT user_id, name, email\nFROM users\nWHERE status = 'active';\n\n-- ✅ UPDATE 가능 - 실제 테이블에 반영됨\nUPDATE active_users \nSET email = 'new@example.com' \nWHERE user_id = 1;\n-- users 테이블의 email이 실제로 변경됨\n\n-- ✅ INSERT 가능\nINSERT INTO active_users (user_id, name, email)\nVALUES (100, '홍길동', 'hong@example.com');\n-- users 테이블에 실제로 삽입됨 (status는 NULL이 됨)\n\n-- ✅ DELETE 가능\nDELETE FROM active_users WHERE user_id = 100;\n-- users 테이블에서 실제로 삭제됨\n```\n\n---\n\n**수정 불가능한 View:**\n\n**1. 조인이 있는 View**\n```sql\nCREATE VIEW employee_details AS\nSELECT e.emp_id, e.emp_name, d.dept_name\nFROM employees e\nJOIN departments d ON e.dept_id = d.dept_id;\n\n-- ❌ 수정 불가 (어느 테이블을 수정해야 할지 모호)\nUPDATE employee_details \nSET dept_name = '개발팀' \nWHERE emp_id = 1;\n-- ERROR: Cannot modify more than one base table through a join view\n```\n\n**2. 집계 함수가 있는 View**\n```sql\nCREATE VIEW dept_summary AS\nSELECT dept_id, COUNT(*) as emp_count, AVG(salary) as avg_salary\nFROM employees\nGROUP BY dept_id;\n\n-- ❌ 수정 불가 (집계 결과는 가상 데이터)\nUPDATE dept_summary SET emp_count = 10 WHERE dept_id = 1;\n-- ERROR: The target table of the UPDATE is not updatable\n```\n\n**3. DISTINCT가 있는 View**\n```sql\nCREATE VIEW unique_depts AS\nSELECT DISTINCT dept_id FROM employees;\n\n-- ❌ 수정 불가\nUPDATE unique_depts SET dept_id = 99 WHERE dept_id = 1;\n```\n\n---\n\n**WITH CHECK OPTION:**\n\nView의 WHERE 조건을 위반하는 수정을 방지합니다.\n\n```sql\nCREATE VIEW active_users AS\nSELECT user_id, name, email, status\nFROM users\nWHERE status = 'active'\nWITH CHECK OPTION;\n\n-- ✅ 가능\nUPDATE active_users SET name = '김철수' WHERE user_id = 1;\n\n-- ❌ 불가능 (View 조건 위반)\nUPDATE active_users SET status = 'inactive' WHERE user_id = 1;\n-- ERROR: CHECK OPTION failed\n\n-- ❌ 불가능 (삽입 후 View에서 보이지 않음)\nINSERT INTO active_users (user_id, name, status)\nVALUES (200, '이영희', 'inactive');\n-- ERROR: CHECK OPTION failed\n```\n\n---\n\n**INSTEAD OF Trigger (SQL Server, Oracle, PostgreSQL):**\n\n수정 불가능한 View를 수정 가능하게 만듭니다.\n\n```sql\n-- PostgreSQL 예시\nCREATE VIEW employee_details AS\nSELECT e.emp_id, e.emp_name, d.dept_name\nFROM employees e\nJOIN departments d ON e.dept_id = d.dept_id;\n\n-- INSTEAD OF Trigger 생성\nCREATE TRIGGER update_employee_details\nINSTEAD OF UPDATE ON employee_details\nFOR EACH ROW\nBEGIN\n    -- 적절한 테이블에 수정 적용\n    UPDATE employees \n    SET emp_name = NEW.emp_name \n    WHERE emp_id = NEW.emp_id;\n    \n    UPDATE departments \n    SET dept_name = NEW.dept_name \n    WHERE dept_id = (SELECT dept_id FROM employees WHERE emp_id = NEW.emp_id);\nEND;\n```\n\n---\n\n**결론:**\n\n| View 타입 | 수정 가능 여부 |\n|-----------|----------------|\n| 단순 View (단일 테이블) | ✅ 가능 |\n| 조인 View | ❌ 불가능 (트리거로 가능) |\n| 집계 View | ❌ 불가능 |\n| DISTINCT View | ❌ 불가능 |\n\n**실무 팁:**\n- View는 주로 조회용으로 사용\n- 수정은 원본 테이블에 직접 하는 것이 명확하고 안전",
      "type": "essay",
      "tags": ["View", "Updatable View", "CHECK OPTION", "SQL"]
    },
    {
      "question": "DB Join이 무엇인지 설명하고, 각각의 종류에 대해 설명해 주세요.",
      "answer": "**JOIN:**\n\n두 개 이상의 테이블을 **연결**하여 관련된 데이터를 함께 조회하는 연산입니다.\n\n**테이블 예시:**\n```sql\n-- employees 테이블\n| emp_id | emp_name | dept_id |\n|--------|----------|---------|\n| 1      | 홍길동   | 10      |\n| 2      | 김철수   | 20      |\n| 3      | 이영희   | NULL    |  -- 부서 없음\n\n-- departments 테이블\n| dept_id | dept_name |\n|---------|-----------|\n| 10      | 개발팀    |\n| 20      | 마케팅팀  |\n| 30      | 인사팀    |  -- 직원 없음\n```\n\n---\n\n**1. INNER JOIN (내부 조인)**\n\n**설명:** 두 테이블에서 **조건이 일치하는 행만** 반환합니다.\n\n```sql\nSELECT e.emp_name, d.dept_name\nFROM employees e\nINNER JOIN departments d ON e.dept_id = d.dept_id;\n\n-- 결과\n| emp_name | dept_name |\n|----------|----------|\n| 홍길동   | 개발팀    |\n| 김철수   | 마케팅팀  |\n-- 이영희(부서 없음), 인사팀(직원 없음) 제외\n```\n\n**사용 사례:** 양쪽 테이블에 모두 존재하는 데이터만 필요할 때\n\n---\n\n**2. LEFT (OUTER) JOIN**\n\n**설명:** **왼쪽 테이블의 모든 행** + 오른쪽에서 일치하는 행 (없으면 NULL)\n\n```sql\nSELECT e.emp_name, d.dept_name\nFROM employees e\nLEFT JOIN departments d ON e.dept_id = d.dept_id;\n\n-- 결과\n| emp_name | dept_name |\n|----------|-----------|\n| 홍길동   | 개발팀    |\n| 김철수   | 마케팅팀  |\n| 이영희   | NULL      |  ← 부서 없는 직원도 포함\n```\n\n**사용 사례:** 주 테이블의 모든 데이터와 관련 정보를 함께 조회\n\n---\n\n**3. RIGHT (OUTER) JOIN**\n\n**설명:** **오른쪽 테이블의 모든 행** + 왼쪽에서 일치하는 행 (없으면 NULL)\n\n```sql\nSELECT e.emp_name, d.dept_name\nFROM employees e\nRIGHT JOIN departments d ON e.dept_id = d.dept_id;\n\n-- 결과\n| emp_name | dept_name |\n|----------|-----------|\n| 홍길동   | 개발팀    |\n| 김철수   | 마케팅팀  |\n| NULL     | 인사팀    |  ← 직원 없는 부서도 포함\n```\n\n**사용 사례:** 참조 테이블의 모든 항목과 관련 데이터 조회\n\n---\n\n**4. FULL (OUTER) JOIN**\n\n**설명:** **양쪽 테이블의 모든 행** 반환 (일치하지 않으면 NULL)\n\n```sql\nSELECT e.emp_name, d.dept_name\nFROM employees e\nFULL OUTER JOIN departments d ON e.dept_id = d.dept_id;\n\n-- 결과\n| emp_name | dept_name |\n|----------|-----------|\n| 홍길동   | 개발팀    |\n| 김철수   | 마케팅팀  |\n| 이영희   | NULL      |  ← 부서 없는 직원\n| NULL     | 인사팀    |  ← 직원 없는 부서\n```\n\n**주의:** MySQL은 FULL OUTER JOIN을 지원하지 않음 (UNION으로 대체)\n\n```sql\n-- MySQL에서 FULL OUTER JOIN 구현\nSELECT e.emp_name, d.dept_name\nFROM employees e LEFT JOIN departments d ON e.dept_id = d.dept_id\nUNION\nSELECT e.emp_name, d.dept_name\nFROM employees e RIGHT JOIN departments d ON e.dept_id = d.dept_id;\n```\n\n---\n\n**5. CROSS JOIN (교차 조인)**\n\n**설명:** 두 테이블의 **모든 조합**(Cartesian Product)\n\n```sql\nSELECT e.emp_name, d.dept_name\nFROM employees e\nCROSS JOIN departments d;\n\n-- 결과 (3명 × 3개 부서 = 9행)\n| emp_name | dept_name |\n|----------|-----------|\n| 홍길동   | 개발팀    |\n| 홍길동   | 마케팅팀  |\n| 홍길동   | 인사팀    |\n| 김철수   | 개발팀    |\n| 김철수   | 마케팅팀  |\n| 김철수   | 인사팀    |\n| 이영희   | 개발팀    |\n| 이영희   | 마케팅팀  |\n| 이영희   | 인사팀    |\n```\n\n**사용 사례:** 모든 조합이 필요한 경우 (테스트 데이터 생성 등)\n\n---\n\n**6. SELF JOIN (자기 조인)**\n\n**설명:** 같은 테이블을 자기 자신과 조인\n\n```sql\n-- 직원과 그의 매니저 조회\nCREATE TABLE employees (\n    emp_id INT,\n    emp_name VARCHAR(100),\n    manager_id INT  -- 같은 테이블의 emp_id 참조\n);\n\nSELECT \n    e.emp_name as employee,\n    m.emp_name as manager\nFROM employees e\nLEFT JOIN employees m ON e.manager_id = m.emp_id;\n\n-- 결과\n| employee | manager |\n|----------|---------|\n| 홍길동   | NULL    |  -- 최고 관리자\n| 김철수   | 홍길동  |\n| 이영희   | 홍길동  |\n```\n\n**사용 사례:** 계층 구조, 친구 관계 등\n\n---\n\n**시각적 비교:**\n\n```\nINNER JOIN:      교집합 (∩)\nLEFT JOIN:       왼쪽 전체 + 교집합\nRIGHT JOIN:      오른쪽 전체 + 교집합\nFULL OUTER JOIN: 합집합 (∪)\nCROSS JOIN:      곱집합 (×)\n```\n\n**결론:**\n- 기본적으로 INNER JOIN 사용\n- NULL 포함 필요 시 LEFT/RIGHT JOIN\n- 실무에서는 LEFT JOIN이 가장 많이 사용됨",
      "type": "essay",
      "tags": ["JOIN", "INNER JOIN", "LEFT JOIN", "RIGHT JOIN", "SQL"]
    },
    {
      "question": "사실, JOIN은 상당한 시간이 걸릴 수 있기에 내부적으로 다양한 구현 방식을 사용하고 있습니다. 그 예시에 대해 설명해 주세요.",
      "answer": "데이터베이스는 JOIN을 실행할 때 **3가지 주요 알고리즘**을 사용합니다.\n\n**1. Nested Loop Join (중첩 루프 조인)**\n\n**동작 방식:**\n```python\nfor row_a in table_a:  # 외부 루프\n    for row_b in table_b:  # 내부 루프\n        if row_a.key == row_b.key:\n            return (row_a, row_b)\n```\n\n**SQL 예시:**\n```sql\nSELECT *\nFROM employees e  -- 100행\nJOIN departments d ON e.dept_id = d.dept_id;  -- 10행\n\n-- 최악의 경우: 100 × 10 = 1,000번 비교\n```\n\n**특징:**\n- **시간 복잡도:** O(N × M) (인덱스 없을 때)\n- **시간 복잡도:** O(N × log M) (내부 테이블에 인덱스 있을 때)\n\n**장점:**\n- 간단하고 직관적\n- 작은 테이블에는 효율적\n- 메모리 사용량 적음\n\n**단점:**\n- 큰 테이블에는 매우 느림\n- 인덱스가 없으면 비효율적\n\n**최적화:**\n```sql\n-- dept_id에 인덱스가 있으면 빠름\nCREATE INDEX idx_dept_id ON employees(dept_id);\n\nSELECT *\nFROM departments d  -- 10행 (작은 테이블)\nJOIN employees e ON d.dept_id = e.dept_id;  -- 100행\n-- 10 × log(100) = 약 70번 연산 (인덱스 사용)\n```\n\n---\n\n**2. Hash Join (해시 조인)**\n\n**동작 방식:**\n\n**Phase 1 - Build Phase:**\n```python\nhash_table = {}\nfor row in table_a:  # 작은 테이블\n    hash_key = hash(row.dept_id)\n    hash_table[hash_key] = row\n```\n\n**Phase 2 - Probe Phase:**\n```python\nfor row in table_b:  # 큰 테이블\n    hash_key = hash(row.dept_id)\n    if hash_key in hash_table:\n        return (hash_table[hash_key], row)\n```\n\n**SQL 예시:**\n```sql\nSELECT *\nFROM employees e  -- 100,000행\nJOIN departments d ON e.dept_id = d.dept_id;  -- 100행\n\n-- 1. departments를 Hash Table로 변환 (100번)\n-- 2. employees를 순회하며 Hash 조회 (100,000번, 각 O(1))\n-- 총: O(N + M)\n```\n\n**특징:**\n- **시간 복잡도:** O(N + M)\n- **공간 복잡도:** O(min(N, M)) - 작은 테이블 크기\n\n**장점:**\n- 큰 테이블 조인에 매우 효율적\n- 인덱스 없어도 빠름\n- = (등호) 조인에 최적\n\n**단점:**\n- 메모리 필요 (Hash Table 저장)\n- 범위 조인(>, <, BETWEEN)에는 사용 불가\n- 정렬되지 않음\n\n**사용 조건:**\n```sql\n-- ✅ Hash Join 사용 가능 (등호 조인)\nSELECT * FROM a JOIN b ON a.id = b.id;\n\n-- ❌ Hash Join 사용 불가 (범위 조인)\nSELECT * FROM a JOIN b ON a.id > b.id;\n```\n\n---\n\n**3. Sort Merge Join (정렬 병합 조인)**\n\n**동작 방식:**\n\n**Phase 1 - Sort Phase:**\n```python\ntable_a = sort(table_a, key='dept_id')\ntable_b = sort(table_b, key='dept_id')\n```\n\n**Phase 2 - Merge Phase:**\n```python\ni, j = 0, 0\nwhile i < len(table_a) and j < len(table_b):\n    if table_a[i].key == table_b[j].key:\n        return (table_a[i], table_b[j])\n        i += 1\n    elif table_a[i].key < table_b[j].key:\n        i += 1\n    else:\n        j += 1\n```\n\n**SQL 예시:**\n```sql\nSELECT *\nFROM employees e  -- 10,000행\nJOIN departments d ON e.dept_id = d.dept_id  -- 1,000행\nORDER BY e.dept_id;\n\n-- 1. employees 정렬: O(N log N) = 10,000 × 13\n-- 2. departments 정렬: O(M log M) = 1,000 × 10\n-- 3. 병합: O(N + M) = 11,000\n```\n\n**특징:**\n- **시간 복잡도:** O(N log N + M log M + N + M)\n- 양쪽 테이블을 정렬 후 병합\n\n**장점:**\n- 범위 조인(>, <, BETWEEN) 가능\n- 정렬된 결과 제공 (ORDER BY 생략 가능)\n- 이미 정렬된 인덱스가 있으면 매우 빠름\n\n**단점:**\n- 정렬 비용 발생\n- 메모리 또는 디스크 공간 필요\n\n**최적화:**\n```sql\n-- dept_id에 인덱스가 있으면 정렬 생략\nCREATE INDEX idx_dept_id ON employees(dept_id);\n\nSELECT *\nFROM employees e\nJOIN departments d ON e.dept_id = d.dept_id;\n-- 이미 정렬되어 있어 Merge만 수행 → O(N + M)\n```\n\n---\n\n**알고리즘 선택 기준:**\n\n| 상황 | 선택 알고리즘 |\n|------|---------------|\n| 작은 테이블 × 큰 테이블 (인덱스 O) | Nested Loop |\n| 큰 테이블 × 큰 테이블 (등호 조인) | Hash Join |\n| 범위 조인, 정렬 필요 | Sort Merge Join |\n| 인덱스가 이미 정렬되어 있음 | Sort Merge Join |\n| 메모리 부족 | Nested Loop |\n\n**실행 계획 확인:**\n```sql\n-- MySQL\nEXPLAIN SELECT * FROM a JOIN b ON a.id = b.id;\n\n-- 결과\n| id | select_type | table | type  | Extra                    |\n|----|-------------|-------|-------|---------------------------|\n| 1  | SIMPLE      | a     | ALL   | NULL                      |\n| 1  | SIMPLE      | b     | ref   | Using where; Using index  |\n-- type: ALL (Full Scan), ref (Index Scan)\n-- Extra: Using index (Index Only Scan)\n```\n\n**결론:**\n- Nested Loop: 작은 테이블 + 인덱스\n- Hash Join: 큰 테이블 + 등호 조인\n- Sort Merge: 범위 조인 + 정렬\n- 옵티마이저가 자동으로 최적 알고리즘 선택",
      "type": "essay",
      "tags": ["JOIN", "Nested Loop", "Hash Join", "Sort Merge Join", "쿼리 최적화"]
    },
    {
      "question": "그렇다면 입력한 쿼리에서 어떤 구현 방식을 사용하는지는 어떻게 알 수 있나요?",
      "answer": "**EXPLAIN (실행 계획)** 을 사용하여 확인할 수 있습니다.\n\n**MySQL:**\n\n```sql\nEXPLAIN SELECT e.emp_name, d.dept_name\nFROM employees e\nJOIN departments d ON e.dept_id = d.dept_id\nWHERE e.salary > 5000;\n\n-- 결과\n+----+-------------+-------+------+---------------+------+---------+------+------+----------------------------------------------------+\n| id | select_type | table | type | possible_keys | key  | key_len | ref  | rows | Extra                                              |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------------------------------------------------+\n|  1 | SIMPLE      | e     | ALL  | dept_id       | NULL | NULL    | NULL | 1000 | Using where                                        |\n|  1 | SIMPLE      | d     | ref  | PRIMARY       | PRIMARY | 4     | e.dept_id | 1 | NULL                                            |\n+----+-------------+-------+------+---------------+------+---------+------+------+----------------------------------------------------+\n```\n\n**주요 컬럼:**\n\n**type (조인 타입):**\n- **system**: 테이블에 행이 1개 (가장 빠름)\n- **const**: PRIMARY KEY 또는 UNIQUE 인덱스로 조회 (매우 빠름)\n- **eq_ref**: JOIN에서 PRIMARY KEY 또는 UNIQUE 인덱스 사용 (빠름)\n- **ref**: 인덱스 사용 (보통)\n- **range**: 인덱스 범위 스캔 (보통)\n- **index**: 인덱스 풀 스캔 (느림)\n- **ALL**: 테이블 풀 스캔 (매우 느림) ⚠️\n\n**Extra (추가 정보):**\n- **Using index**: 커버링 인덱스 (테이블 접근 없음) ✅\n- **Using where**: WHERE 조건 필터링\n- **Using filesort**: 정렬 작업 발생 ⚠️\n- **Using temporary**: 임시 테이블 생성 ⚠️\n- **Using join buffer**: 조인 버퍼 사용 (Nested Loop 또는 Hash Join)\n\n---\n\n**EXPLAIN ANALYZE (MySQL 8.0.18+):**\n\n실제 실행 시간과 행 수를 보여줍니다.\n\n```sql\nEXPLAIN ANALYZE \nSELECT * FROM employees e \nJOIN departments d ON e.dept_id = d.dept_id;\n\n-- 결과\n-> Nested loop inner join  (cost=450.00 rows=1000) (actual time=0.123..15.456 rows=1000 loops=1)\n    -> Table scan on e  (cost=100.00 rows=1000) (actual time=0.045..8.234 rows=1000 loops=1)\n    -> Index lookup on d using PRIMARY (dept_id=e.dept_id)  (cost=0.35 rows=1) (actual time=0.006..0.007 rows=1 loops=1000)\n```\n\n**actual time**: 실제 소요 시간 (ms)\n**rows**: 실제 처리한 행 수\n**loops**: 반복 횟수\n\n---\n\n**PostgreSQL:**\n\n```sql\nEXPLAIN ANALYZE\nSELECT * FROM employees e \nJOIN departments d ON e.dept_id = d.dept_id;\n\n-- 결과\nHash Join  (cost=35.00..185.00 rows=1000 width=68) (actual time=0.234..3.456 rows=1000 loops=1)\n  Hash Cond: (e.dept_id = d.dept_id)\n  -> Seq Scan on employees e  (cost=0.00..135.00 rows=1000 width=40)\n  -> Hash  (cost=20.00..20.00 rows=100 width=28)\n        -> Seq Scan on departments d  (cost=0.00..20.00 rows=100 width=28)\nPlanning Time: 0.123 ms\nExecution Time: 3.678 ms\n```\n\n**조인 알고리즘 확인:**\n- **Hash Join**: 해시 조인 사용\n- **Nested Loop**: 중첩 루프 조인\n- **Merge Join**: 정렬 병합 조인\n\n---\n\n**Oracle:**\n\n```sql\nEXPLAIN PLAN FOR\nSELECT * FROM employees e \nJOIN departments d ON e.dept_id = d.dept_id;\n\nSELECT * FROM TABLE(DBMS_XPLAN.DISPLAY);\n\n-- 결과\nPlan hash value: 1234567890\n \n--------------------------------------------------------------------------------\n| Id | Operation          | Name       | Rows | Bytes | Cost (%CPU)| Time     |\n--------------------------------------------------------------------------------\n|  0 | SELECT STATEMENT   |            | 1000 | 68000 |   185  (1) | 00:00:01 |\n|* 1 |  HASH JOIN         |            | 1000 | 68000 |   185  (1) | 00:00:01 |\n|  2 |   TABLE ACCESS FULL| EMPLOYEES  | 1000 | 40000 |   135  (0) | 00:00:01 |\n|  3 |   TABLE ACCESS FULL| DEPARTMENTS|  100 |  2800 |    20  (0) | 00:00:01 |\n--------------------------------------------------------------------------------\n```\n\n---\n\n**실행 계획 읽는 법:**\n\n```sql\nEXPLAIN SELECT * FROM orders WHERE customer_id = 123;\n\n-- ✅ 좋은 실행 계획\ntype: ref  -- 인덱스 사용\nExtra: Using index  -- 커버링 인덱스\n\n-- ⚠️ 나쁜 실행 계획\ntype: ALL  -- 풀 스캔\nExtra: Using filesort, Using temporary  -- 정렬, 임시 테이블\n```\n\n**최적화 힌트:**\n```sql\n-- type이 ALL이면 인덱스 추가 고려\nCREATE INDEX idx_customer_id ON orders(customer_id);\n\n-- Using filesort가 보이면 인덱스로 정렬 회피\nCREATE INDEX idx_created_at ON orders(created_at);\n```\n\n**결론:**\nEXPLAIN을 사용하여 쿼리 실행 계획을 확인하고, type과 Extra를 보고 최적화 여부를 판단합니다.",
      "type": "essay",
      "tags": ["EXPLAIN", "실행 계획", "쿼리 최적화", "성능"]
    },
    {
      "question": "앞 질문들을 통해 인덱스의 중요성을 알 수 있었는데, 그렇다면 JOIN의 성능도 인덱스의 유무의 영향을 받나요?",
      "answer": "**네, 매우 큰 영향을 받습니다.** 인덱스는 JOIN 성능에 결정적입니다.\n\n**인덱스 없는 경우 (최악):**\n\n```sql\n-- employees: 10,000행\n-- departments: 100행\n-- dept_id에 인덱스 없음\n\nSELECT * FROM employees e\nJOIN departments d ON e.dept_id = d.dept_id;\n\n-- Nested Loop Join 사용 시\n-- 10,000 × 100 = 1,000,000번 비교 (Full Scan)\n-- 매우 느림!\n\nEXPLAIN:\ntype: ALL  -- Full Table Scan\nrows: 10000\nExtra: Using where; Using join buffer (Block Nested Loop)\n```\n\n---\n\n**인덱스 있는 경우 (최적):**\n\n```sql\n-- dept_id에 인덱스 추가\nCREATE INDEX idx_dept_id ON employees(dept_id);\n\nSELECT * FROM employees e\nJOIN departments d ON e.dept_id = d.dept_id;\n\n-- Nested Loop Join + Index Lookup\n-- 100 × log(10,000) = 100 × 13 ≈ 1,300번 연산\n-- 매우 빠름!\n\nEXPLAIN:\ntype: ref  -- Index Scan\nkey: idx_dept_id  -- 인덱스 사용\nrows: 100  -- 예상 행 수 감소\n```\n\n**성능 차이:**\n```\n인덱스 없음: 1,000,000번 연산\n인덱스 있음: 1,300번 연산\n→ 약 770배 빠름!\n```\n\n---\n\n**복합 인덱스와 JOIN:**\n\n```sql\n-- 3개 테이블 조인\nSELECT *\nFROM orders o\nJOIN customers c ON o.customer_id = c.customer_id\nJOIN products p ON o.product_id = p.product_id\nWHERE o.order_date >= '2024-01-01';\n\n-- 최적 인덱스\nCREATE INDEX idx_orders_1 ON orders(customer_id, order_date);\nCREATE INDEX idx_orders_2 ON orders(product_id);\nCREATE INDEX idx_customers ON customers(customer_id);\nCREATE INDEX idx_products ON products(product_id);\n```\n\n---\n\n**커버링 인덱스로 JOIN 최적화:**\n\n```sql\n-- 쿼리\nSELECT e.emp_id, e.emp_name, d.dept_name\nFROM employees e\nJOIN departments d ON e.dept_id = d.dept_id\nWHERE e.salary > 5000;\n\n-- 일반 인덱스\nCREATE INDEX idx_salary ON employees(salary);  -- 부분 최적화\n\n-- 커버링 인덱스 (더 빠름)\nCREATE INDEX idx_salary_covering \nON employees(salary, dept_id, emp_id, emp_name);\n-- 테이블 접근 없이 인덱스만으로 처리\n\nEXPLAIN:\nExtra: Using index  -- 커버링 인덱스 사용\n```\n\n---\n\n**Hash Join에서의 인덱스:**\n\nHash Join은 인덱스가 없어도 효율적이지만, WHERE 조건에는 인덱스가 필요합니다.\n\n```sql\nSELECT *\nFROM large_table l\nJOIN small_table s ON l.key = s.key\nWHERE l.created_at > '2024-01-01';  -- 이 조건에 인덱스 필요\n\n-- 인덱스 추가\nCREATE INDEX idx_created_at ON large_table(created_at);\n\n-- 실행 과정\n-- 1. created_at 인덱스로 large_table 필터링 (빠름)\n-- 2. small_table을 Hash Table로 변환\n-- 3. 필터링된 결과와 Hash Join\n```\n\n---\n\n**인덱스 힌트 (필요시):**\n\n```sql\n-- MySQL\nSELECT * FROM employees e USE INDEX (idx_dept_id)\nJOIN departments d ON e.dept_id = d.dept_id;\n\n-- 옵티마이저가 잘못된 인덱스를 선택하면 힌트로 강제\n```\n\n---\n\n**실무 팁:**\n\n**1. 외래키 컬럼에는 반드시 인덱스 생성**\n```sql\nCREATE TABLE orders (\n    order_id INT PRIMARY KEY,\n    customer_id INT,\n    product_id INT,\n    INDEX idx_customer_id (customer_id),  -- 필수!\n    INDEX idx_product_id (product_id)     -- 필수!\n);\n```\n\n**2. JOIN 조건과 WHERE 조건 모두 고려**\n```sql\n-- 이 쿼리에는 2개 인덱스 필요\nSELECT *\nFROM orders o\nJOIN customers c ON o.customer_id = c.customer_id\nWHERE o.order_date >= '2024-01-01';\n\n-- 필요한 인덱스\nCREATE INDEX idx_customer_id ON orders(customer_id);  -- JOIN용\nCREATE INDEX idx_order_date ON orders(order_date);    -- WHERE용\n\n-- 또는 복합 인덱스\nCREATE INDEX idx_combined ON orders(order_date, customer_id);\n```\n\n**3. 작은 테이블은 인덱스 불필요**\n```sql\n-- departments 테이블이 100행 이하라면\n-- 인덱스 없이도 Full Scan이 빠를 수 있음\n```\n\n**결론:**\n- JOIN 성능은 인덱스에 크게 의존\n- 외래키 컬럼에는 반드시 인덱스 생성\n- EXPLAIN으로 인덱스 사용 여부 확인\n- 인덱스 없는 JOIN은 성능 재앙!",
      "type": "essay",
      "tags": ["JOIN", "인덱스", "성능 최적화", "쿼리"]
    },
    {
      "question": "3중 조인 부터는 동작 방식이 약간 바뀝니다. 어떻게 동작하는지, 그리고 그 방식이 성능에 어떠한 영향을 주는지 설명해 주세요.",
      "answer": "3개 이상의 테이블을 조인할 때는 **조인 순서**가 성능에 큰 영향을 미칩니다.\n\n**2-way JOIN (2개 테이블):**\n```sql\nSELECT * FROM A JOIN B ON A.id = B.id;\n-- 순서: A → B 또는 B → A (2가지)\n```\n\n**3-way JOIN (3개 테이블):**\n```sql\nSELECT *\nFROM orders o\nJOIN customers c ON o.customer_id = c.customer_id\nJOIN products p ON o.product_id = p.product_id;\n```\n\n**가능한 조인 순서:** 6가지\n\n**동작 방식:**\n```\n1단계: A와 B 조인 → 중간 결과 R1\n2단계: R1과 C 조인 → 최종 결과\n```\n\n**옵티마이저의 선택 기준:**\n1. 테이블 크기: 작은 테이블 먼저\n2. 인덱스 존재\n3. WHERE 조건 선택도\n4. 통계 정보\n\n**좋은 순서:**\n```sql\n-- products를 WHERE로 10행까지 줄임\n-- → products (10) → orders (100) → customers (100)\n-- 총 처리: 약 210행\n```\n\n**나쁜 순서:**\n```sql\n-- customers (10,000) → orders (100,000) → products (1,000,000)\n-- 총 처리: 수백만 행\n```\n\n**결론:**\n작은 테이블/필터링 많은 테이블을 먼저 조인하면 성능이 크게 향상됩니다.",
      "type": "essay",
      "tags": ["JOIN", "조인 순서", "옵티마이저", "성능"]
    },
    {
      "question": "B-Tree와 B+Tree에 대해 설명해 주세요.",
      "answer": "**B-Tree (Balanced Tree):**\n\n균형 잡힌 트리 자료구조로, 각 노드가 여러 개의 키와 자식을 가집니다.\n\n**특징:**\n- 모든 노드(내부 + 리프)가 데이터 저장\n- 모든 리프 노드의 깊이가 같음\n- 시간 복잡도: O(log N)\n\n**B+Tree:**\n\nB-Tree의 변형으로, 리프 노드만 데이터를 저장하고 리프 노드끼리 연결된 구조입니다.\n\n**특징:**\n1. **내부 노드**: 키만 저장 (인덱스 역할)\n2. **리프 노드**: 모든 데이터 저장\n3. **리프 노드가 연결 리스트로 연결**\n4. 범위 검색에 최적화\n\n**비교:**\n\n| 특징 | B-Tree | B+Tree |\n|------|--------|--------|\n| 데이터 위치 | 모든 노드 | 리프 노드만 |\n| 리프 연결 | 없음 | 연결 리스트 |\n| 범위 검색 | 느림 | 빠름 ⭐ |\n| 풀 스캔 | 느림 | 빠름 ⭐ |\n| 사용 | 파일 시스템 | **데이터베이스** ⭐ |\n\n**왜 DB는 B+Tree를 사용할까?**\n\n1. **범위 검색 최적화**\n```sql\nSELECT * FROM orders \nWHERE order_date BETWEEN '2024-01-01' AND '2024-01-31';\n-- B+Tree: 시작점 찾고 → 연결 리스트 순회 (빠름)\n-- B-Tree: 트리를 여러 번 탐색 (느림)\n```\n\n2. **순차 접근 (ORDER BY)**\n```sql\nSELECT * FROM users ORDER BY created_at LIMIT 100;\n-- B+Tree: 리프 노드 처음부터 100개 (빠름)\n-- B-Tree: 정렬 필요 (느림)\n```\n\n3. **디스크 I/O 감소**\n- 내부 노드가 작아서 더 많은 키를 메모리에 캐싱 가능\n- 트리 높이 감소 → 디스크 접근 감소\n\n**결론:**\nDB는 범위 검색과 순차 접근이 빈번하므로 B+Tree가 최적입니다.",
      "type": "essay",
      "tags": ["B-Tree", "B+Tree", "인덱스", "자료구조"]
    },
    {
      "question": "그렇다면, B+Tree가 B-Tree에 비해 반드시 좋다고 할 수 있을까요? 그렇지 않다면 어떤 단점이 있을까요?",
      "answer": "**아니오**, B+Tree가 모든 상황에서 좋은 것은 아닙니다.\n\n**B+Tree의 단점:**\n\n**1. 특정 값 검색 시 항상 리프까지 가야 함**\n```\nB-Tree: Root에서 바로 찾을 수 있음 → 1번 탐색\nB+Tree: Root → 내부 → 리프 → 3번 탐색\n```\n\n**2. 리프 노드 간 포인터 오버헤드**\n- 다음/이전 리프 포인터로 인한 메모리 사용량 증가\n\n**3. 중복 키 저장**\n- 내부 노드와 리프 노드에 키가 중복 저장\n- 저장 공간 증가\n\n**4. 삽입/삭제 복잡도**\n- 리프 노드 연결을 유지해야 하므로 더 복잡\n\n**5. 단순 키-값 저장에는 오버헤드**\n\nB-Tree가 유리한 경우:**\n\n**1. 파일 시스템**\n```bash\nfind / -name \"config.txt\"  # 특정 파일명 검색\n# B-Tree: 파일명으로 빠르게 찾음\n# 범위 검색 불필요\n```\n\n**2. In-Memory 데이터베이스**\n```java\nMap<String, String> cache = new HashMap<>();\ncache.get(\"user:12345\");  # 단순 조회\n# B+Tree의 범위 검색 기능 불필요\n```\n\n**3. 작은 데이터셋**\n- 수천 개 이하면 B-Tree의 단순성이 유리\n\n**B+Tree가 유리한 경우:**\n\n**1. 데이터베이스 (범위 검색 많음)**\n```sql\nSELECT * FROM orders \nWHERE order_date BETWEEN '2024-01-01' AND '2024-12-31';\n```\n\n**2. 대용량 데이터**\n- 수백만 ~ 수십억 행\n\n**결론:**\nDB는 범위 검색과 정렬이 빈번하므로 B+Tree가 압도적으로 유리합니다.",
      "type": "essay",
      "tags": ["B-Tree", "B+Tree", "비교", "트레이드오프"]
    },
    {
      "question": "DB에서 RBT를 사용하지 않고, B-Tree/B+Tree를 사용하는 이유가 있을까요?",
      "answer": "네, **디스크 I/O 특성** 때문입니다.\n\n**핵심 차이: 디스크 I/O**\n\n```\n메모리 접근: 100 나노초\n디스크 접근: 10 밀리초 (100,000배 느림)\n\n→ 디스크 I/O 횟수를 최소화해야 함!\n```\n\n**예시: 1,000,000개 데이터에서 검색**\n\n**RBT (Red-Black Tree):**\n```\n높이: log₂(1,000,000) ≈ 20\n디스크 I/O: 20번\n\n각 노드가 작아서 (키 1개)\n→ 20번의 디스크 접근 필요\n→ 20 × 10ms = 200ms\n```\n\n**B+Tree (분기 계수 = 100):**\n```\n높이: log₁₀₀(1,000,000) ≈ 3\n디스크 I/O: 3번\n\n각 노드가 크고 (키 100개)\n→ 3번의 디스크 접근으로 충분\n→ 3 × 10ms = 30ms\n\n6배 이상 빠름!\n```\n\n**디스크 블록과의 관계:**\n\n```\n디스크는 블록 단위로 읽음 (보통 4KB)\n\nRBT:\n- 노드 크기: 29 bytes\n- 4KB 블록에 140개 노드 들어감\n- 하지만 트리 구조상 1개만 읽음\n- 나머지 139개는 낭비!\n\nB+Tree:\n- 노드 크기: 4KB (블록 크기와 일치)\n- 한 번에 키 100개를 읽음\n- 디스크 블록을 효율적으로 사용\n```\n\n**범위 검색:**\n\n```sql\nSELECT * FROM users WHERE age BETWEEN 20 AND 30;\n\nRBT: 각 노드마다 디스크 I/O → 수백 번\nB+Tree: 리프 노드 연결 리스트 → 10번 미만\n```\n\n**결론:**\n\n디스크 기반 DB는 B-Tree/B+Tree 사용:\n1. 디스크 I/O 횟수 최소화\n2. 디스크 블록 크기와 일치\n3. 범위 검색 효율\n\n메모리 기반은 RBT 사용 가능:\n- Redis, Java TreeMap, C++ std::map",
      "type": "essay",
      "tags": ["RBT", "B-Tree", "디스크 I/O", "자료구조"]
    },
    {
      "question": "오름차순으로 정렬된 인덱스가 있다고 할 때, 내림차순 정렬을 시도할 경우 성능이 어떻게 될까요? B-Tree/B+Tree의 구조를 기반으로 설명해 주세요.",
      "answer": "**대부분의 DBMS에서는 내림차순도 빠릅니다.** B-Tree/B+Tree는 양방향 탐색이 가능하기 때문입니다.\n\n**오름차순 인덱스:**\n```sql\nCREATE INDEX idx_created_at ON orders(created_at ASC);\n```\n\n**B+Tree 구조:**\n```\n리프 노드: [2024-01-01] ↔ [2024-01-15] ↔ [2024-01-31] ↔ [2024-02-15]\n```\n\n---\n\n**오름차순 정렬 (ASC):**\n```sql\nSELECT * FROM orders \nORDER BY created_at ASC  -- 인덱스와 동일\nLIMIT 100;\n\n-- B+Tree 탐색:\n-- 1. 리프 노드 맨 왼쪽으로 이동\n-- 2. 오른쪽으로 100개 읽기 →→→\n-- 매우 빠름!\n```\n\n---\n\n**내림차순 정렬 (DESC):**\n```sql\nSELECT * FROM orders \nORDER BY created_at DESC  -- 인덱스와 반대\nLIMIT 100;\n\n-- B+Tree 탐색:\n-- 1. 리프 노드 맨 오른쪽으로 이동\n-- 2. 왼쪽으로 100개 읽기 ←←←\n-- 마찬가지로 매우 빠름!\n```\n\nB+Tree 리프 노드는 **양방향 연결 리스트**이므로, 역방향 순회도 빠릅니다.\n\n---\n\n**MySQL InnoDB 예시:**\n\n```sql\nEXPLAIN SELECT * FROM orders \nORDER BY created_at DESC LIMIT 100;\n\n-- 결과\nExtra: Using index; Backward index scan\n-- Backward index scan: 인덱스를 역으로 스캔\n-- filesort 없음 → 정렬 작업 불필요\n```\n\n---\n\n**언제 느려질까?**\n\n**1. 인덱스가 없는 경우**\n```sql\nSELECT * FROM orders \nORDER BY created_at DESC;\n-- 인덱스 없음 → filesort 발생 (느림)\n\nEXPLAIN:\nExtra: Using filesort  -- 메모리/디스크 정렬 발생\n```\n\n**2. 복합 인덱스에서 일부만 역순**\n```sql\n-- 인덱스: (user_id ASC, created_at ASC)\nCREATE INDEX idx_user_created ON orders(user_id, created_at);\n\n-- ✅ 빠름 (인덱스 사용)\nSELECT * FROM orders \nWHERE user_id = 123 \nORDER BY created_at DESC;\n\n-- ❌ 느림 (filesort 발생)\nSELECT * FROM orders \nORDER BY user_id DESC, created_at ASC;\n-- 정렬 방향이 섞여서 인덱스 사용 불가\n```\n\n---\n\n**MySQL 8.0 이상: Descending Index**\n\n```sql\n-- 내림차순 인덱스 명시 가능\nCREATE INDEX idx_created_desc \nON orders(created_at DESC);\n\n-- 하지만 B+Tree는 양방향이므로 큰 차이 없음\n-- 복합 인덱스에서 유용:\nCREATE INDEX idx_mixed \nON orders(user_id ASC, created_at DESC);\n\nSELECT * FROM orders \nORDER BY user_id ASC, created_at DESC;\n-- 이제 인덱스 사용 가능!\n```\n\n---\n\n**결론:**\n\n| 상황 | 성능 |\n|------|------|\n| 오름차순 인덱스 + ASC 정렬 | 빠름 ✅ |\n| 오름차순 인덱스 + DESC 정렬 | 빠름 ✅ (Backward scan) |\n| 인덱스 없음 | 느림 ❌ (filesort) |\n| 복합 인덱스, 섞인 정렬 | 느림 ❌ (MySQL 8.0+ DESC 인덱스로 해결) |\n\n**B+Tree의 양방향 연결 리스트 덕분에 역순 정렬도 빠릅니다!**",
      "type": "essay",
      "tags": ["인덱스", "정렬", "B+Tree", "역순"]
    },
    {
      "question": "DB Locking에 대해 설명해 주세요.",
      "answer": "**DB Locking:**\n\n동시에 여러 트랜잭션이 같은 데이터를 접근할 때 **데이터 일관성**을 보장하기 위한 메커니즘입니다.\n\n**Lock의 종류:**\n\n**1. Shared Lock (공유 락, S-Lock, Read Lock)**\n- 읽기 작업에 사용\n- 여러 트랜잭션이 동시에 획득 가능\n- Shared Lock끼리는 호환 가능\n\n```sql\n-- Transaction 1\nSELECT * FROM accounts WHERE id = 1 FOR SHARE;\n-- S-Lock 획득\n\n-- Transaction 2\nSELECT * FROM accounts WHERE id = 1 FOR SHARE;\n-- S-Lock 획득 가능 (동시 읽기 OK)\n```\n\n**2. Exclusive Lock (배타 락, X-Lock, Write Lock)**\n- 쓰기 작업에 사용\n- 한 번에 하나의 트랜잭션만 획득 가능\n- 다른 모든 Lock과 호환 불가\n\n```sql\n-- Transaction 1\nUPDATE accounts SET balance = 1000 WHERE id = 1;\n-- X-Lock 획득\n\n-- Transaction 2\nSELECT * FROM accounts WHERE id = 1;\n-- 대기 (X-Lock이 풀릴 때까지)\n```\n\n---\n\n**Lock 호환성 표:**\n\n|  | S-Lock | X-Lock |\n|-------|--------|--------|\n| **S-Lock** | ✅ OK | ❌ 대기 |\n| **X-Lock** | ❌ 대기 | ❌ 대기 |\n\n---\n\n**Lock의 범위 (Granularity):**\n\n**1. Row-Level Lock (행 레벨)**\n- 가장 작은 단위\n- 동시성 최고, 오버헤드 있음\n- InnoDB 기본\n\n**2. Table-Level Lock (테이블 레벨)**\n- 전체 테이블 잠금\n- 동시성 낮음, 오버헤드 적음\n- MyISAM 사용\n\n**3. Page-Level Lock, Block-Level Lock**\n- 중간 단위\n\n---\n\n**예시:**\n\n```sql\n-- Transaction 1\nSTART TRANSACTION;\nUPDATE accounts SET balance = balance - 100 WHERE id = 1;\n-- id=1 행에 X-Lock\n\n-- Transaction 2\nSTART TRANSACTION;\nUPDATE accounts SET balance = balance + 50 WHERE id = 1;\n-- id=1에 대한 X-Lock 대기...\n\n-- Transaction 1\nCOMMIT;\n-- Lock 해제\n\n-- Transaction 2\n-- 이제 X-Lock 획득하고 UPDATE 실행\n```\n\n---\n\n**MySQL InnoDB Lock:**\n\n**1. Record Lock**\n```sql\nUPDATE users SET name = '홍길동' WHERE id = 1;\n-- id=1 행만 Lock\n```\n\n**2. Gap Lock**\n- 인덱스 레코드 사이의 간격을 잠금\n- Phantom Read 방지\n\n```sql\n-- 인덱스: age\nSELECT * FROM users WHERE age BETWEEN 20 AND 30 FOR UPDATE;\n-- age 20~30 사이의 간격도 Lock → 새로운 삽입 방지\n```\n\n**3. Next-Key Lock**\n- Record Lock + Gap Lock\n- REPEATABLE READ에서 기본\n\n---\n\n**명시적 Lock:**\n\n```sql\n-- Shared Lock\nSELECT * FROM accounts WHERE id = 1 FOR SHARE;\nSELECT * FROM accounts WHERE id = 1 LOCK IN SHARE MODE;\n\n-- Exclusive Lock\nSELECT * FROM accounts WHERE id = 1 FOR UPDATE;\n```\n\n**결론:**\nLock은 데이터 일관성을 보장하지만, 동시성을 낮추고 Deadlock 위험이 있으므로 적절히 사용해야 합니다.",
      "type": "essay",
      "tags": ["Lock", "Shared Lock", "Exclusive Lock", "동시성"]
    },
    {
      "question": "Optimistic Lock/Pessimistic Lock에 대해 설명해 주세요.",
      "answer": "**Optimistic Lock (낙관적 락):**\n\n\"충돌이 드물 것\"이라고 가정하고, **Lock 없이** 읽고, **커밋 시점에 충돌 검사**합니다.\n\n**구현 방식: Version/Timestamp**\n\n```sql\n-- 테이블 구조\nCREATE TABLE products (\n    id INT PRIMARY KEY,\n    name VARCHAR(100),\n    price DECIMAL,\n    version INT  -- 버전 컬럼\n);\n\n-- 읽기\nSELECT id, name, price, version FROM products WHERE id = 1;\n-- version = 5\n\n-- 수정 (버전 체크)\nUPDATE products \nSET price = 15000, version = version + 1\nWHERE id = 1 AND version = 5;\n\n-- 영향받은 행 = 0 이면 충돌 발생 → 재시도\n-- 영향받은 행 = 1 이면 성공\n```\n\n**Java 예시 (JPA):**\n```java\n@Entity\npublic class Product {\n    @Id\n    private Long id;\n    \n    private String name;\n    private BigDecimal price;\n    \n    @Version  // Optimistic Lock\n    private int version;\n}\n\n// 사용\ntry {\n    product.setPrice(new BigDecimal(\"15000\"));\n    productRepository.save(product);\n} catch (OptimisticLockingFailureException e) {\n    // 충돌 발생 → 재시도\n}\n```\n\n**장점:**\n- Lock 없어서 성능 좋음\n- Deadlock 없음\n- 읽기 작업 방해 없음\n\n**단점:**\n- 충돌 시 재시도 필요\n- 충돌이 많으면 비효율\n\n**사용 사례:**\n- 충돌이 드문 경우\n- 읽기가 많은 경우\n- 웹 애플리케이션 (긴 트랜잭션)\n\n---\n\n**Pessimistic Lock (비관적 락):**\n\n\"충돌이 자주 발생할 것\"이라고 가정하고, **미리 Lock**을 걸어 다른 트랜잭션의 접근을 차단합니다.\n\n**구현 방식: Database Lock**\n\n```sql\n-- Transaction 1\nSTART TRANSACTION;\nSELECT * FROM products WHERE id = 1 FOR UPDATE;\n-- X-Lock 획득 (다른 트랜잭션 차단)\n\nUPDATE products SET price = 15000 WHERE id = 1;\nCOMMIT;\n-- Lock 해제\n\n-- Transaction 2\nSELECT * FROM products WHERE id = 1 FOR UPDATE;\n-- Transaction 1이 끝날 때까지 대기...\n```\n\n**Java 예시 (JPA):**\n```java\n// Pessimistic Write Lock\nProduct product = em.find(\n    Product.class, \n    1L, \n    LockModeType.PESSIMISTIC_WRITE\n);\n// SELECT ... FOR UPDATE 실행\n\nproduct.setPrice(new BigDecimal(\"15000\"));\nem.getTransaction().commit();\n// Lock 해제\n```\n\n**장점:**\n- 충돌 발생 안 함 (미리 차단)\n- 데이터 일관성 확실\n\n**단점:**\n- 성능 저하 (Lock 대기)\n- Deadlock 위험\n- 동시성 낮음\n\n**사용 사례:**\n- 충돌이 자주 발생하는 경우\n- 쓰기가 많은 경우\n- 데이터 정합성이 매우 중요\n- 금융 거래, 재고 관리\n\n---\n\n**비교:**\n\n| | Optimistic Lock | Pessimistic Lock |\n|----------|-----------------|------------------|\n| 충돌 가정 | 드물다 | 자주 발생 |\n| Lock 시점 | 커밋 시 | 읽기 시 |\n| 성능 | 좋음 | 나쁨 |\n| 동시성 | 높음 | 낮음 |\n| Deadlock | 없음 | 있음 |\n| 재시도 | 필요 | 불필요 |\n| 사용 | 웹, 읽기 많음 | 금융, 쓰기 많음 |\n\n---\n\n**실무 사례:**\n\n**Optimistic Lock:**\n```java\n// 게시글 조회수 증가 (충돌 드뭄)\n@Transactional\npublic void increaseViewCount(Long postId) {\n    Post post = postRepository.findById(postId);\n    post.increaseViewCount();\n    // @Version으로 Optimistic Lock\n}\n```\n\n**Pessimistic Lock:**\n```java\n// 재고 차감 (동시 주문 많음)\n@Transactional\npublic void decreaseStock(Long productId, int quantity) {\n    Product product = productRepository.findByIdWithLock(productId);\n    // SELECT ... FOR UPDATE\n    \n    if (product.getStock() < quantity) {\n        throw new OutOfStockException();\n    }\n    \n    product.decreaseStock(quantity);\n}\n```\n\n**결론:**\n- 읽기 많음, 충돌 드뭄 → Optimistic Lock\n- 쓰기 많음, 충돌 빈번 → Pessimistic Lock",
      "type": "essay",
      "tags": ["Optimistic Lock", "Pessimistic Lock", "동시성", "버전 관리"]
    },
    {
      "question": "물리적인 Lock을 건다면, 만약 이를 수행중인 요청에 문제가 생겨 비정상 종료되면 Lock이 절대 해제되지 않는 문제가 생길 수도 있을 것 같습니다. DB는 이를 위한 해결책이 있나요? 없다면, 우리가 이 문제를 해결할 수 없을까요?",
      "answer": "**네, DBMS는 이 문제를 자동으로 해결합니다.**\n\n**DBMS의 자동 Lock 해제:**\n\n**1. 트랜잭션 종료 시 자동 해제**\n\n모든 Lock은 **트랜잭션에 종속**되어 있어서, 트랜잭션이 종료(COMMIT/ROLLBACK)되면 자동으로 해제됩니다.\n\n```sql\nSTART TRANSACTION;\nSELECT * FROM accounts WHERE id = 1 FOR UPDATE;\n-- Lock 획득\n\n-- ⚠️ 여기서 애플리케이션이 비정상 종료되면?\nCOMMIT;  -- 실행 안 됨\n```\n\n**2. 연결(Connection) 종료 시 자동 Rollback**\n\n애플리케이션이 비정상 종료되면:\n```\n1. DB Connection 끊어짐\n2. DBMS가 감지 → 자동 ROLLBACK\n3. 모든 Lock 해제\n```\n\n**MySQL 예시:**\n```sql\n-- Session 1\nmysql> START TRANSACTION;\nmysql> UPDATE accounts SET balance = 1000 WHERE id = 1;\n-- Lock 획득\n\n-- (애플리케이션 강제 종료)\n-- Connection 끊어짐\n\n-- Session 2\nmysql> SELECT * FROM information_schema.INNODB_TRX;\n-- 트랜잭션 자동 ROLLBACK됨\n-- Lock 자동 해제됨\n```\n\n---\n\n**3. Timeout 설정**\n\n**Lock Wait Timeout:**\n```sql\n-- MySQL\nSET innodb_lock_wait_timeout = 50;  -- 50초\n\n-- PostgreSQL\nSET lock_timeout = '30s';  -- 30초\n\n-- Lock을 기다리다가 타임아웃되면 에러 발생\n```\n\n**Idle Transaction Timeout:**\n```sql\n-- PostgreSQL\nSET idle_in_transaction_session_timeout = '60s';\n\n-- MySQL 8.0.31+\nSET SESSION innodb_idle_transaction_timeout = 60;  -- 60초\n\n-- 트랜잭션이 60초 동안 아무것도 안 하면 자동 ROLLBACK\n```\n\n---\n\n**4. 강제 Kill**\n\n관리자가 수동으로 프로세스를 종료할 수 있습니다.\n\n**MySQL:**\n```sql\n-- 실행 중인 프로세스 확인\nSHOW PROCESSLIST;\n\n+----+------+-----------+------+---------+------+-------+------------------+\n| Id | User | Host      | db   | Command | Time | State | Info             |\n+----+------+-----------+------+---------+------+-------+------------------+\n| 10 | user | localhost | test | Sleep   | 3600 |       | NULL             |\n+----+------+-----------+------+---------+------+-------+------------------+\n\n-- 강제 종료\nKILL 10;\n-- 트랜잭션 ROLLBACK, Lock 해제\n```\n\n**PostgreSQL:**\n```sql\n-- 프로세스 확인\nSELECT pid, usename, state, query FROM pg_stat_activity;\n\n-- 강제 종료\nSELECT pg_terminate_backend(12345);\n```\n\n---\n\n**5. Deadlock Detection**\n\nDBMS는 **Deadlock을 자동으로 감지**하고, 하나의 트랜잭션을 Rollback합니다.\n\n```sql\n-- Transaction 1\nUPDATE accounts SET balance = balance - 100 WHERE id = 1;  -- Lock A\nUPDATE accounts SET balance = balance + 100 WHERE id = 2;  -- Lock B 대기\n\n-- Transaction 2  \nUPDATE accounts SET balance = balance - 50 WHERE id = 2;   -- Lock B\nUPDATE accounts SET balance = balance + 50 WHERE id = 1;   -- Lock A 대기\n\n-- Deadlock 발생!\n-- MySQL이 자동 감지 → Transaction 2를 ROLLBACK\n-- ERROR 1213: Deadlock found when trying to get lock\n```\n\n---\n\n**애플리케이션 레벨 해결책:**\n\n**1. Connection Pool Timeout**\n```java\n// HikariCP 설정\nHikariConfig config = new HikariConfig();\nconfig.setConnectionTimeout(30000);  // 30초\nconfig.setMaxLifetime(600000);       // 10분\n\n// Connection이 30초 이상 idle이면 반환\n```\n\n**2. Try-with-resources (자동 close)**\n```java\ntry (Connection conn = dataSource.getConnection()) {\n    conn.setAutoCommit(false);\n    \n    // ... 작업 ...\n    \n    conn.commit();\n} catch (Exception e) {\n    // 자동으로 close() 호출 → Connection 반환 → ROLLBACK\n}\n// finally 블록 불필요\n```\n\n**3. Spring @Transactional**\n```java\n@Transactional\npublic void transfer(Long from, Long to, BigDecimal amount) {\n    // 예외 발생 시 자동 ROLLBACK\n    // 메서드 종료 시 자동 COMMIT\n}\n// Spring이 자동으로 트랜잭션 관리\n```\n\n**4. Health Check & Monitoring**\n```java\n// 주기적으로 긴 트랜잭션 감지\nSELECT * FROM information_schema.INNODB_TRX\nWHERE trx_started < NOW() - INTERVAL 5 MINUTE;\n\n// 알람 발생 → 조사\n```\n\n---\n\n**결론:**\n\n1. **DBMS가 자동 해결**:\n   - Connection 끊어지면 자동 ROLLBACK\n   - 트랜잭션 종료 시 Lock 자동 해제\n   - Deadlock 자동 감지 및 해결\n\n2. **추가 보호 장치**:\n   - Timeout 설정\n   - Connection Pool 관리\n   - Monitoring 및 Alert\n\n**Lock이 영구히 유지되는 일은 발생하지 않습니다!**",
      "type": "essay",
      "tags": ["Lock", "트랜잭션", "Connection", "Timeout"]
    },
    {
      "question": "트래픽이 높아질 때, DB는 어떻게 관리를 할 수 있을까요?",
      "answer": "**트래픽 증가 시 DB 관리 전략:**\n\n**1. Scale-Up (수직 확장)**\n\n서버 성능 업그레이드\n```\n- CPU: 4코어 → 16코어\n- RAM: 16GB → 128GB\n- SSD: SATA → NVMe\n\n장점: 구현 간단\n단점: 한계 있음, 비용 급증\n```\n\n**2. Scale-Out (수평 확장)**\n\n**레플리케이션 (Replication)**\n```sql\n-- Master-Slave 구조\nMaster (쓰기) ──┬─→ Slave 1 (읽기)\n                ├─→ Slave 2 (읽기)\n                └─→ Slave 3 (읽기)\n\n-- 읽기 부하 분산\nSELECT * FROM users;  -- Slave에서 조회\nINSERT INTO users;    -- Master에만 쓰기\n\n장점:\n- 읽기 성능 향상\n- 가용성 향상 (Failover)\n\n단점:\n- 쓰기는 여전히 Master만\n- 복제 지연 (Replication Lag)\n```\n\n**샤딩 (Sharding)**\n```sql\n-- 데이터를 여러 DB에 분산\nShard 1: user_id 1 ~ 1,000,000\nShard 2: user_id 1,000,001 ~ 2,000,000\nShard 3: user_id 2,000,001 ~ 3,000,000\n\n장점:\n- 쓰기/읽기 모두 분산\n- 진정한 수평 확장\n\n단점:\n- 복잡한 구현\n- JOIN 어려움\n- 샤드 키 선택 중요\n```\n\n---\n\n**3. 캐싱 (Caching)**\n\n**Application Cache (Redis, Memcached)**\n```java\n// 1. 캐시 확인\nUser user = redisTemplate.opsForValue().get(\"user:\" + userId);\n\nif (user == null) {\n    // 2. DB 조회\n    user = userRepository.findById(userId);\n    \n    // 3. 캐시 저장\n    redisTemplate.opsForValue().set(\"user:\" + userId, user, 1, TimeUnit.HOURS);\n}\n\nreturn user;\n\n효과:\n- DB 부하 90% 이상 감소\n- 응답 속도 10~100배 향상\n```\n\n**Query Cache**\n```sql\n-- MySQL (8.0 이전)\nSET query_cache_type = ON;\n\n-- 같은 쿼리는 캐시에서 반환\nSELECT * FROM products WHERE category = 'Electronics';\n```\n\n---\n\n**4. 인덱스 최적화**\n\n```sql\n-- 느린 쿼리 찾기\nSHOW PROCESSLIST;\nSLOW QUERY LOG 분석\n\n-- 인덱스 추가\nCREATE INDEX idx_user_created ON users(created_at);\nCREATE INDEX idx_order_status ON orders(status, created_at);\n\n효과:\n- 쿼리 속도 100배 이상 향상 가능\n```\n\n---\n\n**5. Connection Pool 최적화**\n\n```java\n// HikariCP 설정\nHikariConfig config = new HikariConfig();\nconfig.setMaximumPoolSize(20);      // Connection 개수\nconfig.setMinimumIdle(10);           // 최소 idle\nconfig.setConnectionTimeout(30000);  // 30초\n\n// 적절한 Pool 크기 = (CPU 코어 수 × 2) + 디스크 수\n```\n\n---\n\n**6. 쿼리 최적화**\n\n```sql\n-- ❌ 나쁜 예\nSELECT * FROM orders;  -- 전체 컬럼\nSELECT * FROM users WHERE YEAR(created_at) = 2024;  -- 함수 사용\n\n-- ✅ 좋은 예\nSELECT id, user_id, total FROM orders;  -- 필요한 컬럼만\nSELECT * FROM users WHERE created_at >= '2024-01-01';  -- 인덱스 사용\n```\n\n---\n\n**7. 파티셔닝 (Partitioning)**\n\n```sql\n-- 날짜별 파티션\nCREATE TABLE orders (\n    id INT,\n    created_at DATE,\n    ...\n) PARTITION BY RANGE (YEAR(created_at)) (\n    PARTITION p2022 VALUES LESS THAN (2023),\n    PARTITION p2023 VALUES LESS THAN (2024),\n    PARTITION p2024 VALUES LESS THAN (2025)\n);\n\n-- 2024년 데이터만 조회 → p2024 파티션만 스캔\nSELECT * FROM orders WHERE created_at >= '2024-01-01';\n\n효과:\n- 쿼리 속도 향상\n- 오래된 데이터 삭제 용이\n```\n\n---\n\n**8. 비동기 처리**\n\n```java\n// 즉시 응답 필요 없는 작업은 Queue로\n@Async\npublic void sendEmail(User user) {\n    // 메일 발송 (DB 부하 X)\n}\n\n// Message Queue (Kafka, RabbitMQ)\nproducer.send(\"order.created\", order);\n// 나중에 Consumer가 처리\n```\n\n---\n\n**9. NoSQL 활용**\n\n```java\n// 읽기 많은 데이터 → Redis\nredis.set(\"user:profile:\" + userId, userProfile);\n\n// 로그 데이터 → MongoDB\nmongo.insert(\"logs\", logData);\n\n// 그래프 데이터 → Neo4j\nneo4j.query(\"MATCH (user)-[:FRIEND]->(friend)\");\n```\n\n---\n\n**10. CDN & Static Content**\n\n```\n이미지, CSS, JS → CDN\n동적 데이터만 DB 조회\n```\n\n---\n\n**실무 단계별 대응:**\n\n```\n트래픽 10배 증가:\n1. 캐싱 추가 (Redis)\n2. 인덱스 최적화\n3. Connection Pool 조정\n\n트래픽 100배 증가:\n4. Read Replica 추가 (Replication)\n5. 쿼리 최적화\n6. NoSQL 도입\n\n트래픽 1000배 증가:\n7. 샤딩\n8. 마이크로서비스 분리\n9. CQRS 패턴\n```\n\n**결론:**\n캐싱 → 레플리케이션 → 샤딩 순으로 단계적 확장",
      "type": "essay",
      "tags": ["트래픽", "확장성", "캐싱", "레플리케이션", "샤딩"]
    },
    {
      "question": "DB 서버를 분산하지 않고, 트래픽을 감당할 수 있는 방법은 없을까요?",
      "answer": "**네, DB 분산 없이도 트래픽을 감당할 방법들이 많습니다.**\n\n**1. 캐싱 (가장 효과적) ⭐⭐⭐**\n\n**Redis/Memcached:**\n```java\n// 캐시 적용 전: DB 쿼리 100ms\n// 캐시 적용 후: Redis 조회 1ms (100배 빠름)\n\n@Cacheable(value = \"users\", key = \"#userId\")\npublic User getUser(Long userId) {\n    return userRepository.findById(userId);\n}\n\n// 첫 조회: DB → 100ms\n// 이후 조회: Cache → 1ms\n\n효과: DB 부하 90% 이상 감소\n```\n\n---\n\n**2. 쿼리 최적화**\n\n```sql\n-- ❌ 나쁜 예 (10초)\nSELECT * FROM orders o\nLEFT JOIN users u ON o.user_id = u.id\nWHERE YEAR(o.created_at) = 2024;\n\n-- ✅ 좋은 예 (0.1초)\nCREATE INDEX idx_created ON orders(created_at);\nCREATE INDEX idx_user_id ON orders(user_id);\n\nSELECT o.id, o.total, u.name\nFROM orders o\nJOIN users u ON o.user_id = u.id\nWHERE o.created_at >= '2024-01-01' \n  AND o.created_at < '2025-01-01';\n\n-- 100배 빠름!\n```\n\n---\n\n**3. 인덱스 최적화**\n\n```sql\n-- 자주 조회하는 컬럼에 인덱스\nCREATE INDEX idx_email ON users(email);\nCREATE INDEX idx_status_created ON orders(status, created_at);\n\n-- 커버링 인덱스\nCREATE INDEX idx_covering \nON orders(user_id, status, created_at, total);\n-- 테이블 접근 없이 인덱스만으로 조회\n\nEXPLAIN:\nExtra: Using index  -- 매우 빠름\n```\n\n---\n\n**4. Connection Pool 최적화**\n\n```java\n// Connection Pool 크기 조정\nHikariConfig config = new HikariConfig();\nconfig.setMaximumPoolSize(50);  // 동시 접속 50개\nconfig.setMinimumIdle(20);       // 최소 20개 유지\n\n// 적절한 크기 = (CPU 코어 × 2) + 효율적 디스크 수\n// 예: 8코어 → 16~20개 Connection\n\n효과: Connection 재사용으로 오버헤드 감소\n```\n\n---\n\n**5. DB 설정 튜닝**\n\n**MySQL InnoDB:**\n```ini\n# my.cnf\ninnodb_buffer_pool_size = 8G  # 메모리의 70-80%\ninnodb_log_file_size = 512M\ninnodb_flush_log_at_trx_commit = 2  # 성능 향상 (약간 안전성 저하)\nmax_connections = 500  # 최대 연결 수\n\n효과: 메모리 캐싱 증가 → 디스크 I/O 감소\n```\n\n---\n\n**6. 파티셔닝**\n\n```sql\n-- 날짜별 파티션\nCREATE TABLE logs (\n    id BIGINT,\n    message TEXT,\n    created_at DATE\n) PARTITION BY RANGE (YEAR(created_at)) (\n    PARTITION p2023 VALUES LESS THAN (2024),\n    PARTITION p2024 VALUES LESS THAN (2025)\n);\n\n-- 2024년 데이터만 조회 → p2024만 스캔\nSELECT * FROM logs WHERE created_at >= '2024-01-01';\n\n효과: 쿼리 범위 축소 → 빠른 조회\n```\n\n---\n\n**7. SELECT 최소화**\n\n```sql\n-- ❌ 나쁜 예\nSELECT * FROM users;  -- 모든 컬럼\n\n-- ✅ 좋은 예\nSELECT id, name, email FROM users;  -- 필요한 것만\n\n효과: 네트워크 트래픽 감소, 메모리 사용 감소\n```\n\n---\n\n**8. Batch Processing**\n\n```java\n// ❌ 나쁜 예 (N번 쿼리)\nfor (User user : users) {\n    userRepository.save(user);  // INSERT × 1000\n}\n\n// ✅ 좋은 예 (1번 쿼리)\nuserRepository.saveAll(users);  // INSERT × 1 (Batch)\n\n// SQL\nINSERT INTO users (name, email) VALUES\n    ('A', 'a@example.com'),\n    ('B', 'b@example.com'),\n    ...  -- 1000개\n\n효과: 1000번 → 1번 (1000배 빠름)\n```\n\n---\n\n**9. 비동기 처리**\n\n```java\n// 즉시 응답이 필요 없는 작업은 비동기로\n@Async\npublic void updateStatistics() {\n    // 통계 업데이트 (백그라운드)\n}\n\n// Message Queue\nkafkaTemplate.send(\"notifications\", notification);\n// 나중에 처리 → DB 부하 분산\n```\n\n---\n\n**10. Denormalization (역정규화)**\n\n```sql\n-- 정규화된 테이블\nSELECT o.id, u.name, p.name\nFROM orders o\nJOIN users u ON o.user_id = u.id\nJOIN products p ON o.product_id = p.id;\n-- 3개 테이블 JOIN → 느림\n\n-- 역정규화 (자주 조회하는 경우)\nCREATE TABLE orders (\n    id INT,\n    user_name VARCHAR(100),  -- 중복 저장\n    product_name VARCHAR(100),  -- 중복 저장\n    total DECIMAL\n);\n\nSELECT * FROM orders;\n-- JOIN 없이 빠름!\n```\n\n---\n\n**11. 읽기 전용 복제본 (단일 서버 내)**\n\n```sql\n-- MySQL Group Replication (단일 서버 내 복제)\n-- 메모리/CPU가 충분하면 가능\n```\n\n---\n\n**12. HTTP Caching**\n\n```java\n@GetMapping(\"/api/products/{id}\")\npublic ResponseEntity<Product> getProduct(@PathVariable Long id) {\n    Product product = productService.findById(id);\n    \n    return ResponseEntity.ok()\n        .cacheControl(CacheControl.maxAge(1, TimeUnit.HOURS))\n        .eTag(String.valueOf(product.getVersion()))\n        .body(product);\n}\n\n// 브라우저/CDN이 캐싱 → DB 조회 없음\n```\n\n---\n\n**효과 순위:**\n\n```\n1. 캐싱 (Redis):           90% 부하 감소 ⭐⭐⭐\n2. 인덱스 최적화:          70% 속도 향상 ⭐⭐⭐\n3. 쿼리 최적화:            50% 속도 향상 ⭐⭐\n4. Connection Pool:        30% 개선 ⭐⭐\n5. DB 튜닝:                20% 개선 ⭐\n6. 비동기 처리:            30% 부하 감소 ⭐⭐\n7. Batch Processing:       대량 작업 1000배 ⭐⭐⭐\n```\n\n**결론:**\n**캐싱 + 인덱스 + 쿼리 최적화**만으로도 트래픽 10~100배 감당 가능!",
      "type": "essay",
      "tags": ["성능 최적화", "캐싱", "인덱스", "쿼리 최적화"]
    },
    {
      "question": "Schema가 무엇인가요?",
      "answer": "**Schema (스키마):**\n\n데이터베이스의 **구조와 제약조건**을 정의하는 청사진입니다.\n\n**포함 내용:**\n1. 테이블 구조 (컬럼, 데이터 타입)\n2. 제약조건 (PRIMARY KEY, FOREIGN KEY, UNIQUE, NOT NULL)\n3. 인덱스\n4. 뷰, 프로시저, 트리거\n5. 테이블 간 관계\n\n**예시:**\n```sql\n-- Schema 정의\nCREATE SCHEMA ecommerce;\n\nUSE ecommerce;\n\nCREATE TABLE users (\n    id INT PRIMARY KEY AUTO_INCREMENT,\n    email VARCHAR(255) UNIQUE NOT NULL,\n    name VARCHAR(100) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE orders (\n    id INT PRIMARY KEY AUTO_INCREMENT,\n    user_id INT NOT NULL,\n    total DECIMAL(10,2) NOT NULL,\n    status ENUM('pending', 'completed', 'cancelled'),\n    FOREIGN KEY (user_id) REFERENCES users(id)\n);\n```\n\n**3계층 스키마 아키텍처:**\n\n**1. 외부 스키마 (External Schema / View Level)**\n- 사용자 관점의 데이터\n- 각 사용자 그룹마다 다른 뷰\n\n**2. 개념 스키마 (Conceptual Schema / Logical Level)**\n- 전체 데이터베이스의 논리적 구조\n- 테이블, 관계, 제약조건\n\n**3. 내부 스키마 (Internal Schema / Physical Level)**\n- 물리적 저장 구조\n- 인덱스, 파일 구조, 저장 방식\n\n**결론:**\nSchema는 데이터베이스의 설계도로, 데이터 구조와 규칙을 명확히 정의합니다.",
      "type": "essay",
      "tags": ["Schema", "데이터베이스 설계", "스키마"]
    },
    {
      "question": "3계층에 대해 설명해 주세요.",
      "answer": "**3계층 스키마 아키텍처 (Three-Level Schema Architecture):**\n\nANSI-SPARC에서 제안한 데이터베이스 추상화 모델로, **데이터 독립성**을 제공합니다.\n\n---\n\n**1. 외부 스키마 (External Schema)**\n\n**= View Level, User View**\n\n- **사용자 관점**의 데이터베이스\n- 각 사용자 그룹마다 필요한 데이터만 보여줌\n- 여러 개의 외부 스키마 존재 가능\n\n**예시:**\n```sql\n-- 일반 사용자용 뷰\nCREATE VIEW customer_orders AS\nSELECT o.id, o.total, o.status, o.created_at\nFROM orders o\nWHERE o.user_id = CURRENT_USER_ID();\n-- 자신의 주문만 보임\n\n-- 관리자용 뷰\nCREATE VIEW admin_orders AS\nSELECT o.id, o.user_id, u.email, o.total, o.status\nFROM orders o\nJOIN users u ON o.user_id = u.id;\n-- 모든 주문 정보\n```\n\n**특징:**\n- 보안: 민감한 정보 숨김\n- 단순화: 복잡한 구조를 단순하게\n\n---\n\n**2. 개념 스키마 (Conceptual Schema)**\n\n**= Logical Level, Community View**\n\n- **전체 데이터베이스**의 논리적 구조\n- 모든 사용자가 필요로 하는 데이터 통합\n- **하나**의 개념 스키마만 존재\n\n**예시:**\n```sql\nCREATE TABLE users (\n    id INT PRIMARY KEY,\n    email VARCHAR(255) UNIQUE,\n    name VARCHAR(100),\n    password_hash VARCHAR(255),\n    created_at TIMESTAMP\n);\n\nCREATE TABLE orders (\n    id INT PRIMARY KEY,\n    user_id INT,\n    total DECIMAL(10,2),\n    status VARCHAR(20),\n    created_at TIMESTAMP,\n    FOREIGN KEY (user_id) REFERENCES users(id)\n);\n```\n\n**특징:**\n- 전체 데이터베이스의 논리적 구조\n- 엔티티, 관계, 제약조건 정의\n- 물리적 저장 방식과 무관\n\n---\n\n**3. 내부 스키마 (Internal Schema)**\n\n**= Physical Level, Storage View**\n\n- **물리적 저장** 구조\n- 디스크에 어떻게 저장되는지\n- **하나**의 내부 스키마만 존재\n\n**예시:**\n```sql\n-- 인덱스 정의\nCREATE INDEX idx_user_email ON users(email) USING BTREE;\nCREATE INDEX idx_order_user ON orders(user_id) USING BTREE;\n\n-- 파티셔닝\nCREATE TABLE orders (\n    ...\n) PARTITION BY RANGE (YEAR(created_at)) (\n    PARTITION p2023 VALUES LESS THAN (2024),\n    PARTITION p2024 VALUES LESS THAN (2025)\n);\n\n-- 스토리지 엔진\nCREATE TABLE users (...) ENGINE=InnoDB;\n```\n\n**특징:**\n- 데이터 저장 방식\n- 인덱스 구조 (B-Tree, Hash)\n- 파일 구조, 압축, 암호화\n\n---\n\n**데이터 독립성 (Data Independence):**\n\n**1. 논리적 독립성 (Logical Independence)**\n\n개념 스키마가 변경되어도 외부 스키마는 영향 받지 않음\n\n```sql\n-- 개념 스키마 변경: 컬럼 추가\nALTER TABLE users ADD COLUMN phone VARCHAR(20);\n\n-- 기존 외부 스키마는 그대로 동작\nCREATE VIEW customer_profile AS\nSELECT id, email, name FROM users;\n-- phone 컬럼과 무관하게 동작\n```\n\n**2. 물리적 독립성 (Physical Independence)**\n\n내부 스키마가 변경되어도 개념 스키마는 영향 받지 않음\n\n```sql\n-- 내부 스키마 변경: 인덱스 추가\nCREATE INDEX idx_name ON users(name);\n\n-- 개념 스키마는 변경 없음\nSELECT * FROM users WHERE name = '홍길동';\n-- 자동으로 새 인덱스 사용 (애플리케이션 수정 불필요)\n```\n\n---\n\n**매핑 (Mapping):**\n\n**외부/개념 매핑:**\n- View를 통해 개념 스키마를 외부 스키마로 변환\n\n**개념/내부 매핑:**\n- 논리적 구조를 물리적 저장 구조로 변환\n\n---\n\n**실제 예시:**\n\n```\n외부 스키마 (External):\n- 고객 앱: \"내 주문 목록\"\n- 관리자 패널: \"모든 주문 + 통계\"\n- API: JSON 형식의 주문 데이터\n\n         ↕ (외부/개념 매핑)\n\n개념 스키마 (Conceptual):\n- users 테이블\n- orders 테이블\n- products 테이블\n- FOREIGN KEY 관계\n\n         ↕ (개념/내부 매핑)\n\n내부 스키마 (Internal):\n- InnoDB 스토리지 엔진\n- B+Tree 인덱스\n- 2024년 파티션에 저장\n- SSD에 물리적 저장\n```\n\n**장점:**\n1. **데이터 독립성**: 한 레벨의 변경이 다른 레벨에 영향 X\n2. **보안**: 외부 스키마로 접근 제어\n3. **유연성**: 다양한 사용자 요구 충족\n4. **유지보수성**: 변경 영향 최소화\n\n**결론:**\n3계층 아키텍처는 데이터 독립성과 유연성을 제공하여 효율적인 데이터베이스 관리를 가능하게 합니다.",
      "type": "essay",
      "tags": ["3계층", "스키마", "데이터 독립성", "아키텍처"]
    },
    {
      "question": "DB의 Connection Pool에 대해 설명해 주세요.",
      "answer": "**Connection Pool:**\n\n미리 생성한 DB 연결(Connection)을 **풀에 저장**해두고 **재사용**하는 기법입니다.\n\n---\n\n**Connection Pool 없이 (매번 생성):**\n\n```java\n// 요청마다 새 Connection 생성\npublic User getUser(Long id) {\n    Connection conn = DriverManager.getConnection(url, user, password);\n    // 1. TCP 연결 (3-way handshake)\n    // 2. 인증\n    // 3. 초기화\n    // 총 100~500ms 소요\n    \n    PreparedStatement stmt = conn.prepareStatement(\"SELECT * FROM users WHERE id = ?\");\n    ResultSet rs = stmt.executeQuery();\n    \n    // ... 처리 ...\n    \n    conn.close();  // 연결 종료\n    // 다음 요청 때 다시 생성 (비효율)\n}\n\n문제점:\n- Connection 생성/종료 오버헤드 큼\n- 동시 요청 많으면 DB 연결 수 폭증\n- 성능 저하\n```\n\n---\n\n**Connection Pool 사용:**\n\n```java\n// 애플리케이션 시작 시 미리 생성\nHikariConfig config = new HikariConfig();\nconfig.setJdbcUrl(\"jdbc:mysql://localhost:3306/mydb\");\nconfig.setUsername(\"user\");\nconfig.setPassword(\"password\");\nconfig.setMaximumPoolSize(20);  // 최대 20개 Connection\nconfig.setMinimumIdle(10);       // 최소 10개 유지\n\nHikariDataSource dataSource = new HikariDataSource(config);\n\n// 사용\npublic User getUser(Long id) {\n    Connection conn = dataSource.getConnection();  // Pool에서 빌려옴 (빠름!)\n    // 이미 생성된 Connection 재사용 → 1ms\n    \n    PreparedStatement stmt = conn.prepareStatement(\"SELECT * FROM users WHERE id = ?\");\n    ResultSet rs = stmt.executeQuery();\n    \n    // ... 처리 ...\n    \n    conn.close();  // Pool에 반환 (실제로 종료 X)\n}\n\n장점:\n- Connection 생성/종료 오버헤드 제거\n- 빠른 응답 (100ms → 1ms)\n- DB 연결 수 제어\n```\n\n---\n\n**동작 원리:**\n\n```\n1. 애플리케이션 시작:\n   Pool: [C1, C2, C3, ... , C20]  -- 20개 미리 생성\n\n2. 요청 1:\n   Pool: [C2, C3, ... , C20]\n   사용 중: [C1]  -- C1 빌려감\n\n3. 요청 2:\n   Pool: [C3, ... , C20]\n   사용 중: [C1, C2]  -- C2 빌려감\n\n4. 요청 1 완료:\n   Pool: [C3, ... , C20, C1]  -- C1 반환\n   사용 중: [C2]\n\n5. Pool이 비었을 때 새 요청:\n   → 대기 (timeout까지)\n   → 또는 새로 생성 (maxPoolSize까지)\n```\n\n---\n\n**주요 설정:**\n\n```java\n// HikariCP (가장 빠른 Connection Pool)\nHikariConfig config = new HikariConfig();\n\n// 필수 설정\nconfig.setJdbcUrl(\"jdbc:mysql://localhost:3306/mydb\");\nconfig.setUsername(\"user\");\nconfig.setPassword(\"password\");\n\n// Pool 크기\nconfig.setMaximumPoolSize(20);  // 최대 연결 수\nconfig.setMinimumIdle(10);       // 최소 유휴 연결 수\n\n// Timeout\nconfig.setConnectionTimeout(30000);  // 30초 (Connection 대기 시간)\nconfig.setIdleTimeout(600000);       // 10분 (유휴 Connection 유지 시간)\nconfig.setMaxLifetime(1800000);      // 30분 (Connection 최대 수명)\n\n// 검증\nconfig.setConnectionTestQuery(\"SELECT 1\");  // Connection 유효성 검사\n```\n\n---\n\n**적절한 Pool 크기:**\n\n```\n공식: connections = ((core_count × 2) + effective_spindle_count)\n\n예시:\n- CPU 코어: 8개\n- HDD: 1개\n- 권장 Pool 크기: (8 × 2) + 1 = 17개\n\nSSD인 경우:\n- CPU 코어: 8개\n- 권장 Pool 크기: 16~20개\n\n주의:\n- Pool이 너무 크면: DB 부하 증가, 메모리 낭비\n- Pool이 너무 작으면: 요청 대기, 응답 지연\n```\n\n---\n\n**실무 예시:**\n\n**Spring Boot + HikariCP:**\n```yaml\n# application.yml\nspring:\n  datasource:\n    hikari:\n      maximum-pool-size: 20\n      minimum-idle: 10\n      connection-timeout: 30000\n      idle-timeout: 600000\n      max-lifetime: 1800000\n      connection-test-query: SELECT 1\n```\n\n```java\n@Service\npublic class UserService {\n    @Autowired\n    private JdbcTemplate jdbcTemplate;  // Connection Pool 사용\n    \n    public User getUser(Long id) {\n        return jdbcTemplate.queryForObject(\n            \"SELECT * FROM users WHERE id = ?\",\n            new Object[]{id},\n            new UserRowMapper()\n        );\n        // Connection Pool에서 자동으로 빌려오고 반환\n    }\n}\n```\n\n---\n\n**주요 Connection Pool 라이브러리:**\n\n1. **HikariCP** ⭐ (가장 빠름, Spring Boot 기본)\n2. **Apache DBCP2**\n3. **c3p0**\n4. **Tomcat JDBC Pool**\n\n**성능 비교:**\n```\nHikariCP:     100 req/sec (가장 빠름)\nTomcat Pool:   90 req/sec\nDBCP2:         80 req/sec\nc3p0:          70 req/sec\n```\n\n---\n\n**Connection Leak 방지:**\n\n```java\n// ❌ 나쁜 예 (Connection Leak)\npublic User getUser(Long id) {\n    Connection conn = dataSource.getConnection();\n    // ... 쿼리 실행 ...\n    // close() 안 하면 Pool에 반환 안 됨!\n}\n// Pool이 점점 고갈됨\n\n// ✅ 좋은 예 (Try-with-resources)\npublic User getUser(Long id) {\n    try (Connection conn = dataSource.getConnection();\n         PreparedStatement stmt = conn.prepareStatement(\"SELECT * FROM users WHERE id = ?\")) {\n        \n        stmt.setLong(1, id);\n        ResultSet rs = stmt.executeQuery();\n        // ... 처리 ...\n    }\n    // 자동으로 close() → Pool에 반환\n}\n```\n\n**결론:**\nConnection Pool은 DB 연결을 재사용하여 성능을 크게 향상시키는 필수적인 기법입니다.",
      "type": "essay",
      "tags": ["Connection Pool", "HikariCP", "성능", "DB 연결"]
    },
    {
      "question": "Client가 Connection을 어떻게 구성하는지 설명해 주세요.",
      "answer": "**Client의 Connection 구성 과정:**\n\n---\n\n**1. Driver 로딩**\n\n```java\n// JDBC Driver 로딩\nClass.forName(\"com.mysql.cj.jdbc.Driver\");\n\n// 또는 자동 로딩 (JDBC 4.0+)\n// DriverManager가 자동으로 classpath의 Driver 로드\n```\n\n---\n\n**2. Connection 생성**\n\n**방법 1: DriverManager 사용**\n```java\nString url = \"jdbc:mysql://localhost:3306/mydb\";\nString user = \"root\";\nString password = \"1234\";\n\nConnection conn = DriverManager.getConnection(url, user, password);\n\n// 내부 동작:\n// 1. TCP/IP 연결 (3-way handshake)\n// 2. MySQL 서버 인증\n// 3. 세션 초기화\n// 4. Connection 객체 반환\n```\n\n**방법 2: DataSource 사용 (권장)**\n```java\n// Connection Pool 사용\nHikariDataSource dataSource = new HikariDataSource(config);\n\nConnection conn = dataSource.getConnection();\n// Pool에서 기존 Connection 재사용 → 빠름\n```\n\n---\n\n**3. TCP/IP 연결 과정**\n\n```\nClient                         MySQL Server\n  |                                  |\n  |------- SYN -------------------→ |  (1. SYN)\n  |                                  |\n  | ←----- SYN-ACK ---------------- |  (2. SYN-ACK)\n  |                                  |\n  |------- ACK -------------------→ |  (3. ACK)\n  |                                  |\n  |=== TCP Connection 성립 ===|\n  |                                  |\n  |------- 인증 요청 ------------→ |  (4. Username/Password)\n  |                                  |\n  | ←----- 인증 성공 -------------- |  (5. OK)\n  |                                  |\n  |=== MySQL Connection 성립 ===|\n```\n\n---\n\n**4. Connection URL 구조**\n\n```\njdbc:mysql://localhost:3306/mydb?useSSL=false&serverTimezone=UTC\n└─┬─┘ └─┬─┘  └────┬────┘└┬─┘ └┬┘ └───────────┬───────────┘\n  │     │         │       │    │              │\n프로토콜 DBMS     호스트   포트 DB명         파라미터\n\n// 예시:\njdbc:mysql://192.168.1.100:3306/ecommerce?useUnicode=true&characterEncoding=UTF-8\n\n// PostgreSQL:\njdbc:postgresql://localhost:5432/mydb\n\n// Oracle:\njdbc:oracle:thin:@localhost:1521:orcl\n```\n\n---\n\n**5. Connection 설정**\n\n```java\nConnection conn = DriverManager.getConnection(url, user, password);\n\n// Auto-commit 설정\nconn.setAutoCommit(false);  // 수동 트랜잭션 관리\n\n// 트랜잭션 격리 수준\nconn.setTransactionIsolation(Connection.TRANSACTION_REPEATABLE_READ);\n\n// Read-only\nconn.setReadOnly(true);  // 읽기 전용 (성능 향상)\n\n// Timeout\nStatement stmt = conn.createStatement();\nstmt.setQueryTimeout(30);  // 30초\n```\n\n---\n\n**6. Statement 생성 및 실행**\n\n```java\n// Statement (비권장 - SQL Injection 위험)\nStatement stmt = conn.createStatement();\nResultSet rs = stmt.executeQuery(\"SELECT * FROM users WHERE id = 1\");\n\n// PreparedStatement (권장)\nPreparedStatement pstmt = conn.prepareStatement(\"SELECT * FROM users WHERE id = ?\");\npstmt.setLong(1, 1);\nResultSet rs = pstmt.executeQuery();\n\n// CallableStatement (저장 프로시저)\nCallableStatement cstmt = conn.prepareCall(\"{call getUserById(?)}\");\ncstmt.setLong(1, 1);\nResultSet rs = cstmt.executeQuery();\n```\n\n---\n\n**7. 결과 처리**\n\n```java\nResultSet rs = pstmt.executeQuery();\n\nwhile (rs.next()) {\n    Long id = rs.getLong(\"id\");\n    String name = rs.getString(\"name\");\n    String email = rs.getString(\"email\");\n    \n    User user = new User(id, name, email);\n    users.add(user);\n}\n```\n\n---\n\n**8. Connection 종료**\n\n```java\n// 명시적 종료\nrs.close();\npstmt.close();\nconn.close();\n\n// Try-with-resources (권장)\ntry (Connection conn = dataSource.getConnection();\n     PreparedStatement pstmt = conn.prepareStatement(\"SELECT * FROM users WHERE id = ?\");\n     ResultSet rs = pstmt.executeQuery()) {\n    \n    // 쿼리 처리\n    while (rs.next()) {\n        // ...\n    }\n    \n}  // 자동으로 close() 호출 (역순: rs → pstmt → conn)\n```\n\n---\n\n**실무 예시 (Spring JDBC):**\n\n```java\n@Configuration\npublic class DataSourceConfig {\n    \n    @Bean\n    public DataSource dataSource() {\n        HikariConfig config = new HikariConfig();\n        config.setJdbcUrl(\"jdbc:mysql://localhost:3306/mydb\");\n        config.setUsername(\"root\");\n        config.setPassword(\"1234\");\n        config.setMaximumPoolSize(20);\n        \n        return new HikariDataSource(config);\n    }\n    \n    @Bean\n    public JdbcTemplate jdbcTemplate(DataSource dataSource) {\n        return new JdbcTemplate(dataSource);\n    }\n}\n\n@Service\npublic class UserService {\n    \n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    \n    public User getUser(Long id) {\n        return jdbcTemplate.queryForObject(\n            \"SELECT * FROM users WHERE id = ?\",\n            new Object[]{id},\n            (rs, rowNum) -> new User(\n                rs.getLong(\"id\"),\n                rs.getString(\"name\"),\n                rs.getString(\"email\")\n            )\n        );\n        // Connection은 자동으로 Pool에서 빌려오고 반환됨\n    }\n}\n```\n\n---\n\n**Connection Pool 동작:**\n\n```java\n// 애플리케이션 시작 시\nHikariDataSource dataSource = new HikariDataSource(config);\n// → Pool에 10개 Connection 미리 생성\n\n// 요청 1\nConnection conn1 = dataSource.getConnection();  // Pool에서 빌림\n// Pool: [C2, C3, ..., C10]\n// 사용 중: [C1]\n\n// 요청 2\nConnection conn2 = dataSource.getConnection();  // Pool에서 빌림\n// Pool: [C3, ..., C10]\n// 사용 중: [C1, C2]\n\n// 요청 1 완료\nconn1.close();  // Pool에 반환 (실제 종료 X)\n// Pool: [C3, ..., C10, C1]\n// 사용 중: [C2]\n```\n\n**결론:**\nClient는 Driver 로딩 → Connection 생성 → Statement 실행 → 결과 처리 → Connection 종료의 과정을 거치며, Connection Pool을 사용하면 성능이 크게 향상됩니다.",
      "type": "essay",
      "tags": ["Connection", "JDBC", "DB 연결", "Client"]
    },
    {
      "question": "Table Full Scan, Index Range Scan에 대해 설명해 주세요.",
      "answer": "**Table Full Scan:**\n\n테이블의 **모든 행**을 처음부터 끝까지 순차적으로 읽는 방식입니다.\n\n**동작:**\n```sql\nSELECT * FROM users WHERE name = '홍길동';\n-- name에 인덱스 없음\n\n-- Full Scan:\n-- Row 1: name = '김철수' → 불일치 → 계속\n-- Row 2: name = '이영희' → 불일치 → 계속\n-- Row 3: name = '홍길동' → 일치! → 반환\n-- Row 4: name = '박민수' → 불일치 → 계속\n-- ... (모든 행 검사)\n```\n\n**EXPLAIN:**\n```sql\nEXPLAIN SELECT * FROM users WHERE name = '홍길동';\n\n+------+-------+------+------+\n| type | rows  | key  | Extra |\n+------+-------+------+------+\n| ALL  | 10000 | NULL | Using where |\n+------+-------+------+------+\n\ntype: ALL → Full Table Scan\nrows: 10000 → 10,000행 모두 검사\nkey: NULL → 인덱스 사용 안 함\n```\n\n**특징:**\n- 시간 복잡도: O(N)\n- 모든 행 검사 → 매우 느림\n- 디스크 I/O 많음\n\n**언제 사용될까?**\n1. 인덱스가 없을 때\n2. WHERE 조건이 없을 때 (`SELECT * FROM users`)\n3. 테이블이 매우 작을 때 (수백 행 이하)\n4. 대부분의 행을 조회할 때 (인덱스보다 Full Scan이 빠름)\n\n---\n\n**Index Range Scan:**\n\n인덱스를 사용하여 **특정 범위**의 행만 빠르게 찾는 방식입니다.\n\n**동작:**\n```sql\n-- name에 인덱스 있음\nCREATE INDEX idx_name ON users(name);\n\nSELECT * FROM users WHERE name = '홍길동';\n\n-- Index Range Scan:\n-- 1. 인덱스에서 '홍길동' 검색 (B+Tree 탐색)\n-- 2. 해당 행의 위치 (포인터) 찾기\n-- 3. 실제 테이블에서 데이터 조회\n-- 총 log(N) 시간\n```\n\n**EXPLAIN:**\n```sql\nEXPLAIN SELECT * FROM users WHERE name = '홍길동';\n\n+------+------+-----------+-------+\n| type | rows | key       | Extra |\n+------+------+-----------+-------+\n| ref  | 1    | idx_name  | NULL  |\n+------+------+-----------+-------+\n\ntype: ref → Index Range Scan\nrows: 1 → 1행만 검사\nkey: idx_name → 인덱스 사용\n```\n\n**특징:**\n- 시간 복잡도: O(log N)\n- 필요한 행만 검사 → 매우 빠름\n- 디스크 I/O 적음\n\n---\n\n**비교:**\n\n| | Table Full Scan | Index Range Scan |\n|----------|-----------------|------------------|\n| 속도 | 느림 O(N) | 빠름 O(log N) |\n| 인덱스 | 없음 | 있음 |\n| 디스크 I/O | 많음 | 적음 |\n| 검사 행 수 | 모든 행 | 필요한 행만 |\n| EXPLAIN type | ALL | ref, range |\n| 사용 사례 | 작은 테이블, 전체 조회 | 큰 테이블, 조건 조회 |\n\n---\n\n**범위 조회 (Range Scan):**\n\n```sql\nSELECT * FROM orders \nWHERE created_at BETWEEN '2024-01-01' AND '2024-12-31';\n\n-- created_at에 인덱스 있음\nCREATE INDEX idx_created ON orders(created_at);\n\nEXPLAIN:\ntype: range  -- Index Range Scan\nrows: 1000   -- 범위에 해당하는 행만\nkey: idx_created\nExtra: Using index condition\n```\n\n---\n\n**Index Only Scan (커버링 인덱스):**\n\n```sql\nCREATE INDEX idx_name_email ON users(name, email);\n\nSELECT name, email FROM users WHERE name = '홍길동';\n-- 테이블 접근 없이 인덱스만으로 조회\n\nEXPLAIN:\ntype: ref\nkey: idx_name_email\nExtra: Using index  -- 커버링 인덱스 (가장 빠름)\n```\n\n---\n\n**성능 차이:**\n\n```\n테이블: 1,000,000행\n\nTable Full Scan:\n- 1,000,000행 모두 검사\n- 시간: 10초\n\nIndex Range Scan:\n- log₂(1,000,000) ≈ 20번 탐색\n- 시간: 0.01초\n\n1000배 빠름!\n```\n\n---\n\n**언제 Full Scan이 더 빠를까?**\n\n```sql\n-- 대부분의 행을 조회할 때\nSELECT * FROM users WHERE status = 'active';\n-- 90% 이상이 active 상태\n\n-- Full Scan:\n-- 1,000,000행 순차 읽기 → 2초\n\n-- Index Range Scan:\n-- 인덱스 탐색 + 900,000번 테이블 접근 → 10초\n-- 오히려 더 느림!\n\nMySQL 옵티마이저가 자동으로 Full Scan 선택\n```\n\n**결론:**\n- 작은 테이블, 대부분 조회: Full Scan\n- 큰 테이블, 일부 조회: Index Range Scan\n- 옵티마이저가 자동으로 최적 방식 선택",
      "type": "essay",
      "tags": ["Full Scan", "Index Range Scan", "성능", "EXPLAIN"]
    },
    {
      "question": "인덱스를 타는 쿼리임에도 Table Full Scan 방식으로 동작하는 경우가 있습니다. 왜 그럴까요?",
      "answer": "옵티마이저가 **Full Scan이 더 효율적**이라고 판단하는 경우입니다.\n\n**1. 조회 범위가 너무 넓을 때**\n\n```sql\n-- users 테이블: 1,000,000행\n-- status='active'인 행: 900,000행 (90%)\n\nCREATE INDEX idx_status ON users(status);\n\nSELECT * FROM users WHERE status = 'active';\n\nEXPLAIN:\ntype: ALL  -- Full Scan 선택\n\n이유:\n- Index Scan: 인덱스 탐색 + 900,000번 테이블 접근 = 느림\n- Full Scan: 1,000,000행 순차 읽기 = 빠름\n\n일반적으로 20-30% 이상 조회 시 Full Scan이 유리\n```\n\n---\n\n**2. 인덱스 선택도(Selectivity)가 낮을 때**\n\n```sql\n-- 선택도 = 고유 값 개수 / 전체 행 수\n\nCREATE TABLE users (\n    id INT,\n    gender CHAR(1),  -- 'M', 'F' (2개 값만)\n    INDEX idx_gender (gender)\n);\n\nSELECT * FROM users WHERE gender = 'M';\n-- 50%가 'M' → Full Scan이 더 빠름\n\nEXPLAIN:\ntype: ALL  -- 옵티마이저가 Full Scan 선택\n\n선택도가 낮은 컬럼 (boolean, gender, status 등):\n→ 인덱스 효과 적음\n```\n\n---\n\n**3. 함수를 사용한 경우**\n\n```sql\nCREATE INDEX idx_created ON orders(created_at);\n\n-- ❌ 인덱스 사용 안 됨\nSELECT * FROM orders WHERE YEAR(created_at) = 2024;\n\nEXPLAIN:\ntype: ALL  -- Full Scan\n\n이유: 함수(YEAR)를 적용하면 인덱스 무효화\n\n-- ✅ 인덱스 사용\nSELECT * FROM orders \nWHERE created_at >= '2024-01-01' AND created_at < '2025-01-01';\n\nEXPLAIN:\ntype: range  -- Index Range Scan\n```\n\n---\n\n**4. 데이터 타입 불일치**\n\n```sql\nCREATE TABLE users (\n    phone VARCHAR(20),\n    INDEX idx_phone (phone)\n);\n\n-- ❌ 인덱스 사용 안 됨\nSELECT * FROM users WHERE phone = 1234567890;\n-- VARCHAR 컬럼에 INT 비교 → 타입 변환 발생\n\nEXPLAIN:\ntype: ALL\n\n-- ✅ 인덱스 사용\nSELECT * FROM users WHERE phone = '1234567890';\n\nEXPLAIN:\ntype: ref\n```\n\n---\n\n**5. OR 조건**\n\n```sql\nCREATE INDEX idx_name ON users(name);\nCREATE INDEX idx_email ON users(email);\n\n-- ❌ Full Scan 가능\nSELECT * FROM users WHERE name = '홍길동' OR email = 'test@example.com';\n\n-- 두 인덱스를 합치는 비용이 크면 Full Scan 선택\n\nEXPLAIN:\ntype: ALL 또는 index_merge\n\n-- ✅ UNION으로 최적화\nSELECT * FROM users WHERE name = '홍길동'\nUNION\nSELECT * FROM users WHERE email = 'test@example.com';\n```\n\n---\n\n**6. 부정 조건 (NOT, !=, <>)**\n\n```sql\nCREATE INDEX idx_status ON orders(status);\n\n-- ❌ Full Scan\nSELECT * FROM orders WHERE status != 'cancelled';\n-- 대부분의 행이 해당 → Full Scan이 빠름\n\nEXPLAIN:\ntype: ALL\n\n-- ✅ 긍정 조건으로 변경\nSELECT * FROM orders WHERE status IN ('pending', 'completed', 'shipped');\n\nEXPLAIN:\ntype: range\n```\n\n---\n\n**7. LIKE 패턴 (앞에 와일드카드)**\n\n```sql\nCREATE INDEX idx_name ON users(name);\n\n-- ❌ Full Scan\nSELECT * FROM users WHERE name LIKE '%길동';\n-- 앞에 %가 있으면 인덱스 사용 불가\n\nEXPLAIN:\ntype: ALL\n\n-- ✅ Index Scan\nSELECT * FROM users WHERE name LIKE '홍%';\n-- 앞부분이 고정되면 인덱스 사용 가능\n\nEXPLAIN:\ntype: range\n```\n\n---\n\n**8. NULL 비교**\n\n```sql\nCREATE INDEX idx_deleted ON users(deleted_at);\n\n-- 일부 DBMS에서 NULL 값은 인덱스에 저장 안 됨\nSELECT * FROM users WHERE deleted_at IS NULL;\n\n-- MySQL InnoDB는 NULL도 인덱스 사용 가능\n-- 하지만 옵티마이저가 Full Scan 선택할 수 있음\n```\n\n---\n\n**9. 통계 정보가 오래됨**\n\n```sql\n-- 테이블 통계 정보가 오래되면 옵티마이저가 잘못 판단\n\n-- 통계 갱신\nANALYZE TABLE users;\n\n-- 또는\nOPTIMIZE TABLE users;\n```\n\n---\n\n**10. 힌트로 강제**\n\n```sql\n-- ❌ Full Scan 강제\nSELECT /*+ NO_INDEX(users idx_name) */ * FROM users WHERE name = '홍길동';\n\n-- ✅ Index 강제\nSELECT /*+ INDEX(users idx_name) */ * FROM users WHERE name = '홍길동';\n\n-- MySQL\nSELECT * FROM users USE INDEX (idx_name) WHERE name = '홍길동';\nSELECT * FROM users FORCE INDEX (idx_name) WHERE name = '홍길동';\n```\n\n---\n\n**확인 방법:**\n\n```sql\n-- 실행 계획 확인\nEXPLAIN SELECT * FROM users WHERE status = 'active';\n\n-- 실제 실행 통계\nEXPLAIN ANALYZE SELECT * FROM users WHERE status = 'active';\n\n-- 옵티마이저 트레이스\nSET optimizer_trace='enabled=on';\nSELECT * FROM users WHERE status = 'active';\nSELECT * FROM information_schema.OPTIMIZER_TRACE;\n-- 왜 Full Scan을 선택했는지 확인\n```\n\n**결론:**\n옵티마이저가 비용을 계산하여 Full Scan이 더 빠르다고 판단하면 인덱스가 있어도 사용하지 않습니다. 대부분의 경우 옵티마이저의 선택이 맞습니다.",
      "type": "essay",
      "tags": ["Full Scan", "인덱스", "옵티마이저", "성능"]
    },
    {
      "question": "COUNT (개수를 세는 쿼리) 는 어떻게 동작하나요? COUNT(1), COUNT(*), COUNT(column) 의 동작 과정에는 차이가 있나요?",
      "answer": "**COUNT 동작 방식:**\n\n---\n\n**1. COUNT(*)**\n\n테이블의 **전체 행 개수**를 센다.\n\n```sql\nSELECT COUNT(*) FROM users;\n\n동작:\n- 모든 행을 센다 (NULL 포함)\n- 가장 일반적인 사용법\n```\n\n**MySQL InnoDB:**\n```sql\n-- WHERE 조건 없음\nSELECT COUNT(*) FROM users;\n-- → Full Table Scan (모든 행 확인)\n\n-- WHERE 조건 있음\nSELECT COUNT(*) FROM users WHERE status = 'active';\n-- → 인덱스 있으면 Index Scan\n```\n\n**MyISAM:**\n```sql\n-- WHERE 조건 없음\nSELECT COUNT(*) FROM users;\n-- → 메타데이터에 저장된 행 개수 반환 (즉시)\n\n-- WHERE 조건 있음\nSELECT COUNT(*) FROM users WHERE status = 'active';\n-- → Full Scan 필요\n```\n\n---\n\n**2. COUNT(1)**\n\n**COUNT(*)와 동일합니다.**\n\n```sql\nSELECT COUNT(1) FROM users;\n\n동작:\n- 모든 행을 센다\n- 1은 상수 (어떤 숫자도 가능)\n- COUNT(*) 와 성능 차이 없음\n```\n\n**EXPLAIN:**\n```sql\nEXPLAIN SELECT COUNT(*) FROM users;\nEXPLAIN SELECT COUNT(1) FROM users;\n-- 실행 계획 동일\n```\n\n---\n\n**3. COUNT(column)**\n\n**NULL이 아닌 행의 개수**를 센다.\n\n```sql\nCREATE TABLE users (\n    id INT,\n    name VARCHAR(100),\n    email VARCHAR(100)  -- NULL 가능\n);\n\n-- 데이터\n| id | name   | email               |\n|----|--------|---------------------|\n| 1  | 홍길동 | hong@example.com    |\n| 2  | 김철수 | NULL                 |  -- email NULL\n| 3  | 이영희 | lee@example.com     |\n\nSELECT COUNT(*) FROM users;      -- 3 (모든 행)\nSELECT COUNT(1) FROM users;      -- 3 (모든 행)\nSELECT COUNT(id) FROM users;     -- 3 (NULL 없음)\nSELECT COUNT(email) FROM users;  -- 2 (NULL 제외)\n\n동작:\n- 해당 컬럼이 NULL이 아닌 행만 센다\n- 모든 행을 검사해야 함\n```\n\n---\n\n**성능 비교:**\n\n**같은 성능:**\n```sql\nSELECT COUNT(*) FROM users;\nSELECT COUNT(1) FROM users;\nSELECT COUNT(0) FROM users;\nSELECT COUNT(100) FROM users;\n\n-- 모두 동일한 실행 계획\n-- 옵티마이저가 COUNT(*)로 변환\n```\n\n**다른 성능:**\n```sql\nSELECT COUNT(*) FROM users;     -- 빠름\nSELECT COUNT(email) FROM users;  -- 느림 (NULL 체크 필요)\n\n-- COUNT(column)은 NULL 체크 오버헤드\n```\n\n---\n\n**최적화:**\n\n**1. 인덱스 활용**\n\n```sql\nCREATE INDEX idx_status ON users(status);\n\nSELECT COUNT(*) FROM users WHERE status = 'active';\n\n-- Index Only Scan (커버링 인덱스)\nEXPLAIN:\ntype: index\nExtra: Using index\n-- 테이블 접근 없이 인덱스만으로 COUNT → 빠름\n```\n\n**2. 작은 인덱스 사용**\n\n```sql\n-- id (INT, 4 bytes) vs name (VARCHAR(100), 가변)\n\nSELECT COUNT(id) FROM users;\n-- id 컬럼의 인덱스가 작아서 빠름\n\nSELECT COUNT(name) FROM users;\n-- name 컬럼이 크면 느림\n\n-- 하지만 COUNT(*)가 가장 빠름 (옵티마이저가 최적 선택)\n```\n\n---\n\n**대용량 테이블 COUNT 최적화:**\n\n**방법 1: 근사값 사용**\n\n```sql\n-- MySQL\nSELECT table_rows \nFROM information_schema.TABLES \nWHERE table_schema = 'mydb' AND table_name = 'users';\n-- 근사값 (빠름, 정확도 낮음)\n\n-- PostgreSQL\nSELECT reltuples::BIGINT AS estimate \nFROM pg_class \nWHERE relname = 'users';\n```\n\n**방법 2: 카운터 테이블**\n\n```java\n// INSERT 시 카운터 증가\n@Transactional\npublic void insertUser(User user) {\n    userRepository.save(user);\n    counterRepository.increment(\"users\", 1);\n}\n\n// COUNT 대신 카운터 조회\nSELECT count FROM counters WHERE table_name = 'users';\n-- 즉시 반환 (빠름)\n```\n\n**방법 3: Redis 캐시**\n\n```java\n// 주기적으로 COUNT 캐싱\n@Scheduled(fixedDelay = 60000)  // 1분마다\npublic void cacheUserCount() {\n    long count = jdbcTemplate.queryForObject(\"SELECT COUNT(*) FROM users\", Long.class);\n    redis.set(\"user:count\", count, 60, TimeUnit.SECONDS);\n}\n\n// 캐시에서 조회\nLong count = redis.get(\"user:count\");\n```\n\n---\n\n**COUNT DISTINCT:**\n\n```sql\nSELECT COUNT(DISTINCT email) FROM users;\n-- 고유한 email 개수\n\n동작:\n1. 모든 email 값 조회\n2. 중복 제거\n3. 개수 세기\n→ 느림 (정렬 또는 해시 필요)\n\nEXPLAIN:\nExtra: Using temporary\n```\n\n---\n\n**실제 성능 차이:**\n\n```\n테이블: 10,000,000행\n\n1. COUNT(*):\n   - Index Scan: 5초\n   - Full Scan: 30초\n\n2. COUNT(1):\n   - COUNT(*)와 동일: 5초\n\n3. COUNT(column):\n   - NULL 체크: 6초 (약간 느림)\n\n4. COUNT(DISTINCT column):\n   - 중복 제거: 60초 (매우 느림)\n\n권장: COUNT(*) 사용\n```\n\n**결론:**\n- **COUNT(*)**: 전체 행 개수, 가장 빠름\n- **COUNT(1)**: COUNT(*)와 동일\n- **COUNT(column)**: NULL 제외, 약간 느림\n- **권장**: COUNT(*) 사용",
      "type": "essay",
      "tags": ["COUNT", "성능", "NULL", "최적화"]
    },
    {
      "question": "SQL Injection에 대해 설명해 주세요.",
      "answer": "**SQL Injection:**\n\n악의적인 SQL 코드를 **입력값에 삽입**하여 데이터베이스를 공격하는 기법입니다.\n\n---\n\n**취약한 코드:**\n\n```java\n// ❌ 매우 위험!\nString userId = request.getParameter(\"userId\");\nString query = \"SELECT * FROM users WHERE id = \" + userId;\nStatement stmt = conn.createStatement();\nResultSet rs = stmt.executeQuery(query);\n\n// 정상 입력:\nuserI = \"1\"\nquery = \"SELECT * FROM users WHERE id = 1\"  // 정상\n\n// 악의적 입력:\nuserId = \"1 OR 1=1\"\nquery = \"SELECT * FROM users WHERE id = 1 OR 1=1\"  // 모든 사용자 조회!\n\nuserId = \"1; DROP TABLE users; --\"\nquery = \"SELECT * FROM users WHERE id = 1; DROP TABLE users; --\"  // 테이블 삭제!\n```\n\n---\n\n**공격 예시:**\n\n**1. 인증 우회**\n\n```java\nString username = request.getParameter(\"username\");\nString password = request.getParameter(\"password\");\n\nString query = \"SELECT * FROM users WHERE username = '\" + username + \n               \"' AND password = '\" + password + \"'\";\n\n// 공격:\nusername = \"admin' --\"\npassword = \"anything\"\n\nquery = \"SELECT * FROM users WHERE username = 'admin' --' AND password = 'anything'\"\n// -- 는 주석 → password 검사 무시\n// admin으로 로그인 성공!\n```\n\n**2. 데이터 유출**\n\n```java\nString productId = request.getParameter(\"productId\");\nString query = \"SELECT * FROM products WHERE id = \" + productId;\n\n// 공격:\nproductId = \"1 UNION SELECT username, password, NULL FROM users\"\n\nquery = \"SELECT * FROM products WHERE id = 1 \n         UNION SELECT username, password, NULL FROM users\"\n// 제품 정보 + 모든 사용자 계정 정보 노출!\n```\n\n**3. 데이터 수정/삭제**\n\n```java\n// 공격:\nuserId = \"1; UPDATE users SET password='hacked' WHERE username='admin'; --\"\n\nquery = \"SELECT * FROM users WHERE id = 1; \n         UPDATE users SET password='hacked' WHERE username='admin'; --\"\n// admin 비밀번호 변경!\n\nuserId = \"1; DROP TABLE users; --\"\n// 테이블 삭제!\n```\n\n---\n\n**방어 방법:**\n\n**1. PreparedStatement 사용 (가장 중요) ⭐⭐⭐**\n\n```java\n// ✅ 안전\nString userId = request.getParameter(\"userId\");\n\nString query = \"SELECT * FROM users WHERE id = ?\";\nPreparedStatement pstmt = conn.prepareStatement(query);\npstmt.setString(1, userId);  // 자동으로 이스케이프 처리\nResultSet rs = pstmt.executeQuery();\n\n// 공격 시도:\nuserId = \"1 OR 1=1\"\n→ 실제 쿼리: SELECT * FROM users WHERE id = '1 OR 1=1'\n// 문자열 그대로 처리 → SQL 실행 안 됨\n```\n\n**2. ORM 사용 (JPA, Hibernate)**\n\n```java\n// ✅ 안전 (JPA)\n@Repository\npublic interface UserRepository extends JpaRepository<User, Long> {\n    Optional<User> findById(Long id);\n}\n\n// 사용\nUser user = userRepository.findById(userId).orElse(null);\n// JPA가 자동으로 PreparedStatement 사용\n\n// JPQL도 안전\n@Query(\"SELECT u FROM User u WHERE u.username = :username\")\nUser findByUsername(@Param(\"username\") String username);\n// :username이 자동으로 바인딩됨\n```\n\n**3. 입력 검증**\n\n```java\n// ✅ 화이트리스트 검증\nString userId = request.getParameter(\"userId\");\n\nif (!userId.matches(\"^[0-9]+$\")) {  // 숫자만 허용\n    throw new IllegalArgumentException(\"Invalid user ID\");\n}\n\n// ✅ 길이 제한\nif (username.length() > 50) {\n    throw new IllegalArgumentException(\"Username too long\");\n}\n\n// ✅ 특수문자 제거\nString sanitized = username.replaceAll(\"[^a-zA-Z0-9]\", \"\");\n```\n\n**4. Escape 처리**\n\n```java\n// 부득이하게 동적 쿼리를 사용해야 할 때\nString escaped = StringEscapeUtils.escapeSql(userInput);\n// ' → ''\n// ; → \\;\n```\n\n**5. 최소 권한 원칙**\n\n```sql\n-- 애플리케이션용 DB 계정은 최소 권한만\nGRANT SELECT, INSERT, UPDATE ON mydb.* TO 'app_user'@'localhost';\n-- DROP, ALTER 등 위험한 권한 제외\n\n-- 관리자 계정과 분리\n```\n\n**6. 에러 메시지 숨기기**\n\n```java\n// ❌ 나쁜 예\ntry {\n    // SQL 실행\n} catch (SQLException e) {\n    return e.getMessage();  // SQL 구조 노출\n}\n\n// ✅ 좋은 예\ntry {\n    // SQL 실행\n} catch (SQLException e) {\n    logger.error(\"Database error\", e);  // 로그에만 기록\n    return \"An error occurred\";  // 일반적인 메시지만 반환\n}\n```\n\n**7. WAF (Web Application Firewall)**\n\n```\nCloudflare, AWS WAF 등\n→ SQL Injection 패턴 자동 차단\n```\n\n---\n\n**실무 예시:**\n\n**Spring Boot:**\n```java\n@RestController\npublic class UserController {\n    \n    @Autowired\n    private JdbcTemplate jdbcTemplate;\n    \n    // ❌ 위험\n    @GetMapping(\"/users/unsafe\")\n    public User getUser Unsafe(@RequestParam String userId) {\n        String sql = \"SELECT * FROM users WHERE id = \" + userId;\n        return jdbcTemplate.queryForObject(sql, new UserRowMapper());\n    }\n    \n    // ✅ 안전 (PreparedStatement)\n    @GetMapping(\"/users/safe\")\n    public User getUserSafe(@RequestParam Long userId) {\n        String sql = \"SELECT * FROM users WHERE id = ?\";\n        return jdbcTemplate.queryForObject(sql, new Object[]{userId}, new UserRowMapper());\n    }\n    \n    // ✅ 안전 (JPA)\n    @Autowired\n    private UserRepository userRepository;\n    \n    @GetMapping(\"/users/{id}\")\n    public User getUser(@PathVariable Long id) {\n        return userRepository.findById(id).orElse(null);\n    }\n}\n```\n\n---\n\n**테스트:**\n\n```java\n// SQL Injection 테스트\n@Test\npublic void testSQLInjection() {\n    String maliciousInput = \"1 OR 1=1\";\n    \n    // PreparedStatement는 안전해야 함\n    assertThrows(NumberFormatException.class, () -> {\n        userService.getUser(maliciousInput);\n    });\n}\n```\n\n**결론:**\n- **절대 사용자 입력을 직접 SQL에 삽입하지 말 것**\n- **항상 PreparedStatement 또는 ORM 사용**\n- **입력 검증과 최소 권한 원칙 적용**",
      "type": "essay",
      "tags": ["SQL Injection", "보안", "PreparedStatement", "ORM"]
    },
    {
      "question": "우리가 서버 개발 과정에서 사용하는 수많은 DB 라이브러리들은 이 문제를 어떻게 해결할까요?",
      "answer": "**DB 라이브러리의 SQL Injection 방어 메커니즘:**\n\n---\n\n**1. PreparedStatement (Parameterized Query)**\n\n**핵심: SQL과 데이터를 분리**\n\n```java\n// JDBC\nString sql = \"SELECT * FROM users WHERE id = ?\";\nPreparedStatement pstmt = conn.prepareStatement(sql);\npstmt.setLong(1, userId);  // 파라미터 바인딩\n\n내부 동작:\n1. SQL 구조 먼저 DB에 전송: \"SELECT * FROM users WHERE id = ?\"\n2. DB가 SQL을 컴파일 (Prepared)\n3. 파라미터 값 별도로 전송: userId\n4. DB가 값을 데이터로만 처리 (SQL 코드로 해석하지 않음)\n\n공격 시도:\nuserId = \"1 OR 1=1\"\n→ 실제 처리: WHERE id = '1 OR 1=1'  (문자열 그대로)\n→ SQL로 실행되지 않음 → 안전\n```\n\n---\n\n**2. JPA/Hibernate**\n\n**Named Parameter:**\n```java\n// ✅ 안전\n@Query(\"SELECT u FROM User u WHERE u.username = :username\")\nUser findByUsername(@Param(\"username\") String username);\n\n// Hibernate가 자동으로 PreparedStatement로 변환:\n// SELECT * FROM users WHERE username = ?\n\n// 공격 시도:\nusername = \"admin' OR '1'='1\"\n→ PreparedStatement로 처리 → 안전\n```\n\n**Criteria API:**\n```java\n// ✅ 안전 (SQL을 직접 작성하지 않음)\nCriteriaBuilder cb = em.getCriteriaBuilder();\nCriteriaQuery<User> query = cb.createQuery(User.class);\nRoot<User> root = query.from(User.class);\nquery.where(cb.equal(root.get(\"username\"), username));\n\nList<User> users = em.createQuery(query).getResultList();\n// 내부적으로 PreparedStatement 사용\n```\n\n---\n\n**3. MyBatis**\n\n**#{} vs ${}:**\n\n```xml\n<!-- ✅ 안전: PreparedStatement -->\n<select id=\"findById\" resultType=\"User\">\n    SELECT * FROM users WHERE id = #{id}\n</select>\n<!-- #{id} → PreparedStatement 파라미터 바인딩 -->\n\n<!-- ❌ 위험: 문자열 치환 -->\n<select id=\"findByIdUnsafe\" resultType=\"User\">\n    SELECT * FROM users WHERE id = ${id}\n</select>\n<!-- ${id} → 직접 문자열 치환 → SQL Injection 가능! -->\n\n사용:\nid = \"1 OR 1=1\"\n\n#{id} → SELECT * FROM users WHERE id = '1 OR 1=1'  -- 안전\n${id} → SELECT * FROM users WHERE id = 1 OR 1=1   -- 위험!\n```\n\n---\n\n**4. Spring JdbcTemplate**\n\n**자동 PreparedStatement:**\n```java\n// ✅ 안전\njdbcTemplate.queryForObject(\n    \"SELECT * FROM users WHERE id = ?\",\n    new Object[]{userId},\n    new UserRowMapper()\n);\n// 내부적으로 PreparedStatement 사용\n\n// ✅ 안전 (Named Parameter)\nNamedParameterJdbcTemplate namedTemplate = new NamedParameterJdbcTemplate(dataSource);\nMap<String, Object> params = new HashMap<>();\nparams.put(\"id\", userId);\n\nnamedTemplate.queryForObject(\n    \"SELECT * FROM users WHERE id = :id\",\n    params,\n    new UserRowMapper()\n);\n```\n\n---\n\n**5. Node.js (mysql2, pg)**\n\n**Parameterized Query:**\n```javascript\n// mysql2 ✅ 안전\nconst [rows] = await connection.execute(\n    'SELECT * FROM users WHERE id = ?',\n    [userId]\n);\n// execute()는 PreparedStatement 사용\n\n// ❌ 위험\nconst [rows] = await connection.query(\n    `SELECT * FROM users WHERE id = ${userId}`\n);\n// 템플릿 리터럴 직접 삽입 → 위험\n\n// PostgreSQL (node-postgres) ✅ 안전\nconst result = await client.query(\n    'SELECT * FROM users WHERE id = $1',\n    [userId]\n);\n```\n\n---\n\n**6. Python (psycopg2, MySQLdb)**\n\n**Parameterized Query:**\n```python\n# psycopg2 ✅ 안전\ncursor.execute(\n    \"SELECT * FROM users WHERE id = %s\",\n    (user_id,)\n)\n# %s는 파라미터 placeholder (문자열 포맷팅 아님!)\n\n# ❌ 위험\ncursor.execute(\n    f\"SELECT * FROM users WHERE id = {user_id}\"\n)\n# f-string 직접 삽입 → 위험\n\n# SQLAlchemy ✅ 안전 (ORM)\nuser = session.query(User).filter(User.id == user_id).first()\n# 자동으로 PreparedStatement 사용\n```\n\n---\n\n**7. Django ORM**\n\n**안전한 쿼리:**\n```python\n# ✅ 안전\nUser.objects.filter(id=user_id)\n# ORM이 자동으로 PreparedStatement 생성\n\n# ✅ 안전 (Raw Query with parameters)\nUser.objects.raw(\n    'SELECT * FROM users WHERE id = %s',\n    [user_id]\n)\n\n# ❌ 위험\nUser.objects.raw(\n    f'SELECT * FROM users WHERE id = {user_id}'\n)\n```\n\n---\n\n**8. Go (database/sql)**\n\n**Prepared Statement:**\n```go\n// ✅ 안전\nrows, err := db.Query(\"SELECT * FROM users WHERE id = ?\", userId)\n// Query()가 자동으로 PreparedStatement 사용\n\n// ✅ 안전 (Named Parameter - sqlx)\nrows, err := db.NamedQuery(\n    \"SELECT * FROM users WHERE id = :id\",\n    map[string]interface{}{\"id\": userId}\n)\n\n// ❌ 위험\nquery := fmt.Sprintf(\"SELECT * FROM users WHERE id = %s\", userId)\nrows, err := db.Query(query)\n```\n\n---\n\n**내부 메커니즘:**\n\n**1. 파라미터 이스케이프:**\n```java\n// PreparedStatement 내부\npublic void setString(int parameterIndex, String x) {\n    if (x == null) {\n        setNull(parameterIndex, Types.VARCHAR);\n    } else {\n        // 특수문자 이스케이프\n        String escaped = x.replace(\"'\", \"''\");  // ' → ''\n        // 데이터로만 처리\n        setParameter(parameterIndex, escaped);\n    }\n}\n\n입력: admin' OR '1'='1\n이스케이프: admin'' OR ''1''=''1\n실제 쿼리: SELECT * FROM users WHERE username = 'admin'' OR ''1''=''1'\n→ 'admin' OR '1'='1' 라는 username을 찾음 (SQL 실행 X)\n```\n\n**2. 타입 검증:**\n```java\npstmt.setInt(1, userId);  // userId가 정수인지 검증\n// \"1 OR 1=1\" → NumberFormatException 발생\n```\n\n**3. SQL 구조 분리:**\n```\nStep 1: SQL 구조 전송\n   Client → Server: \"SELECT * FROM users WHERE id = ?\"\n   Server: SQL을 파싱하고 컴파일\n\nStep 2: 파라미터 값 전송\n   Client → Server: [\"1 OR 1=1\"]\n   Server: 값을 데이터로만 처리 (SQL로 해석 X)\n\nStep 3: 실행\n   WHERE id = '1 OR 1=1'  (문자열 그대로)\n```\n\n---\n\n**주의사항:**\n\n**동적 쿼리에서도 안전하게:**\n```java\n// ❌ 위험\nString orderBy = request.getParameter(\"orderBy\");\nString sql = \"SELECT * FROM users ORDER BY \" + orderBy;\n// orderBy = \"id; DROP TABLE users;--\" → 위험\n\n// ✅ 화이트리스트 검증\nString orderBy = request.getParameter(\"orderBy\");\nif (!Arrays.asList(\"id\", \"name\", \"email\").contains(orderBy)) {\n    throw new IllegalArgumentException(\"Invalid order by\");\n}\nString sql = \"SELECT * FROM users ORDER BY \" + orderBy;\n// 허용된 값만 사용 → 안전\n```\n\n**결론:**\n- 모든 주요 DB 라이브러리는 **PreparedStatement** 지원\n- **파라미터 바인딩**으로 SQL과 데이터 분리\n- **이스케이프 처리**와 **타입 검증**으로 2중 방어\n- 개발자는 **PreparedStatement를 항상 사용**해야 함",
      "type": "essay",
      "tags": ["SQL Injection", "PreparedStatement", "ORM", "보안", "DB 라이브러리"]
    }
  ]
}
