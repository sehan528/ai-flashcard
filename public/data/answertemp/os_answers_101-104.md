# OS 답변 101-104

## 101. 32비트 운영체제는 램을 최대 4G 까지 사용할 수 있습니다. 이 이유를 페이징과 연관 지어서 설명해 주세요.

**기본 개념**

32비트 운영체제의 4GB 메모리 제한은 주소 버스의 비트 수에서 비롯됩니다. 32비트로 표현할 수 있는 주소의 개수가 2의 32제곱이며, 이는 4,294,967,296개입니다. 각 주소가 1바이트를 가리키므로 최대 4GB를 표현할 수 있습니다.

**물리 주소의 한계**

32비트 시스템에서 물리 주소 레지스터와 버스도 32비트입니다. 프레임 번호와 오프셋을 합쳐 32비트 물리 주소를 만듭니다. 4KB 페이지를 사용하면 오프셋이 12비트이고, 프레임 번호가 20비트입니다. 20비트로 100만 개 프레임을 표현하며, 각 프레임이 4KB이므로 4GB가 됩니다. 더 많은 메모리를 설치해도 주소를 표현할 수 없어 사용할 수 없습니다.

**페이지 테이블의 역할**

페이징 시스템에서도 결국 물리 주소가 필요합니다. 페이지 테이블은 가상 페이지를 물리 프레임에 매핑하는데, 물리 프레임 번호도 32비트 주소 공간 내에 있어야 합니다. 아무리 큰 가상 주소 공간을 가져도, 물리 메모리는 32비트 주소로 접근 가능한 4GB로 제한됩니다.

**PAE의 우회**

Physical Address Extension은 페이지 테이블 엔트리를 확장하여 36비트 물리 주소를 지원합니다. 이론적으로 64GB까지 사용할 수 있지만, 개별 프로세스는 여전히 4GB 가상 주소 공간만 가집니다. 여러 프로세스가 전체 물리 메모리의 다른 부분을 사용할 수 있지만, 각 프로세스는 4GB 제한이 있습니다. PAE는 복잡하고 호환성 문제가 있어 널리 사용되지 않았습니다.

**커널 공간 분할**

32비트 리눅스에서는 4GB 주소 공간을 사용자 공간 3GB와 커널 공간 1GB로 나눕니다. 커널이 전체 물리 메모리를 직접 매핑할 수 없으면, highmem 메커니즘으로 일부를 임시 매핑합니다. 이는 복잡성과 성능 저하를 초래합니다. 4GB 이상의 메모리는 커널도 효율적으로 관리하기 어렵습니다.

**64비트의 해결**

64비트 시스템은 이론상 16엑사바이트를 표현할 수 있습니다. 실제로는 48비트나 52비트만 사용하여 256TB나 4PB를 지원합니다. 현실적으로 무한에 가까운 주소 공간이며, 메모리 제한이 사실상 사라집니다. 페이지 테이블도 멀티레벨로 거대한 공간을 효율적으로 관리합니다.

**실무 영향**

32비트 윈도우는 4GB 중 일부를 하드웨어와 시스템용으로 예약하여 실제 사용 가능 메모리는 3GB 정도입니다. 서버나 워크스테이션은 32비트로는 부족하여 64비트로 전환했습니다. 모바일 기기도 4GB 이상 RAM을 탑재하면서 64비트로 이동했습니다. 현재 대부분의 시스템은 64비트입니다.

**페이징의 연관성**

페이징 자체가 4GB 제한을 만드는 것은 아니지만, 페이징 시스템도 물리 주소 비트 수에 제약받습니다. 세그멘테이션을 사용해도 32비트 물리 버스로는 4GB 이상을 접근할 수 없습니다. 근본 원인은 32비트 주소 체계이며, 페이징은 이 체계 내에서 동작하는 메모리 관리 방식입니다.

---

## 102. C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요?

**기본 개념**

Segmentation Fault는 잘못된 메모리 접근으로 인한 에러이며, 이름과 달리 세그멘테이션 방식과 직접적 관계는 없습니다. 페이징 시스템에서도 발생하며, 메모리 보호 위반을 나타내는 일반적인 용어입니다.

**발생 원인**

프로세스가 허용되지 않은 메모리 영역에 접근하려 할 때 발생합니다. 할당되지 않은 주소, 읽기 전용 메모리에 쓰기, 널 포인터 역참조, 범위를 벗어난 배열 접근 등이 원인입니다. 하드웨어 MMU가 권한 검사를 수행하여, 위반 시 예외를 발생시킵니다. 운영체제가 이를 SIGSEGV 신호로 프로세스에 전달합니다.

**페이징 시스템에서의 동작**

현대 시스템은 대부분 페이징을 사용하지만, Segmentation Fault라는 이름은 계속 사용됩니다. 페이지 테이블의 Present 비트가 0이거나, 권한 비트가 위반되면 페이지 폴트가 발생합니다. 운영체제가 주소의 유효성을 확인하여, 정상적인 페이지 폴트면 처리하고, 잘못된 접근이면 SIGSEGV를 보냅니다. 프로세스는 기본적으로 종료되며, 에러 메시지가 출력됩니다.

**세그멘테이션과의 역사적 관계**

용어는 세그멘테이션 방식에서 유래했습니다. 초기 시스템에서 세그먼트 경계를 벗어난 접근을 세그멘테이션 위반이라 불렀습니다. 페이징이 주류가 된 후에도 관습적으로 같은 용어를 사용합니다. 실제로는 페이지 보호 위반이지만, Segmentation Fault로 부릅니다.

**흔한 원인 예시**

널 포인터 역참조는 주소 0에 접근하려는 시도입니다. 이 주소는 보통 매핑되지 않아 즉시 폴트가 발생합니다. 해제된 메모리 접근은 free 후 포인터를 사용하는 경우입니다. 스택 오버플로는 재귀가 깊어져 스택 한계를 넘는 경우입니다. 버퍼 오버런은 배열 경계를 넘어 쓰는 경우입니다.

**권한 위반**

코드 영역에 쓰기를 시도하면 Writable 비트가 0이어서 폴트가 발생합니다. 데이터 영역을 실행하려 하면 NX 비트로 차단됩니다. 읽기 전용 문자열 리터럴을 수정하려 하면 실패합니다. 이런 보호 메커니즘은 메모리 안전성과 보안을 제공합니다.

**디버깅 방법**

디버거를 사용하면 어느 주소에서 폴트가 발생했는지 확인할 수 있습니다. 백트레이스로 호출 스택을 추적하여 원인을 파악합니다. Valgrind 같은 도구는 메모리 오류를 미리 탐지합니다. AddressSanitizer는 컴파일 시 체크 코드를 삽입하여 실행 중 오류를 찾습니다.

**운영체제별 이름**

리눅스와 유닉스는 Segmentation Fault라고 부릅니다. 윈도우는 Access Violation이라는 용어를 사용합니다. macOS도 Segmentation Fault를 사용하지만, EXC_BAD_ACCESS로도 표시됩니다. 이름은 다르지만 모두 같은 메모리 보호 위반을 의미합니다.

**실무 예방**

널 포인터를 사용 전에 항상 검사합니다. 메모리를 해제한 후 포인터를 NULL로 설정합니다. 배열 경계를 확인하고 범위 검사를 수행합니다. 스마트 포인터나 안전한 자료구조를 사용합니다. 정적 분석 도구와 코드 리뷰로 잠재적 오류를 찾습니다. 메모리 안전성은 C/C++ 프로그래밍의 핵심 과제입니다.

---

## 103. TLB는 무엇인가요?

**기본 개념**

TLB는 Translation Lookaside Buffer의 약자로, 최근 사용된 가상 주소와 물리 주소 매핑을 캐시하는 하드웨어입니다. 페이지 테이블 접근을 줄여 주소 변환 속도를 크게 향상시킵니다.

**TLB의 필요성**

매번 메모리 접근마다 페이지 테이블을 참조하면 성능이 크게 저하됩니다. 단일 레벨 테이블도 한 번 메모리 접근이 필요하고, 멀티레벨은 여러 번 접근해야 합니다. 4단계 페이지 테이블에서는 하나의 데이터 접근을 위해 4번의 추가 메모리 접근이 필요합니다. TLB는 이 오버헤드를 제거하여 대부분의 변환을 빠르게 수행합니다.

**TLB의 구조**

TLB는 가상 페이지 번호를 키로, 물리 프레임 번호와 권한 비트를 값으로 저장하는 캐시입니다. 연관 메모리로 구현되어 모든 엔트리를 병렬로 검색합니다. 일반적으로 64개에서 512개의 엔트리를 가지며, 매우 빠른 SRAM으로 만들어집니다. CPU 코어 내부에 위치하여 클럭 사이클 내에 접근 가능합니다.

**TLB 동작 과정**

CPU가 가상 주소를 생성하면, MMU가 먼저 TLB를 확인합니다. 가상 페이지 번호로 TLB를 검색하여 히트되면 즉시 프레임 번호를 얻습니다. 권한도 함께 확인하여 접근 가능 여부를 판단합니다. 모든 과정이 하드웨어로 자동 수행되며, 1-2 사이클 내에 완료됩니다.

**TLB 미스**

TLB에 엔트리가 없으면 TLB 미스가 발생합니다. 하드웨어 또는 소프트웨어가 페이지 테이블을 워킹하여 변환을 수행합니다. x86-64는 하드웨어가 자동으로 페이지 테이블을 탐색하고 TLB를 업데이트합니다. 일부 아키텍처는 TLB 미스 예외를 발생시켜 운영체제가 처리합니다. 변환 완료 후 TLB에 엔트리를 추가하여 다음 접근은 빠르게 처리됩니다.

**TLB 히트율**

지역성 원리로 인해 TLB 히트율은 매우 높습니다. 일반적으로 95% 이상이며, 99%에 달하는 경우도 많습니다. 작업 세트가 TLB 크기 내에 들어가면 거의 모든 접근이 히트됩니다. 이 높은 히트율 덕분에 페이징 오버헤드가 무시할 수 있을 정도로 작아집니다.

**TLB 무효화**

컨텍스트 스위칭 시 TLB를 무효화해야 합니다. 다른 프로세스의 페이지 테이블을 사용하므로, 이전 매핑이 유효하지 않습니다. 전체 TLB를 비우는 것은 비용이 크므로, ASID나 PCID로 프로세스를 구분합니다. 각 엔트리에 프로세스 ID를 태그하여 선택적으로 무효화합니다. 페이지 테이블 업데이트 시에도 해당 엔트리를 무효화합니다.

**TLB 계층**

일부 CPU는 L1, L2 TLB를 가집니다. L1 TLB는 매우 빠르지만 작고, L2 TLB는 느리지만 큽니다. L1 미스 시 L2를 확인하고, 둘 다 미스면 페이지 테이블을 참조합니다. 명령어와 데이터 TLB를 분리하기도 합니다. 이는 일반 캐시 계층과 유사한 구조입니다.

**실무 영향**

TLB 미스는 성능 병목이 될 수 있습니다. Huge Pages를 사용하면 TLB 엔트리당 커버 범위가 넓어져 히트율이 향상됩니다. 메모리 접근 패턴을 지역화하여 TLB 활용도를 높입니다. 프로파일러로 TLB 미스율을 측정하고 최적화합니다. TLB는 가상 메모리 성능의 핵심 요소입니다.

---

## 104. TLB를 쓰면 왜 빨라지나요?

**기본 개념**

TLB를 사용하면 대부분의 주소 변환이 추가 메모리 접근 없이 즉시 완료되어 성능이 크게 향상됩니다. 메모리 접근 시간을 대폭 단축하는 효과가 있습니다.

**메모리 접근 비용**

메인 메모리 접근은 수십에서 수백 나노초가 걸립니다. 캐시 히트는 수 나노초이지만, 메모리는 훨씬 느립니다. 멀티레벨 페이지 테이블에서는 데이터 하나를 읽기 위해 4-5번의 메모리 접근이 필요합니다. 4단계 테이블 워크와 실제 데이터 접근을 합치면 1마이크로초에 가까워집니다. 이는 CPU 클럭에 비해 수천 배 느린 속도입니다.

**TLB 접근 속도**

TLB는 CPU 내부의 SRAM으로 만들어져 1-2 클럭 사이클에 접근 가능합니다. 3GHz CPU에서 1 사이클은 0.33 나노초입니다. 메모리 접근 100 나노초와 비교하면 수백 배 빠릅니다. 페이지 테이블 워크를 생략하므로 4번의 메모리 접근을 모두 절약합니다.

**효과적인 접근 시간**

TLB 히트율이 95%이고, TLB 접근 1ns, 페이지 테이블 워크 100ns, 데이터 접근 100ns라고 가정합니다. TLB 히트 시: 1ns + 100ns = 101ns입니다. TLB 미스 시: 1ns + 100ns + 100ns = 201ns입니다. 평균: 0.95 × 101 + 0.05 × 201 = 106ns입니다. TLB 없이는 200ns이므로, 거의 2배 빠릅니다.

**멀티레벨 테이블에서 더 큰 효과**

4단계 페이지 테이블에서는 TLB 미스 시 5번의 메모리 접근이 필요합니다. 4번의 테이블 워크와 1번의 데이터 접근입니다. 총 500ns가 소요됩니다. TLB 히트 시 101ns이므로, 약 5배 빠릅니다. 히트율이 99%면 평균 106ns로 TLB 없는 500ns 대비 거의 5배 향상됩니다.

**캐시와의 시너지**

TLB는 물리 주소를 빠르게 제공하여 캐시 접근도 가속화합니다. 가상 주소를 물리 주소로 변환한 후 캐시를 확인합니다. TLB가 빠르면 캐시 조회도 빨리 시작됩니다. 일부 캐시는 VIPT로 가상 인덱스를 사용하여 TLB와 병렬로 동작합니다. 이는 성능을 더욱 향상시킵니다.

**Huge Pages의 추가 효과**

큰 페이지를 사용하면 TLB 엔트리당 커버 범위가 넓어집니다. 4KB 페이지 64개 엔트리는 256KB를 커버하지만, 2MB 페이지는 128MB를 커버합니다. 같은 TLB 크기로 500배 넓은 영역을 표현합니다. 작업 세트가 TLB에 들어갈 가능성이 높아져 히트율이 향상됩니다. 이는 TLB 효과를 극대화합니다.

**실증적 성능 향상**

벤치마크에서 TLB는 메모리 집약적 작업의 성능을 10-50% 향상시킵니다. 무작위 접근 패턴에서는 효과가 크고, 순차 접근은 프리페칭으로 이미 빠릅니다. 데이터베이스, 과학 계산, 가상화 같은 워크로드에서 TLB 최적화가 중요합니다. Huge Pages 활용으로 더 큰 성능 개선을 얻을 수 있습니다.

**TLB 없는 시스템의 한계**

초기 페이징 시스템은 TLB가 없어 성능이 매우 나빴습니다. 모든 메모리 접근이 2배 느렸고, 멀티레벨 테이블은 사용할 수 없었습니다. TLB 도입으로 페이징이 실용적이 되었으며, 현대 시스템의 필수 요소가 되었습니다. TLB 없이는 가상 메모리의 오버헤드가 너무 커서 채택되기 어려웠을 것입니다.

**결론**

TLB는 메모리 접근의 대부분을 1-2 사이클로 단축시켜 페이징 오버헤드를 거의 제거합니다. 높은 히트율과 빠른 접근 속도로 가상 메모리를 실용적으로 만드는 핵심 하드웨어입니다. 현대 CPU 성능에서 TLB의 중요성은 아무리 강조해도 지나치지 않습니다.
