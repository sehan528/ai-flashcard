# Network 답변 모음 (93-96)

## 93. 로드밸런서가 무엇인가요?

**로드밸런서(Load Balancer)**는 들어오는 네트워크 트래픽을 여러 서버에 분산하는 장치 또는 소프트웨어입니다.

**목적:**

**트래픽 분산:**
한 서버에 부하가 집중되는 것을 방지합니다. 여러 서버에 고르게 요청을 분배합니다.

**고가용성(High Availability):**
한 서버가 다운되어도 다른 서버가 계속 서비스를 제공합니다. 단일 장애점(Single Point of Failure)을 제거합니다.

**확장성(Scalability):**
서버를 추가하여 처리 용량을 쉽게 늘릴 수 있습니다. 수평 확장(Scale-Out)이 가능합니다.

**성능 향상:**
서버 간 부하를 균등하게 분배하여 응답 시간을 줄입니다.

**동작 원리:**

**1. 요청 수신:**
클라이언트가 로드밸런서의 가상 IP(VIP)로 요청을 보냅니다. 사용자는 로드밸런서와 통신한다고 인식합니다.

**2. 서버 선택:**
로드밸런싱 알고리즘에 따라 백엔드 서버 중 하나를 선택합니다.

**3. 요청 전달:**
선택된 서버로 요청을 포워딩합니다. 필요시 IP 주소나 포트를 변경(NAT)합니다.

**4. 응답 반환:**
서버의 응답을 클라이언트에게 전달합니다.

**유형:**

**하드웨어 로드밸런서:**
전용 장비(F5, Citrix NetScaler, Radware)입니다. 고성능이지만 비용이 높습니다. 대규모 엔터프라이즈 환경에서 사용합니다.

**소프트웨어 로드밸런서:**
범용 서버에 설치하는 소프트웨어(HAProxy, Nginx, Apache)입니다. 유연하고 비용이 저렴합니다. 클라우드 환경에 적합합니다.

**클라우드 로드밸런서:**
클라우드 제공자의 관리형 서비스(AWS ELB, Google Cloud Load Balancer, Azure Load Balancer)입니다. 설정과 관리가 간편합니다. 자동 스케일링을 지원합니다.

**헬스 체크(Health Check):**

**목적:**
백엔드 서버의 상태를 지속적으로 확인합니다. 장애가 발생한 서버를 자동으로 제외합니다.

**방법:**
- **TCP 연결**: 특정 포트에 연결을 시도합니다
- **HTTP 요청**: 특정 경로에 GET 요청을 보내고 응답 코드를 확인합니다
- **커스텀 스크립트**: 복잡한 상태 검증을 수행합니다

**간격:**
일반적으로 5-30초마다 확인합니다. 연속 실패 횟수로 서버를 제외합니다(예: 3회 연속 실패).

**세션 유지(Session Persistence):**

**문제:**
Stateful 애플리케이션에서 사용자 요청이 서로 다른 서버로 가면 세션이 끊어집니다.

**해결:**

**Sticky Session(고정 세션):**
같은 클라이언트의 요청을 항상 같은 서버로 보냅니다. 쿠키나 IP 주소로 클라이언트를 식별합니다.

**Session Clustering:**
서버 간 세션을 공유합니다. Redis, Memcached 등 외부 저장소를 사용합니다.

**Stateless 설계:**
JWT 같은 토큰 기반 인증을 사용하여 세션 의존성을 제거합니다.

**SSL/TLS 종료:**

**SSL Termination:**
로드밸런서에서 HTTPS를 복호화합니다. 백엔드 서버는 HTTP로 통신하여 부담을 줄입니다. 인증서 관리가 중앙화됩니다.

**SSL Passthrough:**
암호화된 트래픽을 그대로 백엔드로 전달합니다. 엔드투엔드 암호화를 유지합니다.

**장점:**

**안정성:**
서버 장애 시 자동으로 다른 서버로 전환합니다.

**유연성:**
서버를 추가/제거하여 용량을 조절할 수 있습니다. 무중단 배포가 가능합니다.

**보안:**
백엔드 서버를 외부에 직접 노출하지 않습니다. DDoS 공격 완화에 도움이 됩니다.

**단점:**

**단일 장애점:**
로드밸런서 자체가 고장나면 전체 서비스가 중단됩니다. 로드밸런서도 이중화해야 합니다.

**비용:**
추가 하드웨어/소프트웨어 비용이 발생합니다.

**복잡성:**
설정과 관리가 복잡해질 수 있습니다.

**실무 활용:**

**웹 서비스:**
여러 웹 서버 앞에 로드밸런서를 배치합니다. 트래픽 증가 시 서버를 추가합니다.

**마이크로서비스:**
각 서비스마다 로드밸런서를 두어 독립적으로 확장합니다. 서비스 메시(Istio, Linkerd)가 이를 자동화합니다.

**데이터베이스:**
읽기 전용 복제본에 대한 쿼리를 분산합니다.

---

## 94. L4 로드밸런서와, L7 로드밸런서의 차이에 대해 설명해 주세요.

**L4 로드밸런서**와 **L7 로드밸런서**는 OSI 모델의 서로 다른 계층에서 동작하는 로드밸런서입니다.

**L4 로드밸런서 (전송 계층):**

**동작 계층:**
OSI 모델의 4계층(전송 계층)에서 동작합니다. TCP/UDP 수준에서 트래픽을 처리합니다.

**판단 기준:**
- **IP 주소**: 송신/수신 IP
- **포트 번호**: 송신/수신 포트
- **프로토콜**: TCP, UDP

**처리 방식:**
패킷의 IP 헤더와 TCP/UDP 헤더만 확인합니다. 애플리케이션 데이터(페이로드)를 보지 않습니다. 빠른 패킷 전달에 집중합니다.

**예시:**
모든 80번 포트 트래픽을 서버 풀에 분산합니다. IP 주소 기반으로 라운드 로빈을 수행합니다.

**장점:**
- **속도**: 패킷 처리가 매우 빠릅니다
- **효율**: 적은 리소스로 높은 처리량을 제공합니다
- **프로토콜 독립성**: HTTP 외 다양한 프로토콜을 지원합니다(FTP, SMTP, DB 등)
- **보안**: 애플리케이션 데이터를 복호화하지 않아도 됩니다

**단점:**
- **제한된 분산**: URL, 헤더, 쿠키 등을 고려할 수 없습니다
- **세션 유지 한계**: IP 기반 고정만 가능합니다
- **캐싱 불가**: 콘텐츠를 이해하지 못해 캐싱할 수 없습니다

**사용 사례:**
단순한 트래픽 분산, 높은 처리량이 필요한 경우, 프로토콜 다양성이 필요한 경우.

**L7 로드밸런서 (애플리케이션 계층):**

**동작 계층:**
OSI 모델의 7계층(애플리케이션 계층)에서 동작합니다. HTTP/HTTPS 같은 애플리케이션 프로토콜을 이해합니다.

**판단 기준:**
- **URL 경로**: /api, /images, /admin
- **HTTP 헤더**: Host, User-Agent, Content-Type
- **쿠키**: 세션 ID, 사용자 정보
- **HTTP 메서드**: GET, POST, PUT, DELETE
- **요청 내용**: JSON 데이터, 쿼리 파라미터

**처리 방식:**
패킷의 애플리케이션 데이터를 파싱하고 분석합니다. HTTP 요청을 완전히 이해하고 처리합니다. 필요시 콘텐츠를 수정하거나 캐싱합니다.

**예시:**
- /api/* 요청은 API 서버로
- /images/* 요청은 이미지 서버로
- 모바일 User-Agent는 모바일 최적화 서버로

**장점:**
- **정교한 분산**: URL, 헤더 등 다양한 조건으로 라우팅합니다
- **콘텐츠 기반 라우팅**: 요청 내용을 분석하여 최적 서버를 선택합니다
- **SSL 종료**: HTTPS 복호화/암호화를 담당합니다
- **캐싱**: 정적 콘텐츠를 캐싱하여 서버 부하를 줄입니다
- **압축**: Gzip 압축으로 대역폭을 절약합니다
- **보안**: WAF(Web Application Firewall) 기능을 통합할 수 있습니다

**단점:**
- **느린 속도**: 애플리케이션 데이터 파싱으로 지연이 증가합니다
- **높은 리소스**: CPU와 메모리를 더 많이 사용합니다
- **프로토콜 제한**: 주로 HTTP/HTTPS만 지원합니다

**사용 사례:**
마이크로서비스 아키텍처, API 게이트웨이, 복잡한 라우팅 규칙이 필요한 경우.

**비교 표:**

**처리 속도:**
- L4: 매우 빠름 (수백만 pps)
- L7: 상대적으로 느림

**판단 정보:**
- L4: IP, 포트
- L7: URL, 헤더, 쿠키, 콘텐츠

**프로토콜:**
- L4: 모든 TCP/UDP
- L7: 주로 HTTP/HTTPS

**세션 유지:**
- L4: IP 기반
- L7: 쿠키 기반

**캐싱:**
- L4: 불가
- L7: 가능

**SSL 처리:**
- L4: Passthrough
- L7: Termination 가능

**실제 예시:**

**L4 라우팅:**
```
클라이언트:50123 → 로드밸런서:80 → 서버1:8080
클라이언트:50124 → 로드밸런서:80 → 서버2:8080
```
포트 정보만으로 단순 분산합니다.

**L7 라우팅:**
```
GET /api/users → API 서버
GET /images/logo.png → 이미지 서버
POST /admin/login → 관리 서버
```
URL 경로로 서비스별 라우팅합니다.

**하이브리드 구성:**

**L4 + L7 조합:**
L4 로드밸런서를 앞단에 두어 트래픽을 먼저 분산합니다. 각 L4 뒤에 L7 로드밸런서를 배치하여 세밀한 라우팅을 수행합니다. 성능과 유연성을 동시에 확보합니다.

**대표 제품:**

**L4:**
AWS NLB(Network Load Balancer), IPVS, LVS.

**L7:**
AWS ALB(Application Load Balancer), Nginx, HAProxy, Envoy.

**선택 기준:**
단순한 트래픽 분산, 높은 성능 필요 → L4. 복잡한 라우팅, HTTP 기능 필요 → L7. 초고성능 + 세밀한 제어 → L4와 L7 조합.

---

## 95. 로드밸런서 알고리즘에 대해 설명해 주세요.

**로드밸런서 알고리즘**은 들어오는 요청을 어느 서버로 보낼지 결정하는 방법입니다.

**1. 라운드 로빈(Round Robin):**

**원리:**
요청을 서버 목록 순서대로 순환하며 분배합니다. 서버 A → B → C → A → B → C...

**장점:**
구현이 간단합니다. 서버 간 균등하게 분산됩니다.

**단점:**
서버 성능 차이를 고려하지 않습니다. 요청 처리 시간이 다를 때 불균형이 발생합니다.

**적합한 경우:**
모든 서버가 동일한 성능을 가질 때. 요청 처리 시간이 비슷할 때.

**2. 가중 라운드 로빈(Weighted Round Robin):**

**원리:**
각 서버에 가중치를 부여합니다. 가중치가 높은 서버에 더 많은 요청을 보냅니다. 예: A(가중치 3), B(가중치 2), C(가중치 1) → A, A, A, B, B, C 순서로 분배.

**장점:**
서버 성능 차이를 반영할 수 있습니다. 점진적인 배포(Canary Deployment)에 유용합니다.

**단점:**
가중치를 수동으로 설정해야 합니다.

**적합한 경우:**
서버 성능이 다를 때. 일부 서버에 더 많은 트래픽을 보내고 싶을 때.

**3. 최소 연결(Least Connections):**

**원리:**
현재 활성 연결 수가 가장 적은 서버를 선택합니다. 동적으로 서버 부하를 고려합니다.

**장점:**
장시간 연결이나 처리 시간이 다를 때 효과적입니다. 실시간으로 부하를 반영합니다.

**단점:**
연결 수를 추적해야 하므로 오버헤드가 있습니다.

**적합한 경우:**
WebSocket, 스트리밍 등 장시간 연결. 요청 처리 시간이 크게 다를 때.

**4. 가중 최소 연결(Weighted Least Connections):**

**원리:**
최소 연결 방식에 서버 가중치를 추가합니다. 연결 수를 가중치로 나눈 값이 가장 작은 서버를 선택합니다.

**장점:**
서버 성능과 현재 부하를 모두 고려합니다.

**적합한 경우:**
성능이 다른 서버를 효율적으로 활용할 때.

**5. IP 해시(IP Hash):**

**원리:**
클라이언트 IP 주소를 해시하여 서버를 결정합니다. 같은 IP는 항상 같은 서버로 연결됩니다.

**장점:**
세션 고정(Sticky Session)이 자동으로 이루어집니다. 추가 쿠키나 설정이 필요 없습니다.

**단점:**
IP 주소가 변경되면 다른 서버로 연결됩니다. NAT 뒤의 여러 사용자가 같은 IP로 보일 수 있습니다. 서버 추가/제거 시 많은 세션이 재분배됩니다.

**적합한 경우:**
Stateful 애플리케이션. 세션 유지가 중요한 경우.

**6. URL 해시(URL Hash):**

**원리:**
요청 URL을 해시하여 서버를 결정합니다. 같은 URL은 항상 같은 서버로 연결됩니다.

**장점:**
캐싱 효율이 높아집니다. 같은 콘텐츠는 항상 같은 서버에서 제공됩니다.

**단점:**
URL 분포가 고르지 않으면 불균형이 발생합니다.

**적합한 경우:**
CDN, 프록시 캐시. 정적 콘텐츠 서빙.

**7. 최소 응답 시간(Least Response Time):**

**원리:**
응답 시간이 가장 짧은 서버를 선택합니다. 헬스 체크로 응답 시간을 측정합니다.

**장점:**
사용자가 가장 빠른 서비스를 받습니다.

**단점:**
지속적인 측정이 필요하여 오버헤드가 큽니다.

**적합한 경우:**
지연 시간이 중요한 애플리케이션. 지리적으로 분산된 서버.

**8. 랜덤(Random):**

**원리:**
서버를 무작위로 선택합니다.

**장점:**
구현이 간단합니다. 서버 수가 많을 때 통계적으로 균등해집니다.

**단점:**
단기적으로 불균형이 발생할 수 있습니다.

**적합한 경우:**
간단한 테스트 환경. 서버 수가 매우 많을 때.

**9. 리소스 기반(Resource-Based):**

**원리:**
서버의 CPU, 메모리, 디스크 사용률을 실시간 모니터링합니다. 리소스가 가장 여유로운 서버를 선택합니다.

**장점:**
서버 상태를 정확히 반영합니다.

**단점:**
모니터링 오버헤드가 큽니다. 네트워크 지연이 추가될 수 있습니다.

**적합한 경우:**
서버 부하가 매우 다양할 때. 동적 워크로드.

**10. 일관성 해싱(Consistent Hashing):**

**원리:**
해시 링을 사용하여 서버를 배치합니다. 서버 추가/제거 시 최소한의 키만 재분배됩니다.

**장점:**
서버 변경 시 영향을 최소화합니다. 캐시 무효화를 줄입니다.

**단점:**
구현이 복잡합니다.

**적합한 경우:**
분산 캐시. 동적으로 서버가 추가/제거되는 환경.

**선택 기준:**

**동일 성능, 단순 환경:**
라운드 로빈.

**성능 차이, 정적 환경:**
가중 라운드 로빈.

**동적 부하, 장시간 연결:**
최소 연결.

**세션 유지 필요:**
IP 해시.

**캐싱 최적화:**
URL 해시 또는 일관성 해싱.

**실무 권장:**
대부분의 경우 라운드 로빈이나 최소 연결로 시작합니다. 필요에 따라 가중치를 추가하거나 해시 기반으로 전환합니다. 모니터링하여 알고리즘 효과를 검증합니다.

---

## 96. 로드밸런싱 대상이 되는 장치중 일부 장치가 문제가 생겨 접속이 불가능하다고 가정해 봅시다. 이 경우, 로드밸런서가 해당 장비로 요청을 보내지 않도록 하려면 어떻게 해야 할까요?

로드밸런서는 **헬스 체크(Health Check)** 메커니즘으로 장애 서버를 자동으로 감지하고 제외합니다.

**헬스 체크 메커니즘:**

**1. 주기적 검사:**
로드밸런서가 일정 간격으로 백엔드 서버의 상태를 확인합니다. 일반적으로 5-30초마다 검사합니다.

**2. 검사 방법:**

**TCP 연결 확인:**
특정 포트에 TCP 연결을 시도합니다. 연결 성공하면 서버가 살아있다고 판단합니다. 빠르고 간단하지만 애플리케이션 상태를 확인하지 못합니다.

**HTTP/HTTPS 요청:**
특정 경로(예: /health, /ping)에 GET 요청을 보냅니다. 응답 코드를 확인합니다(일반적으로 200 OK 기대). 응답 본문을 검증할 수도 있습니다.

**커스텀 스크립트:**
복잡한 검증 로직을 실행합니다. 데이터베이스 연결, 의존 서비스 확인 등을 수행합니다.

**3. 실패 판정:**

**연속 실패 횟수:**
일시적인 오류를 무시하기 위해 여러 번 실패해야 제외합니다. 일반적으로 2-3회 연속 실패 시 제외합니다.

**타임아웃:**
응답이 일정 시간(예: 3초) 내에 오지 않으면 실패로 간주합니다.

**4. 서버 제외:**
실패 조건을 만족하면 해당 서버를 서버 풀에서 제외합니다. 새로운 요청을 해당 서버로 보내지 않습니다.

**5. 복구 감지:**

**계속 검사:**
제외된 서버도 계속 헬스 체크를 수행합니다.

**복구 확인:**
연속적으로 성공하면(예: 2-3회) 서버 풀에 다시 추가합니다.

**점진적 복구:**
즉시 전체 트래픽을 보내지 않고 점진적으로 증가시킵니다.

**헬스 체크 예시:**

**AWS ELB:**
```
Target: /health
Interval: 30초
Timeout: 5초
Healthy threshold: 2회 연속 성공
Unhealthy threshold: 3회 연속 실패
```

**Nginx:**
```
upstream backend {
    server backend1.example.com;
    server backend2.example.com;

    health_check interval=5s
                 fails=3
                 passes=2
                 uri=/health
                 match=server_ok;
}

match server_ok {
    status 200;
    body ~ "OK";
}
```

**고급 헬스 체크:**

**애플리케이션 레벨 체크:**
단순히 서버가 실행 중인지가 아니라 정상 동작하는지 확인합니다. 데이터베이스 연결, 캐시 접근, 의존 서비스 확인 등을 포함합니다.

**엔드포인트 구현:**
백엔드 서버에 /health 엔드포인트를 구현합니다. 자체 진단 로직을 실행하고 상태를 반환합니다.
```
GET /health
200 OK
{ "status": "healthy", "database": "ok", "cache": "ok" }
```

**Graceful Shutdown:**

**문제:**
서버 종료 중에도 로드밸런서가 요청을 보낼 수 있습니다.

**해결:**

**1. 헬스 체크 실패 반환:**
서버가 종료를 시작하면 헬스 체크에 실패 응답을 반환합니다.

**2. 대기:**
로드밸런서가 서버를 제외할 때까지 기다립니다(헬스 체크 간격 + 실패 횟수).

**3. 기존 요청 완료:**
진행 중인 요청을 모두 처리합니다.

**4. 종료:**
안전하게 서버를 종료합니다.

**드레이닝(Draining):**

**원리:**
서버를 서버 풀에서 제외하되 기존 연결은 유지합니다. 새 요청은 받지 않고 기존 요청만 완료합니다.

**사용:**
배포, 유지보수, 서버 교체 시 사용합니다.

**자동 복구:**

**Auto Healing:**
클라우드 환경에서 헬스 체크 실패 시 자동으로 인스턴스를 교체합니다. AWS Auto Scaling, Kubernetes Liveness Probe 등이 해당합니다.

**Self-Healing:**
서버 자체가 문제를 감지하고 재시작을 시도합니다.

**모니터링과 알림:**

**서버 제외 알림:**
서버가 서버 풀에서 제외되면 관리자에게 알립니다.

**헬스 체크 실패 로그:**
실패 원인을 분석할 수 있도록 로깅합니다.

**대시보드:**
실시간으로 서버 풀 상태를 시각화합니다.

**실무 권장사항:**

**적절한 간격:**
너무 짧으면 서버 부하, 너무 길면 장애 감지 지연. 일반적으로 10-30초가 적절합니다.

**타임아웃 설정:**
네트워크 지연을 고려하여 여유 있게 설정합니다.

**점진적 제외:**
연속 실패로 일시적 문제를 무시합니다.

**테스트:**
헬스 체크 엔드포인트를 정기적으로 테스트합니다. 장애 시나리오를 시뮬레이션합니다.

**백업:**
최소 2대 이상의 서버를 유지하여 모든 서버가 동시에 제외되지 않도록 합니다.
