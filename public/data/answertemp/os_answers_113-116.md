# OS 답변 113-116

## 113. LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?

**기본 개념**

LRU 알고리즘은 시간적 지역성을 이용합니다. 최근에 사용된 데이터는 가까운 미래에 다시 사용될 가능성이 높다는 프로그램 실행 패턴을 활용하는 알고리즘입니다.

**시간적 지역성의 원리**

프로그램은 한정된 시간 동안 제한된 데이터 집합을 집중적으로 사용합니다. 루프 변수, 함수 지역 변수, 자주 호출되는 함수 코드가 반복적으로 접근됩니다. 최근에 사용했다는 것은 작업 세트에 포함되어 있다는 신호입니다. 반대로 오랫동안 사용되지 않은 데이터는 작업 세트를 벗어났을 가능성이 높습니다.

**과거로 미래 예측**

LRU는 과거의 접근 패턴이 미래에도 지속된다고 가정합니다. 통계적으로 대부분의 프로그램에서 이 가정이 맞습니다. 작업 세트는 점진적으로 변하므로, 최근 사용 이력이 미래를 예측하는 좋은 지표입니다. 이는 경험적으로 검증된 원리이며, 다양한 워크로드에서 효과적입니다.

**작업 세트 이론과의 관계**

작업 세트는 프로세스가 특정 시간 창 동안 접근하는 페이지 집합입니다. LRU는 암묵적으로 작업 세트를 추적합니다. 최근 사용된 페이지들이 현재 작업 세트를 구성하며, 이를 메모리에 유지합니다. 오래된 페이지는 작업 세트에서 벗어난 것으로 간주하여 교체합니다.

**LRU의 효과**

시간적 지역성이 강한 프로그램에서 LRU는 거의 최적에 가까운 성능을 제공합니다. 루프 중심 코드, 재귀 함수, 반복 데이터 처리에서 페이지 폴트를 최소화합니다. 지역성이 약한 무작위 접근 패턴에서는 효과가 떨어지지만, 여전히 FIFO보다는 우수합니다.

**공간적 지역성과의 차이**

LRU는 주로 시간적 지역성을 활용합니다. 공간적 지역성은 캐시 라인이나 프리페칭으로 활용됩니다. 페이지 크기가 커지면 한 페이지에 인접 데이터가 함께 들어와 공간적 지역성도 간접적으로 활용됩니다. 하지만 LRU 자체는 시간 기반 정책입니다.

**실증적 성능**

벤치마크와 실제 시스템에서 LRU는 우수한 성능을 보입니다. Optimal 알고리즘과 비교하여 페이지 폴트가 10-20% 정도만 더 발생합니다. FIFO보다는 30-50% 적은 폴트를 기록합니다. 이는 시간적 지역성이 실제 프로그램에서 강하게 나타난다는 증거입니다.

**예외 상황**

순차 스캔처럼 데이터를 한 번만 읽고 버리는 패턴에서는 LRU가 불리할 수 있습니다. 스캔된 페이지가 메모리를 차지하여 정작 필요한 작업 세트를 밀어냅니다. 이런 경우 MRU나 특수한 정책이 더 나을 수 있습니다. 하지만 대부분의 워크로드는 LRU가 적합합니다.

**결론**

LRU는 시간적 지역성이라는 프로그램의 근본적 특성을 이용한 알고리즘입니다. 이 특성이 널리 나타나기 때문에 LRU는 효과적이며, 페이지 교체의 표준적인 선택이 되었습니다. 간단한 원리이지만 강력한 성능을 제공하는 우아한 알고리즘입니다.

---

## 114. LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?

**기본 개념**

LRU는 각 페이지의 마지막 사용 시간을 추적하여, 교체 시 가장 오래된 것을 선택합니다. 하지만 정확한 구현은 비용이 크므로, 실제로는 근사 방법을 사용합니다.

**완전 LRU - 타임스탬프 방식**

각 페이지에 마지막 접근 시간을 기록합니다. 메모리 접근마다 현재 시간으로 업데이트해야 합니다. 교체 필요 시 모든 페이지를 순회하여 가장 오래된 것을 찾습니다. 이는 매우 비용이 크며, 하드웨어 지원 없이 실용적이지 않습니다. 모든 메모리 접근에 타임스탬프 업데이트 오버헤드가 발생합니다.

**완전 LRU - 연결 리스트 방식**

이중 연결 리스트로 페이지를 순서대로 관리합니다. 가장 최근 사용된 페이지는 리스트 앞에, 오래된 것은 뒤에 위치합니다. 페이지 접근 시 해당 노드를 리스트 앞으로 이동시킵니다. 교체 시 리스트 뒤에서 제거합니다. 이것도 메모리 접근마다 리스트 조작이 필요하여 비용이 큽니다.

**Reference 비트 - 1비트 근사**

하드웨어가 제공하는 1비트 Reference 비트를 사용합니다. 페이지 접근 시 하드웨어가 자동으로 1로 설정합니다. 주기적으로 소프트웨어가 비트를 읽고 0으로 리셋합니다. 교체 시 비트가 0인 페이지를 선택합니다. 이는 최근 사용 여부만 구분하여 정확하지 않지만, 오버헤드가 매우 적습니다.

**Clock 알고리즘**

페이지를 원형 리스트로 구성하고 시계 바늘처럼 포인터를 이동시킵니다. 교체 필요 시 포인터 위치부터 순회하며 Reference 비트를 확인합니다. 1이면 0으로 바꾸고 다음으로, 0이면 해당 페이지를 교체합니다. 한 바퀴 돌면 모든 비트가 0이 되어 다음 페이지가 선택됩니다. LRU의 실용적 근사이며, 구현이 간단하고 성능이 좋습니다.

**Multiple Reference 비트**

여러 비트를 사용하여 정확도를 높입니다. 8비트를 사용하면 더 세밀한 시간 추적이 가능합니다. 주기적으로 비트를 오른쪽으로 시프트하고, 최상위 비트에 Reference 비트 값을 넣습니다. 교체 시 비트 값을 숫자로 해석하여 가장 작은 페이지를 선택합니다. 이는 근사 타임스탬프로 작동하며, 정확도와 비용의 균형을 제공합니다.

**Second Chance와 Enhanced Second Chance**

FIFO에 Reference 비트를 추가하여 최근 사용된 페이지에 기회를 줍니다. Enhanced 버전은 Dirty 비트도 고려하여 쓰기 비용을 최소화합니다. 네 가지 클래스로 분류하여 우선순위를 정합니다. 구현이 간단하면서도 효과적인 LRU 근사입니다.

**소프트웨어 LRU**

운영체제가 페이지 테이블을 주기적으로 스캔하여 Reference 비트를 수집합니다. 커스텀 카운터나 타임스탬프를 소프트웨어로 유지합니다. 페이지 폴트 핸들러에서 접근 정보를 기록합니다. 하드웨어 지원이 제한적일 때 사용하지만, 오버헤드가 큽니다.

**실무 구현**

리눅스는 Active/Inactive 리스트를 사용합니다. 최근 접근된 페이지를 Active로, 오래된 것을 Inactive로 분류합니다. Reference 비트로 두 리스트 간 이동을 관리합니다. Inactive 리스트의 끝에서 교체하여 LRU를 근사합니다. 효율적이고 확장 가능한 설계로 실제 시스템에서 잘 동작합니다.

**결론**

완전한 LRU는 비용이 커서 실용적이지 않습니다. Reference 비트와 Clock 알고리즘 같은 하드웨어 지원 근사가 표준입니다. 간단하면서도 LRU의 이점을 대부분 제공하여, 실제 운영체제에서 널리 사용됩니다. 정확도보다 효율성과 단순성을 우선합니다.

---

## 115. LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요.

**기본 개념**

LRU는 우수한 알고리즘이지만 몇 가지 단점이 있습니다. 구현 복잡도, 특정 접근 패턴에서의 비효율성, 스캔 문제 등이 대표적입니다.

**구현 복잡도와 비용**

정확한 LRU는 모든 메모리 접근마다 타임스탬프나 리스트를 업데이트해야 합니다. 이는 하드웨어와 소프트웨어 모두 비용이 큽니다. 페이지 수가 많으면 교체 대상 찾기도 오래 걸립니다. Reference 비트 근사도 완벽하지 않으며, 주기적 스캔이 필요합니다.

**순차 스캔 문제**

대용량 파일을 한 번 스캔하면 모든 페이지가 "최근 사용됨"으로 표시됩니다. 실제 작업 세트가 메모리에서 밀려나서 성능이 저하됩니다. 스캔 데이터는 다시 사용되지 않는데 메모리를 오래 차지합니다. LRU는 이런 일회성 접근을 구분하지 못합니다.

**Belady's Anomaly 가능성**

LRU는 Stack 알고리즘이어서 Belady's Anomaly가 발생하지 않습니다. 하지만 Clock 같은 LRU 근사는 stack property를 보장하지 않아 드물게 anomaly가 발생할 수 있습니다. 프레임 수를 늘려도 성능이 개선되지 않을 수 있습니다.

**대안 1 - LRU-K**

마지막 K번의 접근 시간을 추적합니다. K=2인 LRU-2는 두 번째 마지막 접근 시간으로 교체를 결정합니다. 일회성 접근은 한 번만 기록되어 우선 교체 대상이 됩니다. 반복 접근은 두 번째 시간이 기록되어 보호됩니다. 스캔 문제를 완화하지만 구현이 더 복잡합니다.

**대안 2 - ARC**

Adaptive Replacement Cache는 LRU와 LFU를 결합합니다. 최근 사용과 빈번 사용 두 기준을 동적으로 조절합니다. 워크로드 특성에 따라 자동으로 적응하여 최적 균형을 찾습니다. IBM이 특허를 가지고 있어 리눅스에서는 사용하지 않지만, 상용 시스템에서 활용됩니다.

**대안 3 - LIRS**

Low Inter-reference Recency Set은 재사용 거리를 추적합니다. 짧은 재사용 거리를 가진 페이지를 우선 유지합니다. 스캔 같은 큰 재사용 거리 패턴을 효과적으로 처리합니다. LRU보다 복잡하지만 다양한 워크로드에서 우수한 성능을 보입니다.

**대안 4 - CAR**

Clock with Adaptive Replacement는 ARC를 Clock으로 구현한 버전입니다. 특허 회피와 구현 단순화를 동시에 달성합니다. LRU 리스트와 LFU 리스트를 Clock으로 관리하여 효율적입니다. 적응적 조절로 다양한 패턴에 대응합니다.

**대안 5 - Working Set**

작업 세트 알고리즘은 시간 창 내 접근된 페이지를 유지합니다. 현재 작업 세트를 명시적으로 추적하여 폴트를 최소화합니다. 이론적으로 우수하지만 구현이 복잡하고 비용이 커서 실용성이 떨어집니다.

**실무 접근**

대부분의 시스템은 Clock이나 Second Chance 같은 간단한 LRU 근사를 사용합니다. 복잡한 알고리즘의 이점이 구현 비용을 정당화하기 어렵습니다. 충분한 메모리를 제공하여 교체를 최소화하는 것이 더 실용적입니다. 특수한 워크로드는 애플리케이션 레벨에서 캐시를 관리합니다.

**결론**

LRU의 단점은 구현 비용과 특정 패턴에서의 비효율성입니다. 다양한 대안이 제안되었지만, 대부분은 복잡도 증가로 실제 채택이 제한적입니다. 간단한 LRU 근사가 여전히 가장 균형잡힌 선택이며, 실무에서 널리 사용됩니다.

---

## 116. File Descriptor와, File System에 대해 설명해 주세요.

**기본 개념**

File Descriptor는 열린 파일을 가리키는 정수 식별자이고, File System은 디스크의 데이터를 파일과 디렉토리로 구조화하여 관리하는 시스템입니다. 두 개념은 파일 I/O의 핵심입니다.

**File Descriptor의 정의**

File Descriptor는 프로세스가 열린 파일을 참조하는 작은 음수가 아닌 정수입니다. 프로세스별로 독립적인 FD 테이블을 가지며, 같은 파일도 프로세스마다 다른 FD를 가질 수 있습니다. 0은 표준 입력, 1은 표준 출력, 2는 표준 에러로 예약되어 있습니다. 새로 열린 파일은 가장 작은 사용 가능한 번호를 할당받습니다.

**File Descriptor Table**

커널은 각 프로세스의 FD 테이블을 관리합니다. 테이블의 각 엔트리는 열린 파일 테이블을 가리킵니다. 열린 파일 테이블은 파일 오프셋, 접근 모드, 플래그를 저장합니다. 여러 FD가 같은 열린 파일 엔트리를 공유할 수 있으며, fork 후 부모와 자식이 이를 공유합니다. 열린 파일 엔트리는 실제 파일의 inode를 가리킵니다.

**File Descriptor 사용**

파일을 open하면 FD를 반환받습니다. 이후 read, write, lseek, close 등의 시스템 콜에 FD를 전달합니다. FD는 파일뿐 아니라 소켓, 파이프, 디바이스도 표현합니다. 유닉스의 "모든 것은 파일" 철학을 구현하는 추상화입니다. dup과 dup2로 FD를 복제하여 리다이렉션을 구현할 수 있습니다.

**File System의 정의**

File System은 저장 장치의 데이터를 파일과 디렉토리로 조직화하는 방법입니다. 파일 이름, 경로, 메타데이터, 권한을 관리합니다. 디스크 블록을 할당하고, 빈 공간을 추적하며, 일관성을 유지합니다. ext4, NTFS, APFS, FAT32 등 다양한 파일 시스템이 존재합니다.

**File System 구조**

슈퍼블록은 파일 시스템 메타데이터를 저장합니다. 크기, 블록 수, inode 수, 마운트 상태 등입니다. inode 테이블은 각 파일의 메타데이터를 저장합니다. 크기, 권한, 타임스탬프, 블록 포인터가 포함됩니다. 데이터 블록은 실제 파일 내용을 저장합니다. 비트맵이나 리스트로 빈 블록을 추적합니다.

**디렉토리**

디렉토리는 파일 이름과 inode 번호의 매핑을 저장하는 특수 파일입니다. 계층 구조를 통해 파일을 구조화합니다. 경로 탐색 시 각 디렉토리를 순회하여 inode를 찾습니다. 하드 링크는 같은 inode를 가리키는 여러 디렉토리 엔트리입니다. 심볼릭 링크는 다른 파일의 경로를 저장하는 특수 파일입니다.

**파일 I/O 과정**

프로세스가 open을 호출하면, 커널이 경로를 탐색하여 inode를 찾습니다. 권한을 확인하고, 열린 파일 엔트리를 생성합니다. FD를 할당하여 프로세스에 반환합니다. read/write 시 FD로 inode를 찾고, 오프셋에 해당하는 블록을 읽거나 씁니다. 블록 I/O는 버퍼 캐시를 거쳐 성능을 최적화합니다. close 시 FD와 열린 파일 엔트리를 정리합니다.

**VFS**

Virtual File System은 여러 파일 시스템에 대한 공통 인터페이스를 제공합니다. 애플리케이션은 VFS를 통해 파일에 접근하고, VFS가 실제 파일 시스템으로 요청을 전달합니다. 이는 ext4, NFS, FAT 등 다른 파일 시스템을 투명하게 사용할 수 있게 합니다.

**실무 활용**

프로그램은 FD를 통해 파일을 조작하며, 내부 파일 시스템 구조를 알 필요가 없습니다. 저널링 파일 시스템은 크래시 복구를 빠르게 합니다. SSD 최적화 파일 시스템은 플래시 특성에 맞춰 설계됩니다. 분산 파일 시스템은 네트워크를 통해 투명하게 접근합니다. FD와 파일 시스템은 운영체제 I/O의 근간입니다.
