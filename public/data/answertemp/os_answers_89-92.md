# OS 답변 89-92

## 89. 가상 메모리란 무엇인가요?

**기본 개념**

가상 메모리는 프로세스에게 실제 물리 메모리보다 큰 주소 공간을 제공하는 메모리 관리 기법입니다. 프로그램은 연속된 가상 주소 공간을 사용하지만, 실제로는 불연속적인 물리 메모리에 매핑됩니다.

**가상 메모리의 구현**

각 프로세스는 독립적인 가상 주소 공간을 가지며, MMU가 가상 주소를 물리 주소로 변환합니다. 페이지 테이블이 매핑 정보를 저장하여, 가상 페이지가 어느 물리 프레임에 있는지 추적합니다. 모든 가상 페이지가 항상 메모리에 있을 필요는 없으며, 필요할 때 디스크에서 가져옵니다. 이를 요구 페이징이라고 하며, 실제 사용되는 페이지만 메모리에 적재하여 효율성을 높입니다.

**가상 메모리의 장점**

프로세스가 물리 메모리 크기에 제약받지 않습니다. 64비트 시스템에서는 이론상 엑사바이트 규모의 주소 공간을 사용할 수 있습니다. 각 프로세스가 독립적인 주소 공간을 가져 메모리 보호가 자동으로 이루어집니다. 한 프로세스는 다른 프로세스의 메모리에 접근할 수 없어 안전합니다. 코드와 라이브러리를 여러 프로세스가 공유하여 메모리를 절약할 수 있습니다.

**요구 페이징**

프로그램 시작 시 모든 코드를 로드하지 않고, 실제 실행되는 부분만 메모리에 가져옵니다. 페이지 폴트가 발생하면 운영체제가 필요한 페이지를 디스크에서 읽어 메모리에 적재합니다. 대부분의 프로그램은 전체 코드의 일부만 사용하므로, 요구 페이징으로 메모리 사용량을 크게 줄입니다. 프로그램 시작 속도도 빨라집니다.

**스와핑**

물리 메모리가 부족하면 사용되지 않는 페이지를 디스크로 스왑 아웃합니다. 나중에 해당 페이지가 필요하면 다시 스왑 인합니다. 스왑 공간은 디스크의 특별한 영역이나 파일로 구현됩니다. 이를 통해 실행 중인 프로세스들의 메모리 합이 물리 메모리보다 클 수 있습니다. 하지만 과도한 스와핑은 Thrashing을 유발합니다.

**메모리 오버커밋**

리눅스 같은 시스템은 메모리 오버커밋을 허용하여, 프로세스가 요청한 메모리를 모두 할당한 것처럼 보이지만 실제로는 사용할 때 할당합니다. fork 후 copy-on-write로 부모와 자식이 페이지를 공유하다가, 수정 시에만 복사합니다. 이는 메모리 효율성을 크게 높이지만, 실제 메모리 부족 시 OOM Killer가 프로세스를 종료할 수 있습니다.

**주소 변환 과정**

CPU가 가상 주소를 생성하면, MMU가 페이지 테이블을 조회하여 물리 주소로 변환합니다. TLB 캐시가 최근 변환을 저장하여 대부분의 경우 빠르게 처리됩니다. TLB 미스 시 페이지 테이블을 참조하고, 페이지 폴트 시 운영체제가 개입합니다. 변환은 하드웨어가 자동으로 수행하여 프로그램은 가상 주소만 사용하면 됩니다.

**실무 활용**

모든 현대 운영체제가 가상 메모리를 사용합니다. 데이터베이스는 버퍼 풀을 가상 메모리에 매핑하여 큰 데이터셋을 다룹니다. 메모리 맵 파일로 파일을 메모리처럼 접근하여 I/O를 간소화합니다. 가상 메모리는 현대 컴퓨팅의 핵심 기술이며, 멀티태스킹과 보안의 기반입니다.

---

## 90. 가상 메모리가 가능한 이유가 무엇일까요?

**기본 개념**

가상 메모리가 실용적으로 동작하는 이유는 프로그램의 지역성 원리와 하드웨어 지원 덕분입니다. 이론적으로는 모든 메모리를 디스크에 둘 수 있지만, 지역성 때문에 작은 물리 메모리로도 충분합니다.

**지역성의 원리**

프로그램은 시간적 지역성과 공간적 지역성을 가지므로, 특정 시점에는 전체 주소 공간 중 작은 부분만 접근합니다. 작업 세트가 물리 메모리에 들어가면, 대부분의 메모리 접근이 페이지 폴트 없이 처리됩니다. 루프는 같은 코드와 데이터를 반복 사용하고, 함수 호출은 스택의 제한된 영역을 사용합니다. 이런 패턴 덕분에 전체 프로그램을 메모리에 둘 필요가 없습니다.

**하드웨어 주소 변환**

MMU가 가상 주소를 물리 주소로 빠르게 변환합니다. 각 메모리 접근마다 변환이 필요하지만, TLB 캐시로 오버헤드를 최소화합니다. TLB 히트율이 95% 이상이면 성능 영향이 크지 않습니다. 페이지 테이블 워크도 하드웨어가 자동으로 수행하여 소프트웨어 개입이 적습니다. 하드웨어 지원 없이는 가상 메모리가 실용적이지 않습니다.

**페이징의 투명성**

프로그램은 가상 주소만 사용하며, 물리 메모리 관리를 인식할 필요가 없습니다. 컴파일러도 가상 주소로 코드를 생성하여, 프로그램이 어느 물리 위치에 로드되든 동작합니다. 운영체제가 페이지 폴트를 투명하게 처리하여, 프로그램은 모든 메모리가 항상 존재하는 것처럼 느낍니다. 이 추상화가 프로그래밍을 크게 단순화합니다.

**디스크의 보조 역할**

디스크는 느리지만 용량이 크고 저렴합니다. 자주 사용되지 않는 페이지를 디스크에 저장하여 물리 메모리를 효율적으로 활용합니다. 대부분의 접근은 메모리에서 처리되고, 가끔 디스크 접근이 발생합니다. 지역성이 강하면 디스크 접근 빈도가 낮아 성능 저하가 크지 않습니다. SSD의 등장으로 스왑 성능이 더욱 향상되었습니다.

**멀티레벨 페이지 테이블**

64비트 주소 공간은 엄청나게 크지만, 대부분은 사용되지 않습니다. 멀티레벨 페이지 테이블은 실제 사용되는 영역만 테이블을 할당하여 메모리를 절약합니다. 4단계 페이지 테이블로 거대한 주소 공간을 효율적으로 관리합니다. 희소한 주소 공간 사용 패턴이 이를 가능하게 합니다.

**운영체제의 정교한 관리**

운영체제는 LRU 같은 교체 알고리즘으로 중요한 페이지를 메모리에 유지합니다. 프리페칭으로 필요한 페이지를 미리 가져오고, Dirty 비트로 불필요한 쓰기를 방지합니다. 작업 세트 크기를 추적하여 프로세스별 프레임 할당을 최적화합니다. 이런 관리 덕분에 제한된 물리 메모리로 많은 프로세스를 효율적으로 실행합니다.

**실증적 검증**

수십 년간의 경험으로 가상 메모리가 실용적임이 입증되었습니다. 대부분의 프로그램은 강한 지역성을 가져서 페이지 폴트율이 낮습니다. 물리 메모리의 몇 배 크기의 프로그램도 실용적 성능으로 실행됩니다. 가끔 Thrashing이 발생하지만, 일반적으로는 매우 효과적입니다. 이론과 실제가 모두 뒷받침하는 성공적인 기술입니다.

---

## 91. Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.

**기본 개념**

Page Fault는 프로세스가 접근하려는 페이지가 물리 메모리에 없을 때 발생하는 예외입니다. MMU가 페이지 테이블을 조회했을 때 유효하지 않으면 인터럽트를 발생시킵니다.

**Page Fault 감지**

CPU가 가상 주소로 메모리 접근을 시도하면, MMU가 페이지 테이블을 확인합니다. Present 비트가 0이면 해당 페이지가 메모리에 없다는 뜻입니다. MMU는 Page Fault 예외를 발생시키고, CPU는 현재 명령어 실행을 중단합니다. 제어가 커널의 Page Fault 핸들러로 전달됩니다. 폴트를 일으킨 주소와 접근 유형이 저장됩니다.

**주소 유효성 검사**

Page Fault 핸들러는 먼저 접근 주소가 유효한지 확인합니다. 프로세스의 가상 주소 공간 내에 있고, 접근 권한이 있는지 검사합니다. 유효하지 않은 주소나 권한 위반이면 Segmentation Fault를 발생시켜 프로세스를 종료합니다. 유효한 주소이지만 메모리에 없는 경우만 정상적인 Page Fault로 처리합니다.

**빈 프레임 찾기**

물리 메모리에 사용 가능한 빈 프레임이 있는지 확인합니다. 빈 프레임이 있으면 바로 사용하고, 없으면 희생 페이지를 선택하여 제거해야 합니다. LRU나 Clock 같은 교체 알고리즘으로 희생자를 결정합니다. 희생 페이지가 Dirty면 먼저 디스크에 써야 하고, Clean이면 바로 폐기할 수 있습니다. 쓰기 작업은 시간이 오래 걸려서 프로세스가 블로킹됩니다.

**페이지 로드**

필요한 페이지를 디스크의 스왑 공간이나 파일 시스템에서 읽어옵니다. 실행 파일의 코드 페이지는 파일에서, 스왑 아웃된 데이터 페이지는 스왑 공간에서 가져옵니다. 디스크 I/O는 느리므로 프로세스는 대기 상태로 전환되고, 다른 프로세스가 실행됩니다. I/O가 완료되면 인터럽트가 발생하고, 프로세스가 준비 큐로 이동합니다.

**페이지 테이블 업데이트**

로드된 페이지를 페이지 테이블에 등록합니다. Present 비트를 1로 설정하고, 물리 프레임 번호를 기록합니다. 접근 비트와 Dirty 비트를 초기화합니다. 권한 비트를 설정하여 읽기/쓰기/실행 여부를 지정합니다. TLB를 무효화하거나 업데이트하여 캐시 일관성을 유지합니다.

**명령어 재실행**

Page Fault를 일으킨 명령어를 다시 실행합니다. 이번에는 페이지가 메모리에 있으므로 정상적으로 완료됩니다. 프로세스는 Page Fault가 발생한 것을 인식하지 못하고, 약간의 지연만 경험합니다. 이 투명성이 가상 메모리의 핵심입니다.

**특수 케이스 - Copy-on-Write**

fork 후 부모와 자식이 페이지를 공유하다가, 쓰기 시도 시 Page Fault가 발생합니다. 이때는 디스크 접근 없이 페이지를 복사하여 각자 소유합니다. 읽기 전용 페이지는 계속 공유하여 메모리를 절약합니다. mmap의 MAP_PRIVATE도 비슷하게 동작합니다.

**성능 고려사항**

Page Fault는 비용이 큽니다. 컨텍스트 스위칭, 디스크 I/O, 페이지 테이블 업데이트 등이 필요합니다. 한 번의 폴트가 밀리초 단위 시간을 소요합니다. 따라서 폴트율을 낮게 유지하는 것이 중요합니다. 지역성이 좋고 충분한 메모리가 있으면 폴트가 드물어 성능이 좋습니다.

---

## 92. 페이지 크기에 대한 Trade-Off를 설명해 주세요.

**기본 개념**

페이지 크기는 가상 메모리 시스템의 중요한 설계 파라미터입니다. 작은 페이지와 큰 페이지는 각각 장단점이 있으며, 시스템 성능에 큰 영향을 미칩니다.

**작은 페이지의 장점**

내부 단편화가 줄어듭니다. 페이지 크기가 4KB일 때 평균 낭비는 2KB이지만, 4MB면 2MB입니다. 더 세밀한 메모리 관리가 가능하여 필요한 부분만 메모리에 적재합니다. 프로세스의 작업 세트를 더 정확하게 표현할 수 있습니다. 공유 라이브러리에서 실제 사용하는 함수만 로드하여 메모리를 절약합니다. 전체 메모리 활용도가 높아집니다.

**작은 페이지의 단점**

페이지 테이블이 커집니다. 같은 주소 공간을 표현하려면 더 많은 페이지 테이블 엔트리가 필요합니다. 4KB 페이지로 4GB를 관리하면 100만 개 엔트리가 필요하지만, 4MB면 1천 개만 필요합니다. 페이지 테이블 자체가 많은 메모리를 소비하고, 페이지 워크 시간도 길어집니다. TLB 미스율이 높아져 주소 변환 오버헤드가 증가합니다.

**큰 페이지의 장점**

페이지 테이블이 작아져 메모리를 절약하고 변환 속도가 빨라집니다. TLB가 더 큰 주소 범위를 커버하여 히트율이 높아집니다. 하나의 TLB 엔트리로 큰 영역을 표현하여 TLB 용량을 효율적으로 사용합니다. 디스크 I/O도 큰 단위로 수행되어 처리량이 향상됩니다. 대용량 데이터셋을 다루는 애플리케이션에 유리합니다.

**큰 페이지의 단점**

내부 단편화가 심해집니다. 작은 프로세스도 큰 페이지를 할당받아 메모리를 낭비합니다. 페이지 폴트 발생 시 큰 데이터를 디스크에서 읽어야 하므로 지연 시간이 길어집니다. 불필요한 데이터도 메모리에 적재되어 캐시 오염을 유발할 수 있습니다. 작은 작업에는 과도한 자원 사용입니다.

**실제 페이지 크기**

대부분의 시스템은 4KB를 기본 페이지 크기로 사용합니다. 이는 내부 단편화와 페이지 테이블 크기의 적절한 균형점입니다. ARM은 4KB, 16KB, 64KB를 지원하고, x86-64는 4KB, 2MB, 1GB 페이지를 제공합니다. 애플리케이션 특성에 맞춰 선택할 수 있습니다.

**Huge Pages**

리눅스의 Huge Pages나 윈도우의 Large Pages는 2MB나 1GB 크기를 사용합니다. 데이터베이스, 가상화, 과학 계산 같은 대용량 메모리 애플리케이션이 활용합니다. TLB 미스를 크게 줄여 성능을 10-30% 향상시킬 수 있습니다. 하지만 내부 단편화와 할당 실패 가능성이 증가합니다. Transparent Huge Pages는 자동으로 큰 페이지를 사용하지만, 예측 불가능한 성능 특성을 보일 수 있습니다.

**멀티레벨 페이징**

큰 페이지의 페이지 테이블 장점과 작은 페이지의 단편화 장점을 결합하는 방법입니다. 상위 레벨은 큰 단위로, 하위 레벨은 작은 단위로 관리합니다. 사용되지 않는 영역은 상위 레벨 테이블만 존재하여 메모리를 절약합니다. 현대 시스템은 4단계 또는 5단계 페이지 테이블을 사용합니다.

**실무 선택**

일반 애플리케이션은 기본 4KB 페이지로 충분합니다. 대용량 데이터베이스는 Huge Pages로 성능을 개선합니다. 임베디드 시스템은 메모리 제약으로 더 작은 페이지를 사용할 수 있습니다. 벤치마크와 프로파일링으로 최적 크기를 결정해야 합니다. 일률적인 정답은 없으며, 워크로드 특성이 중요합니다.
