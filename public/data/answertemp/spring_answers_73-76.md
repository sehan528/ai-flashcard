# Spring 답변 73-76

## 질문 73: Spring Boot Actuator를 통한 애플리케이션 모니터링 방법은 무엇인가요?

Spring Boot Actuator는 프로덕션 환경에서 애플리케이션을 모니터링하고 관리할 수 있는 기능을 제공하는 서브 프로젝트입니다.

**Actuator의 핵심 개념:**

첫째, 엔드포인트(Endpoints)입니다. HTTP나 JMX를 통해 접근할 수 있는 모니터링 지점입니다. 애플리케이션의 다양한 정보를 노출합니다. 각 엔드포인트는 특정한 목적을 가지고 있습니다.

둘째, 메트릭(Metrics)입니다. 애플리케이션의 성능과 상태를 수치로 측정합니다. CPU 사용률, 메모리, 요청 수, 응답 시간 등을 수집합니다. 시계열 데이터로 저장하여 추이를 파악할 수 있습니다.

셋째, 헬스 체크(Health Check)입니다. 애플리케이션과 의존 서비스의 상태를 확인합니다. 데이터베이스, 디스크, 메시징 시스템 등의 가용성을 점검합니다. 로드 밸런서가 이를 사용하여 트래픽을 분배합니다.

**설정 방법:**

첫째, 의존성 추가입니다. spring-boot-starter-actuator를 추가합니다. Spring Boot가 자동으로 Actuator를 구성합니다.

둘째, 엔드포인트 노출 설정입니다. 기본적으로 보안상 대부분의 엔드포인트가 비활성화되어 있습니다. management.endpoints.web.exposure.include로 노출할 엔드포인트를 지정합니다. 모든 엔드포인트를 노출하려면 별표를 사용합니다. 특정 엔드포인트만 노출하려면 이름을 나열합니다.

셋째, 베이스 경로 설정입니다. 기본 경로는 /actuator입니다. management.endpoints.web.base-path로 변경할 수 있습니다. 보안을 위해 예측하기 어려운 경로를 사용할 수 있습니다.

**주요 엔드포인트:**

첫째, /actuator/health입니다. 애플리케이션 헬스 상태를 확인합니다. UP, DOWN, OUT_OF_SERVICE, UNKNOWN 상태를 반환합니다. 데이터베이스, 디스크, Redis 등 각 컴포넌트의 상태를 포함합니다. management.endpoint.health.show-details로 상세 정보 노출 여부를 제어합니다.

둘째, /actuator/metrics입니다. 사용 가능한 모든 메트릭 목록을 보여줍니다. 특정 메트릭을 조회할 수 있습니다. JVM 메모리, CPU, HTTP 요청, 데이터베이스 연결 풀 등의 정보를 제공합니다.

셋째, /actuator/info입니다. 애플리케이션 정보를 노출합니다. 버전, 빌드 정보, Git 커밋 정보 등을 포함할 수 있습니다. info 프로퍼티로 커스텀 정보를 추가합니다.

넷째, /actuator/loggers입니다. 로거 설정을 조회하고 변경할 수 있습니다. 런타임에 로그 레벨을 동적으로 변경할 수 있습니다. 특정 패키지의 로그를 일시적으로 DEBUG로 설정하여 문제를 진단할 수 있습니다.

다섯째, /actuator/env입니다. Environment 정보를 보여줍니다. 프로퍼티 소스, 시스템 환경 변수, 애플리케이션 설정 등을 확인할 수 있습니다. 민감한 정보는 마스킹 처리됩니다.

여섯째, /actuator/beans입니다. 등록된 모든 Spring Bean을 보여줍니다. Bean의 타입, 스코프, 의존관계를 확인할 수 있습니다. 애플리케이션 구조를 파악하는 데 유용합니다.

일곱째, /actuator/mappings입니다. 모든 @RequestMapping 정보를 보여줍니다. URL 패턴, HTTP 메서드, 핸들러 메서드를 확인할 수 있습니다. API 목록을 파악할 수 있습니다.

여덟째, /actuator/threaddump입니다. 스레드 덤프를 생성합니다. 현재 실행 중인 모든 스레드의 상태를 확인할 수 있습니다. 데드락이나 성능 문제를 진단하는 데 사용합니다.

아홉째, /actuator/heapdump입니다. 힙 덤프를 생성합니다. 메모리 누수를 분석하는 데 사용합니다. 큰 파일이 생성되므로 주의가 필요합니다.

열째, /actuator/prometheus입니다. Prometheus 형식의 메트릭을 제공합니다. 시계열 데이터베이스로 메트릭을 수집할 수 있습니다.

**헬스 인디케이터:**

Spring Boot는 다양한 헬스 인디케이터를 자동으로 구성합니다.

DataSourceHealthIndicator는 데이터베이스 연결 상태를 확인합니다. 쿼리를 실행하여 응답 여부를 체크합니다.

DiskSpaceHealthIndicator는 디스크 공간을 확인합니다. 임계값 이하로 떨어지면 DOWN을 반환합니다.

RedisHealthIndicator는 Redis 연결 상태를 확인합니다.

RabbitHealthIndicator는 RabbitMQ 연결 상태를 확인합니다.

커스텀 헬스 인디케이터를 만들 수도 있습니다. HealthIndicator 인터페이스를 구현합니다. 외부 API나 특정 비즈니스 로직의 상태를 체크할 수 있습니다.

**메트릭 시스템:**

Actuator는 Micrometer를 사용하여 메트릭을 수집합니다.

Micrometer는 메트릭 파사드입니다. 다양한 모니터링 시스템을 지원합니다. Prometheus, Graphite, Datadog, New Relic 등과 통합됩니다. 벤더 중립적인 API를 제공합니다.

**기본 제공 메트릭:**

JVM 메트릭은 메모리 사용량, GC 정보, 스레드 수를 포함합니다.

CPU 메트릭은 프로세스 CPU 사용률을 제공합니다.

파일 디스크립터 메트릭은 열린 파일 수를 추적합니다.

로그백 메트릭은 각 로그 레벨별 로그 수를 집계합니다.

Uptime 메트릭은 애플리케이션 실행 시간을 기록합니다.

Tomcat 메트릭은 활성 세션, 요청 수, 에러 수를 추적합니다.

Spring MVC 메트릭은 HTTP 요청 수, 응답 시간을 측정합니다.

데이터 소스 메트릭은 커넥션 풀 상태, 활성 커넥션 수를 모니터링합니다.

**커스텀 메트릭:**

MeterRegistry를 주입받아 커스텀 메트릭을 생성할 수 있습니다.

Counter는 증가만 하는 값입니다. 요청 수, 이벤트 발생 횟수 등을 측정합니다.

Gauge는 증가와 감소가 모두 가능한 값입니다. 현재 활성 사용자 수, 큐 크기 등을 측정합니다.

Timer는 이벤트의 빈도와 지속 시간을 측정합니다. 메서드 실행 시간, API 응답 시간 등을 추적합니다.

DistributionSummary는 이벤트의 분포를 측정합니다.

**보안 설정:**

Actuator 엔드포인트는 민감한 정보를 포함할 수 있습니다. Spring Security로 접근을 제한해야 합니다. 특정 IP나 역할만 접근하도록 설정합니다. 프로덕션에서는 필요한 엔드포인트만 노출합니다. 민감한 엔드포인트는 관리자만 접근하도록 합니다.

**태그를 통한 메트릭 분류:**

메트릭에 태그를 추가하여 분류할 수 있습니다. URI, 메서드, 상태 코드 등으로 그룹화합니다. 다차원 분석이 가능합니다. Prometheus 쿼리로 필터링하고 집계할 수 있습니다.

**모니터링 시스템 연동:**

Prometheus와 Grafana를 많이 사용합니다. Prometheus가 주기적으로 /actuator/prometheus를 스크랩합니다. 메트릭을 시계열 데이터베이스에 저장합니다. Grafana로 시각화 대시보드를 만듭니다. 임계값 기반 알람을 설정할 수 있습니다.

ELK 스택(Elasticsearch, Logstash, Kibana)으로 로그를 수집하고 분석합니다.

Datadog, New Relic 같은 상용 APM 도구와도 통합됩니다.

**알림 설정:**

메트릭이 임계값을 초과하면 알림을 전송합니다. Slack, 이메일, SMS 등으로 통보합니다. CPU 사용률이 80%를 넘거나 에러율이 증가하면 알립니다. 빠른 대응이 가능합니다.

**성능 영향:**

Actuator는 약간의 오버헤드가 있습니다. 메트릭 수집이 CPU와 메모리를 사용합니다. 하지만 영향은 미미합니다. 얻는 이점이 훨씬 큽니다. 필요 없는 엔드포인트는 비활성화하여 최적화할 수 있습니다.

**실무 활용 팁:**

health 엔드포인트를 로드 밸런서의 헬스 체크에 사용합니다. 문제가 있는 인스턴스를 자동으로 제거합니다. metrics로 성능 병목을 찾습니다. 느린 API나 메모리 누수를 조기에 발견합니다. loggers로 운영 중 로그 레벨을 조정합니다. 재배포 없이 디버깅할 수 있습니다.

Actuator는 프로덕션 레디 기능의 핵심입니다. 애플리케이션의 건강 상태를 실시간으로 파악하고 문제를 빠르게 해결할 수 있게 합니다.

## 질문 74: Spring Cloud를 활용한 마이크로서비스 아키텍처 구현 전략에 대해 설명해주세요.

Spring Cloud는 분산 시스템과 마이크로서비스 아키텍처를 구축하는 데 필요한 다양한 패턴과 도구를 제공하는 프레임워크입니다.

**마이크로서비스 아키텍처의 특징:**

첫째, 서비스 독립성입니다. 각 서비스가 독립적으로 개발, 배포, 확장됩니다. 서비스마다 다른 기술 스택을 사용할 수 있습니다. 팀이 자율적으로 의사결정할 수 있습니다.

둘째, 느슨한 결합입니다. 서비스 간 의존성이 최소화됩니다. API를 통해서만 통신합니다. 한 서비스의 변경이 다른 서비스에 영향을 주지 않습니다.

셋째, 비즈니스 능력 중심입니다. 도메인 경계에 따라 서비스를 나눕니다. 각 서비스가 특정 비즈니스 기능을 담당합니다.

넷째, 분산 시스템의 복잡성입니다. 네트워크 통신, 장애 처리, 데이터 일관성이 복잡해집니다. 모니터링과 추적이 어려워집니다.

**Spring Cloud의 주요 컴포넌트:**

첫째, Service Discovery(서비스 디스커버리)입니다. 동적으로 서비스 위치를 찾아줍니다. Spring Cloud Netflix Eureka가 대표적입니다. 서비스가 시작되면 Eureka 서버에 등록합니다. 다른 서비스는 Eureka에서 서비스 위치를 조회합니다. 하드코딩된 IP와 포트가 필요 없습니다. 서비스 인스턴스가 동적으로 추가되거나 제거됩니다.

둘째, API Gateway입니다. 클라이언트의 단일 진입점 역할을 합니다. Spring Cloud Gateway가 권장됩니다. 라우팅, 필터링, 인증, 속도 제한 등을 처리합니다. 클라이언트가 여러 서비스를 직접 호출하지 않아도 됩니다. 백엔드 서비스 구조를 숨길 수 있습니다.

셋째, 로드 밸런싱입니다. Spring Cloud LoadBalancer를 사용합니다. 클라이언트 사이드 로드 밸런싱을 제공합니다. 여러 인스턴스 중 하나를 선택하여 요청을 보냅니다. 라운드 로빈, 가중치 기반 등의 전략을 사용합니다.

넷째, Circuit Breaker입니다. Resilience4j를 사용합니다. 장애가 전파되는 것을 방지합니다. 실패가 반복되면 회로를 차단합니다. Fallback 메서드로 대체 응답을 제공합니다. 일정 시간 후 회로를 다시 시도합니다.

다섯째, 분산 구성 관리입니다. Spring Cloud Config를 사용합니다. 중앙 집중식 설정 관리를 제공합니다. Git 저장소에 설정 파일을 저장합니다. 모든 마이크로서비스가 Config 서버에서 설정을 가져옵니다. 환경별 설정을 쉽게 관리할 수 있습니다. 설정 변경 시 재배포 없이 갱신할 수 있습니다.

여섯째, 분산 추적입니다. Spring Cloud Sleuth와 Zipkin을 사용합니다. 요청이 여러 서비스를 거치는 과정을 추적합니다. Trace ID와 Span ID를 자동으로 생성합니다. 로그에 추적 ID를 포함시킵니다. Zipkin 서버로 추적 데이터를 전송합니다. 전체 요청 흐름을 시각화할 수 있습니다.

일곱째, 메시징입니다. Spring Cloud Stream을 사용합니다. 메시지 기반 마이크로서비스를 쉽게 구축합니다. Kafka, RabbitMQ 등과 추상화된 방식으로 통합됩니다. 이벤트 기반 아키텍처를 구현합니다.

**서비스 디스커버리 패턴:**

Eureka 서버를 설정합니다. @EnableEurekaServer로 활성화합니다.

각 마이크로서비스는 Eureka 클라이언트입니다. @EnableDiscoveryClient를 추가합니다. 애플리케이션 시작 시 자동으로 Eureka에 등록됩니다. 주기적으로 하트비트를 전송합니다.

다른 서비스를 호출할 때 서비스 이름을 사용합니다. Eureka에서 실제 위치를 조회합니다. LoadBalancer가 여러 인스턴스 중 하나를 선택합니다.

**API Gateway 패턴:**

Spring Cloud Gateway를 사용합니다. 논블로킹 방식으로 동작합니다. WebFlux 기반입니다.

라우팅 규칙을 정의합니다. 경로 패턴에 따라 백엔드 서비스로 전달합니다. 서비스 디스커버리와 통합되어 동적 라우팅이 가능합니다.

필터를 적용합니다. 요청 전/후 처리를 수행합니다. 인증, 로깅, 헤더 추가, 응답 수정 등을 할 수 있습니다. 전역 필터와 라우트별 필터를 정의할 수 있습니다.

속도 제한(Rate Limiting)을 설정합니다. 특정 클라이언트의 과도한 요청을 막습니다. 서비스를 보호합니다.

**Circuit Breaker 패턴:**

Resilience4j를 사용합니다. @CircuitBreaker 어노테이션으로 적용합니다.

실패율이 임계값을 초과하면 Circuit이 Open됩니다. Open 상태에서는 호출을 즉시 차단합니다. Fallback 메서드가 실행됩니다. 일정 시간 후 Half-Open 상태로 전환됩니다. 일부 요청을 시도하여 서비스 복구 여부를 확인합니다. 성공하면 Closed 상태로 돌아갑니다.

Fallback 메서드에서 캐시된 데이터를 반환하거나 기본값을 제공합니다. 사용자에게 의미 있는 응답을 줍니다.

Timeout, Retry, Bulkhead 패턴도 함께 사용합니다.

**분산 구성 관리:**

Config 서버를 설정합니다. Git 저장소 위치를 지정합니다. 설정 파일을 환경별로 관리합니다.

각 마이크로서비스는 Config 클라이언트입니다. 시작 시 Config 서버에서 설정을 가져옵니다. bootstrap.yml에 Config 서버 위치를 지정합니다.

@RefreshScope를 사용하여 설정을 동적으로 갱신합니다. /actuator/refresh 엔드포인트를 호출하면 설정이 다시 로드됩니다. Spring Cloud Bus를 사용하면 모든 인스턴스에 변경을 브로드캐스트할 수 있습니다.

**분산 추적:**

Sleuth가 자동으로 Trace ID와 Span ID를 생성합니다. 모든 로그에 추적 정보가 포함됩니다. HTTP 헤더로 다음 서비스에 전파됩니다.

Zipkin 서버를 실행합니다. 마이크로서비스들이 추적 데이터를 Zipkin에 전송합니다. Zipkin UI에서 요청 흐름을 시각화합니다. 어느 서비스에서 지연이 발생했는지 파악할 수 있습니다.

**메시징 패턴:**

Spring Cloud Stream을 사용합니다. Source, Processor, Sink 개념으로 메시지를 처리합니다. 바인더를 통해 Kafka나 RabbitMQ와 연결됩니다.

이벤트 발행과 구독으로 서비스 간 통신합니다. 동기 REST 호출보다 느슨한 결합을 제공합니다. 메시지 큐가 버퍼 역할을 합니다.

**데이터 관리 전략:**

각 마이크로서비스가 자신의 데이터베이스를 가집니다. Database per Service 패턴입니다. 서비스 간 데이터베이스를 직접 공유하지 않습니다.

분산 트랜잭션은 Saga 패턴으로 처리합니다. 각 서비스의 로컬 트랜잭션을 순차적으로 실행합니다. 실패 시 보상 트랜잭션으로 롤백합니다.

CQRS(Command Query Responsibility Segregation)를 고려할 수 있습니다. 읽기와 쓰기를 분리합니다.

**보안:**

OAuth2와 JWT를 사용합니다. API Gateway에서 인증을 처리합니다. JWT 토큰을 발급하고 검증합니다. 마이크로서비스는 토큰을 검증하여 인가를 수행합니다.

서비스 간 통신도 보안이 필요합니다. Mutual TLS를 사용할 수 있습니다. 서비스 메시(Service Mesh)를 고려할 수 있습니다.

**배포 전략:**

컨테이너화를 사용합니다. Docker로 각 서비스를 이미지화합니다. Kubernetes에서 오케스트레이션합니다. 자동 스케일링, 로드 밸런싱, 헬스 체크를 제공합니다.

CI/CD 파이프라인을 구축합니다. 각 서비스를 독립적으로 배포합니다. Blue-Green 배포나 Canary 배포를 사용합니다.

**모니터링:**

각 서비스의 Actuator 엔드포인트를 수집합니다. Prometheus로 메트릭을 모읍니다. Grafana로 대시보드를 만듭니다. 전체 시스템의 건강 상태를 한눈에 파악합니다.

로그 수집도 중요합니다. ELK 스택으로 중앙 집중식 로그 관리를 합니다. 분산 환경에서 로그를 추적할 수 있습니다.

**주의사항:**

마이크로서비스는 복잡성을 증가시킵니다. 작은 애플리케이션에는 오버 엔지니어링일 수 있습니다. 분산 시스템의 어려움을 이해하고 시작해야 합니다. 네트워크 지연, 부분 장애, 데이터 일관성 문제를 고려해야 합니다.

**장점:**

독립적인 배포와 확장이 가능합니다. 기술 스택을 자유롭게 선택할 수 있습니다. 장애 격리가 됩니다. 팀이 자율적으로 일할 수 있습니다.

Spring Cloud는 마이크로서비스 개발에 필요한 대부분의 기능을 제공합니다. 복잡한 분산 시스템을 체계적으로 구축할 수 있게 합니다.

## 질문 75: Spring에서 메시징 시스템(Kafka, RabbitMQ 등)과의 연동 방법은 무엇인가요?

메시징 시스템은 애플리케이션 간 비동기 통신을 가능하게 하며, Spring은 다양한 메시징 시스템과 쉽게 통합할 수 있는 추상화를 제공합니다.

**메시징 시스템이 필요한 이유:**

첫째, 비동기 처리입니다. 요청과 응답이 즉시 이루어지지 않아도 됩니다. 긴 작업을 백그라운드에서 처리할 수 있습니다. 사용자는 빠른 응답을 받고 다른 작업을 계속할 수 있습니다.

둘째, 서비스 간 결합도 감소입니다. 직접적인 API 호출보다 느슨하게 연결됩니다. 발신자는 수신자를 알 필요가 없습니다. 메시지 큐가 중간자 역할을 합니다.

셋째, 부하 평준화입니다. 갑작스러운 트래픽 증가를 큐가 흡수합니다. 처리 속도를 일정하게 유지할 수 있습니다. 시스템 과부하를 방지합니다.

넷째, 확장성입니다. 컨슈머를 늘려 처리량을 증가시킬 수 있습니다. 프로듀서와 컨슈머를 독립적으로 확장합니다.

다섯째, 신뢰성입니다. 메시지가 큐에 저장되어 유실을 방지합니다. 컨슈머가 실패해도 메시지는 보존됩니다. 재처리가 가능합니다.

**RabbitMQ 연동:**

RabbitMQ는 AMQP(Advanced Message Queuing Protocol) 기반의 메시지 브로커입니다.

첫째, 의존성 추가입니다. spring-boot-starter-amqp를 추가합니다.

둘째, 연결 설정입니다. application.yml에 RabbitMQ 서버 정보를 설정합니다. 호스트, 포트, 사용자 이름, 비밀번호를 지정합니다.

셋째, 큐와 익스체인지 설정입니다. Queue, Exchange, Binding Bean을 정의합니다. Direct, Topic, Fanout, Headers 타입의 익스체인지를 사용할 수 있습니다. 라우팅 키로 메시지를 적절한 큐로 전달합니다.

넷째, 메시지 전송입니다. RabbitTemplate을 주입받습니다. convertAndSend 메서드로 메시지를 전송합니다. 자바 객체를 자동으로 JSON으로 변환합니다.

다섯째, 메시지 수신입니다. @RabbitListener 어노테이션을 사용합니다. 특정 큐를 리스닝합니다. 메시지가 도착하면 자동으로 메서드가 호출됩니다. JSON을 자동으로 자바 객체로 변환합니다.

**Kafka 연동:**

Kafka는 분산 스트리밍 플랫폼으로, 대용량 실시간 데이터 처리에 적합합니다.

첫째, 의존성 추가입니다. spring-kafka를 추가합니다.

둘째, 프로듀서 설정입니다. application.yml에 Kafka 브로커 주소를 설정합니다. Key와 Value의 직렬화 방식을 지정합니다. 보통 StringSerializer나 JsonSerializer를 사용합니다.

셋째, 메시지 발행입니다. KafkaTemplate을 주입받습니다. send 메서드로 토픽에 메시지를 발행합니다. 비동기로 동작하며 CompletableFuture를 반환합니다.

넷째, 컨슈머 설정입니다. 브로커 주소, 그룹 ID, 역직렬화 방식을 설정합니다. auto-offset-reset으로 초기 읽기 위치를 지정합니다.

다섯째, 메시지 소비입니다. @KafkaListener 어노테이션을 사용합니다. 토픽을 지정하여 메시지를 수신합니다. 파티션과 오프셋 정보도 받을 수 있습니다.

**Spring Cloud Stream:**

Spring Cloud Stream은 메시징 시스템에 대한 추상화 레이어를 제공합니다.

첫째, 바인더 개념입니다. RabbitMQ, Kafka 등 구체적인 메시징 시스템과의 연결을 담당합니다. 코드를 변경하지 않고 바인더만 바꿔 메시징 시스템을 교체할 수 있습니다.

둘째, 함수형 프로그래밍 모델입니다. Supplier는 메시지를 생성합니다. 주기적으로 또는 이벤트 기반으로 메시지를 발행합니다.

Function은 메시지를 받아 변환하고 다시 발행합니다. 파이프라인 처리에 적합합니다.

Consumer는 메시지를 소비합니다. 최종 처리를 담당합니다.

셋째, 바인딩 설정입니다. application.yml에서 입력과 출력 채널을 정의합니다. 토픽이나 큐 이름을 지정합니다. 그룹을 설정하여 컨슈머 그룹을 만듭니다.

**메시지 변환:**

Spring은 자동으로 메시지 변환을 처리합니다. MessageConverter가 자바 객체와 메시지 형식 간 변환을 담당합니다. Jackson2JsonMessageConverter가 JSON 변환을 처리합니다. 커스텀 컨버터를 등록할 수도 있습니다.

**에러 처리:**

메시지 처리 중 예외가 발생할 수 있습니다.

RabbitMQ는 재시도 메커니즘을 제공합니다. 실패한 메시지를 재처리합니다. 최대 재시도 횟수를 설정할 수 있습니다. Dead Letter Queue(DLQ)로 실패한 메시지를 보냅니다.

Kafka는 에러 핸들러를 등록합니다. SeekToCurrentErrorHandler가 현재 레코드를 재시도합니다. DeadLetterPublishingRecoverer로 DLT(Dead Letter Topic)에 발행합니다.

**트랜잭션:**

메시징과 데이터베이스 작업을 함께 트랜잭션으로 묶을 수 있습니다.

RabbitMQ는 트랜잭션을 지원합니다. 하지만 성능이 저하됩니다. Publisher Confirms를 사용하는 것이 더 효율적입니다.

Kafka는 트랜잭션 프로듀서와 컨슈머를 제공합니다. 정확히 한 번(Exactly Once Semantics) 처리를 보장합니다.

**메시지 우선순위:**

RabbitMQ는 메시지 우선순위를 지원합니다. 큐 설정에서 최대 우선순위를 지정합니다. 메시지 전송 시 우선순위를 설정합니다. 중요한 메시지를 먼저 처리할 수 있습니다.

Kafka는 기본적으로 우선순위를 지원하지 않습니다. 별도의 토픽을 사용하여 우선순위를 구현할 수 있습니다.

**메시지 필터링:**

특정 조건의 메시지만 처리할 수 있습니다. @RabbitListener의 @Header를 사용하여 헤더 기반 필터링을 합니다. 메시지 내용을 검사하여 조건부 처리를 합니다.

**파티셔닝:**

Kafka는 토픽을 여러 파티션으로 나눕니다. 파티션별로 순서가 보장됩니다. 같은 키를 가진 메시지는 같은 파티션에 저장됩니다. 병렬 처리로 성능을 높입니다.

**컨슈머 그룹:**

여러 컨슈머가 하나의 그룹을 형성합니다. 각 메시지는 그룹 내 한 컨슈머만 처리합니다. 로드 밸런싱이 자동으로 이루어집니다. 확장성이 높아집니다.

**메시지 압축:**

대량의 메시지 전송 시 압축을 사용합니다. Kafka는 gzip, snappy, lz4 등을 지원합니다. 네트워크 대역폭을 절약합니다.

**모니터링:**

메시징 시스템의 상태를 모니터링해야 합니다. 큐 길이, 처리 속도, 에러율을 추적합니다. RabbitMQ Management UI를 사용합니다. Kafka Manager나 Confluent Control Center를 사용합니다. Actuator로 메트릭을 노출하고 Prometheus로 수집합니다.

**실무 활용 사례:**

주문 처리 시스템에서 주문 이벤트를 발행합니다. 재고 서비스, 배송 서비스, 알림 서비스가 각각 구독합니다. 각 서비스가 독립적으로 처리합니다.

로그 수집 시스템에서 애플리케이션 로그를 Kafka로 전송합니다. Logstash나 Fluentd가 소비하여 Elasticsearch에 저장합니다.

실시간 분석 시스템에서 이벤트 스트림을 처리합니다. Kafka Streams로 집계하고 변환합니다.

**RabbitMQ vs Kafka 선택:**

RabbitMQ는 메시지 브로커로 복잡한 라우팅이 필요할 때 적합합니다. 우선순위 큐, DLQ 등의 기능이 풍부합니다. 작은 규모의 메시지 처리에 좋습니다.

Kafka는 대용량 실시간 데이터 스트리밍에 적합합니다. 높은 처리량과 낮은 지연 시간을 제공합니다. 로그 수집, 이벤트 소싱, 실시간 분석에 사용합니다. 메시지를 영구 저장하여 재처리가 가능합니다.

메시징 시스템은 현대적인 분산 아키텍처의 핵심입니다. Spring의 추상화 덕분에 쉽게 통합하고 사용할 수 있습니다.

## 질문 76: Spring의 캐싱 추상화(Cache Abstraction)와 캐시 적용 방법에 대해 설명해주세요.

Spring의 캐싱 추상화는 메서드 수준에서 캐싱을 선언적으로 적용할 수 있게 하는 기능입니다. 다양한 캐시 제공자와 통합되며, 코드 변경 없이 캐시 구현체를 교체할 수 있습니다.

**캐싱이 필요한 이유:**

첫째, 성능 향상입니다. 반복적인 연산이나 데이터베이스 조회를 줄입니다. 이미 계산한 결과를 재사용합니다. 응답 시간이 크게 단축됩니다.

둘째, 데이터베이스 부하 감소입니다. 같은 쿼리를 반복 실행하지 않습니다. 데이터베이스 연결을 절약합니다. 시스템 전체 확장성이 높아집니다.

셋째, 외부 API 호출 감소입니다. 비용이 발생하는 API 호출을 최소화합니다. 네트워크 지연을 줄입니다. API 사용량 제한을 피할 수 있습니다.

**캐싱 활성화:**

첫째, @EnableCaching 어노테이션입니다. 설정 클래스에 추가합니다. Spring이 캐시 관련 어노테이션을 처리하기 시작합니다. AOP 프록시를 사용하여 캐싱 로직을 삽입합니다.

둘째, CacheManager Bean 등록입니다. 캐시 구현체를 선택합니다. SimpleCacheManager는 메모리 기반의 간단한 캐시입니다. ConcurrentMapCacheManager는 ConcurrentHashMap을 사용합니다. EhCacheCacheManager는 EhCache를 사용합니다. RedisCacheManager는 Redis를 사용합니다.

**주요 캐시 어노테이션:**

첫째, @Cacheable입니다. 메서드의 반환값을 캐시에 저장합니다. 같은 인자로 호출하면 캐시된 값을 반환합니다. 메서드를 실행하지 않습니다. 조회 작업에 사용합니다.

value나 cacheNames로 캐시 이름을 지정합니다. key로 캐시 키를 지정합니다. SpEL 표현식을 사용할 수 있습니다. 기본적으로 메서드 파라미터를 키로 사용합니다.

condition으로 캐싱 조건을 지정합니다. 특정 조건에서만 캐싱합니다.

unless로 결과 기반 조건을 지정합니다. 반환값이 null이면 캐싱하지 않는 등의 로직을 구현합니다.

둘째, @CachePut입니다. 항상 메서드를 실행합니다. 실행 결과를 캐시에 저장하거나 갱신합니다. 캐시를 최신 상태로 유지하는 데 사용합니다. 수정 작업 후 캐시를 갱신할 때 사용합니다.

셋째, @CacheEvict입니다. 캐시에서 항목을 제거합니다. 삭제나 수정 작업 후 캐시를 무효화할 때 사용합니다.

allEntries 속성으로 모든 캐시 항목을 삭제할 수 있습니다. beforeInvocation으로 메서드 실행 전에 캐시를 삭제할지 결정합니다. 기본값은 false로 실행 후 삭제입니다.

넷째, @Caching입니다. 여러 캐시 어노테이션을 함께 사용할 때 사용합니다. cacheable, put, evict 배열을 가집니다. 복잡한 캐싱 시나리오를 표현합니다.

다섯째, @CacheConfig입니다. 클래스 레벨에서 공통 캐시 설정을 정의합니다. cacheNames를 한 번만 지정하면 모든 메서드에 적용됩니다. 중복을 줄입니다.

**캐시 키 생성:**

기본적으로 메서드 파라미터를 키로 사용합니다. 파라미터가 없으면 SimpleKey.EMPTY를 사용합니다. 여러 파라미터가 있으면 SimpleKey로 조합합니다.

커스텀 키를 지정할 수 있습니다. SpEL 표현식을 사용합니다. 파라미터 이름이나 필드에 접근할 수 있습니다.

KeyGenerator 인터페이스를 구현하여 커스텀 키 생성 로직을 만들 수 있습니다.

**조건부 캐싱:**

condition 속성으로 캐싱 여부를 결정합니다. 메서드 실행 전에 평가됩니다. 파라미터 값에 따라 캐싱을 선택적으로 적용합니다.

unless 속성으로 결과에 따라 캐싱을 건너뜁니다. 메서드 실행 후에 평가됩니다. 결과가 특정 조건을 만족하지 않으면 캐싱하지 않습니다.

**Redis를 캐시로 사용:**

Redis는 분산 캐시로 널리 사용됩니다.

첫째, 의존성 추가입니다. spring-boot-starter-data-redis를 추가합니다.

둘째, Redis 연결 설정입니다. application.yml에 Redis 서버 정보를 설정합니다.

셋째, RedisCacheManager 설정입니다. RedisCacheConfiguration으로 기본 설정을 정의합니다. TTL(Time To Live)을 설정합니다. 직렬화 방식을 지정합니다. GenericJackson2JsonRedisSerializer로 JSON 형태로 저장합니다.

넷째, 캐시별 설정입니다. 각 캐시마다 다른 TTL을 설정할 수 있습니다. withCacheConfiguration으로 캐시별 설정을 추가합니다.

**직렬화:**

캐시에 저장할 때 객체를 직렬화해야 합니다. JDK 직렬화는 호환성 문제가 있을 수 있습니다. JSON 직렬화가 더 유연합니다. Jackson을 사용하여 JSON으로 변환합니다.

**캐시 만료 전략:**

TTL을 설정하여 일정 시간 후 자동으로 만료되게 합니다. 데이터의 신선도를 유지합니다.

LRU(Least Recently Used) 정책으로 오래된 항목을 제거합니다. 메모리를 효율적으로 사용합니다.

수동으로 @CacheEvict를 사용하여 무효화합니다.

**캐시 웜업:**

애플리케이션 시작 시 캐시를 미리 채웁니다. 첫 요청에서 지연이 발생하지 않습니다. @PostConstruct 메서드에서 자주 사용되는 데이터를 캐싱합니다.

**캐시 히트율 모니터링:**

캐시가 얼마나 효과적인지 측정해야 합니다. 히트율(Hit Rate)을 추적합니다. 미스율(Miss Rate)이 높으면 캐시 전략을 재검토합니다. Micrometer로 캐시 메트릭을 수집합니다. Actuator를 통해 노출하고 Prometheus로 모니터링합니다.

**주의사항:**

첫째, 동시성 문제입니다. 여러 스레드가 동시에 같은 키로 캐시를 채우려 할 수 있습니다. sync 속성을 true로 설정하면 하나의 스레드만 메서드를 실행합니다.

둘째, 캐시 일관성입니다. 데이터가 변경되었을 때 캐시를 적절히 갱신해야 합니다. @CachePut이나 @CacheEvict를 사용합니다. 쓰기 작업 후 캐시를 무효화하거나 갱신합니다.

셋째, 메모리 사용량입니다. 캐시가 너무 많은 메모리를 사용하면 문제가 됩니다. 적절한 크기 제한을 설정합니다. 만료 정책을 적용합니다.

넷째, 프록시 방식의 한계입니다. 같은 클래스 내부에서 메서드를 호출하면 캐싱이 적용되지 않습니다. self-invocation 문제입니다. 다른 Bean을 통해 호출해야 합니다.

다섯째, 너무 많은 캐싱은 역효과입니다. 자주 변경되는 데이터는 캐싱하지 않는 것이 좋습니다. 캐시 무효화 비용이 캐싱 이득보다 클 수 있습니다.

**적합한 캐싱 대상:**

읽기가 많고 쓰기가 적은 데이터입니다. 변경 빈도가 낮은 데이터입니다. 계산 비용이 높은 연산 결과입니다. 외부 API 호출 결과입니다. 자주 조회되는 참조 데이터입니다.

**부적합한 캐싱 대상:**

실시간으로 변경되는 데이터입니다. 사용자별로 다른 데이터입니다. (단, 사용자 ID를 키에 포함시키면 가능) 보안이 중요한 민감한 데이터입니다.

**분산 캐시 vs 로컬 캐시:**

로컬 캐시는 각 인스턴스의 메모리에 저장됩니다. 빠르지만 인스턴스 간 공유되지 않습니다. Caffeine, EhCache 등을 사용합니다.

분산 캐시는 모든 인스턴스가 공유합니다. Redis, Memcached 등을 사용합니다. 네트워크 비용이 있지만 일관성이 보장됩니다. 여러 서버 환경에서 필수입니다.

**2단계 캐싱:**

로컬 캐시와 분산 캐시를 함께 사용합니다. L1 캐시는 로컬 메모리입니다. L2 캐시는 Redis 등입니다. 로컬에 없으면 Redis에서 가져옵니다. Redis에도 없으면 데이터베이스에서 조회합니다. 최적의 성능과 일관성을 제공합니다.

캐싱은 성능 최적화의 강력한 도구입니다. Spring의 추상화 덕분에 간단하게 적용하고 다양한 구현체를 사용할 수 있습니다. 적절히 사용하면 시스템 성능을 크게 향상시킬 수 있습니다.
