# OS 답변 85-88

## 85. worst-fit 은 언제 사용할 수 있을까요?

**기본 개념**

Worst-fit은 일반적으로 성능이 좋지 않지만, 특정 상황에서는 유용할 수 있습니다. 할당 패턴과 시스템 특성에 따라 장점을 활용할 수 있는 경우가 있습니다.

**큰 할당과 작은 할당이 혼합된 경우**

매우 큰 프로세스와 작은 프로세스가 번갈아 할당되는 환경에서는 Worst-fit이 도움될 수 있습니다. 큰 공간에서 작은 조각을 떼어내도 남은 공간이 여전히 커서 다른 프로세스가 사용할 수 있습니다. First-fit이나 Best-fit은 큰 공간을 빠르게 소진하여 나중에 큰 프로세스가 들어올 여지가 없어집니다. Worst-fit은 큰 공간을 점진적으로 나누어 사용하여 유연성을 유지합니다.

**할당 크기가 비슷한 경우**

모든 할당 요청이 비슷한 크기라면, Worst-fit은 각 할당 후 남은 공간도 비슷한 크기가 됩니다. 남은 조각들이 여전히 유용한 크기여서 재사용될 수 있습니다. Best-fit처럼 매우 작은 쓸모없는 조각이 생기지 않습니다. 메모리가 균등하게 분할되어 전체적으로 활용도가 높아질 수 있습니다.

**단편화 복구가 용이한 환경**

압축이나 재배치 비용이 낮은 시스템에서는 Worst-fit의 단점이 완화됩니다. 주기적으로 압축을 수행하여 큰 공간을 복구할 수 있다면, Worst-fit의 균등 분할 특성이 유리할 수 있습니다. 가상 메모리 환경에서 페이지 테이블 업데이트만으로 재배치가 가능하다면 압축 비용이 낮습니다.

**실시간 시스템의 예측 가능성**

Worst-fit은 항상 가장 큰 공간을 선택하므로 동작이 예측 가능합니다. 남은 공간 크기가 상대적으로 일정하여, 다음 할당의 성공 여부를 추정하기 쉽습니다. 실시간 시스템에서 최악의 경우 성능을 보장해야 한다면, Worst-fit의 예측 가능성이 장점이 될 수 있습니다. 하지만 여전히 페이징이 더 나은 선택입니다.

**메모리 풀 관리**

고정 크기가 아닌 가변 크기 메모리 풀에서 Worst-fit을 사용할 수 있습니다. 큰 풀에서 다양한 크기의 할당을 처리할 때, 남은 공간을 크게 유지하여 미래 할당의 유연성을 보장합니다. 데이터베이스 버퍼 풀이나 캐시 관리에서 제한적으로 사용될 수 있습니다.

**실무적 한계**

실제로 Worst-fit을 사용하는 프로덕션 시스템은 거의 없습니다. 탐색 오버헤드가 크고, 큰 공간 고갈 문제가 심각합니다. 이론적으로 흥미롭지만 실용성이 떨어집니다. First-fit의 변형이나 Buddy system 같은 대안이 모든 면에서 우수합니다. 페이징 기반 메모리 관리가 연속할당의 모든 문제를 근본적으로 해결하므로, 현대 시스템에서는 거의 사용되지 않습니다.

**교육적 가치**

Worst-fit은 메모리 할당 전략의 trade-off를 이해하는 데 유용합니다. 직관과 다르게 "최선"이 항상 좋은 것은 아니며, 간단한 First-fit이 복잡한 Best-fit보다 나을 수 있음을 보여줍니다. 알고리즘 선택은 이론적 우수성보다 실제 성능과 구현 비용을 고려해야 함을 가르칩니다.

---

## 86. 성능이 가장 좋은 알고리즘은 무엇일까요?

**기본 개념**

메모리 할당 알고리즘의 성능은 속도, 메모리 활용도, 단편화, 구현 복잡도 등 여러 요소를 종합적으로 고려해야 합니다. 상황과 목적에 따라 최적 알고리즘이 달라집니다.

**First-fit의 우수성**

시뮬레이션과 실험 연구에 따르면 First-fit이 전반적으로 가장 우수한 성능을 보입니다. 탐색 속도가 빠르고, 메모리 활용도도 Best-fit과 비슷하거나 더 좋습니다. 구현이 간단하여 오버헤드가 적습니다. 외부 단편화도 Best-fit보다 낫거나 비슷한 수준입니다. 실제 운영체제와 메모리 관리자가 First-fit 기반 전략을 주로 사용하는 이유입니다.

**페이징의 우위**

연속할당 방식 자체가 현대 시스템에서는 거의 사용되지 않습니다. 페이징은 외부 단편화를 근본적으로 해결하고, 가상 메모리를 가능하게 하며, 보호와 공유를 쉽게 합니다. 내부 단편화가 있지만 페이지 크기가 작아서 무시할 수 있습니다. 거의 모든 현대 운영체제가 페이징을 사용하므로, 페이징이 가장 "성능 좋은" 메모리 관리 방식입니다.

**동적 메모리 할당의 실제**

프로세스 내부의 힙 관리에서는 다양한 최적화 기법이 사용됩니다. Segregated free list는 크기별로 빈 블록을 관리하여 First-fit을 빠르게 수행합니다. Buddy system은 2의 거듭제곱 크기로 분할하여 빠른 할당과 합병을 지원합니다. Slab allocator는 고정 크기 객체를 효율적으로 관리합니다. jemalloc이나 tcmalloc 같은 현대 할당자는 여러 기법을 혼합하여 최적 성능을 제공합니다.

**멀티스레드 환경**

멀티스레드 애플리케이션에서는 할당자의 동시성 성능이 중요합니다. 전역 락은 병목이 되므로, 스레드별 캐시나 아레나를 사용합니다. jemalloc은 스레드별 아레나로 락 경쟁을 줄입니다. tcmalloc은 스레드 로컬 캐시로 작은 할당을 빠르게 처리합니다. 동시성과 메모리 효율의 균형이 성능을 결정합니다.

**특수 목적 할당자**

특정 사용 패턴에 맞춘 할당자가 범용 할당자보다 성능이 좋습니다. 메모리 풀은 같은 크기 객체를 빠르게 할당하고 해제합니다. 아레나 할당자는 한꺼번에 해제되는 객체들을 모아 관리합니다. 스택 할당자는 LIFO 패턴을 최적화합니다. 사용 패턴을 알면 맞춤형 할당자로 극적인 성능 향상을 얻을 수 있습니다.

**측정과 최적화**

벤치마크와 프로파일링으로 실제 워크로드에서의 성능을 측정해야 합니다. Valgrind의 Massif로 메모리 사용 패턴을 분석합니다. perf로 할당 함수의 CPU 시간을 측정합니다. 단편화율과 할당 실패율도 모니터링합니다. 이론적 우수성보다 실제 측정이 중요합니다.

**종합 결론**

일반적인 연속할당에서는 First-fit이 가장 좋습니다. 하지만 현대 시스템은 페이징을 사용하므로 연속할당은 주로 학습용입니다. 프로세스 내부 힙 관리는 Segregated free list나 Buddy system 기반 할당자가 우수합니다. 특정 용도에는 맞춤형 할당자가 최고입니다. 상황에 맞는 선택이 가장 중요하며, 단일 "최고" 알고리즘은 없습니다.

---

## 87. Thrashing 이란 무엇인가요?

**기본 개념**

Thrashing은 프로세스들이 실제 작업 수행보다 페이지 교체에 더 많은 시간을 소비하는 상태입니다. 시스템 성능이 급격히 저하되고, CPU 활용도가 낮아지며, 응답 시간이 극도로 길어집니다.

**발생 원인**

메모리보다 큰 작업 세트를 가진 프로세스가 많거나, 멀티프로그래밍 수준이 과도하면 발생합니다. 각 프로세스가 필요한 페이지를 모두 메모리에 유지할 수 없습니다. 한 프로세스가 페이지를 가져오면 다른 프로세스의 페이지가 스왑 아웃됩니다. 스왑 아웃된 프로세스가 실행되면 즉시 페이지 폴트가 발생하여 또 다른 교체를 유발합니다. 악순환이 계속되어 시스템이 마비 상태에 빠집니다.

**Thrashing의 증상**

CPU 활용도가 역설적으로 매우 낮아집니다. 프로세스들이 I/O 대기 상태에서 대부분의 시간을 보내기 때문입니다. 디스크 I/O가 폭증하여 시스템 전체가 느려집니다. 응답 시간이 수초에서 수분으로 늘어납니다. 사용자 입력에 반응하지 않는 것처럼 보입니다. 메모리는 충분하지 않지만 CPU는 거의 쉬고 있는 모순된 상황입니다.

**작업 세트 모델**

작업 세트는 프로세스가 특정 시간 동안 접근하는 페이지들의 집합입니다. 지역성의 원리에 따라 프로세스는 일정 기간 동안 제한된 페이지 집합을 집중적으로 사용합니다. 작업 세트 크기의 합이 물리 메모리보다 크면 Thrashing이 발생합니다. 시스템은 모든 프로세스의 작업 세트를 수용할 수 있을 때만 안정적으로 동작합니다.

**멀티프로그래밍 수준**

멀티프로그래밍 수준을 높이면 처음에는 CPU 활용도가 증가합니다. 하지만 임계점을 넘으면 Thrashing이 시작되어 성능이 급락합니다. 최적 멀티프로그래밍 수준은 작업 세트 크기와 물리 메모리 크기에 따라 결정됩니다. 동적으로 조정하지 않으면 부하 변화에 취약합니다.

**페이지 교체 알고리즘의 영향**

LRU나 Clock 같은 좋은 교체 알고리즘도 Thrashing을 완전히 방지하지 못합니다. 메모리가 부족하면 어떤 알고리즘을 사용해도 페이지 폴트율이 높아집니다. 교체 알고리즘은 상황을 약간 완화할 뿐, 근본 원인은 메모리 부족입니다.

**실제 사례**

오래된 컴퓨터에서 너무 많은 프로그램을 동시에 실행하면 Thrashing을 경험합니다. 웹 브라우저의 수십 개 탭, 대용량 문서 편집, 백그라운드 업데이트가 겹치면 시스템이 멈춘 것처럼 느려집니다. 스왑 파티션 LED가 계속 깜박이고, 디스크가 쉬지 않고 돌아갑니다. 작업 관리자를 열어도 반응하는 데 수십 초가 걸립니다.

**예방과 대응**

메모리를 충분히 확보하는 것이 근본 해결책입니다. 프로세스 수를 제한하여 멀티프로그래밍 수준을 조절합니다. 우선순위 낮은 프로세스를 스왑 아웃하거나 종료합니다. 작업 세트 크기를 모니터링하여 메모리 요구량을 예측합니다. 압축이나 메모리 재확보 기법으로 가용 메모리를 늘립니다. 리눅스 OOM Killer는 메모리 고갈 시 프로세스를 강제 종료하여 시스템을 보호합니다.

---

## 88. Thrashing 발생 시, 어떻게 완화할 수 있을까요?

**기본 개념**

Thrashing은 메모리 부족으로 인한 과도한 페이징 문제이므로, 메모리 압력을 줄이고 페이지 폴트를 감소시키는 방향으로 완화해야 합니다. 단기적 대응과 장기적 해결책이 모두 필요합니다.

**멀티프로그래밍 수준 조절**

가장 효과적인 단기 대응은 실행 중인 프로세스 수를 줄이는 것입니다. 일부 프로세스를 완전히 스왑 아웃하여 나머지 프로세스들이 충분한 메모리를 확보하도록 합니다. 중기 스케줄러가 이 역할을 수행하여, 작업 세트가 모두 메모리에 들어갈 수 있는 만큼만 프로세스를 활성화합니다. 우선순위가 낮거나 대기 상태인 프로세스를 먼저 스왑 아웃합니다. 시스템이 안정화되면 점진적으로 프로세스를 다시 활성화합니다.

**작업 세트 모니터링**

각 프로세스의 작업 세트 크기를 추적하여 메모리 할당을 동적으로 조정합니다. 작업 세트가 큰 프로세스는 더 많은 프레임을 할당받고, 작은 프로세스는 적게 할당받습니다. 페이지 폴트 빈도를 측정하여 프레임 할당량을 조절하는 PFF 알고리즘을 사용합니다. 폴트율이 높으면 프레임을 추가하고, 낮으면 회수하여 효율을 높입니다.

**우선순위 기반 스와핑**

덜 중요한 프로세스를 선택적으로 스왑 아웃합니다. 백그라운드 작업이나 유휴 시간이 긴 프로세스를 우선 대상으로 합니다. 사용자 대화형 프로세스는 응답성이 중요하므로 메모리에 유지합니다. 리눅스의 OOM Killer는 OOM 점수를 계산하여 희생 프로세스를 선택합니다. 메모리 사용량, 실행 시간, 우선순위 등을 종합 고려합니다.

**메모리 확보 기법**

페이지 캐시를 비우거나 줄여서 프로세스에 메모리를 돌려줍니다. 버퍼와 캐시는 성능 향상용이므로 필요 시 해제할 수 있습니다. 프로세스가 사용하지 않는 페이지를 회수합니다. KSM은 동일 내용의 페이지를 병합하여 메모리를 절약합니다. 압축 메모리나 zswap으로 스왑 아웃 대신 메모리 내 압축을 수행하여 더 많은 페이지를 보관합니다.

**프로세스 종료**

완화가 불가능하면 프로세스를 강제 종료하여 메모리를 확보합니다. 사용자에게 알림을 주고 종료할 프로세스를 선택하도록 합니다. 자동화된 경우 메모리를 많이 사용하면서 중요도가 낮은 프로세스를 선택합니다. 크롬 같은 웹 브라우저는 탭별 프로세스이므로 일부 탭만 종료하여 부분 복구할 수 있습니다.

**페이지 교체 알고리즘 최적화**

더 효율적인 교체 알고리즘으로 페이지 폴트를 줄입니다. LRU-K나 ARC 같은 고급 알고리즘은 접근 패턴을 더 정확히 예측합니다. 프리페칭으로 연속 페이지를 미리 가져와 폴트를 감소시킵니다. Clock 알고리즘의 스캔 빈도를 조절하여 적응적으로 동작합니다. 하지만 근본 원인은 메모리 부족이므로 효과가 제한적입니다.

**하드웨어 업그레이드**

장기적으로는 물리 메모리를 증설하는 것이 가장 확실합니다. RAM 가격이 저렴해져서 메모리 추가가 경제적입니다. SSD를 스왑 장치로 사용하면 페이지 교체 속도가 빨라져 Thrashing 영향을 줄입니다. HDD보다 수십 배 빠른 I/O로 체감 성능이 크게 향상됩니다.

**애플리케이션 최적화**

프로그램이 메모리를 효율적으로 사용하도록 개선합니다. 불필요한 데이터를 메모리에 유지하지 않고, 사용 후 즉시 해제합니다. 지역성을 높여 작업 세트 크기를 줄입니다. 메모리 맵 파일로 디스크를 가상 메모리처럼 사용합니다. 데이터 압축이나 경량 자료구조로 메모리 사용량을 감소시킵니다.
