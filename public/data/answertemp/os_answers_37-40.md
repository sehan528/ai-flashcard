# OS 답변 37-40

## 37. 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?

**저장 위치와 구조**

**PCB (Process Control Block)에 저장**
- 프로세스 정보는 주로 PCB에 저장됩니다
- PCB는 커널 메모리 영역에 위치합니다
- 각 프로세스마다 하나의 PCB가 존재합니다
- 리눅스에서는 task_struct 구조체로 구현됩니다

**커널 스택의 역할**
- 커널 스택은 시스템 콜이나 인터럽트 처리 시 사용됩니다
- 함수 호출 스택, 지역 변수, 리턴 주소를 저장합니다
- 컨텍스트 스위칭 시 일부 정보가 커널 스택에 임시 저장될 수 있습니다

**저장되는 정보**

**CPU 레지스터**
- 프로그램 카운터 (PC/IP)
- 스택 포인터 (SP)
- 프레임 포인터 (BP/FP)
- 범용 레지스터 (AX, BX, CX, DX 등)
- 상태 레지스터 (FLAGS/EFLAGS)
- 세그먼트 레지스터 (x86)
- 부동소수점 레지스터 (FPU, SSE)

**프로세스 상태**
- 현재 프로세스 상태 (Running, Ready 등)
- 우선순위 정보
- 스케줄링 관련 통계

**메모리 관리 정보**
- 페이지 테이블 베이스 레지스터 (PTBR)
- 메모리 맵 정보

**저장 형식**

**스택 프레임 형태**
컨텍스트 스위칭 시 커널 스택에 다음과 같은 형태로 저장됩니다:

```
높은 주소
┌──────────────────┐
│ SS (Stack Segment)│
├──────────────────┤
│ ESP (Stack Ptr)   │
├──────────────────┤
│ EFLAGS           │
├──────────────────┤
│ CS (Code Segment)│
├──────────────────┤
│ EIP (Inst Ptr)   │
├──────────────────┤
│ Error Code       │ (옵션)
├──────────────────┤
│ 범용 레지스터     │
└──────────────────┘
낮은 주소
```

**하드웨어 자동 저장**
- 인터럽트나 예외 발생 시 CPU가 자동으로 일부 레지스터를 커널 스택에 저장합니다
- SS, ESP, EFLAGS, CS, EIP 등
- 특권 수준 전환 시 자동으로 수행됩니다

**소프트웨어 저장**
- 나머지 레지스터는 인터럽트 핸들러나 스케줄러가 소프트웨어적으로 저장합니다
- PUSH 명령어를 사용하여 커널 스택에 저장합니다

**저장 과정**

**1단계: 하드웨어 자동 저장**
- 인터럽트 발생 시 CPU가 자동으로 수행
- 현재 SS, ESP, EFLAGS, CS, EIP를 커널 스택에 저장
- 사용자 모드 → 커널 모드 전환

**2단계: 인터럽트 핸들러 진입**
- 나머지 범용 레지스터를 수동으로 저장
- 세그먼트 레지스터 저장 (필요시)
- FPU/SSE 레지스터 저장 (필요시)

**3단계: PCB에 복사**
- 커널 스택에 저장된 정보를 PCB로 복사합니다
- 또는 커널 스택 포인터를 PCB에 저장합니다
- 이후 복원할 때 사용합니다

**4단계: 스케줄러 호출**
- 다음 실행할 프로세스를 선택합니다
- 새 프로세스의 PCB에서 정보를 읽습니다

**5단계: 새 프로세스 복원**
- 새 프로세스의 PCB에서 커널 스택으로 정보를 복사합니다
- 커널 스택에서 레지스터로 값을 복원합니다
- 인터럽트 복귀 명령어로 사용자 모드 전환

**리눅스의 구현**

**thread_struct 구조체**
- task_struct 내에 포함됩니다
- CPU 레지스터 값을 저장하는 구조체입니다
- 아키텍처별로 다릅니다

**pt_regs 구조체**
- 커널 스택 최상단에 위치합니다
- 사용자 모드에서 커널 모드 진입 시 레지스터 저장
- 시스템 콜, 인터럽트, 예외 처리에 사용

**switch_to() 매크로**
- 실제 컨텍스트 스위칭을 수행합니다
- 어셈블리 코드로 구현됩니다
- ESP를 교체하여 커널 스택을 전환합니다

**커널 스택 vs PCB**

**커널 스택 사용**
- 임시 저장 공간
- 빠른 접근
- 함수 호출과 복귀에 사용
- 크기 제한 (보통 8KB 또는 16KB)

**PCB 사용**
- 영구 저장
- 프로세스 전체 정보 보관
- 스케줄링 정보 포함
- 크기가 큼

**실제 동작**

**타이머 인터럽트 예시**
1. 타이머 인터럽트 발생
2. CPU가 현재 레지스터를 커널 스택에 자동 저장
3. 인터럽트 핸들러 실행
4. 스케줄러 호출
5. 현재 프로세스의 컨텍스트를 PCB에 저장
6. 다음 프로세스 선택
7. 새 프로세스의 PCB에서 커널 스택으로 로드
8. 레지스터 복원
9. 인터럽트 복귀로 새 프로세스 실행 재개

**아키텍처별 차이**

**x86-64**
- SYSCALL/SYSRET 명령어 사용
- MSR 레지스터에 커널 진입점 저장
- GS 레지스터로 커널 스택 주소 접근

**ARM**
- SVC (Supervisor Call) 명령어
- 뱅크 레지스터 자동 전환
- SPSR (Saved Program Status Register) 사용

**최적화**

**지연 FPU 저장**
- FPU/SSE 레지스터는 사용 시에만 저장
- 대부분의 프로세스가 사용하지 않음
- 플래그를 통해 저장 여부 추적
- 성능 향상

**레지스터 윈도우 (SPARC)**
- 여러 세트의 레지스터 제공
- 전환 시 윈도우만 이동
- 저장/복원 시간 단축

**실무 활용**
커널 디버깅 시 crash dump나 core dump를 분석하면 각 프로세스의 커널 스택과 PCB를 확인할 수 있습니다. gdb의 backtrace 명령어로 커널 스택의 함수 호출 경로를 추적할 수 있습니다.

---

## 38. 컨텍스트 스위칭은 언제 일어날까요?

**타이머 인터럽트 (시간 만료)**

**정기적 발생**
- 하드웨어 타이머가 주기적으로 인터럽트를 발생시킵니다
- 보통 1ms ~ 10ms 간격입니다
- 리눅스의 기본값은 1ms (HZ=1000)

**Time Slice 만료**
- Round Robin 스케줄링에서 각 프로세스에 할당된 시간이 끝나면
- 현재 프로세스를 선점하고 다음 프로세스로 전환
- 공정한 CPU 시간 분배 보장

**I/O 작업 요청**

**블로킹 I/O**
- 프로세스가 I/O 작업을 요청하면 대기 상태로 전환됩니다
- read(), write(), accept() 등의 시스템 콜
- CPU를 다른 프로세스에 양보합니다
- I/O 완료 시 Ready 상태로 복귀합니다

**디스크, 네트워크, 터미널 I/O**
- 느린 I/O 작업 대기 중 CPU 낭비 방지
- 다른 프로세스가 CPU를 활용할 수 있게 함

**우선순위 선점**

**높은 우선순위 프로세스 도착**
- 더 높은 우선순위의 프로세스가 Ready 상태가 되면
- 현재 실행 중인 낮은 우선순위 프로세스를 선점합니다
- 실시간 시스템에서 중요합니다

**인터럽트 처리 후**
- 인터럽트 서비스 루틴 완료 후 스케줄러 호출
- 더 긴급한 작업이 있으면 전환 발생

**프로세스 종료**

**자발적 종료**
- exit() 시스템 콜로 프로세스 종료
- Running → Terminated 전환
- 다음 프로세스에 CPU 할당

**비정상 종료**
- 세그먼테이션 폴트, 예외 발생
- 커널이 프로세스를 강제 종료
- 컨텍스트 스위칭 발생

**동기화 대기**

**Mutex/Semaphore 대기**
- pthread_mutex_lock()이 이미 잠긴 뮤텍스를 만나면
- 프로세스/스레드가 대기 상태로 전환
- 락이 해제되면 Ready 상태로 복귀

**조건 변수 대기**
- pthread_cond_wait() 호출 시
- 조건이 충족될 때까지 대기

**Sleep 호출**

**명시적 대기**
- sleep(), usleep(), nanosleep() 시스템 콜
- 지정된 시간 동안 프로세스를 대기 상태로 만듭니다
- 타이머 만료 후 Ready 상태로 복귀

**페이지 폴트**

**메모리 접근 예외**
- 페이지가 메모리에 없을 때 (Major Page Fault)
- 디스크에서 페이지를 로드해야 합니다
- 프로세스는 Waiting 상태로 전환
- 페이지 로드 완료 후 Ready로 복귀

**Minor Page Fault**
- 권한 설정만 필요한 경우
- 빠르게 처리되지만 여전히 전환 가능

**프로세스 생성**

**fork() 시스템 콜**
- 새로운 프로세스 생성
- 부모 프로세스가 계속 실행되거나
- 스케줄러가 자식 프로세스로 전환 가능

**exec() 후**
- 새 프로그램 로드 완료 후
- 실행 시작 전 스케줄링 결정

**시그널 처리**

**시그널 수신**
- SIGSTOP, SIGTSTP로 프로세스 일시 중지
- SIGCONT로 재개
- 시그널 핸들러 실행 후 스케줄링

**프로세스 간 통신**

**메시지 큐 대기**
- msgrcv()에서 메시지 도착 대기
- 파이프 읽기에서 데이터 대기
- 소켓 읽기에서 데이터 대기

**사용자 공간에서의 명시적 양보**

**sched_yield() 시스템 콜**
- 프로세스가 자발적으로 CPU를 양보
- 다른 Ready 프로세스가 있으면 전환
- 협력적 멀티태스킹 구현에 사용

**스케줄링 정책 변경**

**우선순위 변경**
- nice(), setpriority() 호출
- 실시간 스케줄링 정책 변경
- 즉시 또는 다음 스케줄링 시점에 반영

**빈도**

**타이머 인터럽트**
- 가장 빈번한 원인
- 초당 수백~수천 번

**I/O 작업**
- I/O 집약적 프로그램에서 빈번
- 네트워크 서버, 파일 처리 등

**자발적 양보**
- 드물게 발생
- 특정 애플리케이션에서만

**스케줄링 정책별 차이**

**선점형 스케줄링**
- 타이머 인터럽트로 강제 전환
- Round Robin, Priority Scheduling

**비선점형 스케줄링**
- 프로세스가 자발적으로 CPU를 놓을 때만
- I/O 요청, 종료, yield() 호출 시
- FCFS, 비선점형 SJF

**멀티코어 환경**

**부하 분산**
- 한 코어의 큐가 비어있으면
- 다른 코어에서 프로세스를 가져옴
- 코어 간 마이그레이션 발생

**인터럽트 어피니티**
- 특정 인터럽트는 특정 코어에서만 처리
- 해당 코어에서 컨텍스트 스위칭 발생

**실무 활용**
시스템 모니터링 시 vmstat의 "cs" 열이나 "r" 열로 컨텍스트 스위칭 빈도와 대기 중인 프로세스 수를 확인합니다. 과도한 컨텍스트 스위칭은 성능 저하의 원인이 되므로 최적화가 필요합니다.

---

## 39. 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?

**FCFS (First-Come, First-Served)**

**특징**
- 가장 단순한 스케줄링 알고리즘입니다
- 먼저 도착한 프로세스를 먼저 실행합니다
- 비선점형 알고리즘입니다
- FIFO 큐로 구현합니다

**장점**
- 구현이 매우 간단합니다
- 공정하고 이해하기 쉽습니다
- 기아 현상이 발생하지 않습니다

**단점**
- Convoy Effect: 긴 프로세스 뒤에 짧은 프로세스들이 대기
- 평균 대기 시간이 길어질 수 있습니다
- 응답 시간이 예측 불가능합니다

**사용 사례**
- 일괄 처리 시스템
- 단순한 임베디드 시스템

**SJF (Shortest Job First)**

**특징**
- CPU 버스트 시간이 가장 짧은 프로세스를 먼저 실행합니다
- 비선점형 버전이 기본입니다
- 평균 대기 시간을 최소화하는 최적 알고리즘입니다

**장점**
- 평균 대기 시간이 가장 짧습니다
- 처리량이 높습니다

**단점**
- CPU 버스트 시간을 미리 알기 어렵습니다
- 긴 프로세스의 기아 현상 발생 가능
- 비현실적입니다 (실제 구현 어려움)

**예측 방법**
- 지수 평균을 사용하여 다음 CPU 버스트 예측
- 과거 실행 시간을 기반으로 추정

**SRTF (Shortest Remaining Time First)**

**특징**
- SJF의 선점형 버전입니다
- 남은 실행 시간이 가장 짧은 프로세스를 실행합니다
- 새 프로세스 도착 시 비교하여 선점합니다

**장점**
- 평균 대기 시간을 더욱 줄입니다
- 짧은 작업의 응답 시간이 빠릅니다

**단점**
- 컨텍스트 스위칭 오버헤드 증가
- 긴 프로세스의 기아 현상 심화
- 실행 시간 예측 필요

**Priority Scheduling (우선순위 스케줄링)**

**특징**
- 각 프로세스에 우선순위를 부여합니다
- 가장 높은 우선순위의 프로세스를 실행합니다
- 선점형과 비선점형 모두 가능합니다

**우선순위 결정 요소**
- 프로세스 타입 (시스템/사용자)
- 메모리 요구량
- I/O vs CPU 비율
- 실행 시간
- nice 값

**장점**
- 중요한 작업을 우선 처리
- 유연한 정책 적용 가능

**단점**
- 낮은 우선순위 프로세스의 기아 현상
- 우선순위 역전 문제

**해결책**
- Aging: 대기 시간이 길어지면 우선순위 상승
- Priority Inheritance: 우선순위 역전 해결

**Round Robin (RR)**

**특징**
- 각 프로세스에 동일한 시간 할당량(Time Quantum)을 부여합니다
- 시간 만료 시 다음 프로세스로 전환합니다
- 선점형 FCFS입니다
- 순환 큐로 구현합니다

**Time Quantum 선택**
- 너무 크면: FCFS와 유사
- 너무 작으면: 컨텍스트 스위칭 오버헤드 증가
- 일반적으로 10-100ms

**장점**
- 공정한 CPU 시간 분배
- 응답 시간이 예측 가능
- 모든 프로세스가 일정 시간 내 실행 보장

**단점**
- 평균 대기 시간이 길 수 있음
- 컨텍스트 스위칭 오버헤드

**사용 사례**
- 시분할 시스템
- 대화형 시스템

**Multi-level Queue**

**특징**
- 여러 개의 Ready Queue를 유지합니다
- 프로세스를 타입별로 분류합니다
- 각 큐는 독립적인 스케줄링 알고리즘을 사용합니다
- 큐 간 우선순위가 고정됩니다

**큐 분류 예시**
- 최상위: 시스템 프로세스
- 상위: 대화형 프로세스 (RR)
- 중간: 일반 프로세스 (RR)
- 하위: 일괄 처리 (FCFS)

**장점**
- 프로세스 타입별 최적화
- 명확한 우선순위 체계

**단점**
- 하위 큐의 기아 현상
- 유연성 부족

**Multi-level Feedback Queue (MLFQ)**

**특징**
- Multi-level Queue의 발전형입니다
- 프로세스가 큐 간 이동 가능합니다
- CPU 사용 패턴에 따라 자동으로 조정됩니다

**동작 방식**
- 모든 프로세스는 최상위 큐에서 시작
- CPU를 많이 사용하면 하위 큐로 이동
- I/O 위주 프로세스는 상위 큐 유지
- Aging으로 기아 현상 방지

**장점**
- 적응형 스케줄링
- I/O bound와 CPU bound 자동 구분
- 응답 시간과 처리량 모두 최적화

**단점**
- 복잡한 구현
- 파라미터 튜닝 필요

**사용 사례**
- 현대 운영체제 (리눅스, Windows 등)
- 범용 시스템

**CFS (Completely Fair Scheduler)**

**특징**
- 리눅스의 기본 스케줄러입니다
- Red-Black Tree로 구현됩니다
- Virtual Runtime 개념 사용합니다

**동작 방식**
- 각 프로세스의 실행 시간을 추적
- 가장 적게 실행된 프로세스를 선택
- 완전히 공정한 CPU 시간 분배

**장점**
- O(log n) 복잡도
- 공정성 보장
- 확장성 우수

**실시간 스케줄링**

**Rate Monotonic (RM)**
- 주기가 짧은 작업에 높은 우선순위
- 정적 우선순위

**Earliest Deadline First (EDF)**
- 마감 시간이 가까운 작업 우선
- 동적 우선순위
- 이론적으로 최적

**사용 사례**
- 임베디드 시스템
- 로봇 제어
- 멀티미디어 스트리밍

**비교 요약**

| 알고리즘 | 선점 | 기아 | 복잡도 | 사용처 |
|---------|------|------|--------|--------|
| FCFS | ✗ | ✗ | 낮음 | 일괄 처리 |
| SJF | ✗ | ✓ | 중간 | 이론적 |
| SRTF | ✓ | ✓ | 중간 | 이론적 |
| Priority | ✓/✗ | ✓ | 중간 | 실시간 |
| RR | ✓ | ✗ | 낮음 | 시분할 |
| MLFQ | ✓ | ✗ | 높음 | 범용 |
| CFS | ✓ | ✗ | 중간 | 리눅스 |

**실무 활용**
현대 운영체제는 MLFQ나 CFS를 기본으로 하되, 실시간 프로세스를 위한 별도 스케줄러를 제공합니다. 시스템 요구사항에 따라 스케줄러를 선택하고 튜닝합니다.

---

## 40. RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.

**Time Slice (Time Quantum)란?**
Round Robin 스케줄링에서 각 프로세스에 할당되는 CPU 실행 시간의 단위입니다.

**Time Slice가 큰 경우**

**장점**

**컨텍스트 스위칭 감소**
- 스위칭 횟수가 줄어듭니다
- 오버헤드가 감소합니다
- CPU 효율성이 향상됩니다
- 캐시 효율이 좋아집니다

**처리량 증가**
- 실제 작업 수행 시간 비율이 높습니다
- 전체 시스템 처리량이 향상됩니다
- 배치 작업에 유리합니다

**단점**

**응답 시간 증가**
- 프로세스가 CPU를 받을 때까지 오래 기다립니다
- 최악의 경우: (n-1) * time_slice 대기
- 대화형 시스템에 부적합합니다

**공정성 저하**
- 짧은 작업도 오래 기다려야 합니다
- 사용자 체감 응답성이 나빠집니다

**FCFS에 근접**
- Time Slice가 매우 크면 FCFS와 거의 동일
- Convoy Effect 발생 가능
- RR의 장점 상실

**Time Slice가 작은 경우**

**장점**

**빠른 응답 시간**
- 모든 프로세스가 자주 CPU를 받습니다
- 대화형 프로세스의 응답성 향상
- 사용자 경험 개선

**공정성 향상**
- CPU 시간이 균등하게 분배됩니다
- 짧은 작업이 빨리 완료됩니다

**다중 프로그래밍 효과**
- 여러 작업이 동시에 진행되는 느낌
- 병렬성이 높아 보입니다

**단점**

**컨텍스트 스위칭 오버헤드 증가**
- 매우 빈번한 컨텍스트 스위칭
- CPU 시간의 많은 부분이 스위칭에 소비됩니다
- 실제 작업 시간 감소

**처리량 감소**
- 전체 시스템 효율이 떨어집니다
- 작업 완료가 지연됩니다

**캐시 효율 저하**
- 캐시 미스율 증가
- 각 프로세스가 캐시를 워밍업할 시간이 부족
- 성능 저하

**극단적인 경우: 프로세서 공유**
- Time Slice가 극도로 작으면
- 프로세서를 동시에 공유하는 것처럼 보임
- 하지만 실제로는 매우 비효율적

**Trade-off 분석**

**컨텍스트 스위칭 비용 예시**
- 컨텍스트 스위칭 시간: 10μs
- Time Slice: 100ms → 오버헤드 0.01%
- Time Slice: 10ms → 오버헤드 0.1%
- Time Slice: 1ms → 오버헤드 1%
- Time Slice: 100μs → 오버헤드 10%

**응답 시간 예시 (10개 프로세스)**
- Time Slice: 100ms → 최대 응답 시간 900ms
- Time Slice: 10ms → 최대 응답 시간 90ms
- Time Slice: 1ms → 최대 응답 시간 9ms

**최적 Time Slice 선택**

**고려 사항**

**시스템 유형**
- 대화형 시스템: 작은 값 (10-50ms)
- 서버 시스템: 중간 값 (50-100ms)
- 배치 시스템: 큰 값 (100-1000ms)

**프로세스 수**
- 프로세스 많음: 작은 값 선호
- 프로세스 적음: 큰 값 가능

**평균 CPU 버스트**
- 짧은 버스트: 작은 time slice
- 긴 버스트: 큰 time slice

**컨텍스트 스위칭 비용**
- 비용 높음(복잡한 시스템): 큰 값
- 비용 낮음: 작은 값 가능

**일반적인 가이드라인**

**경험적 규칙**
- Time Slice: 10-100ms
- 80% 프로세스가 한 타임 슬라이스 내에 CPU 버스트 완료
- 컨텍스트 스위칭 오버헤드 < 1%

**리눅스 사례**
- 전통적: 100ms (HZ=10)
- 2.6 커널: 1ms (HZ=1000)
- CFS: 동적 조정 (sched_latency / 프로세스 수)

**동적 조정**

**적응형 접근**
- 시스템 부하에 따라 조정
- 프로세스 수에 따라 조정
- I/O vs CPU 비율에 따라 조정

**CFS의 접근**
- 목표 지연시간 (sched_latency): 6ms
- Time Slice = sched_latency / running_tasks
- 최소값 (min_granularity): 0.75ms 보장

**실측 성능**

**Time Slice: 10ms**
- 응답성: 좋음
- 처리량: 중간
- 오버헤드: 낮음
- 대부분의 시스템에 적합

**Time Slice: 100ms**
- 응답성: 나쁨
- 처리량: 좋음
- 오버헤드: 매우 낮음
- 배치 시스템 적합

**Time Slice: 1ms**
- 응답성: 매우 좋음
- 처리량: 나쁨
- 오버헤드: 높음
- 실시간 시스템 고려 가능

**실무 권장사항**

**시작점**
- 10-20ms를 기본값으로 시작
- 시스템 특성에 따라 조정
- 모니터링하면서 최적화

**측정 지표**
- 응답 시간
- 처리량
- 컨텍스트 스위칭 횟수
- CPU 사용률
- 사용자 만족도

**실무 활용**
성능 튜닝 시 Time Slice 값을 조정하여 응답성과 처리량의 균형을 맞춥니다. 웹 서버는 빠른 응답을 위해 작은 값을, HPC 시스템은 처리량을 위해 큰 값을 선호합니다.
