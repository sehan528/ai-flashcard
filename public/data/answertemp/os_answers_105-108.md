# OS 답변 105-108

## 105. MMU가 무엇인가요?

**기본 개념**

MMU는 Memory Management Unit의 약자로, 가상 주소를 물리 주소로 변환하는 하드웨어 장치입니다. CPU 내부에 통합되어 있으며, 가상 메모리 시스템의 핵심 구성 요소입니다.

**MMU의 주요 기능**

주소 변환이 가장 중요한 역할입니다. CPU가 생성하는 가상 주소를 페이지 테이블을 참조하여 물리 주소로 바꿉니다. 메모리 보호도 담당하여 권한 비트를 검사하고 위반 시 예외를 발생시킵니다. 캐시 제어 속성을 관리하여 각 페이지가 캐시 가능한지 결정합니다. TLB를 통합하여 빠른 주소 변환을 제공합니다.

**MMU의 동작 원리**

CPU가 명령어를 실행하면서 메모리 주소를 생성합니다. 이 주소는 가상 주소이며, MMU로 전달됩니다. MMU는 TLB를 먼저 확인하여 빠른 경로로 변환을 시도합니다. TLB 미스 시 페이지 테이블을 워킹하여 변환을 수행합니다. 물리 주소를 얻으면 권한을 확인하고, 문제없으면 메모리 버스로 전달합니다. 위반이 있으면 페이지 폴트나 보호 예외를 발생시킵니다.

**페이지 테이블 베이스 레지스터**

MMU는 페이지 테이블의 시작 주소를 알아야 합니다. CR3 레지스터나 TTBR 같은 특수 레지스터에 페이지 테이블 주소를 저장합니다. 컨텍스트 스위칭 시 이 레지스터를 변경하여 다른 프로세스의 페이지 테이블로 전환합니다. 이는 각 프로세스가 독립적인 주소 공간을 가지게 합니다.

**하드웨어 페이지 워크**

현대 MMU는 페이지 테이블 워킹을 하드웨어로 자동 수행합니다. TLB 미스 시 소프트웨어 개입 없이 멀티레벨 테이블을 탐색합니다. 각 레벨의 디렉토리를 순차적으로 읽어 최종 프레임 번호를 찾습니다. 찾은 엔트리를 TLB에 캐시하여 다음 접근을 빠르게 합니다. 이는 성능과 단순성을 모두 제공합니다.

**메모리 속성 관리**

MMU는 각 페이지의 캐시 정책을 관리합니다. Write-Back, Write-Through, Uncacheable 등을 설정할 수 있습니다. 디바이스 메모리는 캐시하지 않도록 설정하여 일관성을 보장합니다. 메모리 배리어 명령어와 협력하여 메모리 순서를 제어합니다.

**IOMMU**

일부 시스템은 IOMMU를 가져서 디바이스도 가상 주소를 사용할 수 있습니다. DMA 컨트롤러가 생성하는 주소를 IOMMU가 변환합니다. 이는 디바이스의 메모리 접근을 격리하고 보호합니다. 가상화 환경에서 게스트 물리 주소를 호스트 물리 주소로 변환하는 데도 사용됩니다.

**MMU 없는 시스템**

임베디드 시스템이나 마이크로컨트롤러는 MMU가 없을 수 있습니다. 프로그램이 물리 주소를 직접 사용하며, 메모리 보호가 제한적입니다. 하나의 프로그램만 실행하거나, 협력적 멀티태스킹을 사용합니다. MPU는 간단한 영역 기반 보호를 제공하지만 가상 메모리는 지원하지 않습니다.

**실무 활용**

운영체제는 MMU를 설정하여 프로세스별 주소 공간을 구성합니다. 페이지 테이블을 생성하고 MMU 레지스터를 초기화합니다. 예외 핸들러를 등록하여 페이지 폴트를 처리합니다. MMU는 투명하게 동작하여 애플리케이션 프로그래머는 의식할 필요가 없습니다. 가상 메모리의 모든 장점을 하드웨어적으로 구현하는 핵심 장치입니다.

---

## 106. TLB와 MMU는 어디에 위치해 있나요?

**기본 개념**

TLB와 MMU는 모두 CPU 칩 내부에 위치합니다. 메모리 접근 파이프라인의 일부로 통합되어 있으며, 매우 빠른 접근 속도를 제공합니다.

**MMU의 위치**

MMU는 CPU 코어 내부 또는 매우 가까운 곳에 위치합니다. 명령어 실행 파이프라인에 통합되어 있어서, 로드/스토어 명령어 실행 시 자동으로 작동합니다. CPU와 메모리 버스 사이에 위치하여 모든 메모리 접근을 중재합니다. 하드웨어 회로로 구현되어 매우 빠르게 동작합니다.

**TLB의 위치**

TLB는 MMU의 일부로 CPU 코어 내부에 있습니다. L1 캐시와 비슷한 위치에 배치되어 극도로 빠른 접근이 가능합니다. 일부 아키텍처는 명령어 TLB와 데이터 TLB를 분리하여 각각 명령어 캐시와 데이터 캐시 옆에 둡니다. 이는 병렬 접근을 가능하게 하여 성능을 향상시킵니다.

**CPU 칩 내 배치**

현대 CPU는 코어, 캐시, MMU, TLB를 모두 하나의 다이에 통합합니다. 멀티코어 CPU에서 L1 캐시와 L1 TLB는 각 코어 전용입니다. L2 TLB는 코어별로 가질 수도, 일부 코어가 공유할 수도 있습니다. L3 캐시처럼 공유 TLB를 가지는 설계도 있습니다.

**메모리 계층과의 관계**

TLB는 캐시와 비슷한 계층 구조를 가집니다. CPU 레지스터 바로 다음에 TLB가 있어서 주소 변환을 담당합니다. 변환된 물리 주소로 L1, L2, L3 캐시를 순차적으로 확인합니다. 캐시 미스 시 메인 메모리에 접근합니다. TLB는 이 전체 과정의 시작 단계입니다.

**물리적 근접성의 중요성**

TLB와 MMU가 CPU 내부에 있어야 빠릅니다. 칩 외부에 있다면 버스 통신으로 인한 지연이 발생합니다. 온칩 배치로 클럭 사이클 내에 접근할 수 있습니다. 이는 가상 메모리 오버헤드를 최소화하는 핵심 요소입니다.

**멀티코어 고려사항**

각 코어는 독립적인 MMU와 TLB를 가집니다. 코어별로 다른 프로세스를 실행할 수 있어서, 각자의 페이지 테이블을 사용합니다. 하지만 물리 메모리는 공유하므로, 캐시 일관성 프로토콜로 동기화합니다. ASID나 PCID로 TLB 엔트리를 구분하여 플러시 빈도를 줄입니다.

**IOMMU의 위치**

IOMMU는 CPU가 아닌 칩셋이나 별도 하드웨어에 위치합니다. 시스템 버스와 메모리 컨트롤러 사이에 있어서 DMA 트래픽을 변환합니다. CPU MMU와 독립적으로 동작하지만, 유사한 페이지 테이블 구조를 사용할 수 있습니다.

**가상화 환경**

가상화에서는 여러 단계의 주소 변환이 필요합니다. 게스트 가상 주소를 게스트 물리 주소로, 다시 호스트 물리 주소로 변환합니다. 2단계 페이지 테이블을 지원하는 MMU가 필요하며, TLB도 이를 캐시합니다. Intel VT-x나 AMD-V 같은 가상화 확장이 이를 하드웨어로 지원합니다.

**실무 의미**

TLB와 MMU가 CPU 내부에 있다는 것은 매우 빠르다는 뜻입니다. 프로그래머는 위치를 직접 제어할 수 없지만, 작동 원리를 이해하면 최적화할 수 있습니다. TLB 크기를 고려하여 작업 세트를 조절하고, 지역성을 높여 히트율을 향상시킵니다. 하드웨어 특성을 활용한 소프트웨어 최적화가 성능 향상의 열쇠입니다.

---

## 107. 코어가 여러개라면, TLB는 어떻게 동기화 할 수 있을까요?

**기본 개념**

멀티코어 시스템에서 각 코어는 독립적인 TLB를 가집니다. 한 코어가 페이지 테이블을 수정하면, 다른 코어의 TLB에 있는 오래된 엔트리를 무효화해야 합니다. 이를 TLB shootdown이라고 합니다.

**문제 상황**

한 코어의 프로세스가 페이지 테이블을 변경합니다. 메모리 매핑 해제, 권한 변경, 페이지 교체 등이 원인입니다. 변경 사항이 메모리에 반영되었지만, 다른 코어의 TLB는 여전히 이전 매핑을 가지고 있습니다. 그 코어가 해당 주소에 접근하면 잘못된 물리 주소나 권한을 사용하여 오류가 발생할 수 있습니다.

**TLB Shootdown 프로토콜**

페이지 테이블을 수정하는 코어가 프로세스를 실행 중인 다른 모든 코어에 IPI를 보냅니다. Inter-Processor Interrupt로 다른 코어를 인터럽트합니다. 각 코어는 IPI를 받으면 해당 TLB 엔트리를 무효화합니다. 무효화 완료 후 응답을 보내고, 모든 코어가 응답하면 원래 코어가 계속 진행합니다. 이는 일관성을 보장하지만 비용이 큽니다.

**ASID와 PCID**

Address Space ID나 Process Context ID로 TLB 엔트리를 태그합니다. 각 프로세스에 고유 ID를 부여하여 TLB 엔트리를 구분합니다. 컨텍스트 스위칭 시 ASID만 변경하고 TLB 전체를 플러시하지 않습니다. 이전 프로세스의 엔트리가 남아 있어도 ASID가 다르면 사용되지 않습니다. Shootdown 시에도 특정 ASID의 엔트리만 무효화할 수 있습니다.

**선택적 무효화**

전체 TLB를 플러시하는 것은 비효율적입니다. 특정 주소나 범위만 무효화하는 명령어를 사용합니다. x86의 INVLPG는 하나의 페이지만 무효화합니다. ARM의 TLB invalidate 명령어도 범위를 지정할 수 있습니다. 이는 불필요한 무효화를 줄여 성능을 향상시킵니다.

**지연 무효화**

모든 변경마다 즉시 shootdown하면 오버헤드가 큽니다. 일부 시스템은 무효화를 배치 처리하여 여러 변경을 모아서 한 번에 처리합니다. 또는 지연 무효화로 실제 사용 시점에 검사하여 오래된 엔트리를 발견하면 재로드합니다. 이는 복잡하지만 IPI 횟수를 줄입니다.

**캐시 일관성과의 차이**

캐시 일관성은 하드웨어 프로토콜로 자동 관리됩니다. MESI나 MOESI 프로토콜이 데이터 일관성을 보장합니다. TLB는 소프트웨어가 명시적으로 무효화해야 합니다. 운영체제가 shootdown을 관리하며, 하드웨어는 IPI와 무효화 명령어만 제공합니다.

**성능 영향**

TLB shootdown은 비용이 큽니다. IPI 전송, 인터럽트 처리, TLB 무효화, 응답 대기 모두 시간이 걸립니다. 많은 코어로 확장할수록 오버헤드가 증가합니다. 페이지 테이블 변경을 최소화하고, 무효화를 배치 처리하며, 큰 페이지를 사용하여 완화합니다.

**실무 최적화**

munmap이나 mprotect 같은 시스템 콜은 TLB shootdown을 유발합니다. 빈번한 메모리 매핑 변경은 성능을 저하시킵니다. 메모리 풀을 재사용하여 매핑 변경을 줄입니다. Huge Pages는 TLB 엔트리 수를 줄여 shootdown 비용을 낮춥니다. 프로파일러로 shootdown 빈도를 측정하고 최적화합니다.

**하드웨어 지원**

일부 CPU는 하드웨어 지원 TLB 일관성을 제공합니다. 페이지 테이블 변경을 하드웨어가 감지하여 자동으로 다른 코어의 TLB를 무효화합니다. 하지만 여전히 대부분은 소프트웨어 관리 방식을 사용합니다. 미래에는 더 자동화된 방식이 등장할 수 있습니다.

---

## 108. TLB 관점에서, Context Switching 발생 시 어떤 변화가 발생하는지 설명해 주세요.

**기본 개념**

컨텍스트 스위칭 시 다른 프로세스의 주소 공간으로 전환되므로, TLB의 매핑이 유효하지 않게 됩니다. TLB 관리가 필요하며, 이는 컨텍스트 스위칭 비용의 일부입니다.

**주소 공간 변경**

각 프로세스는 독립적인 가상 주소 공간을 가집니다. 같은 가상 주소라도 프로세스마다 다른 물리 주소에 매핑됩니다. 컨텍스트 스위칭 시 페이지 테이블 베이스 레지스터를 변경하여 새 프로세스의 페이지 테이블로 전환합니다. 이전 프로세스의 TLB 엔트리는 새 프로세스에 유효하지 않습니다.

**전체 TLB 플러시**

가장 단순한 방법은 컨텍스트 스위칭 시 TLB 전체를 무효화하는 것입니다. 모든 엔트리를 비워서 새 프로세스가 깨끗한 TLB로 시작합니다. 이후 메모리 접근 시 TLB 미스가 발생하고, 페이지 테이블을 조회하여 TLB를 채웁니다. 처음에는 모든 접근이 미스이지만, 곧 작업 세트가 TLB에 적재됩니다.

**TLB 플러시 비용**

전체 플러시는 성능에 큰 영향을 미칩니다. 스위칭 직후 모든 메모리 접근이 느려집니다. 작업 세트를 다시 TLB에 채우는 시간이 필요합니다. 수백에서 수천 사이클의 오버헤드가 발생할 수 있습니다. 컨텍스트 스위칭이 빈번하면 TLB 히트율이 낮아져 전체 성능이 저하됩니다.

**ASID/PCID 사용**

Address Space ID를 사용하면 TLB 플러시를 피할 수 있습니다. 각 TLB 엔트리에 프로세스 ID를 태그하여 어느 프로세스의 것인지 표시합니다. 컨텍스트 스위칭 시 ASID만 변경하고 TLB는 유지합니다. TLB 조회 시 현재 ASID와 일치하는 엔트리만 사용합니다. 이전 프로세스의 엔트리가 남아 있어도 안전하게 무시됩니다.

**ASID의 장점**

빠른 재전환 시 성능이 크게 향상됩니다. 프로세스 A에서 B로, 다시 A로 돌아올 때 A의 TLB 엔트리가 여전히 유효합니다. 멀티태스킹 환경에서 여러 프로세스의 엔트리가 공존하여 전반적인 히트율이 높아집니다. TLB 플러시 없이 스위칭하므로 오버헤드가 감소합니다.

**ASID 고갈**

ASID는 제한된 비트 수를 가집니다. 8비트면 256개 프로세스만 구분할 수 있습니다. 프로세스가 더 많으면 ASID를 재사용해야 합니다. 재사용 시 이전 엔트리를 무효화하여 혼동을 방지합니다. 운영체제가 ASID를 할당하고 관리하는 정책이 필요합니다.

**커널 공간 매핑**

커널 주소 공간은 모든 프로세스에서 공통입니다. 커널 매핑을 위한 TLB 엔트리는 프로세스와 무관하게 유효합니다. 일부 아키텍처는 글로벌 비트로 이런 엔트리를 표시합니다. 컨텍스트 스위칭 시에도 글로벌 엔트리는 유지되어 커널 코드 실행이 빠릅니다.

**Huge Pages와의 상호작용**

큰 페이지를 사용하면 TLB 엔트리 수가 줄어듭니다. 컨텍스트 스위칭 후 재적재해야 할 엔트리가 적어서 워밍업이 빠릅니다. 작업 세트를 적은 엔트리로 표현하므로 ASID 사용 시에도 효율적입니다.

**실무 영향**

자주 스위칭하는 시스템에서는 ASID가 필수적입니다. 웹 서버나 데이터베이스는 많은 프로세스/스레드를 관리하므로 TLB 최적화가 중요합니다. 리눅스는 PCID를 활용하여 성능을 개선합니다. 컨텍스트 스위칭 비용을 줄이려면 TLB 관리를 이해하고 최적화해야 합니다.
