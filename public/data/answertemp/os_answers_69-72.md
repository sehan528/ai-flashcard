# OS 답변 69-72

## 69. Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.

**기본 개념**

Peterson's Algorithm은 두 개의 프로세스나 스레드 간 상호 배제를 보장하는 소프트웨어 기반 동기화 알고리즘입니다. 하드웨어 지원 없이 공유 메모리 변수만으로 임계 영역 문제를 해결합니다.

**알고리즘의 동작 원리**

두 개의 플래그 배열과 하나의 턴 변수를 사용합니다. 각 프로세스는 임계 영역에 진입하기 전에 자신의 플래그를 참으로 설정하고, 턴을 상대방에게 양보합니다. 상대방의 플래그가 참이고 턴이 상대방 차례라면 대기합니다. 상대방이 플래그를 거짓으로 설정하거나 턴이 자신 차례가 되면 임계 영역에 진입합니다. 작업 완료 후 자신의 플래그를 거짓으로 설정하여 나옵니다.

**상호 배제 보장**

Peterson's Algorithm은 상호 배제, 진행, 한정 대기의 세 가지 조건을 모두 만족합니다. 두 프로세스가 동시에 임계 영역에 진입할 수 없으며, 한 프로세스가 임계 영역을 원하면 언젠가는 진입할 수 있습니다. 어느 프로세스도 무한정 대기하지 않으며, 공정성이 보장됩니다.

**현대 아키텍처에서의 한계**

가장 큰 한계는 현대 CPU의 명령어 재배치와 메모리 일관성 모델입니다. 컴파일러와 CPU는 성능 최적화를 위해 명령어 순서를 바꿀 수 있습니다. Peterson's Algorithm은 특정 실행 순서를 가정하므로, 재배치가 발생하면 올바르게 동작하지 않습니다. 메모리 배리어나 volatile 키워드 없이는 현대 시스템에서 안전하지 않습니다.

**캐시 일관성 문제**

멀티코어 시스템에서 각 코어는 자체 캐시를 가집니다. 한 코어가 쓴 값이 다른 코어의 캐시에 즉시 반영되지 않을 수 있습니다. 플래그나 턴 변수의 변경이 즉시 관찰되지 않으면 두 프로세스가 동시에 임계 영역에 진입할 수 있습니다. 캐시 일관성 프로토콜이 있지만, 메모리 배리어가 필요합니다.

**확장성 문제**

Peterson's Algorithm은 두 프로세스에만 적용되며, N개의 프로세스로 확장하면 복잡도가 크게 증가합니다. 필터 알고리즘이나 베이커리 알고리즘으로 일반화할 수 있지만, 실용성이 떨어집니다. 대기 중인 프로세스가 busy-waiting하여 CPU를 낭비합니다.

**실무적 가치**

Peterson's Algorithm은 교육적 목적으로는 훌륭하지만, 실제 시스템에서는 사용되지 않습니다. 현대 운영체제는 하드웨어 지원 원자적 명령어와 커널 동기화 프리미티브를 사용합니다. 뮤텍스, 세마포어, CAS 연산이 더 효율적이고 안전합니다. Peterson's Algorithm은 동기화 문제의 이론적 이해를 돕는 역할을 합니다.

**개선 방안**

메모리 배리어를 추가하여 명령어 재배치를 방지할 수 있습니다. Volatile 또는 atomic 변수를 사용하여 캐시 일관성을 보장할 수 있습니다. 하지만 이러한 개선도 하드웨어 지원 동기화보다는 비효율적입니다. 학습 도구로는 유용하지만, 실제 코드에는 적합하지 않습니다.

---

## 70. Race Condition 이 무엇인가요?

**기본 개념**

Race Condition은 여러 프로세스나 스레드가 공유 자원에 동시에 접근할 때, 실행 순서나 타이밍에 따라 결과가 달라지는 상황입니다. 예측 불가능하고 재현하기 어려운 버그를 발생시킵니다.

**발생 원인**

공유 변수를 여러 스레드가 동시에 읽고 쓸 때 발생합니다. 예를 들어, 두 스레드가 카운터를 동시에 증가시키면 증가 연산이 읽기-수정-쓰기로 나뉘어 중간에 인터럽트될 수 있습니다. 한 스레드가 읽은 값을 다른 스레드도 읽고, 각각 증가시켜 쓰면 하나의 증가만 반영됩니다. 결과적으로 카운터가 예상보다 작은 값을 가집니다.

**구체적인 예시**

은행 계좌에서 두 거래가 동시에 발생하는 경우를 생각해봅시다. 거래 A와 B가 모두 잔액 1000원을 읽습니다. A는 100원을 더해 1100원으로 쓰고, B는 200원을 더해 1200원으로 씁니다. 최종 잔액은 1300원이 아니라 나중에 쓴 1200원이 됩니다. 먼저 완료된 거래가 손실되는 lost update 문제가 발생합니다.

**재현의 어려움**

Race Condition은 타이밍에 의존하므로 재현이 매우 어렵습니다. 테스트 환경에서는 발생하지 않다가 프로덕션에서 간헐적으로 나타납니다. 디버거를 사용하면 타이밍이 바뀌어 문제가 사라지는 하이젠버그라고 불립니다. 로그를 추가하면 실행 속도가 바뀌어 역시 재현되지 않을 수 있습니다.

**심각성**

데이터 손상, 보안 취약점, 시스템 크래시를 유발할 수 있습니다. 금융 시스템에서는 금전적 손실로 이어집니다. 멀티스레드 프로그램의 가장 흔하고 위험한 버그 유형입니다. 발견하기 어렵고 수정하기도 복잡합니다.

**해결 방법**

임계 영역을 뮤텍스나 세마포어로 보호합니다. 원자적 연산을 사용하여 읽기-수정-쓰기를 한 번에 수행합니다. 불변 객체를 사용하여 수정 자체를 방지합니다. 락 프리 알고리즘을 사용하여 CAS 연산으로 안전하게 업데이트합니다. 트랜잭션 메모리를 활용할 수도 있습니다.

**탐지 도구**

ThreadSanitizer, Helgrind, Intel Inspector 같은 도구가 Race Condition을 탐지할 수 있습니다. 정적 분석 도구는 코드를 분석하여 잠재적 Race Condition을 경고합니다. 동적 분석 도구는 실행 중 메모리 접근을 추적하여 문제를 찾습니다. 하지만 완벽하지 않으며, 설계 단계에서 예방하는 것이 최선입니다.

**실무 예방**

공유 상태를 최소화합니다. 필요한 경우에만 동기화를 사용합니다. 락의 범위를 최소화하여 성능과 안전성을 균형있게 유지합니다. 코드 리뷰와 테스트를 철저히 수행합니다. 동시성 문제를 이해하고 있는 개발자가 설계와 구현을 담당해야 합니다.

---

## 71. Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?

**기본 개념**

Thread Safe를 구현하는 방법은 락만 있는 것이 아닙니다. 락 프리 알고리즘, 불변성, 원자적 연산, 설계 패턴 등 다양한 접근 방법이 있으며, 상황에 따라 적절한 방법을 선택할 수 있습니다.

**원자적 연산**

CAS, FAA, TAS 같은 하드웨어 지원 원자적 명령어를 사용하면 락 없이 Thread Safe를 보장할 수 있습니다. 카운터 증가, 포인터 교체, 플래그 설정 등 단순한 연산은 원자적으로 수행 가능합니다. C++의 std::atomic이나 Java의 AtomicInteger가 이를 제공합니다. 락보다 빠르고 데드락 위험이 없지만, 복잡한 다단계 연산에는 부적합합니다.

**불변 객체**

객체를 생성 후 수정할 수 없게 만들면, 여러 스레드가 동시에 접근해도 안전합니다. 동기화가 전혀 필요 없어 성능이 우수합니다. Java의 String, Integer 같은 불변 클래스가 대표적입니다. 함수형 프로그래밍은 불변성을 기본으로 하여 동시성 문제를 원천 차단합니다. 상태 변경이 필요하면 새 객체를 생성하여 반환합니다.

**스레드 로컬 저장소**

각 스레드가 독립적인 데이터 복사본을 가지면 공유가 없으므로 Thread Safe합니다. 전역 변수처럼 접근하지만 실제로는 스레드별로 분리됩니다. 캐시, 버퍼, 난수 생성기 등 스레드별 상태를 관리할 때 유용합니다. C의 __thread, Java의 ThreadLocal, C++의 thread_local을 사용합니다.

**락 프리 자료구조**

CAS 연산을 활용하여 락 없이 Thread Safe한 자료구조를 구현할 수 있습니다. 락 프리 스택은 CAS로 헤드 포인터를 원자적으로 교체합니다. 락 프리 큐는 두 개의 포인터를 독립적으로 관리합니다. 락 경쟁이 없어 확장성이 뛰어나지만, 구현이 매우 복잡하고 ABA 문제 같은 함정이 있습니다.

**메시지 패싱**

공유 메모리 대신 메시지를 주고받으면 동기화 문제를 피할 수 있습니다. Go의 채널이나 Erlang의 액터 모델이 이 방식을 사용합니다. 각 스레드는 독립적인 상태를 가지고, 메시지를 통해서만 통신합니다. 동기화가 메시지 큐 내부에 캡슐화되어 사용자는 신경쓰지 않아도 됩니다.

**불변 데이터와 구조적 공유**

함수형 프로그래밍의 영구 자료구조는 수정 시 기존 구조를 최대한 재사용하면서 새 버전을 생성합니다. Clojure의 영구 벡터나 Scala의 불변 컬렉션이 대표적입니다. 여러 버전이 공존할 수 있어 동시성 제어가 간단합니다. 복사 비용을 최소화하여 성능도 우수합니다.

**소프트웨어 트랜잭셔널 메모리**

STM은 데이터베이스 트랜잭션처럼 메모리 연산을 원자적으로 수행합니다. 명시적인 락 없이 트랜잭션 블록 내에서 자유롭게 메모리를 읽고 씁니다. 충돌이 발생하면 자동으로 롤백하고 재시도합니다. Haskell의 STM이나 Clojure의 Ref가 이를 지원합니다. 아직 주류는 아니지만 유망한 접근입니다.

**실무 선택**

단순한 카운터는 원자적 연산을 사용합니다. 설정 데이터는 불변 객체로 관리합니다. 요청별 상태는 스레드 로컬 저장소를 활용합니다. 복잡한 자료구조는 락으로 보호하거나 검증된 락 프리 라이브러리를 사용합니다. 상황에 맞는 적절한 방법을 선택하여 안전성과 성능을 모두 확보해야 합니다.

---

## 72. Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.

**Thread Pool**

Thread Pool은 미리 생성된 스레드들의 집합으로, 작업을 효율적으로 처리하는 패턴입니다. 스레드 생성과 소멸 비용을 줄이고, 동시 실행 스레드 수를 제한하여 시스템 자원을 보호합니다. 작업 큐에 태스크를 넣으면, 유휴 스레드가 꺼내서 실행합니다. 작업 완료 후 스레드는 종료되지 않고 다음 작업을 대기합니다. 웹 서버, 데이터베이스, 비동기 처리 시스템에서 널리 사용됩니다.

**Thread Pool의 장점**

스레드 생성 비용을 초기화 시 한 번만 지불합니다. 재사용으로 메모리 할당과 컨텍스트 스위칭 오버헤드를 줄입니다. 동시 실행 스레드를 제한하여 시스템 과부하를 방지합니다. 작업 큐를 통해 부하를 평활화합니다. Java의 ExecutorService, Python의 ThreadPoolExecutor, C++의 thread pool 라이브러리가 제공됩니다.

**Thread Pool 설정**

풀 크기는 CPU 코어 수, 작업 유형, 시스템 자원을 고려하여 결정합니다. CPU 집약적 작업은 코어 수만큼, I/O 집약적 작업은 더 많은 스레드가 적합합니다. 고정 크기 풀, 가변 크기 풀, 캐시 풀 등 다양한 전략이 있습니다. 큐 크기와 거부 정책도 중요한 설정 요소입니다.

**Monitor**

Monitor는 상호 배제와 조건 동기화를 결합한 고수준 동기화 구조입니다. 객체에 대한 락과 조건 변수를 캡슐화하여 사용자가 쉽게 사용할 수 있게 합니다. 모니터에 진입하려면 락을 획득해야 하며, 한 번에 하나의 스레드만 모니터 내부에서 실행됩니다. 조건 변수를 사용하여 특정 조건이 만족될 때까지 대기하고, 신호를 받으면 깨어납니다.

**Monitor의 특징**

Java의 synchronized 메서드와 wait, notify가 모니터 개념을 구현합니다. 모든 객체가 내장 락과 조건 변수를 가집니다. Python의 Lock과 Condition도 유사한 기능을 제공합니다. 모니터는 락과 조건 변수를 자동으로 관리하여 프로그래머의 부담을 줄입니다. 생산자-소비자 문제, 독자-저자 문제 등을 간결하게 해결할 수 있습니다.

**Monitor의 동작**

스레드가 모니터 메서드를 호출하면 자동으로 락을 획득합니다. 조건이 만족되지 않으면 wait을 호출하여 락을 해제하고 대기합니다. 다른 스레드가 조건을 변경한 후 notify를 호출하면 대기 중인 스레드가 깨어납니다. 깨어난 스레드는 다시 락을 획득하고 실행을 재개합니다. 메서드가 종료되면 자동으로 락을 해제합니다.

**Fork-Join**

Fork-Join은 작업을 재귀적으로 분할하여 병렬로 처리하고 결과를 합치는 패턴입니다. 큰 문제를 작은 하위 문제로 나누고, 각각을 병렬로 해결한 후 결과를 결합합니다. 분할 정복 알고리즘을 멀티코어에서 효율적으로 실행하는 데 적합합니다. Work-stealing 알고리즘을 사용하여 유휴 스레드가 바쁜 스레드의 작업을 가져와 부하를 균형있게 분산합니다.

**Fork-Join의 구조**

ForkJoinPool이 워커 스레드를 관리합니다. ForkJoinTask는 fork로 하위 작업을 생성하고, join으로 결과를 기다립니다. RecursiveTask는 결과를 반환하는 작업이고, RecursiveAction은 결과가 없는 작업입니다. 각 워커는 자신의 작업 큐를 가지고, 큐가 비면 다른 워커의 큐에서 작업을 훔칩니다.

**Fork-Join의 활용**

병렬 정렬, 병렬 맵-리듀스, 이미지 처리, 과학 계산 등에 사용됩니다. Java 7의 ForkJoinPool과 Java 8의 parallel stream이 내부적으로 Fork-Join을 사용합니다. 재귀적 분할이 자연스러운 문제에 특히 효과적입니다. 작업 크기가 충분히 작아질 때까지 분할하고, 임계값 이하에서는 순차적으로 처리하여 오버헤드를 줄입니다.

**실무 선택**

독립적인 작업들을 처리하려면 Thread Pool을 사용합니다. 복잡한 동기화가 필요하면 Monitor 패턴을 적용합니다. 재귀적 분할 정복 문제는 Fork-Join이 적합합니다. 각 패턴은 서로 다른 문제에 최적화되어 있으므로, 요구사항을 분석하여 적절한 도구를 선택해야 합니다.
