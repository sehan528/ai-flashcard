{
  "name": "Kafka",
  "description": "Apache Kafka의 아키텍처, 메시징 시스템, 스트리밍 처리 등 핵심 개념",
  "cards": [
    {
      "question": "Kafka의 기본 아키텍처와 주요 컴포넌트(Producer, Broker, Consumer, Topic 등)에 대해 설명해주세요.",
      "answer": "Apache Kafka의 기본 아키텍처와 주요 컴포넌트에 대한 상세 설명입니다.\n\n**Kafka 아키텍처 개요**\n\n1. 분산 스트리밍 플랫폼\n   - 대용량 실시간 데이터 파이프라인 구축\n   - 높은 처리량과 낮은 지연시간\n   - 확장 가능하고 내결함성이 있는 시스템\n   - Pub-Sub 메시징과 스트리밍 처리 결합\n\n2. 핵심 설계 원칙\n   - 로그 기반 아키텍처: 메시지를 순차적 로그로 저장\n   - 분산 처리: 여러 브로커에 데이터 분산\n   - 영속성: 디스크에 메시지 저장하여 내구성 보장\n   - 확장성: 수평 확장으로 처리량 증가\n\n**주요 컴포넌트**\n\n1. Producer (생산자)\n   - 역할: 메시지를 Kafka로 전송하는 클라이언트\n   - 기능: Topic에 데이터를 publish\n   - 파티셔닝: 메시지를 어느 Partition에 보낼지 결정\n   - 배치 전송: 여러 메시지를 묶어 효율적으로 전송\n   - 압축: 네트워크 대역폭 절약\n   - 비동기/동기: 전송 방식 선택 가능\n\n2. Broker (브로커)\n   - 역할: Kafka 서버, 메시지 저장 및 관리\n   - 클러스터: 여러 브로커가 하나의 클러스터 구성\n   - 리더/팔로워: 각 Partition은 리더 브로커가 읽기/쓰기 담당\n   - 저장소: 디스크에 메시지를 순차적으로 저장\n   - 복제: 데이터 복제본을 다른 브로커에 유지\n\n3. Consumer (소비자)\n   - 역할: Kafka에서 메시지를 읽는 클라이언트\n   - Pull 모델: Consumer가 능동적으로 메시지 가져감\n   - Consumer Group: 여러 Consumer가 협력하여 병렬 처리\n   - Offset 관리: 어디까지 읽었는지 추적\n   - 재처리: Offset을 조정하여 과거 메시지 재소비 가능\n\n4. Topic (토픽)\n   - 역할: 메시지 카테고리 또는 피드 이름\n   - 논리적 채널: Producer와 Consumer 간 데이터 흐름의 단위\n   - 여러 Partition으로 구성\n   - 명명 규칙: 용도를 명확히 나타내는 이름 사용\n   - 설정: Retention, Replication 등 Topic 단위로 설정\n\n5. Partition (파티션)\n   - 역할: Topic의 물리적 분할 단위\n   - 순서 보장: 동일 Partition 내에서만 메시지 순서 보장\n   - 병렬 처리: 여러 Partition으로 처리량 증가\n   - 불변성: 한번 쓰여진 메시지는 변경 불가\n   - Key 기반 라우팅: 동일 Key는 같은 Partition으로 전송\n\n6. Offset (오프셋)\n   - 역할: Partition 내 메시지의 고유 순차 ID\n   - 순차 증가: 0부터 시작하여 1씩 증가\n   - Consumer 위치: 어디까지 읽었는지 추적\n   - Commit: Consumer가 처리 완료한 Offset 저장\n   - 영속성: 내부 Topic에 Offset 정보 저장\n\n**ZooKeeper (레거시 구성)**\n\n1. 역할\n   - 클러스터 메타데이터 관리\n   - 브로커 상태 추적\n   - Leader 선출 조정\n   - 설정 정보 저장\n\n2. KRaft 모드 (최신)\n   - ZooKeeper 의존성 제거\n   - Kafka 자체적으로 메타데이터 관리\n   - 더 단순한 아키텍처\n   - 확장성과 성능 향상\n\n**데이터 흐름**\n\n1. 메시지 전송 (Producer → Broker)\n   - Producer가 메시지 생성\n   - Topic과 Partition 결정\n   - Leader 브로커로 전송\n   - 디스크에 순차 기록\n   - Replica 브로커에 복제\n   - ACK 응답 (설정에 따라)\n\n2. 메시지 소비 (Broker → Consumer)\n   - Consumer가 Topic 구독\n   - Consumer Group에 Partition 할당\n   - Offset 위치부터 메시지 읽기\n   - 메시지 처리\n   - Offset Commit\n   - 다음 메시지 계속 읽기\n\n**클러스터 구성**\n\n1. 다중 브로커\n   - 고가용성: 브로커 장애 시에도 서비스 계속\n   - 부하 분산: 여러 브로커에 Partition 분산\n   - 확장성: 브로커 추가로 용량 증가\n   - 리밸런싱: 자동으로 부하 재분배\n\n2. Replication Factor\n   - 데이터 복제본 수 설정\n   - 3개가 일반적 (원본 + 복제본 2개)\n   - Leader와 Follower로 구성\n   - Leader 장애 시 Follower가 승격\n   - 내결함성 제공\n\n**주요 특징**\n\n1. 높은 처리량\n   - 순차 디스크 I/O로 빠른 쓰기\n   - Zero-copy로 빠른 읽기\n   - 배치 처리로 효율성 향상\n   - 압축으로 네트워크 절약\n\n2. 확장성\n   - 수평 확장: 브로커 추가\n   - Partition 증가: 병렬 처리 향상\n   - 선형적 성능 증가\n   - 페타바이트급 데이터 처리\n\n3. 내구성\n   - 디스크 영속화\n   - 복제를 통한 데이터 보호\n   - 설정 가능한 보존 기간\n   - 브로커 장애에도 데이터 보존\n\n4. 실시간 처리\n   - 낮은 지연시간 (수 밀리초)\n   - 스트림 처리 지원\n   - 이벤트 기반 아키텍처\n   - 실시간 분석 가능\n\n**사용 사례**\n\n1. 메시징 시스템\n   - 마이크로서비스 간 비동기 통신\n   - 이벤트 기반 아키텍처\n   - 시스템 디커플링\n\n2. 로그 수집\n   - 애플리케이션 로그 중앙 집중화\n   - 실시간 모니터링\n   - 로그 분석 파이프라인\n\n3. 스트림 처리\n   - 실시간 데이터 변환\n   - 이벤트 처리\n   - 복잡한 이벤트 처리 (CEP)\n\n4. 데이터 통합\n   - 이기종 시스템 연결\n   - CDC (Change Data Capture)\n   - ETL 파이프라인\n\n**모범 사례**\n\n1. Topic 설계\n   - 명확한 명명 규칙\n   - 적절한 Partition 수 (처리량 고려)\n   - 합리적인 Retention 설정\n   - 용도별 Topic 분리\n\n2. 성능 최적화\n   - Producer 배치 설정\n   - 압축 활용\n   - Consumer 병렬화\n   - 적절한 Replication Factor\n\n3. 운영 관리\n   - 모니터링 및 알림\n   - 용량 계획\n   - 정기 백업\n   - 보안 설정 (인증, 암호화)",
      "type": "essay",
      "tags": [
        "Kafka",
        "아키텍처",
        "Producer",
        "Consumer",
        "Broker"
      ],
      "id": "kafka-001",
      "createdAt": "2025-11-17T16:00:00.000001",
      "studyCount": 0
    },
    {
      "question": "Kafka Broker의 역할과 주요 기능은 무엇인가요?",
      "answer": "Kafka Broker의 역할과 주요 기능에 대한 상세 설명입니다.\n\n**Broker의 기본 역할**\n\n1. 메시지 저장소\n   - Producer로부터 메시지를 받아 디스크에 저장합니다\n   - Partition 단위로 순차적 로그 파일 형태로 저장\n   - 설정된 Retention 기간 동안 메시지 보관\n   - Consumer에게 메시지를 전달합니다\n\n2. 클러스터 구성원\n   - 여러 브로커가 하나의 클러스터를 형성합니다\n   - 각 브로커는 고유 ID를 가집니다\n   - 클러스터 내에서 역할을 분담합니다\n   - 브로커 간 통신으로 데이터 복제 및 조정\n\n3. 요청 처리\n   - Producer의 메시지 전송 요청 처리\n   - Consumer의 메시지 읽기 요청 처리\n   - 메타데이터 요청 응답\n   - 관리 명령 처리\n\n**주요 기능**\n\n1. 메시지 수신 및 저장\n   - Producer로부터 메시지 배치 수신\n   - Partition의 끝에 메시지 추가 (append-only)\n   - 순차 디스크 쓰기로 높은 성능\n   - 즉시 디스크 플러시 또는 OS 캐시 활용\n   - 압축된 메시지 그대로 저장 (압축 해제 없음)\n\n2. 메시지 제공\n   - Consumer의 Fetch 요청 처리\n   - 지정된 Offset부터 메시지 반환\n   - Zero-copy 전송으로 빠른 읽기\n   - 배치 단위로 메시지 전송\n   - Consumer가 따라잡을 때까지 대기 가능\n\n3. Partition Leader 역할\n   - 각 Partition은 하나의 Leader 브로커를 가집니다\n   - Leader만 읽기/쓰기 요청을 처리합니다\n   - Producer와 Consumer는 Leader와만 통신\n   - Leader는 Follower에게 데이터 복제\n   - ISR (In-Sync Replicas) 관리\n\n4. Partition Follower 역할\n   - Leader의 데이터를 복제합니다\n   - Leader와 동기화 상태 유지\n   - Leader 장애 시 새 Leader로 승격 가능\n   - 읽기 요청을 처리하지 않음 (기본 동작)\n   - Fetch 요청으로 Leader에서 데이터 가져옴\n\n5. Replication 관리\n   - 설정된 Replication Factor만큼 복제본 유지\n   - 각 Partition의 복제본을 다른 브로커에 분산\n   - 동기화 상태 모니터링\n   - ISR 목록 관리 및 업데이트\n   - Leader 선출 참여\n\n**Controller 브로커**\n\n1. 클러스터 컨트롤러\n   - 클러스터 내 하나의 브로커가 Controller 역할\n   - Partition Leader 선출 담당\n   - Topic 생성/삭제 조정\n   - Partition 재할당 관리\n   - 브로커 상태 모니터링\n\n2. Controller 선출\n   - ZooKeeper 또는 KRaft를 통해 선출\n   - 현재 Controller 장애 시 자동 재선출\n   - 빠른 전환으로 클러스터 안정성 유지\n\n**디스크 관리**\n\n1. 로그 세그먼트\n   - 각 Partition은 여러 로그 세그먼트로 구성\n   - 세그먼트는 고정 크기 또는 시간 단위로 생성\n   - 오래된 세그먼트는 Retention 정책에 따라 삭제\n   - 압축 Topic의 경우 로그 압축 수행\n\n2. 인덱스 파일\n   - Offset 인덱스: Offset → 파일 위치 매핑\n   - Timestamp 인덱스: 시간 → Offset 매핑\n   - 빠른 메시지 조회를 위한 인덱스\n   - 메모리 맵 파일로 효율적 접근\n\n3. 디스크 I/O 최적화\n   - 순차 쓰기로 높은 처리량\n   - OS 페이지 캐시 활용\n   - Zero-copy 전송\n   - 배치 처리로 오버헤드 감소\n\n**메타데이터 관리**\n\n1. Topic 메타데이터\n   - Topic 설정 정보 저장\n   - Partition 수, Replication Factor\n   - Retention 정책\n   - 압축 설정\n\n2. Partition 메타데이터\n   - Leader 및 ISR 정보\n   - Replica 위치\n   - High Water Mark\n   - Log End Offset\n\n3. Consumer Group 메타데이터\n   - Group 구성원 정보\n   - Partition 할당 상태\n   - Offset Commit 정보\n   - Rebalance 상태\n\n**성능 특성**\n\n1. 높은 처리량\n   - 순차 I/O로 초당 수십만 메시지 처리\n   - 배치 처리로 네트워크 효율성\n   - Zero-copy로 CPU 사용 최소화\n   - 압축으로 디스크 및 네트워크 절약\n\n2. 낮은 지연시간\n   - 메모리 캐시 활용\n   - 빠른 디스크 쓰기 (순차)\n   - 효율적인 프로토콜\n   - 비동기 복제 옵션\n\n3. 확장성\n   - 수평 확장: 브로커 추가로 용량 증가\n   - Partition 증가로 병렬성 향상\n   - 선형적 성능 증가\n   - 수백 개 브로커까지 확장 가능\n\n**장애 처리**\n\n1. Leader 장애\n   - ISR 중에서 새 Leader 선출\n   - Controller가 선출 조정\n   - 수 초 내 자동 전환\n   - Consumer와 Producer는 자동으로 새 Leader 발견\n\n2. Follower 장애\n   - Leader가 ISR에서 제거\n   - 복구 후 다시 동기화\n   - ISR에 재추가\n   - 읽기/쓰기는 계속 정상 작동\n\n3. 디스크 장애\n   - 영향받은 Partition은 다른 Replica 사용\n   - 자동 Failover\n   - 디스크 복구 후 재동기화\n   - RAID 구성 권장\n\n**모니터링 지표**\n\n1. 메시지 처리량\n   - Messages In/Out per second\n   - Bytes In/Out per second\n   - Request per second\n   - 처리 속도 추세\n\n2. 리소스 사용\n   - CPU 사용률\n   - 메모리 사용량\n   - 디스크 사용률 및 I/O\n   - 네트워크 대역폭\n\n3. Replication 상태\n   - Under-replicated Partitions\n   - ISR 상태\n   - Replica Lag\n   - Leader 분포\n\n4. 성능 지표\n   - Request Latency\n   - Response Queue Size\n   - Purgatory Size\n   - Log Flush Rate\n\n**설정 최적화**\n\n1. 메모리 설정\n   - JVM 힙 크기 (일반적으로 6-8GB)\n   - OS 페이지 캐시 활용\n   - Socket 버퍼 크기\n   - Replica Fetcher 스레드 수\n\n2. 디스크 설정\n   - Log Segment 크기\n   - Log Flush 정책\n   - Retention 설정\n   - Compression 타입\n\n3. 네트워크 설정\n   - Socket Send/Receive 버퍼\n   - Max Request Size\n   - Connections 수 제한\n   - Idle Connection Timeout\n\n**운영 관리**\n\n1. 브로커 추가\n   - 클러스터에 새 브로커 조인\n   - Partition 재할당으로 부하 분산\n   - 리밸런싱으로 균등 분배\n   - 다운타임 없이 확장\n\n2. 브로커 제거\n   - Partition을 다른 브로커로 이동\n   - 안전하게 셧다운\n   - 데이터 손실 방지\n   - 계획된 유지보수\n\n3. 업그레이드\n   - 롤링 업그레이드 지원\n   - 한 번에 하나씩 브로커 업그레이드\n   - 서비스 중단 최소화\n   - 버전 호환성 확인\n\n**보안 기능**\n\n1. 인증\n   - SASL 인증 지원\n   - SSL/TLS 암호화\n   - Kerberos 통합\n   - ACL 기반 권한 제어\n\n2. 권한 관리\n   - Topic 레벨 ACL\n   - Consumer Group ACL\n   - 읽기/쓰기 권한 분리\n   - 관리 작업 권한 제어\n\n3. 암호화\n   - 전송 중 암호화 (SSL/TLS)\n   - 저장 시 암호화 (Disk Encryption)\n   - End-to-end 암호화 (애플리케이션 레벨)\n\n**모범 사례**\n\n1. 하드웨어 선택\n   - 빠른 디스크 (SSD 권장)\n   - 충분한 RAM (OS 캐시)\n   - 다중 디스크로 I/O 분산\n   - 충분한 네트워크 대역폭\n\n2. 클러스터 구성\n   - 최소 3개 브로커 (프로덕션)\n   - 홀수 개 브로커 권장\n   - 다중 랙/가용 영역 분산\n   - 충분한 여유 용량\n\n3. 모니터링\n   - 핵심 지표 지속 추적\n   - 알림 설정\n   - 로그 수집 및 분석\n   - 정기적인 성능 리뷰",
      "type": "essay",
      "tags": [
        "Kafka",
        "Broker",
        "Replication",
        "Leader",
        "성능"
      ],
      "id": "kafka-002",
      "createdAt": "2025-11-17T16:00:00.000002",
      "studyCount": 0
    },
    {
      "question": "Producer와 Consumer의 차이점 및 역할에 대해 설명해주세요.",
      "answer": "Kafka Producer와 Consumer의 차이점과 각각의 역할에 대한 상세 설명입니다.\n\n**Producer (생산자)**\n\n1. 기본 역할\n   - 메시지를 생성하여 Kafka Topic에 전송합니다\n   - 데이터의 소스 역할을 합니다\n   - Push 모델: 능동적으로 메시지를 브로커에 전송\n   - 애플리케이션 이벤트를 Kafka로 발행\n\n2. 주요 기능\n   - 메시지 직렬화 (Serialization)\n   - Partition 선택 (Partitioning)\n   - 배치 전송 (Batching)\n   - 압축 (Compression)\n   - 재시도 로직\n   - 비동기/동기 전송\n\n3. Partition 선택 전략\n   - Key 기반: 동일 Key는 같은 Partition으로\n   - Round-robin: Key 없을 때 순차적 분배\n   - Custom Partitioner: 사용자 정의 로직\n   - Sticky Partitioner: 배치 효율성 향상\n\n4. 전송 보장 수준 (acks)\n   - acks=0: Fire and forget, 응답 대기 안 함 (빠르지만 위험)\n   - acks=1: Leader만 응답, 기본 균형\n   - acks=all: 모든 ISR 응답, 가장 안전\n\n5. 성능 최적화\n   - Batching: 여러 메시지를 묶어 전송\n   - Compression: gzip, snappy, lz4, zstd\n   - Linger time: 배치가 찰 때까지 대기\n   - Buffer memory: 전송 대기 메시지 버퍼\n\n**Consumer (소비자)**\n\n1. 기본 역할\n   - Kafka Topic에서 메시지를 읽어옵니다\n   - 데이터의 싱크 역할을 합니다\n   - Pull 모델: 능동적으로 메시지를 가져감\n   - 메시지를 처리하고 비즈니스 로직 수행\n\n2. 주요 기능\n   - 메시지 역직렬화 (Deserialization)\n   - Offset 관리\n   - Consumer Group 참여\n   - Rebalancing 처리\n   - 메시지 처리 및 Commit\n\n3. Offset 관리\n   - 어디까지 읽었는지 추적\n   - Auto commit: 자동으로 주기적 커밋\n   - Manual commit: 처리 완료 후 명시적 커밋\n   - Offset 초기화: earliest, latest, 특정 위치\n\n4. Consumer Group\n   - 여러 Consumer가 그룹을 형성\n   - Partition을 그룹 내에서 분배\n   - 병렬 처리 및 부하 분산\n   - 고가용성: Consumer 장애 시 재할당\n\n5. 처리 방식\n   - At-most-once: 메시지 손실 가능, 중복 없음\n   - At-least-once: 중복 가능, 메시지 손실 없음\n   - Exactly-once: 중복도 손실도 없음 (Transactional API)\n\n**주요 차이점**\n\n1. 데이터 흐름 방향\n   - Producer: 애플리케이션 → Kafka (Write)\n   - Consumer: Kafka → 애플리케이션 (Read)\n\n2. 통신 모델\n   - Producer: Push (메시지를 밀어넣음)\n   - Consumer: Pull (메시지를 당겨옴)\n\n3. 성능 제어\n   - Producer: 전송 속도 제어 (배치, 압축)\n   - Consumer: 읽기 속도 제어 (Poll 간격, 배치 크기)\n\n4. 상태 관리\n   - Producer: 상태 없음 (Stateless)\n   - Consumer: Offset 상태 관리 (Stateful)\n\n5. 확장성\n   - Producer: 독립적으로 무한 확장 가능\n   - Consumer: Partition 수만큼 병렬화 가능\n\n**Producer 구현 패턴**\n\n1. Fire and Forget\n   - 메시지 전송 후 결과 무시\n   - 가장 빠르지만 손실 가능\n   - 로그, 메트릭 등 손실 허용 가능한 데이터\n\n2. Synchronous Send\n   - 전송 후 응답 대기\n   - 느리지만 확실한 전송 보장\n   - 중요한 트랜잭션 데이터\n\n3. Asynchronous Send with Callback\n   - 비동기 전송 + 결과 콜백\n   - 성능과 안정성 균형\n   - 에러 처리 가능\n\n4. Idempotent Producer\n   - 중복 메시지 자동 제거\n   - 정확히 한 번 전송 보장\n   - enable.idempotence=true\n\n**Consumer 구현 패턴**\n\n1. Auto Commit\n   - 자동으로 Offset 커밋\n   - 간단하지만 중복/손실 가능\n   - 멱등성 처리 필요\n\n2. Manual Commit (Sync)\n   - 처리 완료 후 명시적 커밋\n   - At-least-once 보장\n   - 성능 약간 느림\n\n3. Manual Commit (Async)\n   - 비동기로 커밋\n   - 성능 향상\n   - 신중한 에러 처리 필요\n\n4. Transactional Consumer\n   - Exactly-once 처리\n   - Producer와 함께 트랜잭션 사용\n   - 복잡하지만 정확성 보장\n\n**Producer 설정 예시 (개념)**\n\n주요 설정 파라미터:\n- bootstrap.servers: 브로커 주소\n- key.serializer: Key 직렬화 클래스\n- value.serializer: Value 직렬화 클래스\n- acks: 응답 대기 수준\n- retries: 재시도 횟수\n- batch.size: 배치 크기\n- linger.ms: 배치 대기 시간\n- compression.type: 압축 타입\n\n**Consumer 설정 예시 (개념)**\n\n주요 설정 파라미터:\n- bootstrap.servers: 브로커 주소\n- group.id: Consumer Group ID\n- key.deserializer: Key 역직렬화 클래스\n- value.deserializer: Value 역직렬화 클래스\n- enable.auto.commit: 자동 커밋 여부\n- auto.offset.reset: Offset 초기화 전략\n- max.poll.records: 한 번에 가져올 레코드 수\n\n**성능 고려사항**\n\n1. Producer 성능\n   - 배치 크기 증가로 처리량 향상\n   - 압축으로 네트워크 대역폭 절약\n   - acks 설정으로 지연시간 조절\n   - 비동기 전송으로 응답성 개선\n\n2. Consumer 성능\n   - 여러 Consumer로 병렬 처리\n   - Poll 간격 최적화\n   - 처리 로직 최적화\n   - Offset 커밋 전략 선택\n\n3. 병목 지점\n   - Producer: 직렬화, 네트워크\n   - Consumer: 역직렬화, 비즈니스 로직\n\n**에러 처리**\n\n1. Producer 에러\n   - Retriable Error: 자동 재시도 (네트워크 오류)\n   - Non-retriable Error: 즉시 실패 (직렬화 오류)\n   - Timeout: 재시도 횟수 초과\n   - 콜백에서 에러 처리\n\n2. Consumer 에러\n   - Rebalancing: 그룹 변경 시\n   - Deserialization Error: 메시지 형식 오류\n   - Processing Error: 비즈니스 로직 오류\n   - Dead Letter Queue 패턴\n\n**모범 사례**\n\n1. Producer 모범 사례\n   - Idempotent 활성화\n   - 적절한 acks 설정\n   - 재시도 설정\n   - 에러 모니터링\n   - 메시지 Key 설계\n\n2. Consumer 모범 사례\n   - Consumer Group 활용\n   - 적절한 Commit 전략\n   - 멱등성 처리 구현\n   - Graceful Shutdown\n   - 처리 시간 모니터링\n\n3. 공통 모범 사례\n   - 모니터링 및 알림\n   - 로깅\n   - 메트릭 수집\n   - 부하 테스트\n   - 장애 시나리오 대비\n\n**실무 활용 시나리오**\n\n1. 이벤트 발행 (Producer)\n   - 주문 생성 이벤트\n   - 사용자 행동 추적\n   - 시스템 로그 전송\n   - 센서 데이터 수집\n\n2. 이벤트 처리 (Consumer)\n   - 주문 처리\n   - 실시간 분석\n   - 알림 전송\n   - 데이터 동기화\n\n3. 스트림 처리\n   - Producer와 Consumer 모두 사용\n   - 데이터 변환 파이프라인\n   - 이벤트 기반 마이크로서비스\n   - CDC (Change Data Capture)",
      "type": "essay",
      "tags": [
        "Kafka",
        "Producer",
        "Consumer",
        "메시징"
      ],
      "id": "kafka-003",
      "createdAt": "2025-11-17T16:00:00.000003",
      "studyCount": 0
    },
    {
      "question": "Kafka에서 Partition과 Offset의 개념 및 활용 방법은 무엇인가요?",
      "answer": "Kafka의 Partition과 Offset 개념 및 활용 방법에 대한 상세 설명입니다.\n\n**Partition (파티션) 개념**\n\n1. 기본 정의\n   - Topic의 물리적 분할 단위입니다\n   - 각 Partition은 독립적인 순차 로그입니다\n   - 불변성: 한번 쓰여진 메시지는 변경 불가\n   - 순서 보장: 동일 Partition 내에서만 순서 보장\n\n2. 물리적 구조\n   - 각 Partition은 하나의 디렉토리\n   - 여러 로그 세그먼트 파일로 구성\n   - 세그먼트는 고정 크기로 생성\n   - 인덱스 파일로 빠른 검색 지원\n\n3. 분산 저장\n   - 각 Partition은 서로 다른 브로커에 배치\n   - 클러스터 전체에 걸쳐 분산\n   - 부하 분산 및 병렬 처리\n   - 확장성의 핵심 메커니즘\n\n**Partition의 역할**\n\n1. 병렬 처리\n   - 여러 Partition으로 처리량 증가\n   - 각 Partition은 독립적으로 처리\n   - Consumer를 Partition 수만큼 병렬화 가능\n   - 수평 확장의 기본 단위\n\n2. 순서 보장\n   - 동일 Partition 내 메시지는 순서 보장\n   - Key가 같은 메시지는 같은 Partition으로\n   - 전체 Topic 순서는 보장되지 않음\n   - 순서가 중요한 데이터는 동일 Partition으로\n\n3. 부하 분산\n   - Producer가 여러 Partition에 분산 전송\n   - Consumer Group이 Partition 분배\n   - 브로커 간 I/O 부하 분산\n   - 핫스팟 방지\n\n**Partition 개수 결정**\n\n1. 고려 사항\n   - 목표 처리량 (Producer + Consumer)\n   - Consumer 병렬 처리 수준\n   - 브로커 수 및 디스크 성능\n   - 관리 오버헤드\n\n2. 권장 사항\n   - 처리량 기반: (목표 처리량 / 단일 Partition 처리량)\n   - Consumer 기반: 병렬 처리할 Consumer 수\n   - 일반적으로 브로커당 2-4개 시작\n   - 너무 많으면 오버헤드 증가\n   - 최대 수천 개까지 가능하지만 신중히\n\n3. Partition 증가\n   - Topic 생성 후에도 증가 가능\n   - 감소는 불가능 (Topic 재생성 필요)\n   - 증가 시 기존 메시지 재분배 안 됨\n   - 새 메시지부터 새 Partition 사용\n\n**Partition 할당 전략**\n\n1. Producer Partitioning\n   - Key 기반 해싱: 동일 Key → 동일 Partition\n   - Round-robin: Key 없으면 순차 분배\n   - Custom Partitioner: 사용자 정의 로직\n   - Sticky Partitioner: 배치 효율성\n\n2. Consumer Partition 할당\n   - Range: 순차적 연속 할당\n   - Round-robin: 균등 분배\n   - Sticky: 리밸런싱 최소화\n   - Cooperative Sticky: 점진적 리밸런싱\n\n**Offset (오프셋) 개념**\n\n1. 기본 정의\n   - Partition 내 메시지의 고유 순차 ID\n   - 0부터 시작하여 1씩 증가\n   - 변경 불가능한 순차 번호\n   - Consumer의 읽기 위치를 나타냄\n\n2. Offset 유형\n   - Current Offset: Consumer가 다음에 읽을 위치\n   - Committed Offset: 처리 완료한 위치 (영속화)\n   - Log End Offset (LEO): 마지막으로 쓰여진 메시지 위치\n   - High Water Mark: 모든 ISR이 복제한 위치\n\n3. Offset 저장\n   - 내부 Topic (__consumer_offsets)에 저장\n   - Consumer Group별로 관리\n   - Partition별로 Offset 추적\n   - 주기적으로 자동 또는 수동 커밋\n\n**Offset 관리 전략**\n\n1. Auto Commit\n   - enable.auto.commit=true\n   - 자동으로 주기적 커밋 (기본 5초)\n   - 간단하지만 중복/손실 가능\n   - 멱등성 처리가 필요\n\n2. Manual Commit (Synchronous)\n   - 처리 완료 후 명시적으로 commitSync 호출\n   - At-least-once 보장\n   - 블로킹되어 성능 약간 저하\n   - 안전한 방법\n\n3. Manual Commit (Asynchronous)\n   - commitAsync로 비동기 커밋\n   - 성능 향상\n   - 콜백으로 에러 처리\n   - 재시도 로직 필요\n\n4. Offset 초기화\n   - auto.offset.reset 설정\n   - earliest: 처음부터 읽기\n   - latest: 최신부터 읽기 (기본값)\n   - none: Offset 없으면 에러\n\n**Offset 활용**\n\n1. 재처리 (Reprocessing)\n   - 특정 Offset으로 되돌리기\n   - 과거 데이터 재처리\n   - 장애 복구 시나리오\n   - seek 메서드로 위치 이동\n\n2. 메시지 건너뛰기\n   - 문제 있는 메시지 스킵\n   - Offset을 앞으로 이동\n   - Poison message 처리\n   - Dead Letter Queue로 이동\n\n3. 타임스탬프 기반 검색\n   - 특정 시간의 Offset 찾기\n   - offsetsForTimes 메서드\n   - 시간 기반 재처리\n   - 데이터 복구\n\n**Partition과 Offset 조합 활용**\n\n1. 순서 보장이 필요한 경우\n   - 순서가 중요한 데이터는 동일 Key 사용\n   - 동일 Partition으로 라우팅 보장\n   - Consumer는 순차적으로 처리\n   - 예: 사용자별 이벤트, 계좌 트랜잭션\n\n2. 병렬 처리 최대화\n   - 순서가 중요하지 않으면 Key 없이 전송\n   - 여러 Partition에 분산\n   - 여러 Consumer로 병렬 소비\n   - 처리량 극대화\n\n3. 부분 재처리\n   - 특정 Partition만 재처리\n   - 해당 Partition의 Offset 조정\n   - 다른 Partition은 계속 진행\n   - 세밀한 제어 가능\n\n**성능 최적화**\n\n1. Partition 수 최적화\n   - 처리량 요구사항 기반\n   - 너무 적으면 병렬성 제한\n   - 너무 많으면 오버헤드 증가\n   - 모니터링 후 조정\n\n2. Partition 균등 분배\n   - Key 설계로 균등 분배\n   - 핫 Partition 방지\n   - 브로커 간 균형\n   - Leader 분산\n\n3. Offset Commit 최적화\n   - Commit 빈도 조정\n   - 배치 처리 후 한 번에 커밋\n   - 비동기 커밋으로 성능 향상\n   - 중복 처리 최소화\n\n**모니터링**\n\n1. Partition 메트릭\n   - Partition별 메시지 수\n   - Partition별 크기\n   - Leader 분포\n   - Under-replicated Partitions\n\n2. Offset 메트릭\n   - Consumer Lag: Committed Offset과 LEO 차이\n   - Lag이 크면 처리 지연\n   - Lag 증가 추세 모니터링\n   - 알림 설정\n\n3. 성능 지표\n   - Partition별 처리량\n   - Commit 빈도 및 지연\n   - Rebalance 빈도\n   - 처리 시간\n\n**문제 해결**\n\n1. Consumer Lag 증가\n   - Consumer 수 증가 (Partition 수 이하)\n   - 처리 로직 최적화\n   - Partition 수 증가 고려\n   - 배치 크기 조정\n\n2. 불균등 분배\n   - Key 설계 재검토\n   - Custom Partitioner 구현\n   - Partition 재분배\n   - 핫 Key 분산\n\n3. Offset Commit 실패\n   - 재시도 로직 추가\n   - Timeout 설정 조정\n   - 네트워크 안정성 확인\n   - 브로커 상태 점검\n\n**모범 사례**\n\n1. Partition 설계\n   - 명확한 Key 설계\n   - 적절한 Partition 수 선택\n   - 확장 가능하게 설계\n   - 순서 요구사항 고려\n\n2. Offset 관리\n   - At-least-once를 기본으로\n   - 멱등성 처리 구현\n   - 정기적 Lag 모니터링\n   - Offset 백업 (재처리 대비)\n\n3. 운영\n   - Partition 증가는 신중히\n   - 정기적 성능 리뷰\n   - 용량 계획\n   - 장애 시나리오 대비",
      "type": "essay",
      "tags": [
        "Kafka",
        "Partition",
        "Offset",
        "병렬처리"
      ],
      "id": "kafka-004",
      "createdAt": "2025-11-17T16:00:00.000004",
      "studyCount": 0
    }
  ]
}