{
  "name": "Elasticsearch",
  "description": "Elasticsearch 검색 엔진의 아키텍처, 쿼리, 성능 최적화 등 핵심 개념",
  "cards": [
    {
      "question": "Elasticsearch의 기본 아키텍처와 주요 컴포넌트(Cluster, Node, Index, Document 등)에 대해 설명해주세요.",
      "answer": "Elasticsearch는 분산 검색 및 분석 엔진으로, 계층적 아키텍처를 가지고 있습니다.\n\n**주요 컴포넌트:**\n\n**1. Cluster (클러스터)**\n- 하나 이상의 노드로 구성된 전체 시스템\n- 고유한 이름으로 식별됩니다 (기본: elasticsearch)\n- 데이터를 저장하고 모든 노드에서 검색 및 인덱싱 기능을 제공\n- 여러 노드가 클러스터명을 공유하면 자동으로 클러스터를 형성\n\n**2. Node (노드)**\n- 클러스터의 일부인 단일 서버 인스턴스\n- 데이터를 저장하고 클러스터의 인덱싱 및 검색 기능에 참여\n- 고유한 UUID로 식별됩니다\n- 노드 유형:\n  - Master Node: 클러스터 관리 (인덱스 생성/삭제, 노드 추적)\n  - Data Node: 데이터 저장 및 CRUD, 검색, 집계 수행\n  - Ingest Node: 데이터 전처리 파이프라인 실행\n  - Coordinating Node: 요청 라우팅 전담\n\n**3. Index (인덱스)**\n- 유사한 특성을 가진 문서들의 논리적 집합\n- RDB의 데이터베이스 또는 테이블과 유사\n- 고유한 이름으로 식별 (소문자 필수)\n- 설정(Settings)과 매핑(Mapping)을 가짐\n- 여러 샤드로 분산 저장됩니다\n\n**4. Document (도큐먼트)**\n- 인덱싱할 수 있는 기본 정보 단위\n- JSON 형식으로 표현\n- RDB의 Row(행)와 유사\n- 고유한 ID를 가짐 (자동 생성 또는 수동 지정)\n- 필드(Field)로 구성: Key-Value 쌍\n\n**5. Shard (샤드)**\n- 인덱스를 여러 조각으로 나눈 것\n- 수평적 확장과 병렬 처리를 가능하게 함\n- Primary Shard: 원본 데이터\n- Replica Shard: Primary의 복제본 (고가용성, 읽기 성능 향상)\n\n**6. Type (타입) - Deprecated**\n- ES 7.x부터 제거됨\n- 이전에는 인덱스 내 문서 카테고리를 구분했으나, 현재는 단일 타입만 사용\n\n**아키텍처 계층 구조:**\nCluster → Node → Index → Shard → Document → Field\n\n**데이터 흐름:**\n1. 클라이언트가 노드에 요청\n2. Coordinating Node가 요청을 받아 적절한 샤드로 라우팅\n3. Data Node의 샤드가 데이터 처리\n4. 결과를 Coordinating Node에 반환\n5. Coordinating Node가 결과를 집계하여 클라이언트에 응답\n\n**특징:**\n- **분산 시스템**: 수평 확장 가능\n- **고가용성**: 노드 장애 시 자동 복구\n- **Near Real-time**: 거의 실시간 검색 (1초 refresh interval)\n- **스키마리스**: 동적 매핑 지원 (자동 타입 감지)\n\nElasticsearch는 이러한 컴포넌트들이 유기적으로 결합되어 대규모 데이터에 대한 빠른 검색과 분석을 제공합니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "아키텍처",
        "검색엔진"
      ],
      "id": "elasticsearch-001",
      "createdAt": "2025-11-17T16:00:00.000001",
      "studyCount": 0
    },
    {
      "question": "Elasticsearch에서 인덱스와 도큐먼트의 개념과 관계는 무엇인가요?",
      "answer": "Elasticsearch에서 인덱스와 도큐먼트는 데이터 저장과 조직화의 핵심 개념입니다.\n\n**Index (인덱스):**\n\n**정의:**\n- 유사한 특성을 가진 도큐먼트들의 논리적 집합\n- 데이터를 저장하고 검색하는 기본 단위\n\n**특징:**\n- 고유한 이름 (소문자, 특수문자 제한)\n- Settings: 샤드 수, 복제본 수, 분석기 등 설정\n- Mapping: 필드 타입과 속성 정의 (스키마)\n- 여러 샤드로 물리적으로 분산 저장\n\n**RDB 비교:**\n- Database 또는 Table에 해당\n- 하지만 조인 기능은 제한적\n\n---\n\n**Document (도큐먼트):**\n\n**정의:**\n- 인덱싱할 수 있는 기본 정보 단위\n- JSON 형식의 데이터 구조\n\n**특징:**\n- 고유한 _id 필드 (자동 생성 또는 수동 지정)\n- 여러 필드(Field)로 구성\n- 중첩 구조 지원 (객체, 배열)\n- 불변(Immutable): 수정 시 새 버전 생성\n\n**메타데이터:**\n- _index: 도큐먼트가 속한 인덱스\n- _id: 도큐먼트 고유 식별자\n- _source: 원본 JSON 데이터\n- _version: 버전 번호 (낙관적 동시성 제어)\n- _score: 검색 시 관련성 점수\n\n**RDB 비교:**\n- Row(행)에 해당\n- Column은 Field에 해당\n\n---\n\n**인덱스와 도큐먼트의 관계:**\n\n**1. 1:N 관계**\n- 하나의 인덱스는 여러 도큐먼트를 포함\n- 각 도큐먼트는 정확히 하나의 인덱스에 속함\n\n**2. 매핑을 통한 스키마 정의**\n- 인덱스의 Mapping이 도큐먼트의 구조를 정의\n- 필드 타입: text, keyword, integer, date, boolean, object 등\n- 동적 매핑: 새 필드 자동 감지 및 타입 추론\n- 명시적 매핑: 사전에 스키마 정의 (권장)\n\n**3. 샤딩을 통한 분산**\n- 도큐먼트는 _id의 해시값을 기반으로 특정 샤드에 할당\n- 공식: shard = hash(_id) % number_of_primary_shards\n- 인덱스의 Primary Shard 수는 생성 후 변경 불가\n\n**4. 라우팅**\n- 기본: _id 기반 자동 라우팅\n- 커스텀: routing 파라미터로 특정 샤드 지정 가능\n- 같은 routing 값을 가진 도큐먼트는 같은 샤드에 저장\n\n---\n\n**인덱싱 과정:**\n\n1. 클라이언트가 도큐먼트를 인덱스에 추가 요청\n2. Coordinating Node가 요청 수신\n3. _id 해시를 통해 대상 Primary Shard 결정\n4. Primary Shard에 도큐먼트 저장\n5. Replica Shard에 동기적으로 복제\n6. 성공 응답 반환\n7. Refresh (기본 1초 간격)로 검색 가능하게 됨\n\n---\n\n**검색 과정:**\n\n1. 클라이언트가 검색 쿼리 전송\n2. Coordinating Node가 모든 샤드에 쿼리 브로드캐스트\n3. 각 샤드가 로컬에서 검색 수행\n4. 결과를 Coordinating Node에 반환\n5. Coordinating Node가 결과 병합 및 정렬\n6. 최종 결과를 클라이언트에 반환\n\n---\n\n**인덱스 설계 원칙:**\n\n**1. 인덱스 분리 기준**\n- 데이터 타입이 다르면 별도 인덱스\n- 검색 패턴이 다르면 분리\n- 시간 기반 데이터는 날짜별 인덱스 (logs-2025-01-01)\n\n**2. 도큐먼트 크기**\n- 너무 크면 성능 저하 (권장: 수십 KB 이하)\n- 중첩 객체는 적당히 사용\n\n**3. 필드 설계**\n- 검색용: text (분석됨)\n- 정확한 매칭/정렬/집계용: keyword (분석 안 됨)\n- multi-field로 같은 데이터를 text와 keyword 모두 저장 가능\n\n---\n\n**실제 예시:**\n\n**인덱스: \"products\"**\n- Settings: 5 primary shards, 1 replica\n- Mapping: name(text), category(keyword), price(float), created_at(date)\n\n**도큐먼트들:**\n- { \"_id\": \"1\", \"name\": \"Laptop\", \"category\": \"Electronics\", \"price\": 999.99 }\n- { \"_id\": \"2\", \"name\": \"Mouse\", \"category\": \"Electronics\", \"price\": 29.99 }\n\n인덱스는 도큐먼트를 조직화하고 관리하는 컨테이너이며, 도큐먼트는 실제 저장되는 데이터입니다. 두 개념은 Elasticsearch의 데이터 모델의 핵심을 이룹니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "인덱스",
        "도큐먼트"
      ],
      "id": "elasticsearch-002",
      "createdAt": "2025-11-17T16:00:00.000002",
      "studyCount": 0
    },
    {
      "question": "Shard와 Replica의 역할 및 차이점은 무엇인가요?",
      "answer": "Elasticsearch의 샤드(Shard)와 복제본(Replica)은 분산 시스템의 확장성과 고가용성을 제공하는 핵심 메커니즘입니다.\n\n---\n\n**Shard (샤드):**\n\n**정의:**\n- 인덱스 데이터를 여러 조각으로 나눈 것\n- 각 샤드는 독립적인 Lucene 인덱스\n\n**종류:**\n\n**1. Primary Shard (주 샤드)**\n- 원본 데이터를 저장하는 샤드\n- 인덱스 생성 시 개수를 지정 (기본: 1개)\n- **생성 후 개수 변경 불가** (reindex 필요)\n- 모든 쓰기 작업은 Primary Shard에서 먼저 수행\n\n**2. Replica Shard (복제 샤드)**\n- Primary Shard의 복제본\n- 읽기 작업에도 참여하여 성능 향상\n- 동적으로 개수 조정 가능\n\n**주요 역할:**\n\n**1. 수평 확장 (Horizontal Scaling)**\n- 데이터를 여러 노드에 분산하여 저장 용량 확장\n- 대용량 인덱스를 관리 가능\n\n**2. 병렬 처리**\n- 여러 샤드에서 동시에 쿼리 실행\n- 검색 및 인덱싱 성능 향상\n\n**3. 부하 분산**\n- 요청을 여러 샤드에 분산\n- 단일 노드의 부하 감소\n\n**샤드 할당:**\n- 도큐먼트는 _id의 해시값으로 샤드 결정\n- shard_num = hash(_id) % number_of_primary_shards\n- 같은 샤드에 관련 데이터를 모으려면 routing 사용\n\n---\n\n**Replica (복제본):**\n\n**정의:**\n- Primary Shard의 완전한 복사본\n- 다른 노드에 저장되어 고가용성 제공\n\n**주요 역할:**\n\n**1. 고가용성 (High Availability)**\n- 노드 장애 시 데이터 손실 방지\n- Primary Shard 실패 시 Replica가 Primary로 승격\n- 자동 장애 복구 (Failover)\n\n**2. 읽기 성능 향상**\n- 검색 요청을 Primary와 Replica에 분산\n- 읽기 처리량 증가\n- 특히 읽기 집약적 워크로드에 유리\n\n**3. 데이터 중복성**\n- 여러 노드에 데이터 복제\n- 물리적 장애로부터 보호\n\n**Replica 개수:**\n- 동적으로 변경 가능\n- 기본값: 1 (Primary 1개 + Replica 1개 = 총 2벌)\n- 0으로 설정 가능 (개발 환경, 단일 노드)\n\n---\n\n**Primary Shard vs Replica Shard:**\n\n| 특징 | Primary Shard | Replica Shard |\n|------|--------------|---------------|\n| 목적 | 데이터 저장 및 분산 | 고가용성 및 성능 |\n| 개수 변경 | 불가 (reindex 필요) | 가능 |\n| 쓰기 작업 | 먼저 수행됨 | 동기적으로 복제됨 |\n| 읽기 작업 | 참여 | 참여 |\n| 배치 | 어느 노드에나 | Primary와 다른 노드 |\n| 승격 | - | Primary 실패 시 승격 가능 |\n\n---\n\n**샤드와 복제본의 관계:**\n\n**1. 복제 구조**\n- 1 Primary Shard → N Replica Shards\n- Replica는 항상 Primary와 다른 노드에 배치\n\n**2. 동기화**\n- Primary에 쓰기 발생 → Replica에 동기적 복제\n- 모든 Replica에 복제 완료 후 성공 응답\n\n**3. 읽기 부하 분산**\n- 검색 요청은 Primary 또는 Replica 중 하나에 라우팅\n- 라운드 로빈 또는 응답 시간 기반 선택\n\n---\n\n**실제 예시:**\n\n**설정:**\n- Primary Shards: 3\n- Replicas: 1 (각 Primary마다 1개의 Replica)\n- 총 샤드 수: 3 Primary + 3 Replica = 6개\n\n**3 노드 클러스터에서의 배치:**\n- Node 1: P0, R1, R2\n- Node 2: P1, R0, R2\n- Node 3: P2, R0, R1\n\n(P = Primary, R = Replica, 숫자 = 샤드 번호)\n\n**Node 2 장애 시:**\n- P1이 사라짐 → R1 (Node 1 또는 3에 있음)이 Primary로 승격\n- 클러스터는 계속 작동\n- 자동으로 새 Replica 생성 시도 (Node 복구 또는 새 Node 추가 시)\n\n---\n\n**샤드 개수 결정 가이드:**\n\n**Primary Shard 개수:**\n- 너무 적으면: 노드 추가 시 활용 불가\n- 너무 많으면: 오버헤드 증가, 메모리 낭비\n- 권장: 샤드 크기 10-50GB\n- 공식: (예상 데이터 크기 / 샤드 크기) ≈ Primary Shard 수\n\n**Replica 개수:**\n- 최소 1개 권장 (고가용성)\n- 읽기 성능이 중요하면 2개 이상\n- 비용과 성능의 균형 고려\n\n**예시:**\n- 100GB 데이터, 샤드당 20GB → 5 Primary Shards\n- 고가용성 필요 → Replica 1\n- 높은 읽기 처리량 필요 → Replica 2\n\n---\n\n**오버샤딩 (Over-Sharding) 문제:**\n\n너무 많은 샤드는 역효과:\n- 각 샤드는 메모리와 파일 디스크립터 소비\n- 클러스터 상태 관리 복잡도 증가\n- 검색 성능 저하 (너무 많은 샤드 조회)\n\n**권장:**\n- 노드당 샤드 수: 1000개 이하\n- 샤드당 크기: 10-50GB\n\n---\n\n**성능 최적화 팁:**\n\n**1. 읽기 집약적 워크로드**\n- Replica 수를 늘려 읽기 처리량 증가\n- 검색 요청이 여러 Replica에 분산됨\n\n**2. 쓰기 집약적 워크로드**\n- Replica 수를 줄여 복제 오버헤드 감소\n- 벌크 인덱싱 시 Replica를 0으로 설정 후 복원\n\n**3. 대용량 인덱스**\n- 시간 기반 인덱스 사용 (일별, 월별)\n- Index Lifecycle Management (ILM) 적용\n\nShard와 Replica는 Elasticsearch의 분산 특성과 고가용성의 기반이며, 적절한 설정이 성능과 안정성에 큰 영향을 미칩니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "샤드",
        "복제본",
        "분산시스템"
      ],
      "id": "elasticsearch-003",
      "createdAt": "2025-11-17T16:00:00.000003",
      "studyCount": 0
    },
    {
      "question": "Elasticsearch에서 클러스터와 노드 간의 관계와 역할에 대해 설명해주세요.",
      "answer": "Elasticsearch에서 클러스터와 노드는 분산 시스템의 핵심 구성 요소이며, 서로 밀접하게 연관되어 작동합니다.\n\n---\n\n**Cluster (클러스터):**\n\n**정의:**\n- 하나 이상의 노드가 모여 형성한 논리적 그룹\n- 전체 데이터를 보유하고 모든 노드에서 통합 인덱싱 및 검색 기능 제공\n\n**특징:**\n- **고유한 이름**: 클러스터 식별자 (기본: \"elasticsearch\")\n- **자동 디스커버리**: 같은 네트워크의 동일 클러스터명 노드 자동 결합\n- **단일 진입점**: 어느 노드로든 요청 가능\n- **통합 관리**: 모든 인덱스와 데이터를 통합 관리\n\n**역할:**\n- 전체 시스템의 건강 상태 모니터링\n- 메타데이터 관리 (인덱스, 매핑, 설정)\n- 클러스터 수준 설정 및 정책 적용\n\n**클러스터 상태 (Health):**\n- **Green**: 모든 Primary와 Replica 샤드 활성\n- **Yellow**: 모든 Primary 활성, 일부 Replica 미할당\n- **Red**: 일부 Primary 샤드 미할당 (데이터 손실 가능)\n\n---\n\n**Node (노드):**\n\n**정의:**\n- 클러스터의 일부인 단일 Elasticsearch 서버 인스턴스\n- 데이터를 저장하고 클러스터의 인덱싱 및 검색에 참여\n\n**특징:**\n- **고유 식별자**: UUID로 자동 생성\n- **노드 이름**: 설정 가능 (기본: 랜덤 생성)\n- **역할 지정**: 여러 역할 동시 수행 가능\n- **동적 추가/제거**: 클러스터에 노드 추가/제거 시 자동 재조정\n\n---\n\n**노드 유형 (Node Roles):**\n\n**1. Master-Eligible Node (마스터 후보 노드)**\n\n**역할:**\n- 클러스터 메타데이터 관리\n- 인덱스 생성/삭제\n- 노드 추가/제거 추적\n- 샤드 할당 결정\n\n**특징:**\n- 여러 노드가 master-eligible 가능\n- 그 중 하나가 Active Master로 선출\n- Master 장애 시 새로운 Master 자동 선출\n\n**설정:**\n- node.roles: [master]\n\n**2. Data Node (데이터 노드)**\n\n**역할:**\n- 샤드 저장\n- CRUD, 검색, 집계 작업 수행\n- 대부분의 리소스 소비 (CPU, 메모리, I/O)\n\n**세부 역할:**\n- **Data Content Node**: 일반 콘텐츠\n- **Data Hot Node**: 최신 데이터 (빈번한 쓰기/읽기)\n- **Data Warm Node**: 자주 접근하지 않는 데이터\n- **Data Cold Node**: 거의 접근하지 않는 데이터\n- **Data Frozen Node**: 아카이브 데이터\n\n**설정:**\n- node.roles: [data]\n\n**3. Ingest Node (수집 노드)**\n\n**역할:**\n- 인덱싱 전 문서 전처리\n- 파이프라인 실행 (필터링, 변환, 강화)\n- ETL 작업 수행\n\n**사용 사례:**\n- 로그 파싱\n- 필드 추가/제거/변환\n- IP 위치 정보 추가\n- 날짜 형식 변환\n\n**설정:**\n- node.roles: [ingest]\n\n**4. Coordinating Node (코디네이팅 노드)**\n\n**역할:**\n- 클라이언트 요청 수신\n- 요청을 적절한 데이터 노드로 라우팅\n- 검색 결과 집계 및 반환\n- 로드 밸런서 역할\n\n**특징:**\n- 모든 노드가 기본적으로 coordinating 역할 수행\n- 전용 coordinating node: 다른 역할 없이 라우팅만 담당\n\n**설정:**\n- node.roles: [] (모든 역할 제거)\n\n**5. Machine Learning Node (ML 노드)**\n\n**역할:**\n- 머신러닝 작업 수행\n- 이상 탐지\n- 예측 분석\n\n**설정:**\n- node.roles: [ml]\n\n---\n\n**클러스터와 노드의 관계:**\n\n**1. 1:N 관계**\n- 하나의 클러스터는 여러 노드로 구성\n- 각 노드는 정확히 하나의 클러스터에 속함\n\n**2. 분산 협업**\n- 노드들이 협력하여 전체 데이터 관리\n- 샤드가 여러 노드에 분산\n- 어느 노드로든 동일한 데이터 접근 가능\n\n**3. 자동 관리**\n- 노드 추가 시 자동으로 샤드 재배치\n- 노드 제거 시 샤드를 다른 노드로 이동\n- Master 노드가 클러스터 상태 조율\n\n---\n\n**클러스터 운영 시나리오:**\n\n**시나리오 1: 단일 노드 클러스터**\n- 1개 노드 = 1개 클러스터\n- 개발 환경에 적합\n- 고가용성 없음 (Replica 할당 불가)\n\n**시나리오 2: 3 노드 클러스터 (일반 구성)**\n- 3개 노드 모두 master-eligible + data\n- Master 선출 시 Split-brain 방지 (과반수 투표)\n- 고가용성 확보\n\n**시나리오 3: 역할 분리 클러스터 (대규모)**\n- 3개 전용 Master 노드 (경량)\n- 10개 Data 노드 (대용량 스토리지)\n- 2개 Coordinating 노드 (로드 밸런싱)\n- 각 역할 최적화로 성능 향상\n\n---\n\n**노드 디스커버리 및 클러스터 형성:**\n\n**1. 디스커버리 과정**\n- 새 노드 시작\n- 구성된 seed hosts에 연결 시도\n- 같은 cluster.name 확인\n- 클러스터에 조인\n\n**2. Master 선출**\n- Master-eligible 노드들이 투표\n- 과반수 득표 시 Master로 선출\n- Zen Discovery (ES 7 이전) 또는 Voting Configuration (ES 7+)\n\n**3. Split-brain 방지**\n- 최소 master-eligible 노드: 3개 권장\n- 과반수 투표 메커니즘\n- discovery.seed_hosts 설정\n\n---\n\n**클러스터 크기 조정 (Scaling):**\n\n**수평 확장 (Scale Out):**\n- 노드 추가로 용량 및 성능 증가\n- 샤드 자동 재배치\n- 선형적 확장 가능\n\n**수직 확장 (Scale Up):**\n- 노드의 하드웨어 성능 향상\n- 제한적인 확장성\n\n**축소 (Scale Down):**\n- 노드 제거 시 샤드를 다른 노드로 이동\n- Graceful shutdown 권장\n\n---\n\n**Best Practices:**\n\n**1. 최소 3개의 Master-eligible 노드**\n- Split-brain 방지\n- 고가용성 확보\n\n**2. 전용 Master 노드 (대규모 클러스터)**\n- 클러스터 안정성 향상\n- 메타데이터 관리에만 집중\n\n**3. 데이터 노드 티어링 (Tiering)**\n- Hot-Warm-Cold 아키텍처\n- 비용 효율적 데이터 관리\n\n**4. 적절한 노드 수**\n- 너무 많으면: 관리 복잡도 증가\n- 너무 적으면: 장애 시 위험\n\n**5. 하드웨어 균등성**\n- 노드 간 성능 차이 최소화\n- 예측 가능한 성능\n\n클러스터는 전체 시스템의 논리적 단위이며, 노드는 실제 작업을 수행하는 물리적 단위입니다. 이들의 유기적 결합이 Elasticsearch의 분산 특성과 고가용성을 가능하게 합니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "클러스터",
        "노드",
        "분산시스템"
      ],
      "id": "elasticsearch-004",
      "createdAt": "2025-11-17T16:00:00.000004",
      "studyCount": 0
    },
    {
      "question": "Query DSL의 기본 구조와 사용 방법에 대해 설명해주세요.",
      "answer": "Query DSL (Domain Specific Language)은 Elasticsearch에서 검색 쿼리를 표현하기 위한 JSON 기반 언어입니다.\n\n**Query DSL의 특징:**\n\n**1. JSON 기반**\n- HTTP 요청 본문에 JSON 형식으로 쿼리 작성\n- 구조화되고 가독성이 높음\n- 프로그래밍 방식으로 동적 쿼리 생성 용이\n\n**2. 선언적 (Declarative)**\n- \"무엇을\" 원하는지 명시 (\"어떻게\"가 아님)\n- Elasticsearch가 최적화된 실행 계획 수립\n\n**3. 합성 가능 (Composable)**\n- 작은 쿼리를 조합하여 복잡한 쿼리 구성\n- 중첩 구조 지원\n\n---\n\n**쿼리의 두 가지 컨텍스트:**\n\n**1. Query Context (쿼리 컨텍스트)**\n- \"문서가 쿼리와 얼마나 잘 일치하는가?\"\n- 관련성 점수(_score) 계산\n- 전문 검색(Full-text search)에 사용\n- 느림 (스코어링 비용)\n\n**사용 쿼리:**\n- match, multi_match, query_string 등\n\n**2. Filter Context (필터 컨텍스트)**\n- \"문서가 쿼리와 일치하는가?\" (Yes/No)\n- 점수 계산 없음\n- 정확한 매칭, 범위 필터링에 사용\n- 빠름 (캐싱 가능)\n\n**사용 쿼리:**\n- term, range, exists, bool의 filter 절 등\n\n---\n\n**Query DSL 기본 구조:**\n\n**쿼리 구성:**\n- query: 메인 쿼리 정의\n- from/size: 페이지네이션\n- sort: 정렬\n- _source: 반환할 필드 지정\n- aggs: 집계\n- highlight: 하이라이트\n- script_fields: 스크립트 필드\n\n---\n\n**주요 쿼리 타입:**\n\n**1. Full-text Queries (전문 검색 쿼리)**\n\n**목적:** 텍스트 분석 후 검색\n\n**종류:**\n- **match**: 단일 필드 전문 검색\n- **multi_match**: 여러 필드에서 검색\n- **match_phrase**: 구문 검색 (순서 중요)\n- **query_string**: 고급 쿼리 문자열\n- **simple_query_string**: 간단한 쿼리 문자열\n\n**특징:**\n- 텍스트 분석 적용 (토큰화, 소문자화 등)\n- 관련성 점수 계산\n- text 타입 필드에 사용\n\n**2. Term-level Queries (용어 수준 쿼리)**\n\n**목적:** 정확한 값 매칭\n\n**종류:**\n- **term**: 정확한 값 일치\n- **terms**: 여러 값 중 하나 일치\n- **range**: 범위 검색\n- **exists**: 필드 존재 여부\n- **prefix**: 접두사 매칭\n- **wildcard**: 와일드카드 패턴\n- **regexp**: 정규 표현식\n\n**특징:**\n- 분석 없이 저장된 정확한 값과 비교\n- keyword 타입 필드에 사용\n- 필터 컨텍스트에 적합\n\n**3. Compound Queries (복합 쿼리)**\n\n**목적:** 여러 쿼리 조합\n\n**종류:**\n- **bool**: 논리 조합 (must, should, must_not, filter)\n- **boosting**: 특정 조건에 가중치 부여\n- **constant_score**: 일정한 점수 부여\n- **dis_max**: 여러 쿼리 중 최고 점수 사용\n- **function_score**: 커스텀 점수 계산\n\n**4. Nested & Join Queries**\n\n**종류:**\n- **nested**: 중첩 객체 검색\n- **has_child**: 자식 문서 조건\n- **has_parent**: 부모 문서 조건\n\n---\n\n**쿼리 실행 흐름:**\n\n**1. 쿼리 파싱**\n- JSON 쿼리를 Lucene 쿼리로 변환\n\n**2. 샤드 라우팅**\n- Coordinating Node가 쿼리를 모든 관련 샤드로 전송\n\n**3. 로컬 검색**\n- 각 샤드가 로컬에서 쿼리 실행\n- Top-N 결과 반환\n\n**4. 결과 병합**\n- Coordinating Node가 결과 집계 및 정렬\n- 최종 Top-N 선정\n\n**5. Fetch Phase**\n- 실제 문서 내용 가져오기\n- 하이라이트 적용\n\n**6. 응답 반환**\n- 클라이언트에게 결과 전송\n\n---\n\n**성능 최적화 팁:**\n\n**1. Filter Context 활용**\n- 점수가 필요 없는 조건은 filter 사용\n- 캐싱으로 성능 향상\n\n**2. Query 재사용**\n- 자주 사용하는 쿼리는 캐싱됨\n\n**3. 필요한 필드만 반환**\n- _source filtering으로 네트워크 비용 감소\n\n**4. 페이지네이션 최적화**\n- 깊은 페이지네이션은 search_after 사용\n- from + size는 10000 제한\n\n**5. 집계 최적화**\n- doc_values 활용\n- 필드 데이터 캐시 관리\n\n---\n\n**일반적인 사용 패턴:**\n\n**1. 단순 검색**\n- match 쿼리로 텍스트 검색\n\n**2. 필터링 + 검색**\n- bool 쿼리로 filter와 must 조합\n- 예: 카테고리 필터 + 키워드 검색\n\n**3. 범위 검색**\n- range 쿼리로 날짜/숫자 범위\n\n**4. 다중 조건**\n- bool 쿼리로 여러 조건 조합\n\n**5. 정확한 매칭**\n- term 쿼리로 ID, 상태 등 검색\n\n---\n\n**Best Practices:**\n\n**1. 적절한 쿼리 타입 선택**\n- 전문 검색: match\n- 정확한 매칭: term\n- 범위: range\n\n**2. 필드 타입 고려**\n- text: match 쿼리\n- keyword: term 쿼리\n\n**3. 복잡한 쿼리는 단계적 구성**\n- 작은 쿼리로 시작해 점진적으로 확장\n\n**4. Explain API 활용**\n- 점수 계산 과정 이해\n- 쿼리 튜닝\n\n**5. Profile API 사용**\n- 성능 병목 지점 파악\n\nQuery DSL은 Elasticsearch의 핵심 기능으로, 강력하고 유연한 검색을 가능하게 합니다. 적절한 쿼리 타입과 컨텍스트를 선택하는 것이 성능과 정확성의 열쇠입니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "Query DSL",
        "검색쿼리"
      ],
      "id": "elasticsearch-005",
      "createdAt": "2025-11-17T16:00:00.000005",
      "studyCount": 0
    },
    {
      "question": "Match 쿼리와 Term 쿼리의 차이점은 무엇인가요?",
      "answer": "Match 쿼리와 Term 쿼리는 Elasticsearch에서 가장 많이 사용되는 쿼리이지만, 동작 방식과 사용 목적이 완전히 다릅니다.\n\n---\n\n**Match Query (전문 검색 쿼리):**\n\n**특징:**\n\n**1. 텍스트 분석 적용**\n- 쿼리 문자열이 분석기(Analyzer)를 거침\n- 토큰화, 소문자 변환, 불용어 제거, 어간 추출 등\n- 인덱싱 시 적용된 분석기와 동일한 처리\n\n**2. 부분 일치 (Partial Match)**\n- 토큰 단위로 매칭\n- 여러 토큰이 있으면 OR 조건 (기본)\n- operator: \"and\"로 AND 조건 가능\n\n**3. 관련성 점수 계산**\n- Query Context에서 실행\n- TF-IDF 또는 BM25 알고리즘으로 스코어 계산\n- 결과가 점수순으로 정렬\n\n**4. 퍼지 매칭 지원**\n- fuzziness 옵션으로 오타 허용\n- 레벤슈타인 거리 기반\n\n**사용 사례:**\n- 사용자 검색 입력\n- 제목, 내용 등 텍스트 필드 검색\n- 전문 검색(Full-text search)\n- 자연어 쿼리\n\n**적용 필드 타입:**\n- **text** 타입 필드 (분석됨)\n\n**예시 시나리오:**\n- 쿼리: \"Quick Brown\"\n- 분석 후: [\"quick\", \"brown\"]\n- 매칭: \"quick\" 또는 \"brown\" 포함 문서\n- \"The quick fox\" → 매칭 (quick 포함)\n- \"Brown dog\" → 매칭 (brown 포함)\n- \"QUICK BROWN FOX\" → 매칭 (소문자 변환 후 매칭)\n\n---\n\n**Term Query (용어 수준 쿼리):**\n\n**특징:**\n\n**1. 분석 없음**\n- 쿼리 문자열이 그대로 사용됨\n- 인덱스에 저장된 정확한 값과 비교\n- 대소문자 구분\n\n**2. 정확한 일치 (Exact Match)**\n- 전체 값이 정확히 일치해야 함\n- 부분 일치 불가\n\n**3. 점수 계산 최소화**\n- Filter Context에서 주로 사용\n- 일치/불일치만 판단 (Yes/No)\n- 캐싱 가능\n\n**4. 빠른 성능**\n- 분석 오버헤드 없음\n- 역색인에서 직접 조회\n- 필터로 사용 시 캐시 활용\n\n**사용 사례:**\n- ID, 상태, 카테고리 등 정확한 값 검색\n- Enum 값 필터링\n- 태그, 키워드 매칭\n- 숫자, 날짜 정확한 매칭\n\n**적용 필드 타입:**\n- **keyword** 타입 필드 (분석 안 됨)\n- 숫자, 날짜, boolean 타입\n\n**예시 시나리오:**\n- 쿼리: \"Quick Brown\"\n- 분석 없음: \"Quick Brown\" 그대로\n- 매칭: \"Quick Brown\"과 정확히 일치하는 문서만\n- \"Quick Brown\" → 매칭\n- \"quick brown\" → 불일치 (소문자)\n- \"Quick\" → 불일치 (부분 일치 안 됨)\n\n---\n\n**핵심 차이점:**\n\n| 특성 | Match Query | Term Query |\n|------|------------|-----------|\n| 텍스트 분석 | O (Analyzer 적용) | X (원본 그대로) |\n| 매칭 방식 | 부분 일치 (토큰 단위) | 정확한 일치 (전체 값) |\n| 대소문자 | 구분 안 함 (분석기 설정 따름) | 구분함 |\n| 점수 계산 | O (관련성 점수) | X (1.0 또는 0) |\n| 컨텍스트 | Query Context | Filter Context 권장 |\n| 성능 | 상대적으로 느림 | 빠름 (캐싱 가능) |\n| 필드 타입 | text | keyword, 숫자, 날짜 |\n| 사용 목적 | 전문 검색 | 정확한 필터링 |\n\n---\n\n**실제 비교 예시:**\n\n**필드:**\n- title (text 타입): \"The Quick Brown Fox\"\n- status (keyword 타입): \"active\"\n\n**Match Query 동작:**\n- 쿼리: \"quick fox\"\n- 분석 → [\"quick\", \"fox\"]\n- 결과: title 필드에 \"quick\" 또는 \"fox\" 포함된 문서\n- 점수: 두 토큰 모두 포함 시 더 높은 점수\n\n**Term Query 동작:**\n- 쿼리: \"active\"\n- 분석 없음\n- 결과: status 필드가 정확히 \"active\"인 문서만\n- \"Active\" → 불일치\n\n---\n\n**잘못된 사용 예시:**\n\n**1. text 필드에 Term Query 사용**\n- text 필드는 인덱싱 시 분석되어 \"Quick Brown\" → [\"quick\", \"brown\"]으로 저장\n- Term 쿼리로 \"Quick Brown\" 검색 시 매칭 실패\n- 해결: Match Query 사용\n\n**2. keyword 필드에 Match Query 사용**\n- 불필요한 분석 수행\n- 예상치 못한 결과 발생 가능\n- 해결: Term Query 사용\n\n---\n\n**필드 타입 선택 가이드:**\n\n**text 타입 사용 시:**\n- 전문 검색이 필요한 필드\n- 예: 제목, 내용, 설명, 리뷰 등\n- Match Query 사용\n\n**keyword 타입 사용 시:**\n- 정확한 값 매칭이 필요한 필드\n- 예: ID, 상태, 카테고리, 태그, URL, 이메일 등\n- Term Query 사용\n\n**Multi-field 활용:**\n- 같은 필드를 text와 keyword 모두로 인덱싱\n- 예: name (text) + name.keyword (keyword)\n- 전문 검색과 정확한 정렬/집계 모두 지원\n\n---\n\n**성능 고려사항:**\n\n**Match Query:**\n- 분석 오버헤드\n- 점수 계산 비용\n- 캐싱 어려움\n- 필요할 때만 사용\n\n**Term Query:**\n- 빠른 실행\n- Filter Context에서 캐싱\n- 대량 필터링에 적합\n- bool 쿼리의 filter 절에 사용 권장\n\n---\n\n**조합 사용 예시:**\n\n**bool 쿼리로 조합:**\n- must: Match Query (전문 검색)\n- filter: Term Query (정확한 필터)\n\n**시나리오:**\n\"active 상태인 제품 중에서 'laptop' 키워드 검색\"\n- filter: status가 \"active\" (Term Query)\n- must: 제목에 \"laptop\" 포함 (Match Query)\n\n---\n\n**Best Practices:**\n\n**1. 필드 타입에 맞는 쿼리 사용**\n- text → Match\n- keyword → Term\n\n**2. Filter Context 활용**\n- Term Query는 bool 쿼리의 filter 절에 배치\n\n**3. Multi-field 전략**\n- 검색과 집계 모두 필요하면 multi-field 사용\n\n**4. 대소문자 문제**\n- Term Query 사용 시 대소문자 정확히 맞추기\n- 또는 keyword 필드에 normalizer 적용\n\n두 쿼리는 목적과 동작이 다르므로, 상황에 맞게 적절히 선택하는 것이 중요합니다. Match는 검색, Term은 필터링으로 기억하면 좋습니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "Query DSL",
        "Match",
        "Term"
      ],
      "id": "elasticsearch-006",
      "createdAt": "2025-11-17T16:00:00.000006",
      "studyCount": 0
    },
    {
      "question": "Range 쿼리의 활용 사례와 주의사항에 대해 설명해주세요.",
      "answer": "Range 쿼리는 Elasticsearch에서 범위 조건을 검색할 때 사용하는 Term-level 쿼리입니다.\n\n**Range Query 개요:**\n\n**정의:**\n- 숫자, 날짜, 문자열 필드의 값이 특정 범위 내에 있는 문서를 찾는 쿼리\n\n**특징:**\n- Filter Context에서 주로 사용\n- 점수 계산 없음 (필터로 사용 시)\n- 캐싱 가능\n- 효율적인 범위 검색\n\n---\n\n**Range 연산자:**\n\n**1. gte (Greater Than or Equal)**\n- 이상 (≥)\n- 지정한 값 포함\n\n**2. gt (Greater Than)**\n- 초과 (>)\n- 지정한 값 제외\n\n**3. lte (Less Than or Equal)**\n- 이하 (≤)\n- 지정한 값 포함\n\n**4. lt (Less Than)**\n- 미만 (<)\n- 지정한 값 제외\n\n**조합 사용:**\n- gte + lte: 닫힌 구간 [a, b]\n- gt + lt: 열린 구간 (a, b)\n- gte + lt: 반열린 구간 [a, b)\n\n---\n\n**활용 사례:**\n\n**1. 숫자 범위 검색**\n\n**가격 범위:**\n- 10000원 이상 50000원 이하 제품 검색\n- 연산자: gte: 10000, lte: 50000\n\n**나이 범위:**\n- 20세 이상 30세 미만 사용자\n- 연산자: gte: 20, lt: 30\n\n**점수 범위:**\n- 80점 초과 학생 조회\n- 연산자: gt: 80\n\n**2. 날짜 범위 검색**\n\n**최근 데이터:**\n- 최근 7일간 로그 조회\n- 연산자: gte: \"now-7d/d\", lte: \"now\"\n\n**특정 기간:**\n- 2025년 1월 데이터\n- 연산자: gte: \"2025-01-01\", lt: \"2025-02-01\"\n\n**미래 이벤트:**\n- 앞으로 예정된 이벤트\n- 연산자: gte: \"now\"\n\n**과거 데이터:**\n- 1년 이전 데이터 (아카이빙)\n- 연산자: lt: \"now-1y\"\n\n**3. 문자열 범위 (사전순)**\n\n**알파벳 범위:**\n- A-M으로 시작하는 이름\n- 연산자: gte: \"a\", lt: \"n\"\n\n**IP 주소 범위:**\n- 특정 IP 대역\n- 연산자: gte: \"192.168.1.0\", lte: \"192.168.1.255\"\n\n---\n\n**날짜 수학 (Date Math):**\n\n**상대적 날짜:**\n\n**now 기준:**\n- now: 현재 시각\n- now-1h: 1시간 전\n- now-1d: 1일 전\n- now-1M: 1개월 전\n- now-1y: 1년 전\n- now+1d: 1일 후\n\n**반올림 (Rounding):**\n- now/d: 오늘 00:00:00\n- now/M: 이번 달 1일 00:00:00\n- now/y: 올해 1월 1일 00:00:00\n- now-1d/d: 어제 00:00:00\n\n**조합:**\n- now-7d/d: 7일 전 00:00:00\n- now/d: 오늘 00:00:00\n\n**사용 예:**\n- \"오늘 하루 데이터\": gte: \"now/d\", lt: \"now/d+1d\"\n- \"이번 주 데이터\": gte: \"now/w\", lt: \"now/w+1w\"\n\n---\n\n**주의사항:**\n\n**1. 타임존 (Time Zone)**\n\n**문제:**\n- Elasticsearch는 기본적으로 UTC 시간 사용\n- 로컬 타임존과 불일치 가능\n\n**해결:**\n- time_zone 파라미터 사용\n- 예: time_zone: \"+09:00\" (한국 시간)\n\n**권장:**\n- 데이터를 UTC로 저장\n- 표시할 때만 로컬 타임존 적용\n\n**2. 날짜 형식 (Format)**\n\n**문제:**\n- 다양한 날짜 형식 존재\n- 파싱 오류 발생 가능\n\n**해결:**\n- format 파라미터로 명시\n- 예: format: \"yyyy-MM-dd\"\n\n**권장:**\n- ISO 8601 형식 사용 (2025-01-17T10:00:00Z)\n- 필드 매핑에서 format 지정\n\n**3. 성능 고려사항**\n\n**인덱스 크기:**\n- 범위가 넓을수록 많은 문서 스캔\n- 필터 조합으로 범위 좁히기\n\n**캐싱:**\n- Filter Context에서 사용하여 캐싱 활용\n- now는 캐싱되지 않음 (매번 다른 값)\n\n**해결:**\n- now 대신 절대 시간 사용 (캐싱 가능)\n- 반올림 사용 (now/h, now/d 등)\n\n**4. 경계값 처리**\n\n**문제:**\n- gte vs gt, lte vs lt 혼동\n- 경계값 포함 여부 불명확\n\n**해결:**\n- 요구사항에 맞는 연산자 정확히 선택\n- 주석으로 의도 명시\n\n**5. 널(Null) 처리**\n\n**문제:**\n- 필드가 없는 문서는 매칭되지 않음\n\n**해결:**\n- exists 쿼리와 조합\n- 또는 bool 쿼리의 should 절 활용\n\n**6. 문자열 범위의 한계**\n\n**문제:**\n- 사전순 정렬이 예상과 다를 수 있음\n- 예: \"10\" < \"2\" (문자열로 비교 시)\n\n**해결:**\n- 숫자는 숫자 타입 필드 사용\n- 필요시 keyword 타입에 normalizer 적용\n\n---\n\n**최적화 팁:**\n\n**1. Filter Context 사용**\n- bool 쿼리의 filter 절에 배치\n- 점수 계산 오버헤드 제거\n- 캐싱으로 성능 향상\n\n**2. 적절한 데이터 타입**\n- 숫자는 long, integer, float, double\n- 날짜는 date 타입\n- 범위 검색이 빈번한 필드는 doc_values 활성화 (기본)\n\n**3. 시간 기반 인덱스**\n- 날짜 범위 검색이 많은 경우\n- 인덱스를 날짜별로 분리 (예: logs-2025-01-17)\n- 필요한 인덱스만 검색\n\n**4. 범위 좁히기**\n- 다른 필터와 조합하여 범위 축소\n- 먼저 선택적 필터 적용\n\n---\n\n**일반적인 패턴:**\n\n**1. 최근 N일 데이터**\n- gte: \"now-7d/d\"\n- lte: \"now\"\n\n**2. 특정 월 데이터**\n- gte: \"2025-01-01\"\n- lt: \"2025-02-01\"\n\n**3. 오늘 데이터 (한국 시간)**\n- gte: \"now/d\"\n- lt: \"now/d+1d\"\n- time_zone: \"+09:00\"\n\n**4. 가격 범위 (숫자)**\n- gte: 10000\n- lte: 50000\n\n**5. 미래 이벤트**\n- gte: \"now\"\n\n---\n\n**bool 쿼리와 조합 예시:**\n\n**시나리오:** \"active 상태이고 가격이 10000~50000원이며 최근 30일 내 등록된 제품\"\n\n**구성:**\n- filter 절:\n  - Term: status = \"active\"\n  - Range: price 10000~50000\n  - Range: created_at 최근 30일\n\n**장점:**\n- 모든 조건이 filter로 캐싱 가능\n- 점수 계산 없어 빠름\n\n---\n\n**Best Practices:**\n\n**1. Filter Context에서 사용**\n**2. 타임존 명시 (날짜 검색 시)**\n**3. ISO 8601 날짜 형식 사용**\n**4. now 사용 시 반올림 고려 (캐싱)**\n**5. 경계값 포함 여부 명확히**\n**6. 시간 기반 인덱스 전략 고려**\n\nRange 쿼리는 간단하지만 강력한 도구이며, 날짜/숫자 범위 검색의 핵심입니다. 타임존과 날짜 형식에 주의하고 Filter Context에서 사용하면 최적의 성능을 얻을 수 있습니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "Query DSL",
        "Range"
      ],
      "id": "elasticsearch-007",
      "createdAt": "2025-11-17T16:00:00.000007",
      "studyCount": 0
    },
    {
      "question": "Bool 쿼리의 구성 요소(Must, Should, Must Not, Filter)에 대해 설명해주세요.",
      "answer": "Bool 쿼리는 Elasticsearch에서 여러 쿼리를 논리적으로 조합하는 가장 중요하고 유연한 복합 쿼리입니다.\n\n**Bool Query 개요:**\n\n**정의:**\n- 여러 쿼리 절(clause)을 논리 연산자로 결합하는 쿼리\n- AND, OR, NOT 로직 구현\n- 가장 많이 사용되는 복합 쿼리\n\n**특징:**\n- 4가지 절(clause) 제공\n- 각 절에 여러 쿼리 포함 가능\n- 중첩 구조 지원 (bool 안에 bool)\n- 유연한 점수 계산\n\n---\n\n**Bool 쿼리의 4가지 절:**\n\n**1. Must (필수 조건)**\n\n**의미:**\n- 반드시 만족해야 하는 조건\n- 논리적 AND\n\n**특징:**\n- Query Context에서 실행\n- **점수 계산에 기여**\n- 모든 must 절을 만족하는 문서만 반환\n- 여러 must 절의 점수가 합산됨\n\n**사용 사례:**\n- 반드시 포함해야 하는 키워드\n- 필수 조건 + 점수 중요\n\n**점수 계산:**\n- must 절들의 점수 합산\n- 관련성이 높을수록 높은 점수\n\n**예시 시나리오:**\n- \"laptop\"과 \"gaming\" 키워드 모두 포함\n- must: [match: \"laptop\", match: \"gaming\"]\n\n---\n\n**2. Should (선택 조건)**\n\n**의미:**\n- 만족하면 좋은 조건\n- 논리적 OR\n\n**특징:**\n- Query Context에서 실행\n- **점수 계산에 기여**\n- 하나 이상 만족하면 점수 상승\n- minimum_should_match로 최소 매칭 개수 지정 가능\n\n**사용 사례:**\n- 부가적인 키워드 (있으면 더 좋음)\n- 동의어, 유사어 검색\n- 부스팅 효과\n\n**점수 계산:**\n- should 절을 만족할수록 점수 증가\n- 만족하지 않아도 다른 조건으로 검색 가능\n\n**minimum_should_match:**\n- should 절 중 최소 몇 개를 만족해야 하는지\n- 기본값: must나 filter가 있으면 0, 없으면 1\n\n**예시 시나리오:**\n- \"laptop\" 검색 시 \"SSD\" 또는 \"RAM\" 포함 시 우선\n- should: [match: \"SSD\", match: \"RAM\"]\n\n---\n\n**3. Must Not (제외 조건)**\n\n**의미:**\n- 만족하지 않아야 하는 조건\n- 논리적 NOT\n\n**특징:**\n- **Filter Context에서 실행**\n- **점수 계산에 기여하지 않음**\n- 조건을 만족하는 문서는 제외됨\n- 성능 최적화 (필터링만)\n\n**사용 사례:**\n- 특정 카테고리 제외\n- 삭제된 항목 제외\n- 블랙리스트 필터링\n\n**점수:**\n- 0점 (단순 제외)\n\n**예시 시나리오:**\n- \"discontinued\" 상태 제품 제외\n- must_not: term: status = \"discontinued\"\n\n---\n\n**4. Filter (필터 조건)**\n\n**의미:**\n- 반드시 만족해야 하지만 점수에 영향 없는 조건\n- 논리적 AND (점수 없음)\n\n**특징:**\n- **Filter Context에서 실행**\n- **점수 계산에 기여하지 않음**\n- 결과 캐싱 가능\n- 빠른 성능\n\n**사용 사례:**\n- 정확한 필터링 (카테고리, 상태, 범위 등)\n- 구조화된 데이터 필터\n- 점수가 필요 없는 조건\n\n**장점:**\n- 캐싱으로 성능 향상\n- 점수 계산 오버헤드 없음\n\n**예시 시나리오:**\n- \"active\" 상태이고 가격 10000~50000원\n- filter: [term: status = \"active\", range: price 10000-50000]\n\n---\n\n**절 간의 차이점:**\n\n| 절 | 컨텍스트 | 점수 기여 | 용도 | 성능 |\n|------|---------|---------|------|------|\n| must | Query | O | 필수 + 점수 | 느림 |\n| should | Query | O | 선택 + 점수 | 느림 |\n| must_not | Filter | X | 제외 | 빠름 |\n| filter | Filter | X | 필수 필터 | 빠름 (캐싱) |\n\n---\n\n**Must vs Filter 선택 기준:**\n\n**Must 사용 시:**\n- 전문 검색 (match 쿼리)\n- 점수가 중요한 조건\n- 관련성 순위가 필요\n\n**Filter 사용 시:**\n- 정확한 매칭 (term, range 등)\n- 점수가 필요 없는 조건\n- 구조화된 데이터 필터\n- 성능이 중요\n\n**핵심:** \"점수가 필요한가?\"로 판단\n\n---\n\n**점수 계산:**\n\n**기본 점수:**\n- must 점수 합 + should 점수 합\n\n**상세:**\n1. **must 절**: 모든 절의 점수 합산\n2. **should 절**: 만족하는 절의 점수 합산\n3. **filter 절**: 점수 기여 없음 (1.0)\n4. **must_not 절**: 점수 기여 없음 (제외)\n\n**boost 파라미터:**\n- 특정 절의 가중치 조정\n- 기본값: 1.0\n- 예: boost: 2.0 (2배 가중치)\n\n---\n\n**실제 사용 패턴:**\n\n**패턴 1: 검색 + 필터**\n- must: 검색 키워드 (match)\n- filter: 카테고리, 가격 범위 (term, range)\n\n**시나리오:** \"노트북\" 검색, 전자제품 카테고리, 가격 50만원 이하\n\n**패턴 2: 다중 조건 검색**\n- must: 필수 키워드들\n- should: 부가 키워드들\n- filter: 구조화된 필터\n\n**패턴 3: 제외 조건**\n- must: 검색어\n- filter: 정상 상태\n- must_not: 삭제됨, 비활성\n\n---\n\n**minimum_should_match 활용:**\n\n**기본 동작:**\n- must 또는 filter 있음: minimum = 0\n- must와 filter 없음: minimum = 1\n\n**커스텀 설정:**\n- 숫자: 최소 매칭 개수\n- 백분율: 예) \"75%\" (75% 이상)\n\n**사용 사례:**\n- should 3개 중 최소 2개 만족\n- minimum_should_match: 2\n\n---\n\n**중첩 Bool 쿼리:**\n\n**복잡한 논리 표현:**\n- bool 안에 bool 중첩 가능\n- (A AND B) OR (C AND D) 같은 복잡한 조건\n\n**사용 예:**\n- \"고급 검색\" 기능\n- 복잡한 비즈니스 로직\n\n---\n\n**성능 최적화:**\n\n**1. Filter 우선 사용**\n- 점수 불필요한 조건은 filter로\n- 캐싱 활용\n\n**2. 필터 순서**\n- 선택적인 필터 먼저 (결과를 많이 줄이는 것)\n- Elasticsearch가 자동 최적화하지만 도움이 됨\n\n**3. Should 절 최소화**\n- 너무 많은 should는 성능 저하\n- 정말 필요한 것만\n\n**4. Must_not 활용**\n- 제외 조건은 must_not으로\n- Filter Context라 빠름\n\n---\n\n**일반적인 안티패턴:**\n\n**1. Filter 대신 Must 사용**\n- 점수 불필요한데 must 사용\n- 불필요한 점수 계산\n\n**2. 모든 조건을 Should로**\n- minimum_should_match 미설정\n- 원하는 결과 안 나올 수 있음\n\n**3. 과도한 중첩**\n- 너무 복잡한 쿼리\n- 가독성과 유지보수성 저하\n\n---\n\n**Best Practices:**\n\n**1. 역할에 맞는 절 선택**\n- 검색: must/should\n- 필터: filter\n- 제외: must_not\n\n**2. Filter를 적극 활용**\n- 성능 향상\n- 캐싱 효과\n\n**3. 명확한 구조**\n- 복잡한 로직은 주석\n- 중첩은 최소화\n\n**4. Boost 활용**\n- 중요도에 따라 가중치 조정\n\n**5. Explain API로 점수 확인**\n- 점수 계산 과정 이해\n- 쿼리 튜닝\n\nBool 쿼리는 Elasticsearch 쿼리의 핵심이며, 4가지 절을 적절히 조합하면 매우 복잡한 검색 로직도 구현할 수 있습니다. Must/Should는 점수 계산, Filter/Must_not은 필터링으로 기억하면 좋습니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "Query DSL",
        "Bool Query"
      ],
      "id": "elasticsearch-008",
      "createdAt": "2025-11-17T16:00:00.000008",
      "studyCount": 0
    },
    {
      "question": "Aggregation의 개념과 Bucket Aggregation, Metric Aggregation의 차이에 대해 설명해주세요.",
      "answer": "Aggregation은 Elasticsearch에서 데이터를 집계하고 분석하는 강력한 기능으로, SQL의 GROUP BY와 집계 함수를 결합한 것과 유사합니다.\n\n**Aggregation 개요:**\n\n**정의:**\n- 데이터를 요약하고 통계를 생성하는 분석 도구\n- 검색 결과에 대한 메타데이터 제공\n- 실시간 분석 및 대시보드 구축의 핵심\n\n**특징:**\n- 검색과 함께 실행 가능\n- 중첩 구조 지원\n- 빠른 성능 (doc_values 활용)\n- 다양한 집계 타입 제공\n\n---\n\n**주요 Aggregation 타입:**\n\n**1. Bucket Aggregation (버킷 집계)**\n\n**정의:**\n- 문서를 특정 기준으로 그룹화(버킷)하는 집계\n- SQL의 GROUP BY와 유사\n- 각 버킷은 문서들의 집합\n\n**특징:**\n- 문서를 카테고리로 분류\n- 여러 버킷 생성\n- 중첩 집계 가능 (버킷 안에 또 다른 집계)\n- 버킷별 문서 개수 반환\n\n**주요 종류:**\n\n**Terms Aggregation:**\n- 필드 값별로 그룹화\n- 예: 카테고리별 제품 수\n- 가장 많이 사용됨\n\n**Range Aggregation:**\n- 숫자/날짜 범위별 그룹화\n- 예: 가격대별 제품 수\n\n**Date Histogram Aggregation:**\n- 시간 간격별 그룹화\n- 예: 일별/월별 주문 수\n- 시계열 분석에 필수\n\n**Histogram Aggregation:**\n- 숫자 간격별 그룹화\n- 예: 나이대별 사용자 수\n\n**Filter Aggregation:**\n- 특정 조건을 만족하는 문서만 집계\n- 조건부 집계\n\n**Nested Aggregation:**\n- 중첩 객체 집계\n\n**사용 예:**\n- 카테고리별 제품 개수\n- 가격대별 분포\n- 일별 판매 추이\n\n---\n\n**2. Metric Aggregation (메트릭 집계)**\n\n**정의:**\n- 문서의 필드 값에 대한 수학적 계산\n- SQL의 집계 함수(SUM, AVG, MAX 등)와 유사\n- 단일 값 또는 여러 값 반환\n\n**특징:**\n- 숫자 계산\n- 통계 값 산출\n- 버킷 집계와 조합 사용\n- 빠른 계산 (doc_values)\n\n**주요 종류:**\n\n**단일 값 메트릭 (Single-value):**\n\n**Sum Aggregation:**\n- 합계\n- 예: 총 매출액\n\n**Avg Aggregation:**\n- 평균\n- 예: 평균 가격\n\n**Min Aggregation:**\n- 최솟값\n- 예: 최저 가격\n\n**Max Aggregation:**\n- 최댓값\n- 예: 최고 가격\n\n**Cardinality Aggregation:**\n- 고유 값 개수 (DISTINCT COUNT)\n- 예: 고유 사용자 수\n- 근사치 (HyperLogLog++ 알고리즘)\n\n**Value Count Aggregation:**\n- 값의 개수 (COUNT)\n\n**다중 값 메트릭 (Multi-value):**\n\n**Stats Aggregation:**\n- 여러 통계를 한 번에 (count, min, max, avg, sum)\n- 편리한 종합 통계\n\n**Extended Stats Aggregation:**\n- 확장 통계 (표준편차, 분산 등 추가)\n\n**Percentiles Aggregation:**\n- 백분위수\n- 예: 응답 시간의 95th, 99th percentile\n\n**Percentile Ranks Aggregation:**\n- 특정 값의 백분위 순위\n\n**사용 예:**\n- 평균 주문 금액\n- 총 매출\n- 최고/최저 가격\n- 응답 시간 백분위수\n\n---\n\n**3. Pipeline Aggregation (파이프라인 집계)**\n\n**정의:**\n- 다른 집계의 결과를 입력으로 받는 집계\n- 집계의 집계\n\n**종류:**\n- Derivative: 변화율\n- Cumulative Sum: 누적 합\n- Moving Average: 이동 평균\n- Bucket Script: 버킷 간 계산\n\n---\n\n**Bucket vs Metric 비교:**\n\n| 특성 | Bucket Aggregation | Metric Aggregation |\n|------|-------------------|-------------------|\n| 목적 | 그룹화 | 계산 |\n| 결과 | 여러 버킷 | 단일/다중 값 |\n| SQL 비교 | GROUP BY | SUM, AVG, MAX 등 |\n| 중첩 | 다른 집계 포함 가능 | 보통 리프 노드 |\n| 예시 | 카테고리별 분류 | 평균 가격 계산 |\n\n---\n\n**조합 사용 (가장 강력한 패턴):**\n\n**버킷 + 메트릭:**\n- Bucket으로 그룹화\n- 각 버킷 내에서 Metric 계산\n\n**예시 1: 카테고리별 평균 가격**\n- Terms Aggregation (카테고리별 버킷)\n  - 각 버킷에 Avg Aggregation (평균 가격)\n\n**예시 2: 일별 매출 통계**\n- Date Histogram (일별 버킷)\n  - 각 버킷에 Sum Aggregation (매출 합계)\n\n**예시 3: 가격대별 제품 수와 평균 평점**\n- Range Aggregation (가격대별 버킷)\n  - Doc Count (제품 수 - 자동)\n  - Avg Aggregation (평균 평점)\n\n---\n\n**중첩 집계 (Nested Aggregations):**\n\n**개념:**\n- 집계 안에 또 다른 집계\n- 계층적 분석 가능\n\n**예시: 카테고리별 브랜드별 평균 가격**\n1. Terms Aggregation (카테고리)\n2. → Terms Aggregation (브랜드)\n3. → → Avg Aggregation (가격)\n\n**결과 구조:**\n- Electronics\n  - Samsung: 평균 500,000원\n  - Apple: 평균 1,000,000원\n- Clothing\n  - Nike: 평균 80,000원\n  - Adidas: 평균 70,000원\n\n---\n\n**성능 고려사항:**\n\n**1. doc_values 활용**\n- 집계는 doc_values를 사용 (기본 활성화)\n- 메모리 효율적\n- text 필드는 doc_values 없음 (keyword 사용)\n\n**2. 카디널리티 주의**\n- Terms 집계에서 고유 값이 많으면 메모리 소비 증가\n- size 파라미터로 제한 (기본: 10)\n- 필요시 Composite Aggregation 사용\n\n**3. 집계 순서**\n- 선택적 필터로 문서 수 먼저 줄이기\n- 집계 전에 query/filter 적용\n\n**4. 캐싱**\n- Filter Context의 집계는 캐싱 가능\n- Query Context는 캐싱 어려움\n\n---\n\n**실전 사용 예시:**\n\n**대시보드 구축:**\n- 일별 방문자 수 (Date Histogram + Cardinality)\n- 카테고리별 매출 (Terms + Sum)\n- 응답 시간 분포 (Histogram + Count)\n\n**비즈니스 분석:**\n- 고객 세그먼트별 평균 구매액\n- 지역별 판매 추이\n- 제품별 평점 분포\n\n**로그 분석:**\n- 시간대별 에러 발생 빈도\n- 서버별 응답 시간 통계\n- 상태 코드별 요청 수\n\n---\n\n**주의사항:**\n\n**1. 메모리 사용**\n- 고카디널리티 필드는 메모리 많이 사용\n- 필요한 만큼만 집계\n\n**2. 정확도 vs 성능**\n- Cardinality는 근사치 (정확도 조절 가능)\n- Terms는 상위 N개만 (전체는 Composite 사용)\n\n**3. 필드 타입**\n- text 필드는 집계 불가\n- keyword 필드 사용\n\n---\n\n**Best Practices:**\n\n**1. 적절한 집계 타입 선택**\n- 그룹화: Bucket\n- 계산: Metric\n- 조합: Bucket + Metric\n\n**2. keyword 필드 사용**\n- 집계용 필드는 keyword 타입\n\n**3. size 파라미터 조절**\n- 필요한 만큼만 버킷 반환\n\n**4. 중첩 최소화**\n- 너무 깊은 중첩은 성능 저하\n\n**5. 필터 먼저**\n- 집계 전에 문서 수 줄이기\n\nAggregation은 Elasticsearch의 강력한 분석 도구이며, Bucket으로 그룹화하고 Metric으로 계산하는 패턴이 가장 일반적입니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "Aggregation",
        "데이터분석"
      ],
      "id": "elasticsearch-009",
      "createdAt": "2025-11-17T16:00:00.000009",
      "studyCount": 0
    },
    {
      "question": "Analyzers, Tokenizers, Filters의 역할과 설정 방법에 대해 설명해주세요.",
      "answer": "Elasticsearch의 텍스트 분석(Text Analysis)은 전문 검색의 핵심이며, Analyzer, Tokenizer, Filter는 이를 구성하는 주요 컴포넌트입니다.\n\n**텍스트 분석 개요:**\n\n**목적:**\n- 검색 가능한 형태로 텍스트를 변환\n- 인덱싱 시와 검색 시 동일한 분석 적용\n- 언어별, 도메인별 최적화\n\n**과정:**\n1. 원본 텍스트 입력\n2. Character Filters 적용\n3. Tokenizer로 토큰 분리\n4. Token Filters 적용\n5. 최종 토큰 생성\n\n---\n\n**1. Analyzer (분석기):**\n\n**정의:**\n- 텍스트 분석 과정을 정의하는 컨테이너\n- Character Filters, Tokenizer, Token Filters의 조합\n\n**구성 요소:**\n\n**Character Filters (0개 이상):**\n- 원본 텍스트 전처리\n- 문자 레벨 변환\n- 순서대로 적용\n\n**Tokenizer (정확히 1개):**\n- 텍스트를 토큰으로 분리\n- 필수 컴포넌트\n\n**Token Filters (0개 이상):**\n- 토큰 후처리\n- 순서대로 적용\n\n**내장 Analyzer:**\n\n**Standard Analyzer (기본):**\n- 구성: Standard Tokenizer + Lowercase Filter\n- 용도: 범용 분석\n- 예: \"The Quick BROWN Fox!\" → [\"the\", \"quick\", \"brown\", \"fox\"]\n\n**Simple Analyzer:**\n- 구성: Lowercase Tokenizer\n- 비문자 기준 분리, 소문자 변환\n- 예: \"The Quick-Fox\" → [\"the\", \"quick\", \"fox\"]\n\n**Whitespace Analyzer:**\n- 구성: Whitespace Tokenizer\n- 공백 기준 분리만\n- 예: \"The Quick-Fox\" → [\"The\", \"Quick-Fox\"]\n\n**Stop Analyzer:**\n- 구성: Lowercase Tokenizer + Stop Filter\n- 불용어 제거\n- 예: \"The quick fox\" → [\"quick\", \"fox\"]\n\n**Keyword Analyzer:**\n- 구성: Keyword Tokenizer\n- 전체를 하나의 토큰으로\n- 예: \"The Quick Fox\" → [\"The Quick Fox\"]\n\n**Pattern Analyzer:**\n- 정규식 패턴으로 분리\n\n**Language Analyzers:**\n- 언어별 최적화 (english, korean 등)\n- 어간 추출, 언어별 불용어\n\n---\n\n**2. Tokenizer (토큰화기):**\n\n**정의:**\n- 텍스트를 토큰(단어)으로 분리하는 컴포넌트\n- 분석 파이프라인의 핵심\n\n**주요 Tokenizer:**\n\n**Standard Tokenizer:**\n- Unicode 텍스트 세그멘테이션\n- 단어 경계 인식\n- 대부분의 언어에 적합\n- 예: \"Wi-Fi\" → [\"Wi\", \"Fi\"]\n\n**Whitespace Tokenizer:**\n- 공백 문자로 분리\n- 간단하고 빠름\n- 예: \"foo bar\" → [\"foo\", \"bar\"]\n\n**Letter Tokenizer:**\n- 비문자 기준 분리\n- 예: \"foo123bar\" → [\"foo\", \"bar\"]\n\n**Lowercase Tokenizer:**\n- 비문자 기준 분리 + 소문자 변환\n- 예: \"Foo-Bar\" → [\"foo\", \"bar\"]\n\n**Keyword Tokenizer:**\n- 전체를 하나의 토큰으로\n- keyword 필드 타입의 기본\n\n**Pattern Tokenizer:**\n- 정규식 패턴으로 분리\n- 유연한 커스터마이징\n\n**N-gram Tokenizer:**\n- 고정 길이의 문자 시퀀스 생성\n- 부분 문자열 검색\n- 예: \"quick\" (bigram) → [\"qu\", \"ui\", \"ic\", \"ck\"]\n\n**Edge N-gram Tokenizer:**\n- 시작부터 N-gram 생성\n- 자동완성에 유용\n- 예: \"quick\" (2-5) → [\"qu\", \"qui\", \"quic\", \"quick\"]\n\n**UAX URL Email Tokenizer:**\n- URL과 이메일 보존\n\n---\n\n**3. Token Filters (토큰 필터):**\n\n**정의:**\n- 토큰을 변환, 추가, 삭제하는 컴포넌트\n- 여러 필터를 순서대로 적용 가능\n\n**주요 Token Filters:**\n\n**Lowercase Filter:**\n- 모든 토큰을 소문자로\n- 대소문자 무시 검색\n\n**Uppercase Filter:**\n- 모든 토큰을 대문자로\n\n**Stop Filter:**\n- 불용어(Stop Words) 제거\n- 예: \"the\", \"a\", \"is\" 제거\n- 언어별 불용어 목록\n\n**Stemmer Filter:**\n- 어간 추출\n- 예: \"running\" → \"run\", \"runs\" → \"run\"\n- 언어별 스테머\n\n**Synonym Filter:**\n- 동의어 추가\n- 예: \"quick\" → [\"quick\", \"fast\"]\n- 검색 범위 확장\n\n**NGram Filter:**\n- 토큰을 N-gram으로 분할\n- 예: \"quick\" → [\"qu\", \"ui\", \"ic\", \"ck\"]\n\n**Edge NGram Filter:**\n- 시작부터 N-gram\n- 자동완성\n\n**Shingle Filter:**\n- 단어 단위 N-gram\n- 예: \"the quick fox\" → [\"the quick\", \"quick fox\"]\n\n**Trim Filter:**\n- 앞뒤 공백 제거\n\n**Length Filter:**\n- 특정 길이의 토큰만 유지\n- min_length, max_length\n\n**Unique Filter:**\n- 중복 토큰 제거\n\n**Reverse Filter:**\n- 토큰 역순\n- 접미사 검색\n\n**Phonetic Filter:**\n- 음성학적 매칭\n- 발음이 비슷한 단어\n\n---\n\n**Character Filters:**\n\n**HTML Strip Filter:**\n- HTML 태그 제거\n- 예: \"<p>Hello</p>\" → \"Hello\"\n\n**Mapping Filter:**\n- 문자 매핑/교체\n- 예: \"&\" → \"and\"\n\n**Pattern Replace Filter:**\n- 정규식 기반 교체\n\n---\n\n**커스텀 Analyzer 설정:**\n\n**인덱스 설정에서 정의:**\n\n**기본 구조:**\n- settings.analysis.analyzer: Analyzer 정의\n- settings.analysis.tokenizer: 커스텀 Tokenizer\n- settings.analysis.filter: 커스텀 Filter\n\n**예시: 이메일 주소 분석기**\n\n**목적:**\n- 이메일을 도메인과 사용자명으로 분리\n\n**구성:**\n- Tokenizer: UAX URL Email\n- Filters: Lowercase\n\n**예시: 자동완성 분석기**\n\n**목적:**\n- 부분 검색 지원\n\n**구성:**\n- Tokenizer: Edge NGram (2-10)\n- Filters: Lowercase\n\n---\n\n**분석기 적용:**\n\n**인덱싱 시 분석기:**\n- 매핑에서 analyzer 지정\n- 문서 인덱싱 시 적용\n\n**검색 시 분석기:**\n- search_analyzer 지정\n- 쿼리 텍스트에 적용\n- 기본: analyzer와 동일\n\n**서로 다른 분석기 사용:**\n- 인덱싱: Edge NGram (자동완성용)\n- 검색: Standard (일반 검색)\n\n---\n\n**언어별 분석:**\n\n**영어:**\n- english Analyzer\n- 어간 추출, 불용어 제거\n\n**한글:**\n- nori Analyzer (Nori 플러그인 필요)\n- 형태소 분석\n- 예: \"한글 분석기\" → [\"한글\", \"분석\", \"기\"]\n\n**다국어:**\n- ICU Analysis 플러그인\n- Unicode 정규화\n- 음역, 폴딩\n\n---\n\n**테스트 및 디버깅:**\n\n**Analyze API:**\n- 분석기 테스트\n- 각 단계 결과 확인\n\n**사용:**\n- 개발 시 분석 결과 확인\n- 디버깅\n- 최적화\n\n---\n\n**성능 고려사항:**\n\n**1. 필터 순서**\n- 토큰 수를 줄이는 필터 먼저\n- 예: Stop Filter → Stemmer\n\n**2. N-gram 주의**\n- 인덱스 크기 급증\n- min_gram, max_gram 적절히 설정\n\n**3. Synonym 관리**\n- 동의어가 많으면 인덱스 증가\n- 검색 시 적용 고려\n\n---\n\n**일반적인 패턴:**\n\n**검색 엔진:**\n- Standard Analyzer\n- Synonym Filter\n- Stop Filter\n\n**자동완성:**\n- Edge NGram Tokenizer\n- Lowercase Filter\n\n**로그 분석:**\n- Whitespace Tokenizer\n- 최소한의 필터\n\n**다국어:**\n- Language-specific Analyzer\n- ICU Normalizer\n\n---\n\n**Best Practices:**\n\n**1. 목적에 맞는 분석기 선택**\n- 전문 검색: Standard\n- 정확한 매칭: Keyword\n- 자동완성: Edge NGram\n\n**2. 인덱싱/검색 분석기 일관성**\n- 다르게 설정 시 주의 필요\n\n**3. Analyze API로 테스트**\n- 프로덕션 배포 전 검증\n\n**4. 언어 고려**\n- 해당 언어에 최적화된 분석기 사용\n\n**5. 성능 모니터링**\n- 복잡한 분석기는 성능 영향\n\n분석기는 Elasticsearch 전문 검색의 핵심이며, 데이터 특성에 맞는 적절한 조합이 검색 품질을 결정합니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "Analyzer",
        "텍스트분석"
      ],
      "id": "elasticsearch-010",
      "createdAt": "2025-11-17T16:00:00.000010",
      "studyCount": 0
    },
    {
      "question": "Mapping의 개념과 동적 매핑(Dynamic Mapping) 및 명시적 매핑(Explicit Mapping)의 차이점은 무엇인가요?",
      "answer": "Mapping은 Elasticsearch에서 문서의 구조와 필드 타입을 정의하는 스키마로, RDB의 테이블 스키마와 유사한 역할을 합니다.\n\n**Mapping 개요:**\n\n**정의:**\n- 인덱스 내 문서의 필드와 그 속성을 정의\n- 각 필드의 데이터 타입, 분석 방법, 저장 방식 지정\n- 인덱스별로 하나의 매핑 (ES 7.x 이후)\n\n**역할:**\n- 필드 타입 정의\n- 분석기 지정\n- 검색 및 집계 동작 제어\n- 저장 및 인덱싱 방식 결정\n\n---\n\n**Mapping의 주요 구성 요소:**\n\n**1. 필드 데이터 타입:**\n\n**Core Types:**\n- text: 전문 검색용 (분석됨)\n- keyword: 정확한 매칭, 집계, 정렬용 (분석 안 됨)\n- long, integer, short, byte: 정수\n- double, float: 실수\n- boolean: true/false\n- date: 날짜/시간\n- binary: Base64 인코딩 바이너리\n\n**Complex Types:**\n- object: JSON 객체 (중첩 가능)\n- nested: 독립적으로 쿼리 가능한 중첩 객체\n- array: 배열 (명시적 타입 없음, 첫 값으로 결정)\n\n**Geo Types:**\n- geo_point: 위치 (위도/경도)\n- geo_shape: 지리적 형태\n\n**Specialized Types:**\n- ip: IP 주소\n- completion: 자동완성\n- token_count: 토큰 개수\n- join: 부모-자식 관계\n\n**2. 메타 필드:**\n- _source: 원본 JSON 저장 여부\n- _id: 문서 ID\n- _index: 인덱스명\n- _routing: 샤드 라우팅\n\n**3. 매핑 파라미터:**\n- analyzer: 분석기 지정\n- index: 인덱싱 여부 (true/false)\n- store: 별도 저장 여부\n- doc_values: 집계/정렬용 (기본 true)\n- null_value: null 대신 사용할 기본값\n- fields: Multi-field 정의\n\n---\n\n**동적 매핑 (Dynamic Mapping):**\n\n**정의:**\n- Elasticsearch가 문서를 보고 자동으로 필드 타입을 추론\n- 스키마리스(Schema-less) 특성\n\n**동작 방식:**\n\n**1. 자동 타입 감지:**\n- JSON 데이터 타입 기반 추론\n- 첫 번째 값으로 타입 결정\n\n**타입 추론 규칙:**\n- true/false → boolean\n- 123 → long\n- 123.45 → float\n- \"2025-01-17\" → date (날짜 형식 감지)\n- \"텍스트\" → text + keyword (multi-field)\n- { } → object\n- [ ] → 첫 요소 타입의 배열\n\n**2. 동적 필드 추가:**\n- 새 필드 발견 시 자동으로 매핑 추가\n- 기존 매핑은 변경 불가 (호환 가능한 경우만)\n\n**장점:**\n- 빠른 프로토타이핑\n- 스키마 없이 즉시 사용 가능\n- 유연성\n\n**단점:**\n- 예상치 못한 타입 지정 가능\n- 매핑 폭발(Mapping Explosion) 위험\n- 성능 저하 가능\n- 타입 변경 불가능\n\n**동적 매핑 제어:**\n\n**dynamic 파라미터:**\n- true (기본): 새 필드 자동 추가\n- false: 새 필드 무시 (저장되지만 인덱싱/검색 불가)\n- strict: 새 필드 발견 시 오류 발생\n\n**사용 예:**\n- 개발 환경: dynamic: true\n- 프로덕션: dynamic: \"strict\"\n\n---\n\n**명시적 매핑 (Explicit Mapping):**\n\n**정의:**\n- 사용자가 직접 필드와 타입을 정의\n- 인덱스 생성 시 또는 생성 후 추가\n\n**생성 시점:**\n- 인덱스 생성 시 (권장)\n- 인덱스 생성 후 필드 추가 (기존 필드 변경 불가)\n\n**장점:**\n- 정확한 타입 지정\n- 의도한 대로 동작\n- 성능 최적화 가능\n- 명확한 스키마 관리\n- 타입 오류 방지\n\n**단점:**\n- 초기 설계 필요\n- 변경 어려움 (reindex 필요)\n\n**권장 사항:**\n- 프로덕션 환경에서 필수\n- 핵심 필드는 명시적 정의\n- 동적 매핑과 조합 가능\n\n---\n\n**동적 vs 명시적 매핑 비교:**\n\n| 특성 | 동적 매핑 | 명시적 매핑 |\n|------|----------|-----------|\n| 정의 방식 | 자동 추론 | 사용자 정의 |\n| 유연성 | 높음 | 낮음 |\n| 정확성 | 낮음 (추론 오류 가능) | 높음 |\n| 초기 작업 | 없음 | 설계 필요 |\n| 변경 | 자동 | 어려움 (reindex) |\n| 사용 환경 | 개발, 프로토타입 | 프로덕션 |\n| 성능 | 예측 불가 | 최적화 가능 |\n\n---\n\n**동적 매핑의 문제 사례:**\n\n**1. 타입 추론 오류:**\n- 첫 값이 \"123\" (문자열) → text로 매핑\n- 이후 숫자 연산 불가\n\n**2. 날짜 인식 오류:**\n- \"2025-01-17\" → date로 잘못 인식\n- 실제로는 제품 코드\n\n**3. 매핑 폭발:**\n- 너무 많은 필드 자동 생성\n- 메모리 소진\n- 클러스터 불안정\n\n**해결:**\n- 명시적 매핑 사용\n- dynamic: \"strict\" 설정\n\n---\n\n**매핑 변경의 제약:**\n\n**변경 불가:**\n- 기존 필드의 타입 변경\n- 예: text → keyword\n\n**이유:**\n- 역색인(Inverted Index) 재구성 필요\n- 기존 데이터와 충돌\n\n**해결 방법:**\n\n**1. Reindex:**\n- 새 인덱스 생성 (올바른 매핑)\n- 기존 데이터를 새 인덱스로 복사\n- 인덱스 별칭(Alias) 전환\n\n**2. Multi-field 추가:**\n- 같은 데이터를 다른 타입으로 추가 인덱싱\n- 기존 필드는 유지\n\n---\n\n**Best Practices:**\n\n**1. 프로덕션에서 명시적 매핑 사용**\n- 핵심 필드는 반드시 정의\n- dynamic: \"strict\" 권장\n\n**2. Multi-field 활용**\n- text + keyword 조합\n- 검색과 집계 모두 지원\n\n**3. 날짜 형식 명시**\n- 자동 감지에 의존하지 않기\n- format 파라미터 사용\n\n**4. 매핑 템플릿 사용**\n- Index Template으로 일관된 매핑\n- 시계열 데이터에 유용\n\n**5. 필드 수 제한**\n- index.mapping.total_fields.limit 설정\n- 매핑 폭발 방지\n\n**6. 테스트 환경에서 검증**\n- 프로덕션 배포 전 매핑 테스트\n- 샘플 데이터로 검증\n\n---\n\n**실전 전략:**\n\n**하이브리드 접근:**\n- 핵심 필드: 명시적 매핑\n- 부가 필드: 동적 매핑\n- dynamic: false + 필요 시 필드 추가\n\n**매핑 설계 단계:**\n1. 데이터 구조 분석\n2. 검색 요구사항 파악\n3. 필드 타입 결정\n4. 분석기 선택\n5. Multi-field 고려\n6. 성능 테스트\n\n---\n\n**매핑 확인 및 관리:**\n\n**매핑 조회:**\n- GET /index/_mapping\n\n**필드 추가 (명시적):**\n- PUT /index/_mapping\n\n**매핑 템플릿:**\n- 패턴 기반 자동 매핑 적용\n- 예: logs-* 패턴\n\n**동적 템플릿:**\n- 특정 조건에 매칭되는 필드에 매핑 적용\n- 이름 패턴, 타입 등으로 조건 지정\n\nMapping은 Elasticsearch의 기반이며, 초기 설계가 성능과 기능을 결정합니다. 프로덕션에서는 명시적 매핑을 사용하고, 동적 매핑은 제한적으로 활용하는 것이 좋습니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "Mapping",
        "스키마"
      ],
      "id": "elasticsearch-011",
      "createdAt": "2025-11-17T16:00:00.000011",
      "studyCount": 0
    },
    {
      "question": "Elasticsearch에서 Relevance Scoring의 원리와 개선 방법에 대해 설명해주세요.",
      "answer": "Relevance Scoring은 Elasticsearch가 검색 결과를 관련성 순으로 정렬하기 위해 각 문서에 점수를 부여하는 메커니즘입니다.\n\n**Relevance Scoring 개요:**\n\n**정의:**\n- 쿼리와 문서 간의 관련성을 나타내는 수치 (_score)\n- 점수가 높을수록 쿼리와 더 관련성이 높음\n- Query Context에서만 계산 (Filter Context는 점수 없음)\n\n**목적:**\n- 가장 관련성 높은 결과를 상위에 표시\n- 사용자 만족도 향상\n- 검색 품질 개선\n\n---\n\n**스코어링 알고리즘:**\n\n**1. TF-IDF (Term Frequency-Inverse Document Frequency)**\n\n**ES 5.0 이전 기본 알고리즘**\n\n**구성 요소:**\n\n**TF (Term Frequency - 용어 빈도):**\n- 문서 내에서 검색어가 얼마나 자주 등장하는가\n- 많이 등장할수록 높은 점수\n- sqrt(termFreq)로 정규화\n\n**IDF (Inverse Document Frequency - 역문서 빈도):**\n- 검색어가 전체 문서에서 얼마나 희귀한가\n- 희귀할수록 높은 점수 (더 구별력 있음)\n- log(총문서수 / 검색어포함문서수)\n\n**Field-length Norm:**\n- 필드 길이 정규화\n- 짧은 문서에서의 매칭이 더 중요\n- 1 / sqrt(fieldLength)\n\n**공식:**\n- score = TF × IDF × Field-length Norm × Boost\n\n**2. BM25 (Best Matching 25)**\n\n**ES 5.0 이후 기본 알고리즘**\n\n**특징:**\n- TF-IDF의 개선 버전\n- 더 정교한 용어 빈도 처리\n- 문서 길이 보정 개선\n- 실험적으로 더 나은 결과\n\n**개선 사항:**\n- TF 포화: 용어 빈도가 높아도 점수가 무한정 증가하지 않음\n- k1 파라미터: TF 포화 속도 조절 (기본 1.2)\n- b 파라미터: 문서 길이 영향 조절 (기본 0.75)\n\n**공식:**\n더 복잡하지만 더 나은 관련성\n\n---\n\n**점수 계산 과정:**\n\n**1. 쿼리 정규화:**\n- 쿼리를 여러 절(clause)로 분해\n- 각 절의 중요도 결정\n\n**2. 문서별 점수 계산:**\n- 각 절에 대해 문서와 매칭 점수 계산\n- BM25 공식 적용\n\n**3. 절 점수 합산:**\n- Bool 쿼리의 must: 모든 절 점수 합\n- Bool 쿼리의 should: 매칭된 절 점수 합\n\n**4. 정규화 및 부스팅:**\n- 최종 점수 계산\n- Boost 적용\n\n**5. 정렬:**\n- 점수 내림차순 정렬\n\n---\n\n**점수에 영향을 미치는 요소:**\n\n**1. 용어 빈도 (TF)**\n- 문서에서 검색어 출현 횟수\n\n**2. 역문서 빈도 (IDF)**\n- 검색어의 희귀성\n\n**3. 필드 길이**\n- 짧은 필드에서 매칭이 더 중요\n\n**4. 필드 부스팅**\n- 특정 필드에 가중치 부여\n\n**5. 쿼리 부스팅**\n- 특정 쿼리 절에 가중치\n\n**6. 함수 스코어**\n- 커스텀 점수 계산 함수\n\n---\n\n**점수 개선 방법:**\n\n**1. Boosting (부스팅)**\n\n**필드 레벨 부스팅:**\n- 특정 필드의 중요도 증가\n- 예: 제목 필드에 2배 가중치\n\n**쿼리 레벨 부스팅:**\n- 특정 쿼리 절에 가중치\n- 예: must 절에 더 높은 boost\n\n**주의:**\n- 과도한 부스팅은 역효과\n- 실험적 조정 필요\n\n**2. Multi-field 전략**\n\n**text + keyword:**\n- text: 전문 검색\n- keyword: 정확한 매칭에 높은 점수\n\n**다양한 분석기:**\n- 기본 분석기\n- 동의어 분석기\n- N-gram 분석기\n\n**3. Function Score Query**\n\n**정의:**\n- 커스텀 점수 계산 함수 적용\n- 비즈니스 로직 반영\n\n**함수 타입:**\n\n**Field Value Factor:**\n- 필드 값을 점수에 반영\n- 예: 평점, 인기도\n\n**Script Score:**\n- 스크립트로 커스텀 계산\n- 가장 유연하지만 느림\n\n**Decay Functions:**\n- 거리/시간 기반 감쇠\n- geo_point, date 필드에 유용\n- gauss, exp, linear 함수\n\n**Random Score:**\n- 랜덤 점수\n- 같은 점수 문서 무작위 정렬\n\n**Weight:**\n- 고정 가중치\n\n**조합 모드:**\n- multiply, sum, avg, max, min\n\n**4. Boosting Query**\n\n**정의:**\n- 특정 조건에 부정적 부스팅\n- 특정 문서의 점수 감소\n\n**사용 예:**\n- 오래된 문서 점수 낮추기\n- 특정 카테고리 우선순위 낮추기\n\n**5. Rescore Query**\n\n**정의:**\n- 상위 N개 결과에 대해 재점수화\n- 복잡한 점수 계산을 일부에만 적용\n\n**장점:**\n- 성능과 품질의 균형\n- 비용이 높은 계산을 제한적으로\n\n**사용 예:**\n- 첫 번째 검색: 간단한 쿼리\n- Rescore: 상위 100개에 복잡한 점수 재계산\n\n**6. Minimum Should Match**\n\n**정의:**\n- should 절 중 최소 몇 개를 만족해야 하는지\n\n**효과:**\n- 관련성 낮은 문서 필터링\n- 점수 분포 개선\n\n**7. Negative Boost**\n\n**정의:**\n- 특정 조건 만족 시 점수 감소\n- 완전 제외는 아님\n\n---\n\n**점수 분석 및 디버깅:**\n\n**1. Explain API**\n\n**기능:**\n- 점수 계산 과정 상세 설명\n- 각 절의 기여도 확인\n\n**사용:**\n- 왜 이 문서가 높은 점수인지 이해\n- 쿼리 튜닝\n\n**2. Profile API**\n\n**기능:**\n- 쿼리 실행 과정 분석\n- 성능 병목 파악\n\n**3. Named Queries**\n\n**기능:**\n- 쿼리 절에 이름 부여\n- 어떤 절이 매칭되었는지 확인\n\n---\n\n**실전 최적화 전략:**\n\n**1. 비즈니스 요구사항 반영**\n\n**인기도 반영:**\n- 조회수, 판매량 등을 점수에 반영\n- Function Score의 field_value_factor\n\n**최신성 반영:**\n- 최근 문서에 높은 점수\n- Decay Function (gauss/exp)\n\n**위치 기반:**\n- 사용자 위치와의 거리\n- Geo Distance Decay\n\n**2. 사용자 행동 학습**\n\n**클릭률 반영:**\n- 많이 클릭되는 결과에 가중치\n\n**개인화:**\n- 사용자 선호도 반영\n\n**3. A/B 테스팅**\n\n**방법:**\n- 여러 스코어링 전략 비교\n- 사용자 만족도 측정\n\n**메트릭:**\n- CTR (클릭률)\n- 체류 시간\n- 전환율\n\n**4. 점진적 개선**\n\n**단계:**\n1. 기본 쿼리로 시작\n2. Explain API로 문제 파악\n3. 점진적 조정\n4. 테스트 및 측정\n5. 반복\n\n---\n\n**일반적인 문제와 해결:**\n\n**1. 모든 결과가 같은 점수**\n- 원인: Filter Context 사용\n- 해결: Query Context (must, should) 사용\n\n**2. 짧은 문서가 항상 높은 점수**\n- 원인: Field-length Norm\n- 해결: BM25의 b 파라미터 조정\n\n**3. 흔한 단어가 높은 점수**\n- 원인: IDF 고려 안 됨\n- 해결: Match 쿼리 사용 (자동 IDF 적용)\n\n**4. 점수 차이가 너무 작음**\n- 원인: 모든 문서가 비슷함\n- 해결: Boosting, Function Score 활용\n\n---\n\n**Best Practices:**\n\n**1. 비즈니스 가치 반영**\n- 기술적 관련성 + 비즈니스 가치\n\n**2. Filter와 Query 분리**\n- 필터링: Filter Context\n- 점수 계산: Query Context\n\n**3. 부스팅 신중히**\n- 과도한 부스팅 지양\n- 자연스러운 관련성 우선\n\n**4. Function Score 활용**\n- 복잡한 비즈니스 로직\n- 다양한 신호 조합\n\n**5. 지속적인 모니터링**\n- 사용자 피드백\n- A/B 테스팅\n- 메트릭 추적\n\n**6. Explain으로 검증**\n- 의도대로 점수 계산되는지 확인\n\nRelevance Scoring은 검색 품질의 핵심이며, 기본 알고리즘(BM25)에 비즈니스 로직을 더해 최적화하는 것이 중요합니다.",
      "type": "essay",
      "tags": [
        "Elasticsearch",
        "Relevance Scoring",
        "검색품질"
      ],
      "id": "elasticsearch-012",
      "createdAt": "2025-11-17T16:00:00.000012",
      "studyCount": 0
    }
  ]
}