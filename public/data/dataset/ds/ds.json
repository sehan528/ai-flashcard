{
  "name": "자료구조",
  "description": "자료구조 핵심 개념 및 면접 질문",
  "cards": [
    {
      "question": "스택 2개로 큐 만들기",
      "answer": "**두 개의 스택으로 큐를 구현하는 방법:**\n\n스택은 LIFO (Last In First Out), 큐는 FIFO (First In First Out) 구조입니다.\n\n**구현 방법:**\n\n```java\nclass QueueUsingTwoStacks {\n    Stack<Integer> inbox = new Stack<>();   // 입력용\n    Stack<Integer> outbox = new Stack<>();  // 출력용\n    \n    // Enqueue: O(1)\n    public void enqueue(int x) {\n        inbox.push(x);\n    }\n    \n    // Dequeue: Amortized O(1)\n    public int dequeue() {\n        if (outbox.isEmpty()) {\n            // inbox의 모든 원소를 outbox로 이동\n            while (!inbox.isEmpty()) {\n                outbox.push(inbox.pop());\n            }\n        }\n        return outbox.pop();\n    }\n    \n    public int peek() {\n        if (outbox.isEmpty()) {\n            while (!inbox.isEmpty()) {\n                outbox.push(inbox.pop());\n            }\n        }\n        return outbox.peek();\n    }\n}\n```\n\n**동작 원리:**\n\n```\n// enqueue(1, 2, 3, 4)\ninbox: [1, 2, 3, 4] (top)\noutbox: []\n\n// dequeue() 호출\ninbox → outbox 이동:\ninbox: []\noutbox: [4, 3, 2, 1] (top)\n\n// dequeue() 반환값: 1 (FIFO)\noutbox: [4, 3, 2]\n```\n\n**시간복잡도:**\n- Enqueue: O(1)\n- Dequeue: Amortized O(1) (최악 O(n), 평균 O(1))\n\n**JavaScript 구현:**\n\n```javascript\nclass QueueUsingStacks {\n    constructor() {\n        this.inbox = [];\n        this.outbox = [];\n    }\n    \n    enqueue(x) {\n        this.inbox.push(x);\n    }\n    \n    dequeue() {\n        if (this.outbox.length === 0) {\n            while (this.inbox.length > 0) {\n                this.outbox.push(this.inbox.pop());\n            }\n        }\n        return this.outbox.pop();\n    }\n}\n```",
      "type": "essay",
      "tags": [
        "자료구조",
        "Stack",
        "Queue",
        "구현"
      ]
    },
    {
      "question": "큐 2개로 스택 만들기",
      "answer": "**두 개의 큐로 스택을 구현하는 방법:**\n\n스택은 LIFO, 큐는 FIFO 구조입니다.\n\n**구현 방법 1: Push가 O(n)**\n\n```java\nclass StackUsingTwoQueues {\n    Queue<Integer> q1 = new LinkedList<>();\n    Queue<Integer> q2 = new LinkedList<>();\n    \n    // Push: O(n)\n    public void push(int x) {\n        // 새 원소를 q2에 추가\n        q2.offer(x);\n        \n        // q1의 모든 원소를 q2로 이동\n        while (!q1.isEmpty()) {\n            q2.offer(q1.poll());\n        }\n        \n        // q1과 q2를 교환\n        Queue<Integer> temp = q1;\n        q1 = q2;\n        q2 = temp;\n    }\n    \n    // Pop: O(1)\n    public int pop() {\n        return q1.poll();\n    }\n    \n    // Top: O(1)\n    public int top() {\n        return q1.peek();\n    }\n}\n```\n\n**동작 원리:**\n\n```\n// push(1)\nq1: [1]\nq2: []\n\n// push(2)\nq2: [2] → q1의 원소 이동 → [2, 1]\nq1과 q2 교환\nq1: [2, 1] (front가 top)\n\n// push(3)\nq2: [3] → [3, 2, 1]\nq1: [3, 2, 1]\n\n// pop() → 3 반환\n```\n\n**구현 방법 2: 하나의 큐만 사용 (더 효율적)**\n\n```java\nclass StackUsingOneQueue {\n    Queue<Integer> queue = new LinkedList<>();\n    \n    // Push: O(n)\n    public void push(int x) {\n        queue.offer(x);\n        int size = queue.size();\n        \n        // 새 원소를 맨 앞으로 이동\n        for (int i = 0; i < size - 1; i++) {\n            queue.offer(queue.poll());\n        }\n    }\n    \n    // Pop: O(1)\n    public int pop() {\n        return queue.poll();\n    }\n}\n```\n\n**JavaScript 구현:**\n\n```javascript\nclass StackUsingQueue {\n    constructor() {\n        this.queue = [];\n    }\n    \n    push(x) {\n        this.queue.push(x);\n        // 새 원소를 맨 앞으로 회전\n        for (let i = 0; i < this.queue.length - 1; i++) {\n            this.queue.push(this.queue.shift());\n        }\n    }\n    \n    pop() {\n        return this.queue.shift();\n    }\n}\n```\n\n**시간복잡도:**\n- Push: O(n)\n- Pop: O(1)\n- Top: O(1)",
      "type": "essay",
      "tags": [
        "자료구조",
        "Stack",
        "Queue",
        "구현"
      ]
    },
    {
      "question": "Prefix, Infix, Postfix 에 대해 설명하고, 이를 스택을 활용해서 계산하는 방법에 대해 설명해 주세요.",
      "answer": "**표기법 종류:**\n\n1. **Infix (중위 표기법)**: 연산자가 피연산자 사이에 위치\n   - 예: `3 + 4 * 2`\n   - 사람이 읽기 쉽지만 우선순위 처리 복잡\n\n2. **Prefix (전위 표기법)**: 연산자가 피연산자 앞에 위치\n   - 예: `+ 3 * 4 2` → `3 + (4 * 2)`\n   - 괄호 불필요\n\n3. **Postfix (후위 표기법)**: 연산자가 피연산자 뒤에 위치\n   - 예: `3 4 2 * +` → `3 + (4 * 2)`\n   - 스택으로 계산이 가장 쉬움\n\n---\n\n**Postfix 계산 (스택 사용):**\n\n```java\npublic int evaluatePostfix(String expression) {\n    Stack<Integer> stack = new Stack<>();\n    String[] tokens = expression.split(\" \");\n    \n    for (String token : tokens) {\n        if (isOperator(token)) {\n            int b = stack.pop();\n            int a = stack.pop();\n            \n            switch (token) {\n                case \"+\": stack.push(a + b); break;\n                case \"-\": stack.push(a - b); break;\n                case \"*\": stack.push(a * b); break;\n                case \"/\": stack.push(a / b); break;\n            }\n        } else {\n            stack.push(Integer.parseInt(token));\n        }\n    }\n    \n    return stack.pop();\n}\n```\n\n**동작 과정 예시: `3 4 2 * +`**\n\n```\n토큰: 3 → stack: [3]\n토큰: 4 → stack: [3, 4]\n토큰: 2 → stack: [3, 4, 2]\n토큰: * → pop 2, 4 → 4*2=8 → stack: [3, 8]\n토큰: + → pop 8, 3 → 3+8=11 → stack: [11]\n결과: 11\n```\n\n---\n\n**Infix → Postfix 변환 (Shunting Yard Algorithm):**\n\n```java\npublic String infixToPostfix(String infix) {\n    StringBuilder result = new StringBuilder();\n    Stack<Character> stack = new Stack<>();\n    \n    for (char c : infix.toCharArray()) {\n        if (Character.isDigit(c)) {\n            result.append(c).append(' ');\n        } else if (c == '(') {\n            stack.push(c);\n        } else if (c == ')') {\n            while (!stack.isEmpty() && stack.peek() != '(') {\n                result.append(stack.pop()).append(' ');\n            }\n            stack.pop(); // '(' 제거\n        } else if (isOperator(c)) {\n            while (!stack.isEmpty() && precedence(stack.peek()) >= precedence(c)) {\n                result.append(stack.pop()).append(' ');\n            }\n            stack.push(c);\n        }\n    }\n    \n    while (!stack.isEmpty()) {\n        result.append(stack.pop()).append(' ');\n    }\n    \n    return result.toString().trim();\n}\n\nprivate int precedence(char op) {\n    if (op == '+' || op == '-') return 1;\n    if (op == '*' || op == '/') return 2;\n    return 0;\n}\n```\n\n**예시: `3 + 4 * 2` → `3 4 2 * +`**\n\n```\n토큰: 3 → result: \"3 \", stack: []\n토큰: + → result: \"3 \", stack: [+]\n토큰: 4 → result: \"3 4 \", stack: [+]\n토큰: * → result: \"3 4 \", stack: [+, *] (우선순위 * > +)\n토큰: 2 → result: \"3 4 2 \", stack: [+, *]\n종료  → result: \"3 4 2 * +\", stack: []\n```\n\n**시간복잡도:** O(n)",
      "type": "essay",
      "tags": [
        "자료구조",
        "Stack",
        "Expression",
        "알고리즘"
      ]
    },
    {
      "question": "(C++ 한정) Deque의 Random Access 시간복잡도는 O(1) 입니다. 이게 어떻게 가능한걸까요?",
      "answer": "**C++ `std::deque`의 내부 구조:**\n\nDeque는 \"Double-Ended Queue\"로, 양쪽 끝에서 삽입/삭제가 O(1)이면서도 Random Access가 O(1)인 자료구조입니다.\n\n**구현 방식: Map of Chunks (청크 배열)**\n\n```\n         Map (중앙 관리 배열)\n         ┌───┬───┬───┬───┬───┐\n         │ 0 │ 1 │ 2 │ 3 │ 4 │\n         └─┬─┴─┬─┴─┬─┴─┬─┴─┬─┘\n           │   │   │   │   │\n           ↓   ↓   ↓   ↓   ↓\n        Chunk1 Chunk2 Chunk3 ... (고정 크기 배열들)\n        [][][]  [][][]  [][][]\n```\n\n**핵심 아이디어:**\n\n1. **Map (중앙 배열)**:\n   - 포인터 배열로, 각 포인터는 고정 크기 청크를 가리킴\n   - 청크 크기는 보통 512 bytes (원소 크기에 따라 다름)\n\n2. **Chunk (데이터 블록)**:\n   - 실제 데이터가 저장되는 고정 크기 배열\n   - 예: `sizeof(T) = 4` bytes → 청크당 128개 원소\n\n**Random Access 계산:**\n\n```cpp\n// index 번째 원소 접근: O(1)\nT& operator[](size_t index) {\n    size_t chunk_index = index / CHUNK_SIZE;  // 어느 청크?\n    size_t offset = index % CHUNK_SIZE;       // 청크 내 위치?\n    \n    return map[chunk_index][offset];\n}\n```\n\n**예시:**\n\n```\nCHUNK_SIZE = 4라고 가정\ndeque에 [0, 1, 2, 3, 4, 5, 6, 7, 8] 저장\n\nMap:      [0]  [1]  [2]\n           ↓    ↓    ↓\nChunk 0: [0 1 2 3]\nChunk 1: [4 5 6 7]\nChunk 2: [8 _ _ _]\n\n// deque[6] 접근\nchunk_index = 6 / 4 = 1\noffset = 6 % 4 = 2\n→ map[1][2] = 6\n```\n\n**양쪽 삽입/삭제가 O(1)인 이유:**\n\n```cpp\n// push_back\nvoid push_back(T value) {\n    if (마지막 청크가 가득 참) {\n        map에 새 청크 포인터 추가;  // Map 재할당 가능 (Amortized O(1))\n    }\n    마지막 청크에 추가;\n}\n\n// push_front\nvoid push_front(T value) {\n    if (첫 청크가 가득 참) {\n        map 앞에 새 청크 포인터 추가;\n    }\n    첫 청크에 추가;\n}\n```\n\n**Vector vs Deque 비교:**\n\n| 연산 | Vector | Deque |\n|------|--------|-------|\n| Random Access | O(1) | O(1) |\n| push_back | Amortized O(1) | Amortized O(1) |\n| push_front | O(n) | Amortized O(1) |\n| 메모리 연속성 | 연속 | 비연속 (청크 단위) |\n| 캐시 효율 | 높음 | 낮음 |\n\n**단점:**\n\n- 청크 간 이동 시 캐시 미스 발생 가능\n- Vector보다 메모리 오버헤드 큼 (Map 관리 비용)\n\n**사용 예시:**\n\n```cpp\nstd::deque<int> dq;\n\n// 양쪽 삽입 O(1)\ndq.push_back(1);   // [1]\ndq.push_front(0);  // [0, 1]\n\n// Random Access O(1)\nint x = dq[0];     // 0\nint y = dq[1];     // 1\n```",
      "type": "essay",
      "tags": [
        "자료구조",
        "Deque",
        "C++",
        "Random Access"
      ]
    },
    {
      "question": "해시 자료구조에 대해 설명해 주세요.",
      "answer": "**해시 테이블 (Hash Table):**\n\nKey-Value 쌍을 저장하는 자료구조로, **평균 O(1) 시간복잡도**로 삽입, 삭제, 검색이 가능합니다.\n\n**핵심 구성 요소:**\n\n1. **해시 함수 (Hash Function)**\n   - Key → Index 변환\n   - 예: `hash(key) % table_size`\n\n2. **버킷 배열 (Bucket Array)**\n   - 실제 데이터를 저장하는 배열\n\n3. **충돌 해결 방법 (Collision Resolution)**\n   - Chaining: 연결 리스트로 충돌 처리\n   - Open Addressing: 빈 슬롯 찾기\n\n---\n\n**동작 원리:**\n\n```java\nclass HashTable<K, V> {\n    private static class Entry<K, V> {\n        K key;\n        V value;\n        Entry<K, V> next;  // Chaining\n    }\n    \n    private Entry<K, V>[] table;\n    private int size;\n    \n    public HashTable(int capacity) {\n        table = new Entry[capacity];\n    }\n    \n    // 삽입: O(1) 평균\n    public void put(K key, V value) {\n        int index = hash(key);\n        Entry<K, V> entry = table[index];\n        \n        // 중복 키 확인\n        while (entry != null) {\n            if (entry.key.equals(key)) {\n                entry.value = value;  // 업데이트\n                return;\n            }\n            entry = entry.next;\n        }\n        \n        // 새 엔트리 추가 (체이닝)\n        Entry<K, V> newEntry = new Entry<>(key, value);\n        newEntry.next = table[index];\n        table[index] = newEntry;\n        size++;\n    }\n    \n    // 검색: O(1) 평균\n    public V get(K key) {\n        int index = hash(key);\n        Entry<K, V> entry = table[index];\n        \n        while (entry != null) {\n            if (entry.key.equals(key)) {\n                return entry.value;\n            }\n            entry = entry.next;\n        }\n        \n        return null;\n    }\n    \n    private int hash(K key) {\n        return Math.abs(key.hashCode()) % table.length;\n    }\n}\n```\n\n---\n\n**충돌 해결 방법:**\n\n**1. Chaining (체이닝):**\n\n```\nIndex  Bucket\n  0  → [key1, val1] → [key2, val2] → null\n  1  → null\n  2  → [key3, val3] → null\n  3  → [key4, val4] → [key5, val5] → null\n```\n\n**2. Open Addressing (개방 주소법):**\n\n- **Linear Probing**: `(h(k) + i) % m`\n- **Quadratic Probing**: `(h(k) + i²) % m`\n- **Double Hashing**: `(h1(k) + i * h2(k)) % m`\n\n---\n\n**시간복잡도:**\n\n| 연산 | 평균 | 최악 |\n|------|------|------|\n| 삽입 | O(1) | O(n) |\n| 삭제 | O(1) | O(n) |\n| 검색 | O(1) | O(n) |\n\n**최악의 경우**: 모든 키가 같은 인덱스로 해싱 → 연결 리스트처럼 동작\n\n---\n\n**Load Factor (적재율):**\n\n```\nLoad Factor = 저장된 원소 개수 / 테이블 크기\n```\n\n- Java HashMap: Load Factor 0.75 초과 시 리사이징\n- 적재율이 높을수록 충돌 증가 → 성능 저하\n\n**리사이징 (Rehashing):**\n\n```java\nprivate void resize() {\n    Entry<K, V>[] oldTable = table;\n    table = new Entry[oldTable.length * 2];\n    \n    // 모든 엔트리 재배치\n    for (Entry<K, V> entry : oldTable) {\n        while (entry != null) {\n            put(entry.key, entry.value);\n            entry = entry.next;\n        }\n    }\n}\n```\n\n---\n\n**JavaScript 예시:**\n\n```javascript\nconst map = new Map();\nmap.set('name', 'Alice');  // O(1)\nmap.get('name');           // O(1) → 'Alice'\nmap.has('name');           // O(1) → true\nmap.delete('name');        // O(1)\n```\n\n**Java 예시:**\n\n```java\nHashMap<String, Integer> map = new HashMap<>();\nmap.put(\"apple\", 100);   // O(1)\nint price = map.get(\"apple\");  // O(1)\nmap.containsKey(\"apple\");      // O(1)\n```\n\n**장점:**\n- 빠른 검색, 삽입, 삭제 (평균 O(1))\n- 유연한 키 타입\n\n**단점:**\n- 순서 보장 안 됨 (LinkedHashMap으로 해결)\n- 해시 충돌 가능성\n- 메모리 오버헤드 (빈 공간 존재)",
      "type": "essay",
      "tags": [
        "자료구조",
        "Hash Table",
        "HashMap",
        "시간복잡도"
      ]
    },
    {
      "question": "값이 주어졌을 때, 어떻게 하면 충돌이 최대한 적은 해시 함수를 설계할 수 있을까요?",
      "answer": "**좋은 해시 함수의 조건:**\n\n1. **균등 분포 (Uniform Distribution)**\n   - 모든 버킷에 데이터가 고르게 분산\n   - 충돌 최소화\n\n2. **빠른 계산**\n   - O(1) 시간에 해시값 계산\n\n3. **결정적 (Deterministic)**\n   - 같은 입력 → 항상 같은 출력\n\n---\n\n**해시 함수 설계 기법:**\n\n**1. Division Method (나눗셈)**\n\n```java\nint hash(int key, int tableSize) {\n    return key % tableSize;\n}\n```\n\n**주의사항:**\n- 테이블 크기는 **소수(prime number)** 사용 권장\n- 2의 거듭제곱은 피하기 (하위 비트만 사용되어 편향 발생)\n\n**2. Multiplication Method (곱셈)**\n\n```java\nint hash(int key, int tableSize) {\n    double A = (Math.sqrt(5) - 1) / 2;  // 황금비의 역수\n    double fractional = (key * A) % 1;  // 소수 부분만 추출\n    return (int)(tableSize * fractional);\n}\n```\n\n**3. Universal Hashing**\n\n```java\nclass UniversalHash {\n    private int a, b, p, m;\n    \n    public UniversalHash(int tableSize) {\n        this.m = tableSize;\n        this.p = nextPrime(tableSize * 2);  // tableSize보다 큰 소수\n        this.a = random(1, p);  // 랜덤 계수\n        this.b = random(0, p);\n    }\n    \n    int hash(int key) {\n        return ((a * key + b) % p) % m;\n    }\n}\n```\n\n**장점**: 최악의 경우 공격 방지 (랜덤성)\n\n---\n\n**문자열 해시:**\n\n**Polynomial Rolling Hash:**\n\n```java\nint hash(String s, int tableSize) {\n    final int p = 31;  // 소수 (알파벳 크기보다 큰)\n    final int m = 1_000_000_009;  // 큰 소수\n    \n    long hashValue = 0;\n    long pPow = 1;\n    \n    for (char c : s.toCharArray()) {\n        hashValue = (hashValue + (c - 'a' + 1) * pPow) % m;\n        pPow = (pPow * p) % m;\n    }\n    \n    return (int)(hashValue % tableSize);\n}\n```\n\n**예시:**\n```\n\"abc\" 해시값\n= (1 * 31^0 + 2 * 31^1 + 3 * 31^2) % m\n= (1 + 62 + 2883) % m\n```\n\n---\n\n**Java의 String.hashCode():**\n\n```java\npublic int hashCode() {\n    int h = 0;\n    for (char c : value) {\n        h = 31 * h + c;\n    }\n    return h;\n}\n```\n\n**왜 31을 사용?**\n- 소수라서 분포가 좋음\n- `31 * i == (i << 5) - i` (비트 연산으로 최적화 가능)\n\n---\n\n**충돌 최소화 전략:**\n\n**1. 비트 연산 활용:**\n\n```java\nint hash(int key) {\n    key ^= (key >>> 20) ^ (key >>> 12);\n    return key ^ (key >>> 7) ^ (key >>> 4);\n}\n```\n\n**2. MurmurHash (빠르고 품질 좋음):**\n\n```java\nint murmurhash(int key) {\n    key ^= key >>> 16;\n    key *= 0x85ebca6b;\n    key ^= key >>> 13;\n    key *= 0xc2b2ae35;\n    key ^= key >>> 16;\n    return key;\n}\n```\n\n---\n\n**실전 예시:**\n\n```java\n// 나쁜 예: 2의 거듭제곱 테이블 크기\nint badHash(int key) {\n    return key % 1024;  // 하위 10비트만 사용 → 편향\n}\n\n// 좋은 예: 소수 테이블 크기\nint goodHash(int key) {\n    return key % 1009;  // 균등 분포\n}\n```\n\n**테스트:**\n\n```java\n// 해시 함수 품질 테스트\nvoid testHashDistribution(HashFunction h, int[] keys) {\n    int[] buckets = new int[tableSize];\n    \n    for (int key : keys) {\n        buckets[h.hash(key)]++;\n    }\n    \n    // 표준편차 계산 (낮을수록 균등 분포)\n    double stdDev = calculateStdDev(buckets);\n}\n```",
      "type": "essay",
      "tags": [
        "해시",
        "해시 함수",
        "설계",
        "충돌"
      ]
    },
    {
      "question": "해시값이 충돌했을 때, 어떤 방식으로 처리할 수 있을까요?",
      "answer": "**충돌 해결 방법:**\n\n## 1. Chaining (체이닝)\n\n각 버킷을 연결 리스트로 구현하여 같은 인덱스의 원소들을 체인으로 연결\n\n```java\nclass HashTableChaining<K, V> {\n    class Node {\n        K key;\n        V value;\n        Node next;\n    }\n    \n    Node[] table;\n    \n    void put(K key, V value) {\n        int index = hash(key);\n        Node node = table[index];\n        \n        // 기존 키 업데이트\n        while (node != null) {\n            if (node.key.equals(key)) {\n                node.value = value;\n                return;\n            }\n            node = node.next;\n        }\n        \n        // 새 노드 추가 (맨 앞에)\n        Node newNode = new Node(key, value);\n        newNode.next = table[index];\n        table[index] = newNode;\n    }\n}\n```\n\n**장점:**\n- 구현 간단\n- 삭제 쉬움\n- Load Factor > 1 가능\n\n**단점:**\n- 추가 메모리 (포인터)\n- 캐시 효율 낮음\n\n---\n\n## 2. Open Addressing (개방 주소법)\n\n충돌 시 다른 빈 슬롯을 찾아 저장\n\n### 2-1. Linear Probing (선형 조사)\n\n```java\nvoid put(K key, V value) {\n    int index = hash(key);\n    \n    // 빈 슬롯 찾을 때까지\n    while (table[index] != null && !table[index].key.equals(key)) {\n        index = (index + 1) % table.length;\n    }\n    \n    table[index] = new Entry(key, value);\n}\n\nV get(K key) {\n    int index = hash(key);\n    \n    while (table[index] != null) {\n        if (table[index].key.equals(key)) {\n            return table[index].value;\n        }\n        index = (index + 1) % table.length;\n    }\n    \n    return null;\n}\n```\n\n**문제: Primary Clustering (1차 군집화)**\n- 연속된 슬롯들이 채워지면 더 긴 체인 형성\n\n### 2-2. Quadratic Probing (이차 조사)\n\n```java\nint probe(int hash, int i) {\n    return (hash + i * i) % table.length;\n}\n```\n\n**예시:**\n```\ni=0: hash\ni=1: hash + 1\ni=2: hash + 4\ni=3: hash + 9\n```\n\n**문제: Secondary Clustering (2차 군집화)**\n- 같은 해시값을 가진 키들이 같은 조사 순서\n\n### 2-3. Double Hashing (이중 해싱)\n\n```java\nint hash1(K key) {\n    return key.hashCode() % table.length;\n}\n\nint hash2(K key) {\n    return 1 + (key.hashCode() % (table.length - 1));\n}\n\nint probe(K key, int i) {\n    return (hash1(key) + i * hash2(key)) % table.length;\n}\n```\n\n**예시:**\n```\nkey = 10, table.length = 7\nhash1(10) = 3\nhash2(10) = 1 + (10 % 6) = 5\n\ni=0: 3\ni=1: (3 + 5) % 7 = 1\ni=2: (3 + 10) % 7 = 6\ni=3: (3 + 15) % 7 = 4\n```\n\n**장점:**\n- Clustering 문제 해결\n- 좋은 분포\n\n---\n\n## 3. Separate Chaining vs Open Addressing\n\n| 특성 | Chaining | Open Addressing |\n|------|----------|------------------|\n| 메모리 | 포인터 오버헤드 | 고정 크기 테이블 |\n| Load Factor | > 1 가능 | < 1 제한 |\n| 캐시 효율 | 낮음 | 높음 |\n| 삭제 | 쉬움 | 복잡 (Lazy Deletion) |\n| 성능 | 균등 | Load Factor 의존 |\n\n---\n\n**삭제 처리 (Open Addressing):**\n\n```java\nclass Entry<K, V> {\n    K key;\n    V value;\n    boolean deleted;  // Lazy deletion flag\n}\n\nvoid remove(K key) {\n    int index = findIndex(key);\n    if (index != -1) {\n        table[index].deleted = true;  // 삭제 표시\n    }\n}\n\nV get(K key) {\n    int index = hash(key);\n    \n    while (table[index] != null) {\n        if (!table[index].deleted && table[index].key.equals(key)) {\n            return table[index].value;\n        }\n        index = (index + 1) % table.length;\n    }\n    \n    return null;\n}\n```",
      "type": "essay",
      "tags": [
        "해시",
        "충돌 해결",
        "Chaining",
        "Open Addressing"
      ]
    },
    {
      "question": "본인이 사용하는 언어에서는, 어떤 방식으로 해시 충돌을 처리하나요?",
      "answer": "## Java HashMap\n\n**충돌 처리: Separate Chaining + Tree화**\n\n```java\n// Java 8 이전: 순수 Chaining\nNode<K,V>[] table;\n\nstatic class Node<K,V> {\n    final int hash;\n    final K key;\n    V value;\n    Node<K,V> next;  // 연결 리스트\n}\n\n// Java 8+: Chaining + Red-Black Tree\n// 버킷의 원소가 8개 초과 시 Tree로 변환\n// 6개 이하로 줄면 다시 List로 변환\n```\n\n**왜 Tree로 변환?**\n- 최악의 경우 O(n) → O(log n)으로 개선\n- DoS 공격 방어 (의도적 충돌 공격)\n\n**Load Factor: 0.75**\n```java\nstatic final float DEFAULT_LOAD_FACTOR = 0.75f;\n\n// 75% 차면 2배로 리사이징\nif (size > capacity * loadFactor) {\n    resize();  // capacity *= 2\n}\n```\n\n---\n\n## Python dict\n\n**충돌 처리: Open Addressing (Pseudo-random probing)**\n\n```python\n# CPython 3.6+: 순서 유지 딕셔너리\n# 내부적으로 두 배열 사용:\n# 1. indices: 해시 테이블 (Open Addressing)\n# 2. entries: 실제 키-값 쌍 배열 (삽입 순서대로)\n\nclass dict:\n    indices = [None] * capacity  # 해시 테이블\n    entries = []  # [(hash, key, value), ...]\n```\n\n**Probing 방식:**\n```python\n# Linear probing의 변형\nperturb = hash(key)\nindex = hash(key) % capacity\n\nwhile indices[index] is not None:\n    index = (5*index + 1 + perturb) % capacity\n    perturb >>= 5  # 점점 랜덤하게\n```\n\n**Load Factor: 2/3 (약 0.67)**\n```python\n# 66% 차면 2배로 리사이징\nif used > capacity * 2/3:\n    resize()\n```\n\n---\n\n## JavaScript Map/Object\n\n**Object (레거시):**\n- 구현체마다 다름 (V8, SpiderMonkey 등)\n- 주로 Hash Table + Hidden Class 최적화\n\n**Map (ES6+):**\n```javascript\nconst map = new Map();\nmap.set(key, value);  // O(1)\n\n// V8 엔진: Chaining 방식\n// 내부적으로 OrderedHashTable 사용\n// 삽입 순서 유지 + 해시 충돌 처리\n```\n\n**특징:**\n- 삽입 순서 보장\n- 모든 타입을 키로 사용 가능\n\n---\n\n## C++ std::unordered_map\n\n**충돌 처리: Separate Chaining**\n\n```cpp\ntemplate<typename Key, typename T>\nclass unordered_map {\n    vector<list<pair<Key, T>>> buckets;\n    // 각 버킷은 연결 리스트\n};\n```\n\n**Load Factor: 1.0 (기본값)**\n```cpp\nunordered_map<int, string> map;\nmap.max_load_factor();  // 1.0\n\n// 100% 차면 리사이징\nif (size() > bucket_count() * max_load_factor()) {\n    rehash();\n}\n```\n\n**사용자 정의 Load Factor:**\n```cpp\nmap.max_load_factor(0.75);  // Java처럼 0.75로 설정\n```\n\n---\n\n## 비교 표\n\n| 언어 | 충돌 처리 | Load Factor | 순서 보장 |\n|------|-----------|-------------|----------|\n| Java HashMap | Chaining + Tree | 0.75 | X |\n| Python dict | Open Addressing | 0.67 | O (3.6+) |\n| JavaScript Map | Chaining | 가변 | O |\n| C++ unordered_map | Chaining | 1.0 | X |\n\n---\n\n**각 언어의 특징:**\n\n**Java:**\n- Tree화로 최악의 경우 성능 보장\n- LinkedHashMap으로 순서 유지 가능\n\n**Python:**\n- 메모리 효율적 (Open Addressing)\n- 기본적으로 삽입 순서 유지\n\n**JavaScript:**\n- Map은 항상 삽입 순서 유지\n- Object는 숫자 키 먼저 정렬\n\n**C++:**\n- 가장 빠른 성능 (포인터 직접 제어)\n- 순서가 필요하면 `std::map` 사용",
      "type": "essay",
      "tags": [
        "해시",
        "언어별 구현",
        "Java",
        "Python",
        "JavaScript",
        "C++"
      ]
    },
    {
      "question": "Double Hashing의 장점과 단점에 대해서 설명하고, 단점을 어떻게 해결할 수 있을지 설명해 주세요.",
      "answer": "## Double Hashing\n\n**개념:**\n```java\nint h1(K key) { return key.hashCode() % M; }\nint h2(K key) { return 1 + (key.hashCode() % (M - 1)); }\n\nint probe(K key, int i) {\n    return (h1(key) + i * h2(key)) % M;\n}\n```\n\n---\n\n## 장점\n\n**1. Clustering 문제 해결**\n\nLinear Probing의 Primary Clustering 방지:\n```\nLinear Probing:\n[X] [X] [X] [_] [_]  // 연속된 군집 발생\n     ↑\n   충돌 시 바로 옆 슬롯 사용\n\nDouble Hashing:\n[X] [_] [X] [_] [X]  // 분산된 배치\n     ↑       ↑\n   h2(key)만큼 점프\n```\n\n**2. 균등한 분포**\n\n각 키마다 다른 조사 순서:\n```java\nkey1: h2 = 3 → 3, 6, 9, 12, ...\nkey2: h2 = 5 → 5, 10, 15, 20, ...\n```\n\n**3. 캐시 효율**\n\nOpen Addressing이므로:\n- 연속된 메모리 사용\n- Chaining보다 캐시 친화적\n\n---\n\n## 단점\n\n**1. 해시 함수 계산 비용**\n\n```java\n// 두 개의 해시 함수 계산 필요\nint index = h1(key);  // 첫 번째 계산\nint step = h2(key);   // 두 번째 계산\n```\n\n**해결책:**\n```java\n// 한 번만 계산하고 재사용\nint hashCode = key.hashCode();\nint h1 = hashCode % M;\nint h2 = 1 + (hashCode % (M - 1));\n```\n\n**2. 테이블 크기 제약**\n\n**문제:** h2(key)와 M이 서로소가 아니면 모든 슬롯 방문 불가\n\n```\nM = 10, h2(key) = 2\n시작 = 3\n조사 순서: 3, 5, 7, 9, 1, 3, ... (무한 루프)\n// 0, 2, 4, 6, 8은 절대 방문 안 됨!\n```\n\n**해결책 1: M을 소수로**\n```java\n// M이 소수면 h2 값과 항상 서로소\nint M = 1009;  // 소수\nint h2 = 1 + (hashCode % (M - 1));  // 1 ~ M-1\n// gcd(h2, M) = 1 보장\n```\n\n**해결책 2: h2 범위 조정**\n```java\n// h2가 1 이상이 되도록 보장\nint h2(K key) {\n    int h = key.hashCode() % (M - 1);\n    return h == 0 ? 1 : h;  // 0 방지\n}\n```\n\n**3. 삭제 복잡도**\n\n**문제:** Lazy Deletion 필요\n\n```java\nenum State { EMPTY, OCCUPIED, DELETED }\n\nclass Entry<K, V> {\n    K key;\n    V value;\n    State state;\n}\n\n// 검색 시 DELETED는 건너뛰되 계속 탐색\nV get(K key) {\n    int i = 0;\n    while (true) {\n        int index = probe(key, i++);\n        \n        if (table[index].state == EMPTY) {\n            return null;  // 못 찾음\n        }\n        \n        if (table[index].state == DELETED) {\n            continue;  // 건너뛰고 계속\n        }\n        \n        if (table[index].key.equals(key)) {\n            return table[index].value;\n        }\n    }\n}\n```\n\n**해결책: 주기적 재해싱**\n```java\nvoid compactTable() {\n    // DELETED 상태 제거하고 재배치\n    Entry<K, V>[] oldTable = table;\n    table = new Entry[capacity];\n    \n    for (Entry<K, V> entry : oldTable) {\n        if (entry.state == OCCUPIED) {\n            put(entry.key, entry.value);\n        }\n    }\n}\n```\n\n**4. Load Factor 제한**\n\n**문제:** Load Factor가 높으면 성능 급격히 저하\n\n```java\n// Load Factor > 0.7 이면 성능 나쁨\nif (size > capacity * 0.7) {\n    resize();  // 2배로 확장\n}\n```\n\n**해결책: 동적 리사이징**\n```java\nvoid resize() {\n    int newCapacity = nextPrime(capacity * 2);\n    Entry<K, V>[] oldTable = table;\n    table = new Entry[newCapacity];\n    \n    for (Entry<K, V> entry : oldTable) {\n        if (entry != null && entry.state == OCCUPIED) {\n            put(entry.key, entry.value);  // 재해싱\n        }\n    }\n}\n```\n\n---\n\n## 최적화된 구현 예시\n\n```java\nclass DoubleHashMap<K, V> {\n    private static final double MAX_LOAD_FACTOR = 0.7;\n    private int capacity;  // 항상 소수\n    private Entry<K, V>[] table;\n    \n    private int h1(K key) {\n        return Math.abs(key.hashCode()) % capacity;\n    }\n    \n    private int h2(K key) {\n        int h = Math.abs(key.hashCode()) % (capacity - 1);\n        return h == 0 ? 1 : h;  // 0 방지\n    }\n    \n    public void put(K key, V value) {\n        if (size > capacity * MAX_LOAD_FACTOR) {\n            resize();\n        }\n        \n        int hashCode = key.hashCode();  // 한 번만 계산\n        int h1 = Math.abs(hashCode) % capacity;\n        int h2 = 1 + Math.abs(hashCode) % (capacity - 1);\n        \n        for (int i = 0; i < capacity; i++) {\n            int index = (h1 + i * h2) % capacity;\n            \n            if (table[index] == null || table[index].state != OCCUPIED) {\n                table[index] = new Entry<>(key, value, OCCUPIED);\n                size++;\n                return;\n            }\n        }\n    }\n}\n```\n\n---\n\n## 결론\n\n**Double Hashing 사용 시기:**\n- Open Addressing 필요 (메모리 제약)\n- 높은 성능 필요 (캐시 효율)\n- 삭제 연산 적음\n\n**대안:**\n- 삭제가 많으면: **Chaining**\n- 구현 간단함 우선: **Linear Probing**\n- 최고 성능: **Cuckoo Hashing**",
      "type": "essay",
      "tags": [
        "Double Hashing",
        "해시",
        "충돌 해결",
        "성능 최적화"
      ]
    },
    {
      "question": "Load Factor에 대해 설명해 주세요. 본인이 사용하는 언어에서의 해시 자료구조는 Load Factor에 관련한 정책이 어떻게 구성되어 있나요?",
      "answer": "## Load Factor (적재율)\n\n**정의:**\n```\nLoad Factor (α) = 저장된 원소 개수 / 테이블 크기\n                = n / m\n```\n\n**의미:**\n- 해시 테이블이 얼마나 차 있는지를 나타내는 지표\n- 충돌 확률과 직접적으로 연관\n\n---\n\n## Load Factor와 성능\n\n**Chaining 방식:**\n```\nα = 0.5  → 평균 체인 길이: 0.5\nα = 1.0  → 평균 체인 길이: 1.0\nα = 2.0  → 평균 체인 길이: 2.0\n\n검색 시간: O(1 + α)\n```\n\n**Open Addressing 방식:**\n```\nα = 0.5  → 평균 조사 횟수: ~1.5\nα = 0.7  → 평균 조사 횟수: ~2.5\nα = 0.9  → 평균 조사 횟수: ~5.5\nα = 0.99 → 평균 조사 횟수: ~50\n\n// α가 1에 가까워질수록 급격히 느려짐\n```\n\n---\n\n## Java HashMap\n\n**기본 Load Factor: 0.75**\n\n```java\npublic class HashMap<K,V> {\n    static final float DEFAULT_LOAD_FACTOR = 0.75f;\n    static final int DEFAULT_INITIAL_CAPACITY = 16;\n    \n    // threshold = capacity * loadFactor\n    int threshold;\n    \n    public HashMap() {\n        this.loadFactor = DEFAULT_LOAD_FACTOR;\n        this.threshold = (int)(16 * 0.75);  // 12\n    }\n}\n```\n\n**리사이징 정책:**\n```java\npublic V put(K key, V value) {\n    // ...\n    if (++size > threshold) {\n        resize();  // 2배로 확장\n    }\n    return null;\n}\n\nfinal Node<K,V>[] resize() {\n    int oldCap = table.length;\n    int newCap = oldCap << 1;  // 2배\n    threshold = (int)(newCap * loadFactor);\n    \n    // 모든 원소 재해싱\n    Node<K,V>[] newTab = new Node[newCap];\n    // ... rehashing logic\n    return newTab;\n}\n```\n\n**왜 0.75?**\n- 0.75는 시간-공간 트레이드오프의 최적값\n- 너무 낮으면: 메모리 낭비\n- 너무 높으면: 충돌 증가, 성능 저하\n\n**사용자 정의 Load Factor:**\n```java\n// 메모리 중요 시\nMap<K,V> map = new HashMap<>(16, 0.9f);\n\n// 성능 중요 시\nMap<K,V> map = new HashMap<>(16, 0.5f);\n```\n\n---\n\n## Python dict\n\n**Load Factor: 2/3 (약 0.67)**\n\n```python\n# CPython 내부 구현\n#define USABLE_FRACTION(n) (((n) << 1) / 3)\n\n# 66.7% 차면 리사이징\nif (mp->ma_used > mp->ma_mask * 2/3):\n    dictresize(mp)\n```\n\n**리사이징 정책:**\n```python\n# 크기에 따라 증가 배수 다름\nif size < 50000:\n    new_size = size * 4  # 4배\nelse:\n    new_size = size * 2  # 2배\n```\n\n**특징:**\n- Java보다 낮은 Load Factor (더 공격적)\n- 메모리보다 속도 우선\n- 삽입 순서 유지를 위한 추가 구조\n\n---\n\n## JavaScript (V8 Engine)\n\n**Object:**\n```javascript\n// Hidden Class 최적화\n// Load Factor 정책은 엔진마다 다름\n// V8: 대략 0.75 사용\n```\n\n**Map:**\n```javascript\nconst map = new Map();\n\n// OrderedHashTable 사용\n// Load Factor: 약 1.0\n// 100% 차면 리사이징\n```\n\n---\n\n## C++ std::unordered_map\n\n**기본 Load Factor: 1.0**\n\n```cpp\nstd::unordered_map<int, string> map;\n\nstd::cout << map.max_load_factor();  // 1.0\nstd::cout << map.load_factor();      // 현재 적재율\n\n// 현재 상태\nstd::cout << map.size();             // 원소 개수\nstd::cout << map.bucket_count();     // 버킷 개수\n```\n\n**사용자 정의:**\n```cpp\nmap.max_load_factor(0.75);  // Java처럼 설정\n\n// 수동 리사이징\nmap.reserve(1000);  // 최소 1000개 수용 가능하도록\nmap.rehash(100);    // 버킷 개수를 100개로\n```\n\n**리사이징 정책:**\n```cpp\n// GCC libstdc++ 구현\nif (size() > bucket_count() * max_load_factor()) {\n    rehash(bucket_count() * 2);  // 2배\n}\n```\n\n---\n\n## 언어별 비교\n\n| 언어 | Load Factor | 리사이징 배수 | 비고 |\n|------|-------------|---------------|------|\n| Java | 0.75 | 2배 | 균형잡힌 설정 |\n| Python | 0.67 | 4배 (작을 때), 2배 (클 때) | 속도 우선 |\n| C++ | 1.0 | 2배 | 메모리 효율 |\n| JavaScript | ~0.75 ~ 1.0 | 엔진마다 다름 | 구현체 의존 |\n\n---\n\n## 최적 Load Factor 선택\n\n**Chaining 방식:**\n```java\n// 일반적으로 0.75 ~ 1.0\n// α = 1.0이어도 성능 괜찮음\nLoadFactor = 0.75;  // 추천\n```\n\n**Open Addressing 방식:**\n```java\n// 반드시 < 1.0\n// 0.5 ~ 0.7 추천\nLoadFactor = 0.6;  // 안정적\n```\n\n**성능 테스트 예시:**\n```java\n// 100만 개 삽입 테스트\nLoadFactor 0.5: 150ms, 메모리 20MB\nLoadFactor 0.75: 180ms, 메모리 15MB  // 균형\nLoadFactor 0.9: 250ms, 메모리 12MB\nLoadFactor 1.0: 400ms, 메모리 10MB\n```",
      "type": "essay",
      "tags": [
        "Load Factor",
        "해시",
        "성능",
        "메모리"
      ]
    },
    {
      "question": "다른 자료구조와 비교하여, 해시 테이블은 멀티스레드 환경에서 심각한 수준의 Race Condition 문제에 빠질 위험이 있습니다. 성능 감소를 최소화 한 채로 해당 문제를 해결할 수 있는 방법을 설계해 보세요.",
      "answer": "## 해시 테이블의 멀티스레드 문제\n\n**Race Condition 발생 시나리오:**\n\n```java\n// Thread 1: put(\"A\", 1)\n// Thread 2: put(\"B\", 2)\n// 동시에 같은 버킷 수정 → 데이터 손실\n\n// Thread 1: resize() 진행 중\n// Thread 2: get(\"key\") 호출\n// → 일관성 없는 데이터 읽기\n```\n\n---\n\n## 해결 방법\n\n### 1. 전체 테이블 락 (Coarse-grained Locking)\n\n```java\nclass SynchronizedHashMap<K, V> {\n    private Map<K, V> map = new HashMap<>();\n    \n    public synchronized void put(K key, V value) {\n        map.put(key, value);\n    }\n    \n    public synchronized V get(K key) {\n        return map.get(key);\n    }\n}\n```\n\n**장점:** 구현 간단  \n**단점:** 모든 스레드가 순차 실행 → 병렬성 0\n\n---\n\n### 2. 버킷별 락 (Fine-grained Locking)\n\n```java\nclass BucketLockedHashMap<K, V> {\n    private static final int BUCKET_COUNT = 16;\n    private List<Entry<K, V>>[] buckets = new List[BUCKET_COUNT];\n    private ReentrantLock[] locks = new ReentrantLock[BUCKET_COUNT];\n    \n    public BucketLockedHashMap() {\n        for (int i = 0; i < BUCKET_COUNT; i++) {\n            buckets[i] = new ArrayList<>();\n            locks[i] = new ReentrantLock();\n        }\n    }\n    \n    public void put(K key, V value) {\n        int bucket = hash(key) % BUCKET_COUNT;\n        locks[bucket].lock();\n        try {\n            // 버킷 내 검색 및 삽입\n            for (Entry<K, V> entry : buckets[bucket]) {\n                if (entry.key.equals(key)) {\n                    entry.value = value;\n                    return;\n                }\n            }\n            buckets[bucket].add(new Entry<>(key, value));\n        } finally {\n            locks[bucket].unlock();\n        }\n    }\n}\n```\n\n**장점:** 다른 버킷 동시 접근 가능  \n**단점:** 리사이징 시 모든 락 필요\n\n---\n\n### 3. Lock-Free (CAS 기반)\n\n**Compare-And-Swap 활용:**\n\n```java\nclass LockFreeHashMap<K, V> {\n    private AtomicReferenceArray<Node<K, V>> table;\n    \n    static class Node<K, V> {\n        final K key;\n        volatile V value;\n        volatile Node<K, V> next;\n    }\n    \n    public void put(K key, V value) {\n        int index = hash(key);\n        \n        while (true) {\n            Node<K, V> head = table.get(index);\n            \n            // 기존 키 찾기\n            Node<K, V> node = head;\n            while (node != null) {\n                if (node.key.equals(key)) {\n                    node.value = value;  // volatile write\n                    return;\n                }\n                node = node.next;\n            }\n            \n            // 새 노드 추가 (CAS)\n            Node<K, V> newNode = new Node<>(key, value);\n            newNode.next = head;\n            \n            if (table.compareAndSet(index, head, newNode)) {\n                return;  // 성공\n            }\n            // 실패 시 재시도\n        }\n    }\n}\n```\n\n**장점:** 락 오버헤드 없음  \n**단점:** ABA 문제, 복잡한 구현\n\n---\n\n### 4. Striped Locking (세그먼트 락)\n\n**Java ConcurrentHashMap 방식:**\n\n```java\nclass StripedHashMap<K, V> {\n    private static final int STRIPE_COUNT = 32;\n    \n    private Segment<K, V>[] segments = new Segment[STRIPE_COUNT];\n    \n    static class Segment<K, V> {\n        private ReentrantLock lock = new ReentrantLock();\n        private Map<K, V> map = new HashMap<>();\n        \n        public void put(K key, V value) {\n            lock.lock();\n            try {\n                map.put(key, value);\n            } finally {\n                lock.unlock();\n            }\n        }\n    }\n    \n    public void put(K key, V value) {\n        int segment = hash(key) % STRIPE_COUNT;\n        segments[segment].put(key, value);\n    }\n}\n```\n\n**장점:** 병렬성 증가 (최대 32개 스레드 동시 실행)  \n**단점:** 세그먼트 수만큼만 병렬 가능\n\n---\n\n### 5. 최적 설계: Lock-Free + Optimistic Read\n\n**Java 8+ ConcurrentHashMap 방식:**\n\n```java\nclass OptimizedConcurrentHashMap<K, V> {\n    private volatile Node<K, V>[] table;\n    \n    static class Node<K, V> {\n        final int hash;\n        final K key;\n        volatile V value;\n        volatile Node<K, V> next;\n    }\n    \n    // CAS를 이용한 버킷 헤드 업데이트\n    private static final VarHandle TABLE;\n    \n    public V get(K key) {\n        Node<K, V>[] tab = table;\n        Node<K, V> node = tabAt(tab, hash(key));\n        \n        // Lock-Free Read\n        while (node != null) {\n            if (node.key.equals(key)) {\n                return node.value;\n            }\n            node = node.next;\n        }\n        return null;\n    }\n    \n    public void put(K key, V value) {\n        int hash = hash(key);\n        Node<K, V>[] tab = table;\n        \n        for (;;) {\n            Node<K, V> f = tabAt(tab, hash);\n            \n            if (f == null) {\n                // 빈 버킷: CAS로 추가\n                if (casTabAt(tab, hash, null, new Node<>(key, value))) {\n                    break;\n                }\n            } else {\n                // 버킷에 노드 있음: synchronized로 보호\n                synchronized (f) {\n                    // Double-check\n                    if (tabAt(tab, hash) == f) {\n                        // 체이닝 로직\n                        Node<K, V> node = f;\n                        while (true) {\n                            if (node.key.equals(key)) {\n                                node.value = value;\n                                break;\n                            }\n                            if (node.next == null) {\n                                node.next = new Node<>(key, value);\n                                break;\n                            }\n                            node = node.next;\n                        }\n                    }\n                }\n                break;\n            }\n        }\n    }\n}\n```\n\n**핵심 아이디어:**\n1. **읽기**: 완전 Lock-Free (volatile read)\n2. **쓰기 (빈 버킷)**: CAS로 Lock-Free\n3. **쓰기 (충돌)**: 버킷 헤드만 synchronized\n\n**장점:**\n- 읽기 성능 극대화\n- 쓰기도 대부분 Lock-Free\n- 충돌 시에만 최소한의 락\n\n---\n\n## 리사이징 처리\n\n**점진적 리사이징 (Incremental Resize):**\n\n```java\n// 한 번에 모든 버킷 이동 X\n// 각 연산마다 일부 버킷만 이동\npublic V get(K key) {\n    // 리사이징 중이면 1~2개 버킷 이동 도움\n    helpTransfer();\n    \n    // 실제 get 로직\n    return getValue(key);\n}\n```\n\n---\n\n## 성능 비교\n\n**16 스레드, 100만 연산 기준:**\n\n| 방식 | 처리량 (ops/sec) | 특징 |\n|------|------------------|------|\n| Synchronized | 100K | 순차 실행 |\n| Bucket Lock (16) | 800K | 버킷 수만큼 병렬 |\n| Striped (32) | 1.5M | 세그먼트 수만큼 병렬 |\n| ConcurrentHashMap | 3.5M | Lock-Free Read |\n\n---\n\n## 실전 사용\n\n**Java:**\n```java\nConcurrentHashMap<K, V> map = new ConcurrentHashMap<>();\nmap.put(key, value);  // Thread-Safe\n```\n\n**Python:**\n```python\nimport threading\n\nclass ThreadSafeDict:\n    def __init__(self):\n        self.dict = {}\n        self.lock = threading.RLock()\n    \n    def put(self, key, value):\n        with self.lock:\n            self.dict[key] = value\n```\n\n**C++:**\n```cpp\n#include <shared_mutex>\n\ntemplate<typename K, typename V>\nclass ConcurrentMap {\n    std::unordered_map<K, V> map;\n    mutable std::shared_mutex mutex;\n    \npublic:\n    V get(K key) {\n        std::shared_lock lock(mutex);  // 읽기 락\n        return map[key];\n    }\n    \n    void put(K key, V value) {\n        std::unique_lock lock(mutex);  // 쓰기 락\n        map[key] = value;\n    }\n};\n```",
      "type": "essay",
      "tags": [
        "멀티스레드",
        "Thread Safe",
        "해시",
        "동시성",
        "ConcurrentHashMap"
      ]
    },
    {
      "question": "트리와 이진트리, 이진탐색트리에 대해 설명해 주세요.",
      "answer": "## 트리 (Tree)\n\n**정의:**  \n계층적 구조를 가진 비선형 자료구조. 하나의 루트 노드에서 시작하여 부모-자식 관계로 연결됩니다.\n\n**기본 용어:**\n```\n         1         ← Root (루트)\n       /   \\\n      2     3       ← Internal Node (내부 노드)\n     / \\     \\\n    4   5     6     ← Leaf (리프)\n\n- 노드 (Node): 트리의 각 원소\n- 간선 (Edge): 노드 간의 연결\n- 루트 (Root): 최상위 노드\n- 리프 (Leaf): 자식이 없는 노드\n- 높이 (Height): 루트부터 가장 깊은 리프까지의 거리\n- 깊이 (Depth): 루트부터 특정 노드까지의 거리\n- 서브트리 (Subtree): 특정 노드를 루트로 하는 트리\n```\n\n**트리의 성질:**\n- N개의 노드 → N-1개의 간선\n- 사이클이 없음 (Acyclic)\n- 임의의 두 노드 사이에 경로는 유일\n\n---\n\n## 이진트리 (Binary Tree)\n\n**정의:**  \n각 노드가 **최대 2개의 자식**만 가지는 트리\n\n**기본 구조:**\n\n```java\nclass TreeNode {\n    int value;\n    TreeNode left;   // 왼쪽 자식\n    TreeNode right;  // 오른쪽 자식\n    \n    TreeNode(int value) {\n        this.value = value;\n    }\n}\n```\n\n**이진트리 종류:**\n\n**1. Full Binary Tree (정 이진트리)**\n```\n       1\n     /   \\\n    2     3\n   / \\   / \\\n  4   5 6   7\n\n// 모든 노드가 0개 또는 2개의 자식\n```\n\n**2. Complete Binary Tree (완전 이진트리)**\n```\n       1\n     /   \\\n    2     3\n   / \\   /\n  4   5 6\n\n// 마지막 레벨 제외, 모든 레벨이 꽉 참\n// 마지막 레벨은 왼쪽부터 채워짐\n```\n\n**3. Perfect Binary Tree (포화 이진트리)**\n```\n       1\n     /   \\\n    2     3\n   / \\   / \\\n  4   5 6   7\n\n// 모든 리프가 같은 레벨\n// 높이 h → 노드 개수: 2^(h+1) - 1\n```\n\n**4. Skewed Binary Tree (편향 이진트리)**\n```\n    1\n     \\\n      2\n       \\\n        3\n         \\\n          4\n\n// 한쪽으로만 치우침\n// 최악의 경우 (연결 리스트와 동일)\n```\n\n**이진트리 순회:**\n\n```java\n// 전위 순회 (Pre-order): Root → Left → Right\nvoid preorder(TreeNode node) {\n    if (node == null) return;\n    System.out.print(node.value + \" \");\n    preorder(node.left);\n    preorder(node.right);\n}\n\n// 중위 순회 (In-order): Left → Root → Right\nvoid inorder(TreeNode node) {\n    if (node == null) return;\n    inorder(node.left);\n    System.out.print(node.value + \" \");\n    inorder(node.right);\n}\n\n// 후위 순회 (Post-order): Left → Right → Root\nvoid postorder(TreeNode node) {\n    if (node == null) return;\n    postorder(node.left);\n    postorder(node.right);\n    System.out.print(node.value + \" \");\n}\n```\n\n**예시:**\n```\n     4\n   /   \\\n  2     6\n / \\   / \\\n1   3 5   7\n\nPreorder:  4 2 1 3 6 5 7\nInorder:   1 2 3 4 5 6 7  ← 정렬된 순서!\nPostorder: 1 3 2 5 7 6 4\n```\n\n---\n\n## 이진탐색트리 (Binary Search Tree, BST)\n\n**정의:**  \n모든 노드가 다음 조건을 만족하는 이진트리:\n1. **왼쪽 서브트리**의 모든 값 < **현재 노드 값**\n2. **오른쪽 서브트리**의 모든 값 > **현재 노드 값**\n3. 왼쪽과 오른쪽 서브트리도 각각 BST\n\n**예시:**\n```\n       8\n     /   \\\n    3     10\n   / \\      \\\n  1   6      14\n     / \\    /\n    4   7  13\n\nBST 조건 체크:\n- 8의 왼쪽: 3, 1, 6, 4, 7 (모두 < 8) ✓\n- 8의 오른쪽: 10, 14, 13 (모두 > 8) ✓\n```\n\n**BST 연산:**\n\n**1. 검색 (Search): O(h)**\n```java\nTreeNode search(TreeNode node, int target) {\n    if (node == null || node.value == target) {\n        return node;\n    }\n    \n    if (target < node.value) {\n        return search(node.left, target);\n    } else {\n        return search(node.right, target);\n    }\n}\n```\n\n**2. 삽입 (Insert): O(h)**\n```java\nTreeNode insert(TreeNode node, int value) {\n    if (node == null) {\n        return new TreeNode(value);\n    }\n    \n    if (value < node.value) {\n        node.left = insert(node.left, value);\n    } else if (value > node.value) {\n        node.right = insert(node.right, value);\n    }\n    \n    return node;\n}\n```\n\n**3. 삭제 (Delete): O(h)**\n```java\nTreeNode delete(TreeNode node, int value) {\n    if (node == null) return null;\n    \n    if (value < node.value) {\n        node.left = delete(node.left, value);\n    } else if (value > node.value) {\n        node.right = delete(node.right, value);\n    } else {\n        // Case 1: 리프 노드\n        if (node.left == null && node.right == null) {\n            return null;\n        }\n        // Case 2: 자식 1개\n        if (node.left == null) return node.right;\n        if (node.right == null) return node.left;\n        \n        // Case 3: 자식 2개\n        // → 오른쪽 서브트리의 최솟값으로 대체\n        TreeNode min = findMin(node.right);\n        node.value = min.value;\n        node.right = delete(node.right, min.value);\n    }\n    \n    return node;\n}\n```\n\n**시간복잡도:**\n- 평균: O(log n)\n- 최악: O(n) (편향 트리)\n\n**비교:**\n\n| 연산 | 배열 (정렬) | 연결 리스트 | BST (평균) | BST (최악) |\n|------|-------------|-------------|------------|------------|\n| 검색 | O(log n) | O(n) | O(log n) | O(n) |\n| 삽입 | O(n) | O(1) | O(log n) | O(n) |\n| 삭제 | O(n) | O(n) | O(log n) | O(n) |\n\n**장점:**\n- 정렬된 데이터 유지\n- 빠른 검색, 삽입, 삭제 (평균)\n\n**단점:**\n- 편향 시 성능 저하 → BBST로 해결 (AVL, Red-Black Tree)",
      "type": "essay",
      "tags": [
        "트리",
        "이진트리",
        "이진탐색트리",
        "BST"
      ]
    },
    {
      "question": "이진탐색트리에서 중위 탐색을 하게 되면, 그 결과는 어떤 의미를 가지나요?",
      "answer": "## 중위 탐색 (In-order Traversal)\n\n**정의:**  \n**Left → Root → Right** 순서로 트리를 순회\n\n```java\nvoid inorder(TreeNode node) {\n    if (node == null) return;\n    inorder(node.left);           // 왼쪽 서브트리\n    System.out.print(node.value + \" \");  // 현재 노드\n    inorder(node.right);          // 오른쪽 서브트리\n}\n```\n\n---\n\n## BST에서 중위 탐색의 의미\n\n**핵심: 중위 탐색 결과 = 오름차순 정렬**\n\n**예시:**\n```\n       8\n     /   \\\n    3     10\n   / \\      \\\n  1   6      14\n     / \\    /\n    4   7  13\n\n중위 탐색 결과: 1 3 4 6 7 8 10 13 14\n→ 오름차순으로 정렬됨!\n```\n\n**증명:**\n\nBST의 성질:\n- 왼쪽 서브트리의 모든 값 < 현재 노드\n- 오른쪽 서브트리의 모든 값 > 현재 노드\n\n중위 탐색 순서:\n1. 왼쪽 서브트리 방문 (현재 노드보다 작은 값들)\n2. 현재 노드 방문\n3. 오른쪽 서브트리 방문 (현재 노드보다 큰 값들)\n\n→ **작은 값 → 중간 값 → 큰 값** 순서로 방문\n\n---\n\n## 실전 활용\n\n**1. BST 검증**\n\n```java\n// BST가 올바른지 확인\nboolean isBST(TreeNode root) {\n    List<Integer> result = new ArrayList<>();\n    inorder(root, result);\n    \n    // 오름차순인지 확인\n    for (int i = 1; i < result.size(); i++) {\n        if (result.get(i) <= result.get(i - 1)) {\n            return false;  // BST 아님\n        }\n    }\n    return true;\n}\n\nvoid inorder(TreeNode node, List<Integer> result) {\n    if (node == null) return;\n    inorder(node.left, result);\n    result.add(node.value);\n    inorder(node.right, result);\n}\n```\n\n**2. K번째 작은 원소 찾기**\n\n```java\n// BST에서 K번째 작은 원소 찾기\nclass Solution {\n    private int count = 0;\n    private int result = -1;\n    \n    int kthSmallest(TreeNode root, int k) {\n        inorder(root, k);\n        return result;\n    }\n    \n    void inorder(TreeNode node, int k) {\n        if (node == null) return;\n        \n        inorder(node.left, k);\n        \n        count++;\n        if (count == k) {\n            result = node.value;  // K번째 원소\n            return;\n        }\n        \n        inorder(node.right, k);\n    }\n}\n```\n\n**예시:**\n```\n     5\n   /   \\\n  3     7\n / \\   / \\\n2   4 6   8\n\n중위 탐색: 2 3 4 5 6 7 8\n\nkthSmallest(root, 1) → 2\nkthSmallest(root, 3) → 4\nkthSmallest(root, 5) → 6\n```\n\n**3. 범위 내 원소 찾기**\n\n```java\n// [low, high] 범위 내 모든 원소 찾기\nList<Integer> rangeBST(TreeNode root, int low, int high) {\n    List<Integer> result = new ArrayList<>();\n    inorderRange(root, low, high, result);\n    return result;\n}\n\nvoid inorderRange(TreeNode node, int low, int high, List<Integer> result) {\n    if (node == null) return;\n    \n    // 왼쪽 서브트리 탐색 (node.value > low인 경우만)\n    if (node.value > low) {\n        inorderRange(node.left, low, high, result);\n    }\n    \n    // 현재 노드가 범위 내라면 추가\n    if (node.value >= low && node.value <= high) {\n        result.add(node.value);\n    }\n    \n    // 오른쪽 서브트리 탐색 (node.value < high인 경우만)\n    if (node.value < high) {\n        inorderRange(node.right, low, high, result);\n    }\n}\n```\n\n**4. BST를 정렬된 배열로 변환**\n\n```java\nint[] BSTtoArray(TreeNode root) {\n    List<Integer> list = new ArrayList<>();\n    inorder(root, list);\n    \n    // List → Array\n    return list.stream().mapToInt(i -> i).toArray();\n}\n```\n\n**5. 정렬된 배열 → BST 변환**\n\n```java\n// 정렬된 배열을 균형 BST로 변환\nTreeNode sortedArrayToBST(int[] nums) {\n    return build(nums, 0, nums.length - 1);\n}\n\nTreeNode build(int[] nums, int left, int right) {\n    if (left > right) return null;\n    \n    int mid = left + (right - left) / 2;\n    TreeNode node = new TreeNode(nums[mid]);\n    \n    node.left = build(nums, left, mid - 1);\n    node.right = build(nums, mid + 1, right);\n    \n    return node;\n}\n```\n\n**예시:**\n```\n배열: [1, 2, 3, 4, 5, 6, 7]\n\n생성된 균형 BST:\n       4\n     /   \\\n    2     6\n   / \\   / \\\n  1   3 5   7\n\n중위 탐색: 1 2 3 4 5 6 7 (원래 배열과 동일)\n```\n\n---\n\n## 다른 순회와 비교\n\n```\n       8\n     /   \\\n    3     10\n   / \\      \\\n  1   6      14\n\n중위 (In-order):   1 3 6 8 10 14  ← 정렬됨!\n전위 (Pre-order):  8 3 1 6 10 14  ← 트리 복원 가능\n후위 (Post-order): 1 6 3 14 10 8  ← 삭제 순서\n```\n\n**용도:**\n- **중위**: 정렬된 순서 출력\n- **전위**: 트리 직렬화/복사\n- **후위**: 트리 삭제/평가\n\n---\n\n## 시간/공간 복잡도\n\n**시간복잡도:** O(n)  \n- 모든 노드를 한 번씩 방문\n\n**공간복잡도:** O(h)  \n- 재귀 스택 깊이 = 트리 높이\n- 균형 트리: O(log n)\n- 편향 트리: O(n)\n\n**반복문 구현 (스택 사용):**\n\n```java\nvoid inorderIterative(TreeNode root) {\n    Stack<TreeNode> stack = new Stack<>();\n    TreeNode current = root;\n    \n    while (current != null || !stack.isEmpty()) {\n        // 왼쪽 끝까지 이동\n        while (current != null) {\n            stack.push(current);\n            current = current.left;\n        }\n        \n        // 현재 노드 처리\n        current = stack.pop();\n        System.out.print(current.value + \" \");\n        \n        // 오른쪽으로 이동\n        current = current.right;\n    }\n}\n```",
      "type": "essay",
      "tags": [
        "이진탐색트리",
        "중위 탐색",
        "In-order",
        "순회"
      ]
    },
    {
      "question": "이진탐색트리의 주요 연산에 대한 시간복잡도를 설명하고, 왜 그런 시간복잡도가 도출되는지 설명해 주세요.",
      "answer": "## 이진탐색트리 (BST) 주요 연산\n\n### 1. 검색 (Search)\n\n**시간복잡도:**\n- **평균**: O(log n)\n- **최악**: O(n)\n- **최선**: O(1)\n\n**구현:**\n```java\nTreeNode search(TreeNode node, int target) {\n    if (node == null || node.value == target) {\n        return node;  // 최선: O(1)\n    }\n    \n    if (target < node.value) {\n        return search(node.left, target);  // 왼쪽으로\n    } else {\n        return search(node.right, target); // 오른쪽으로\n    }\n}\n```\n\n**왜 O(log n)?**\n\n```\n균형 BST (높이 h = log n):\n           8\n         /   \\\n        4     12\n       / \\   / \\\n      2   6 10  14\n\n검색: 14 찾기\n1. 8과 비교 → 오른쪽\n2. 12와 비교 → 오른쪽\n3. 14 찾음!\n\n최대 비교 횟수 = 트리 높이 = log₂(n)\n```\n\n**왜 최악이 O(n)?**\n\n```\n편향 BST (높이 h = n):\n    1\n     \\\n      2\n       \\\n        3\n         \\\n          4\n\n검색: 4 찾기\n1 → 2 → 3 → 4 (연결 리스트와 동일)\n\n최대 비교 횟수 = n\n```\n\n---\n\n### 2. 삽입 (Insert)\n\n**시간복잡도:**\n- **평균**: O(log n)\n- **최악**: O(n)\n\n**구현:**\n```java\nTreeNode insert(TreeNode node, int value) {\n    // 1. 빈 위치 찾기: O(h)\n    if (node == null) {\n        return new TreeNode(value);  // 2. 삽입: O(1)\n    }\n    \n    if (value < node.value) {\n        node.left = insert(node.left, value);\n    } else if (value > node.value) {\n        node.right = insert(node.right, value);\n    }\n    \n    return node;\n}\n```\n\n**왜 O(log n)?**\n\n```\n삽입 과정 = 검색 + 노드 생성\n\n1. 삽입 위치 찾기: O(h) = O(log n)\n2. 노드 생성: O(1)\n\n전체: O(log n) + O(1) = O(log n)\n```\n\n---\n\n### 3. 삭제 (Delete)\n\n**시간복잡도:**\n- **평균**: O(log n)\n- **최악**: O(n)\n\n**구현:**\n```java\nTreeNode delete(TreeNode node, int value) {\n    if (node == null) return null;\n    \n    // 1. 삭제할 노드 찾기: O(h)\n    if (value < node.value) {\n        node.left = delete(node.left, value);\n    } else if (value > node.value) {\n        node.right = delete(node.right, value);\n    } else {\n        // 2. 삭제 처리: O(1) or O(h)\n        \n        // Case 1: 리프 노드 - O(1)\n        if (node.left == null && node.right == null) {\n            return null;\n        }\n        \n        // Case 2: 자식 1개 - O(1)\n        if (node.left == null) return node.right;\n        if (node.right == null) return node.left;\n        \n        // Case 3: 자식 2개 - O(h)\n        // 오른쪽 서브트리의 최솟값 찾기\n        TreeNode min = findMin(node.right);  // O(h)\n        node.value = min.value;\n        node.right = delete(node.right, min.value);\n    }\n    \n    return node;\n}\n\n// 최솟값 찾기: O(h)\nTreeNode findMin(TreeNode node) {\n    while (node.left != null) {\n        node = node.left;\n    }\n    return node;\n}\n```\n\n**왜 O(log n)?**\n\n```\n삭제 과정:\n1. 노드 찾기: O(h)\n2. Case 3의 경우:\n   - 후계자 찾기: O(h)\n   - 후계자 삭제: O(h)\n\n전체: O(h) + O(h) = O(h) = O(log n)\n```\n\n---\n\n### 4. 최솟값/최댓값 찾기\n\n**시간복잡도:**\n- **평균**: O(log n)\n- **최악**: O(n)\n\n**구현:**\n```java\n// 최솟값: 왼쪽 끝\nint findMin(TreeNode node) {\n    while (node.left != null) {\n        node = node.left;\n    }\n    return node.value;\n}\n\n// 최댓값: 오른쪽 끝\nint findMax(TreeNode node) {\n    while (node.right != null) {\n        node = node.right;\n    }\n    return node.value;\n}\n```\n\n**왜 O(log n)?**\n\n```\n균형 BST:\n       8\n     /   \\\n    4     12\n   /\n  2\n /\n1    ← 최솟값 (높이만큼 탐색)\n\n탐색 횟수 = 트리 높이 = log n\n```\n\n---\n\n### 5. 중위 순회 (Inorder Traversal)\n\n**시간복잡도:** O(n)  \n**공간복잡도:** O(h) (재귀 스택)\n\n**구현:**\n```java\nvoid inorder(TreeNode node) {\n    if (node == null) return;\n    inorder(node.left);   // n/2 노드\n    visit(node);          // O(1)\n    inorder(node.right);  // n/2 노드\n}\n```\n\n**왜 O(n)?**\n\n```\n모든 노드를 정확히 한 번씩 방문\n\nT(n) = T(n/2) + T(n/2) + O(1)\n     = 2 * T(n/2) + O(1)\n     = O(n)  // Master Theorem\n```\n\n---\n\n## 시간복잡도 비교표\n\n| 연산 | 평균 (균형) | 최악 (편향) | 최선 |\n|------|-------------|-------------|------|\n| 검색 | O(log n) | O(n) | O(1) |\n| 삽입 | O(log n) | O(n) | O(log n) |\n| 삭제 | O(log n) | O(n) | O(log n) |\n| 최솟값/최댓값 | O(log n) | O(n) | O(1) |\n| 순회 | O(n) | O(n) | O(n) |\n\n---\n\n## 높이와 시간복잡도 관계\n\n**핵심: 모든 연산의 시간복잡도 = O(h)**\n\n**균형 트리 (h = log n):**\n```\n완전 이진트리:\n       1\n     /   \\\n    2     3\n   / \\   / \\\n  4   5 6   7\n / \\\n8   9\n\nn = 9\nh = log₂(9) ≈ 3.17 → 높이 = 3\n\n연산 시간 = O(3) = O(log 9)\n```\n\n**편향 트리 (h = n):**\n```\n1\n \\\n  2\n   \\\n    3\n     \\\n      4\n\nn = 4\nh = 4\n\n연산 시간 = O(4) = O(n)\n```\n\n---\n\n## 공간복잡도\n\n**저장 공간:** O(n)\n- n개 노드 저장\n\n**재귀 호출 스택:** O(h)\n- 검색, 삽입, 삭제 모두 재귀 깊이 = 트리 높이\n- 균형 트리: O(log n)\n- 편향 트리: O(n)\n\n**반복문 구현 시:** O(1)\n```java\n// 반복문으로 검색 - 스택 불필요\nTreeNode searchIterative(TreeNode node, int target) {\n    while (node != null && node.value != target) {\n        if (target < node.value) {\n            node = node.left;\n        } else {\n            node = node.right;\n        }\n    }\n    return node;\n}\n```\n\n---\n\n## 다른 자료구조와 비교\n\n| 자료구조 | 검색 | 삽입 | 삭제 | 공간 |\n|----------|------|------|------|------|\n| 배열 (정렬) | O(log n) | O(n) | O(n) | O(n) |\n| 연결 리스트 | O(n) | O(1)* | O(n) | O(n) |\n| BST (평균) | O(log n) | O(log n) | O(log n) | O(n) |\n| BST (최악) | O(n) | O(n) | O(n) | O(n) |\n| AVL/Red-Black | O(log n) | O(log n) | O(log n) | O(n) |\n| 해시 테이블 | O(1) | O(1) | O(1) | O(n) |\n\n*연결 리스트 삽입은 위치를 알고 있을 때 O(1)\n\n---\n\n## 성능 개선: BBST (Balanced Binary Search Tree)\n\n**문제:** 편향 시 O(n)\n\n**해결:** 자동으로 균형 유지\n\n```\nAVL Tree, Red-Black Tree:\n- 삽입/삭제 시 자동 회전\n- 모든 연산 보장: O(log n)\n\n예: Java TreeMap, C++ std::map\n```",
      "type": "essay",
      "tags": [
        "이진탐색트리",
        "시간복잡도",
        "성능 분석",
        "BST"
      ]
    },
    {
      "question": "이진탐색트리의 한계점에 대해 설명해주세요.",
      "answer": "## 이진탐색트리 (BST)의 한계점\n\n### 1. 편향 (Skew) 문제\n\n**최대 한계점: 정렬된 데이터 삽입 시 연결 리스트로 퇴화**\n\n```java\n// 1, 2, 3, 4, 5를 순서대로 삽입\nBST tree = new BST();\ntree.insert(1);\ntree.insert(2);\ntree.insert(3);\ntree.insert(4);\ntree.insert(5);\n\n// 결과: 오른쪽 편향 트리\n1\n \\\n  2\n   \\\n    3\n     \\\n      4\n       \\\n        5\n\n높이: 5 (n)\n검색 시간: O(n) ← BST의 장점 상실!\n```\n\n**비교:**\n```\n균형 BST (높이 log n):\n       3\n     /   \\\n    2     5\n   /     /\n  1     4\n\n검색 시간: O(log 5) ≈ O(2.3)\n\nVS\n\n편향 BST (높이 n):\n1 → 2 → 3 → 4 → 5\n\n검색 시간: O(5)\n```\n\n**언제 발생?**\n- 정렬된 데이터 삽입\n- 역순 정렬된 데이터 삽입\n- 특정 패턴의 데이터\n\n---\n\n### 2. 삽입 순서 의존성\n\n**같은 데이터, 다른 트리 구조:**\n\n```java\n// Case 1: [3, 1, 5, 2, 4]\n       3\n     /   \\\n    1     5\n     \\   /\n      2 4\n높이: 2\n\n// Case 2: [1, 2, 3, 4, 5]\n1\n \\\n  2\n   \\\n    3\n     \\\n      4\n       \\\n        5\n높이: 5\n\n// 동일한 데이터, 다른 성능!\n```\n\n**문제:**\n- 삽입 순서에 따라 성능이 크게 달라짐\n- 예측 불가능한 성능\n\n---\n\n### 3. 균형 유지 불가\n\n**일반 BST는 자동 균형 유지 X:**\n\n```java\n// 삽입: [50, 25, 75, 10, 30, 60, 80]\n        50\n      /    \\\n    25      75\n   /  \\    /  \\\n  10  30  60  80\n\n// 60 삭제 후:\n        50\n      /    \\\n    25      75\n   /  \\      \\\n  10  30     80\n\n// 여전히 균형이지만, 보장은 안 됨\n\n// 10, 30 삭제 후:\n        50\n      /    \\\n    25      75\n             \\\n             80\n\n// 오른쪽으로 편향 시작\n```\n\n---\n\n### 4. 메모리 오버헤드\n\n**각 노드마다 2개의 포인터 필요:**\n\n```java\nclass TreeNode {\n    int value;         // 4 bytes (int)\n    TreeNode left;     // 8 bytes (포인터)\n    TreeNode right;    // 8 bytes (포인터)\n    // 총: 20 bytes\n}\n\n// 배열: int[n]\nint[] array = new int[100];\n// 총: 4 * 100 = 400 bytes\n\n// BST: TreeNode[n]\nBST tree = new BST();\nfor (int i = 0; i < 100; i++) tree.insert(i);\n// 총: 20 * 100 = 2000 bytes (5배!)\n```\n\n---\n\n### 5. 캐시 비효율\n\n**메모리 비연속성:**\n\n```\n배열: 연속된 메모리\n[1][2][3][4][5] ← 캐시 친화적\n\nBST: 흩어진 메모리\n  [3] → 메모리 주소 0x1000\n  / \\\n [1] [5] → 주소 0x2000, 0x3000\n    \\  /\n    [2][4] → 주소 0x4000, 0x5000\n\n// 캐시 미스 빈번 → 성능 저하\n```\n\n**벤치마크 예시:**\n```java\n// 100만 개 검색\n배열 (이진 탐색): 50ms\nBST (균형):      120ms ← 캐시 미스로 느림\n```\n\n---\n\n### 6. 중복 값 처리 모호\n\n**일반 BST는 중복 허용 안 함:**\n\n```java\ntree.insert(5);\ntree.insert(3);\ntree.insert(5);  // 어떻게 처리?\n\n// 옵션 1: 무시\n// 옵션 2: 카운트 증가\n// 옵션 3: 리스트로 저장\n// → 표준 없음, 구현마다 다름\n```\n\n---\n\n### 7. 범위 쿼리 비효율\n\n**모든 원소 순회 필요할 수 있음:**\n\n```java\n// [10, 15] 범위 원소 찾기\n           20\n         /    \\\n       10      30\n      /  \\    /  \\\n     5   15  25  35\n\n// 최악: O(n) - 모든 노드 확인\n// 배열 (정렬): O(log n) - Binary Search로 시작점 찾기\n```\n\n---\n\n### 8. 동시성 제어 어려움\n\n**멀티스레드 환경:**\n\n```java\n// Thread 1: insert(10)\n// Thread 2: delete(10)\n// → Race Condition\n\n// 전체 트리 락 필요\nsynchronized void insert(int value) {\n    // ...\n}\n// → 병렬성 0\n```\n\n---\n\n## 한계점 요약표\n\n| 한계점 | 문제 | 영향 | 해결책 |\n|--------|------|------|--------|\n| 편향 | 정렬 데이터 삽입 시 O(n) | 성능 저하 | AVL, Red-Black Tree |\n| 순서 의존 | 삽입 순서로 구조 결정 | 예측 불가 성능 | BBST |\n| 균형 미보장 | 자동 균형 X | 편향 위험 | BBST |\n| 메모리 | 포인터 오버헤드 | 메모리 5배 | B-Tree |\n| 캐시 | 비연속 메모리 | 캐시 미스 | B-Tree |\n| 중복 | 표준 없음 | 구현 혼란 | Multiset |\n| 범위 쿼리 | O(n) | 비효율 | Segment Tree |\n| 동시성 | 전체 락 필요 | 병렬성 0 | Lock-Free BST |\n\n---\n\n## 해결책: Balanced BST (BBST)\n\n**1. AVL Tree**\n```\n자동 균형 유지 (높이 차이 ≤ 1)\n모든 연산 보장: O(log n)\n```\n\n**2. Red-Black Tree**\n```\nJava TreeMap, C++ std::map\n느슨한 균형 (AVL보다 빠른 삽입/삭제)\n모든 연산 보장: O(log n)\n```\n\n**3. B-Tree**\n```\n데이터베이스, 파일 시스템\n디스크 I/O 최적화\n캐시 효율 높음\n```\n\n**4. Splay Tree**\n```\n최근 접근 노드를 루트로\n캐시 효과\nAmortized O(log n)\n```\n\n---\n\n## 실전 사용\n\n**일반 BST 사용하지 말 것:**\n```java\n// ❌ 나쁜 예\nBST tree = new BST();\ntree.insert(1);\ntree.insert(2);\ntree.insert(3);  // 편향 위험\n\n// ✅ 좋은 예\nTreeSet<Integer> set = new TreeSet<>();  // Red-Black Tree\nset.add(1);\nset.add(2);\nset.add(3);  // 자동 균형\n```\n\n**언어별 BBST:**\n- **Java**: `TreeMap`, `TreeSet` (Red-Black)\n- **C++**: `std::map`, `std::set` (Red-Black)\n- **Python**: `sortedcontainers` 라이브러리\n- **JavaScript**: 직접 구현 필요 (라이브러리 사용)\n\n---\n\n## 결론\n\n일반 BST는 **교육용**으로는 좋지만, **실전에서는 BBST 사용 필수**입니다.\n\n**이유:**\n- 편향 위험\n- 성능 예측 불가\n- 현대 언어의 표준 라이브러리가 모두 BBST 제공",
      "type": "essay",
      "tags": [
        "이진탐색트리",
        "한계점",
        "편향",
        "성능"
      ]
    },
    {
      "question": "이진탐색트리의 값 삽입, 삭제 방법에 대해 설명하고, 어떤식으로 값을 삽입하면 편향이 발생할까요?",
      "answer": "## 이진탐색트리 삽입 (Insert)\n\n### 삽입 알고리즘\n\n```java\nTreeNode insert(TreeNode node, int value) {\n    // 1. 빈 위치 도달 → 새 노드 생성\n    if (node == null) {\n        return new TreeNode(value);\n    }\n    \n    // 2. 값 비교하여 방향 결정\n    if (value < node.value) {\n        node.left = insert(node.left, value);  // 왼쪽\n    } else if (value > node.value) {\n        node.right = insert(node.right, value); // 오른쪽\n    }\n    // value == node.value → 중복, 무시\n    \n    return node;\n}\n```\n\n**삽입 과정 예시:**\n```\n초기 트리:      삽입 value = 7\n       8\n     /   \\\n    3     10\n   / \\\n  1   6\n\nStep 1: 8과 비교 → 7 < 8 → 왼쪽\nStep 2: 3과 비교 → 7 > 3 → 오른쪽\nStep 3: 6과 비교 → 7 > 6 → 오른쪽\nStep 4: null 도달 → 삽입\n\n결과:\n       8\n     /   \\\n    3     10\n   / \\\n  1   6\n       \\\n        7\n```\n\n**시간복잡도:**\n- 평균: O(log n)\n- 최악: O(n) (편향 트리)\n\n---\n\n## 이진탐색트리 삭제 (Delete)\n\n### 삭제 3가지 경우\n\n**Case 1: 리프 노드 (자식 없음)**\n```java\nif (node.left == null && node.right == null) {\n    return null;  // 그냥 제거\n}\n```\n\n**예시:**\n```\n삭제 전:        삭제: 1\n       8\n     /   \\\n    3     10\n   / \\\n  1   6    →     8\n               /   \\\n              3     10\n               \\\n                6\n```\n\n**Case 2: 자식 1개**\n```java\nif (node.left == null) return node.right;\nif (node.right == null) return node.left;\n```\n\n**예시:**\n```\n삭제 전:        삭제: 10\n       8\n     /   \\\n    3     10\n   / \\      \\\n  1   6      14    →     8\n                       /   \\\n                      3     14\n                     / \\\n                    1   6\n```\n\n**Case 3: 자식 2개**\n```java\n// 오른쪽 서브트리의 최솟값(후계자)으로 대체\nTreeNode min = findMin(node.right);\nnode.value = min.value;\nnode.right = delete(node.right, min.value);\n\n// 또는 왼쪽 서브트리의 최댓값으로 대체\n// TreeNode max = findMax(node.left);\n// node.value = max.value;\n// node.left = delete(node.left, max.value);\n```\n\n**예시:**\n```\n삭제 전:              삭제: 8\n       8\n     /   \\\n    3     10\n   / \\      \\\n  1   6      14\n            /\n           13\n\nStep 1: 오른쪽 서브트리 최솟값 찾기 → 10\nStep 2: 8을 10으로 교체\nStep 3: 원래 10 노드 삭제\n\n결과:\n       10\n     /    \\\n    3      14\n   / \\    /\n  1   6  13\n```\n\n**전체 구현:**\n```java\nTreeNode delete(TreeNode node, int value) {\n    if (node == null) return null;\n    \n    // 삭제할 노드 찾기\n    if (value < node.value) {\n        node.left = delete(node.left, value);\n    } else if (value > node.value) {\n        node.right = delete(node.right, value);\n    } else {\n        // 삭제할 노드 발견\n        \n        // Case 1: 리프 노드\n        if (node.left == null && node.right == null) {\n            return null;\n        }\n        \n        // Case 2: 자식 1개\n        if (node.left == null) return node.right;\n        if (node.right == null) return node.left;\n        \n        // Case 3: 자식 2개\n        TreeNode successor = findMin(node.right);\n        node.value = successor.value;\n        node.right = delete(node.right, successor.value);\n    }\n    \n    return node;\n}\n\nTreeNode findMin(TreeNode node) {\n    while (node.left != null) {\n        node = node.left;\n    }\n    return node;\n}\n```\n\n---\n\n## 편향 (Skew) 발생 조건\n\n### 1. 오름차순 삽입 → 오른쪽 편향\n\n```java\nfor (int i = 1; i <= 5; i++) {\n    tree.insert(i);\n}\n\n결과:\n1\n \\\n  2\n   \\\n    3\n     \\\n      4\n       \\\n        5\n\n높이: n\n검색: O(n)\n```\n\n**이유:**\n```\ninsert(1): 1\n\ninsert(2): 2 > 1 → 오른쪽\n1\n \\\n  2\n\ninsert(3): 3 > 1 → 오른쪽, 3 > 2 → 오른쪽\n1\n \\\n  2\n   \\\n    3\n\n// 계속 오른쪽으로만 확장\n```\n\n---\n\n### 2. 내림차순 삽입 → 왼쪽 편향\n\n```java\nfor (int i = 5; i >= 1; i--) {\n    tree.insert(i);\n}\n\n결과:\n        5\n       /\n      4\n     /\n    3\n   /\n  2\n /\n1\n\n높이: n\n```\n\n---\n\n### 3. 특정 패턴\n\n**교대로 증가하는 패턴:**\n```java\ntree.insert(1);\ntree.insert(3);\ntree.insert(2);\ntree.insert(5);\ntree.insert(4);\n\n결과:\n  1\n   \\\n    3\n   / \\\n  2   5\n     /\n    4\n\n// 오른쪽으로 편향 경향\n```\n\n**중간값 없이 삽입:**\n```java\ntree.insert(10);\ntree.insert(5);\ntree.insert(15);\ntree.insert(3);\ntree.insert(7);\ntree.insert(1);  // 왼쪽만 계속 추가\n\n결과:\n      10\n     /  \\\n    5    15\n   / \\\n  3   7\n /\n1\n\n// 왼쪽 서브트리 편향\n```\n\n---\n\n## 편향 방지 삽입 순서\n\n### 최적: 중간값부터 삽입\n\n```java\n// 배열 [1, 2, 3, 4, 5, 6, 7]\n// 중간부터 삽입\ntree.insert(4);  // 중간값\ntree.insert(2);  // 왼쪽 중간\ntree.insert(6);  // 오른쪽 중간\ntree.insert(1);\ntree.insert(3);\ntree.insert(5);\ntree.insert(7);\n\n결과 (균형):\n       4\n     /   \\\n    2     6\n   / \\   / \\\n  1   3 5   7\n\n높이: log n\n```\n\n**구현:**\n```java\nvoid insertBalanced(int[] arr, int left, int right) {\n    if (left > right) return;\n    \n    int mid = left + (right - left) / 2;\n    tree.insert(arr[mid]);\n    \n    insertBalanced(arr, left, mid - 1);\n    insertBalanced(arr, mid + 1, right);\n}\n\nint[] arr = {1, 2, 3, 4, 5, 6, 7};\ninsertBalanced(arr, 0, arr.length - 1);\n```\n\n---\n\n## 편향 발생 비교\n\n| 삽입 순서 | 결과 트리 높이 | 검색 시간 |\n|-----------|----------------|----------|\n| [1,2,3,4,5] | 5 (n) | O(n) |\n| [5,4,3,2,1] | 5 (n) | O(n) |\n| [3,1,5,2,4] | 2 (log n) | O(log n) |\n| [3,2,4,1,5] | 2 (log n) | O(log n) |\n| [4,2,6,1,3,5,7] | 2 (log n) | O(log n) |\n\n---\n\n## 실전 예제\n\n**편향 발생:**\n```java\n// ❌ 나쁜 예: 타임스탬프 삽입\nfor (Event event : events) {\n    tree.insert(event.timestamp);  // 계속 증가\n}\n// → 오른쪽 편향\n\n// ❌ 나쁜 예: 정렬된 배열 삽입\nint[] sorted = {1, 2, 3, 4, 5};\nfor (int x : sorted) {\n    tree.insert(x);\n}\n// → 오른쪽 편향\n```\n\n**편향 방지:**\n```java\n// ✅ 좋은 예: 랜덤 셔플\nList<Integer> list = Arrays.asList(1, 2, 3, 4, 5);\nCollections.shuffle(list);\nfor (int x : list) {\n    tree.insert(x);\n}\n// → 균형 가능성 높음\n\n// ✅ 더 좋은 예: BBST 사용\nTreeSet<Integer> set = new TreeSet<>();\nfor (int i = 1; i <= 5; i++) {\n    set.add(i);  // 자동 균형\n}\n```\n\n---\n\n## 결론\n\n**편향 발생 원인:**\n1. 정렬된 데이터 (오름/내림차순)\n2. 단조 증가/감소 패턴\n3. 중간값 없이 한쪽만 추가\n\n**해결책:**\n1. 중간값부터 삽입\n2. 랜덤 셔플\n3. **BBST 사용 (AVL, Red-Black Tree)** ← 권장",
      "type": "essay",
      "tags": [
        "이진탐색트리",
        "삽입",
        "삭제",
        "편향"
      ]
    },
    {
      "question": "이진탐색트리와 동일한 로직을 사용하면, 삼진탐색트리도 정의할 수 있을까요? 안 된다면, 그 이유에 대해 설명해 주세요.",
      "answer": "## 삼진탐색트리 가능성 검토\n\n**결론: 가능하지만, 일반적으로 사용하지 않음**\n\n---\n\n## 삼진탐색트리 (Ternary Search Tree)\n\n### 정의 가능한 두 가지 방식\n\n**방식 1: 값 범위로 분할 (가능)**\n\n```java\nclass TernaryNode {\n    int value1, value2;  // 두 개의 값 저장\n    TernaryNode left;    // < value1\n    TernaryNode middle;  // value1 < x < value2\n    TernaryNode right;   // > value2\n}\n```\n\n**예시:**\n```\n노드: [10, 20]\n      /    |    \\\n  (<10) (10-20) (>20)\n\n     [10, 20]\n    /    |    \\\n  [5]  [15]  [25, 30]\n  / \\   / \\   / |  \\\n```\n\n**검색 구현:**\n```java\nboolean search(TernaryNode node, int target) {\n    if (node == null) return false;\n    \n    if (target == node.value1 || target == node.value2) {\n        return true;\n    }\n    \n    if (target < node.value1) {\n        return search(node.left, target);\n    } else if (target > node.value2) {\n        return search(node.right, target);\n    } else {\n        return search(node.middle, target);  // value1 < target < value2\n    }\n}\n```\n\n---\n\n**방식 2: 문자열용 TST (Ternary Search Tree)**\n\n```java\nclass TSTNode {\n    char c;              // 현재 문자\n    TSTNode left;        // c보다 작은 문자\n    TSTNode middle;      // c와 같은 문자, 다음 문자로\n    TSTNode right;       // c보다 큰 문자\n    boolean isEndOfWord;\n}\n```\n\n**예시: \"cat\", \"cats\", \"dog\" 저장**\n```\n       c\n      /|\\\n     a m d\n      |   |\n      t   o\n      |   |\n      $ s g\n          |\n          $\n\n$ = 단어 끝\n```\n\n**문자열 검색:**\n```java\nboolean search(TSTNode node, String word, int index) {\n    if (node == null) return false;\n    \n    char c = word.charAt(index);\n    \n    if (c < node.c) {\n        return search(node.left, word, index);\n    } else if (c > node.c) {\n        return search(node.right, word, index);\n    } else {\n        // c == node.c\n        if (index == word.length() - 1) {\n            return node.isEndOfWord;  // 단어 끝\n        }\n        return search(node.middle, word, index + 1);  // 다음 문자\n    }\n}\n```\n\n---\n\n## 왜 일반적으로 사용하지 않는가?\n\n### 1. 복잡도 증가\n\n**이진탐색트리:**\n```java\nif (target < node.value) {\n    // 왼쪽\n} else {\n    // 오른쪽\n}\n// 1번 비교\n```\n\n**삼진탐색트리:**\n```java\nif (target < node.value1) {\n    // 왼쪽\n} else if (target > node.value2) {\n    // 오른쪽\n} else if (target == node.value1 || target == node.value2) {\n    // 찾음\n} else {\n    // 중간\n}\n// 3~4번 비교\n```\n\n---\n\n### 2. 삽입 복잡성\n\n**이진탐색트리 삽입:**\n```java\nTreeNode insert(TreeNode node, int value) {\n    if (node == null) return new TreeNode(value);\n    \n    if (value < node.value) {\n        node.left = insert(node.left, value);\n    } else {\n        node.right = insert(node.right, value);\n    }\n    return node;\n}\n```\n\n**삼진탐색트리 삽입:**\n```java\nTernaryNode insert(TernaryNode node, int value) {\n    if (node == null) {\n        return new TernaryNode(value);  // 초기값 하나만\n    }\n    \n    // Case 1: 노드에 값 1개만 있음\n    if (node.value2 == null) {\n        if (value == node.value1) return node;\n        \n        // 두 값을 정렬하여 저장\n        if (value < node.value1) {\n            node.value2 = node.value1;\n            node.value1 = value;\n        } else {\n            node.value2 = value;\n        }\n        return node;\n    }\n    \n    // Case 2: 노드가 꽉 참 (2개 값)\n    if (value < node.value1) {\n        node.left = insert(node.left, value);\n    } else if (value > node.value2) {\n        node.right = insert(node.right, value);\n    } else if (value != node.value1 && value != node.value2) {\n        node.middle = insert(node.middle, value);\n    }\n    \n    return node;\n}\n// → 케이스 분기가 많고 복잡\n```\n\n---\n\n### 3. 삭제의 복잡성\n\n**자식이 3개 → 후계자 선택 복잡:**\n\n```java\n// 삭제할 노드의 자식이 3개\n      [10, 20]\n      /   |   \\\n    Left Mid Right\n\n// 어느 서브트리에서 후계자를 가져올까?\n// 1. left의 최댓값?\n// 2. middle의 최솟값? 최댓값?\n// 3. right의 최솟값?\n// → 선택지 많음, 균형 유지 어려움\n```\n\n---\n\n### 4. 시간복잡도 개선 미미\n\n**이진탐색트리:**\n```\n높이: log₂(n)\n검색: log₂(n)번 비교\n```\n\n**삼진탐색트리:**\n```\n높이: log₃(n)\n검색: log₃(n)번 노드 방문, 각 노드마다 3번 비교\n\n실제: log₃(n) * 3 ≈ log₂(n) * 1.9\n// 별로 빠르지 않음\n```\n\n**비교:**\n```\nn = 1,000,000\n\n이진:\nlog₂(1,000,000) ≈ 20 비교\n\n삼진:\nlog₃(1,000,000) ≈ 13 노드, 각 노드마다 3번\n= 13 * 3 = 39 비교\n\n// 오히려 느림!\n```\n\n---\n\n### 5. 메모리 오버헤드\n\n**노드당 포인터 수:**\n\n```java\n// 이진 노드\nclass BinaryNode {\n    int value;      // 4 bytes\n    Node left;      // 8 bytes\n    Node right;     // 8 bytes\n    // 총: 20 bytes\n}\n\n// 삼진 노드\nclass TernaryNode {\n    int value1;     // 4 bytes\n    int value2;     // 4 bytes\n    Node left;      // 8 bytes\n    Node middle;    // 8 bytes\n    Node right;     // 8 bytes\n    // 총: 32 bytes (60% 증가)\n}\n```\n\n---\n\n## 삼진탐색트리가 유용한 경우\n\n### 문자열 저장 (TST)\n\n**장점:**\n- Trie보다 메모리 효율적\n- Hash Table보다 정렬 가능\n- 부분 문자열 검색 가능\n\n**사용 사례:**\n- 자동완성\n- 사전 구현\n- DNA 서열 분석\n\n**예시:**\n```java\n// Trie vs TST 메모리 비교\n// 단어: \"cat\", \"car\", \"card\"\n\nTrie:\n       c\n       |\n       a\n      / \\\n     t   r\n         |\n         d\n// 노드당 26개 포인터 배열 (알파벳)\n// 메모리: 노드당 ~200 bytes\n\nTST:\n     c\n     |\n     a\n     |\n     t\n    / \\\n   $   r\n       |\n       $\n      / \\\n     d   (other)\n// 노드당 3개 포인터\n// 메모리: 노드당 ~32 bytes\n```\n\n---\n\n## B-Tree (실전에서 사용되는 다진 트리)\n\n**실무에서는 B-Tree 사용:**\n\n```java\n// B-Tree 노드 (3차 B-Tree)\nclass BTreeNode {\n    int[] keys = new int[2];      // 최대 2개 키\n    BTreeNode[] children = new BTreeNode[3];  // 최대 3개 자식\n    int numKeys;  // 현재 키 개수\n}\n\n// 특징:\n// 1. 모든 리프가 같은 레벨\n// 2. 디스크 I/O 최적화\n// 3. 데이터베이스 인덱스에 사용\n```\n\n**왜 B-Tree는 성공했는가?**\n1. **균형 보장**: 모든 리프가 같은 깊이\n2. **디스크 최적화**: 한 번에 여러 키 읽기\n3. **검증된 알고리즘**: 삽입/삭제 잘 정의됨\n\n---\n\n## 결론\n\n**삼진탐색트리 (범용):**\n- ✅ 정의 가능\n- ❌ 실용성 낮음 (복잡도 증가, 성능 개선 미미)\n- ❌ 균형 유지 어려움\n\n**삼진탐색트리 (문자열 TST):**\n- ✅ 문자열 저장에 유용\n- ✅ Trie보다 메모리 효율적\n- ✅ 자동완성, 사전 구현\n\n**실무 추천:**\n- 범용: **이진탐색트리** (AVL, Red-Black)\n- 디스크: **B-Tree**\n- 문자열: **TST** 또는 Trie\n\n**N-진 트리 일반론:**\n```\nN이 클수록:\n- 높이 감소: log_N(n)\n- 노드당 비교 증가: N-1번\n- 구현 복잡도 증가\n- 균형 유지 어려움\n\n→ 이진(N=2)이 구현과 성능의 최적 균형\n```",
      "type": "essay",
      "tags": [
        "삼진탐색트리",
        "이진탐색트리",
        "TST",
        "트리"
      ]
    },
    {
      "question": "힙에 대해 설명해 주세요.",
      "answer": "## 힙 (Heap)\n\n**정의:**  \n**완전 이진트리** 형태의 자료구조로, 부모-자식 간에 특정 순서 관계를 만족합니다.\n\n---\n\n## 힙의 종류\n\n### 1. 최대 힙 (Max Heap)\n\n**조건:** 부모 노드 ≥ 자식 노드\n\n```\n        100\n       /   \\\n     80     90\n    / \\    / \\\n   50  60 70  40\n  / \\\n 30  20\n\n// 루트: 최댓값 (100)\n// 모든 부모 ≥ 자식\n```\n\n### 2. 최소 힙 (Min Heap)\n\n**조건:** 부모 노드 ≤ 자식 노드\n\n```\n         10\n       /   \\\n     20     30\n    / \\    / \\\n   40  50 60  70\n  / \\\n 80  90\n\n// 루트: 최솟값 (10)\n// 모든 부모 ≤ 자식\n```\n\n---\n\n## 힙의 핵심 특징\n\n### 1. 완전 이진트리 (Complete Binary Tree)\n\n```\n✅ 완전 이진트리 (힙 가능):\n       1\n     /   \\\n    2     3\n   / \\   /\n  4   5 6\n\n// 마지막 레벨 제외 모두 채워짐\n// 마지막 레벨은 왼쪽부터\n\n❌ 불완전 이진트리 (힙 불가능):\n       1\n     /   \\\n    2     3\n     \\     \\\n      4     5\n\n// 왼쪽부터 채워지지 않음\n```\n\n### 2. 부분 순서 (Partial Order)\n\n**BST vs Heap:**\n\n```\nBST (전체 순서):\n       5\n     /   \\\n    3     7\n   / \\   / \\\n  2   4 6   8\n\n// 중위 순회: 2 3 4 5 6 7 8 (완전 정렬)\n// 왼쪽 < 현재 < 오른쪽\n\nMax Heap (부분 순서):\n       8\n     /   \\\n    7     6\n   / \\   / \\\n  5   4 3   2\n\n// 부모 > 자식만 보장\n// 형제 간 순서 없음 (7 vs 6 순서 무관)\n```\n\n---\n\n## 힙의 주요 연산\n\n### 1. 삽입 (Insert) - O(log n)\n\n```java\nvoid insert(int value) {\n    // 1. 맨 끝에 추가\n    heap.add(value);\n    \n    // 2. Heapify Up (상향 조정)\n    int i = heap.size() - 1;\n    while (i > 0) {\n        int parent = (i - 1) / 2;\n        \n        if (heap.get(i) <= heap.get(parent)) {\n            break;  // 힙 조건 만족\n        }\n        \n        // 부모와 교환\n        swap(i, parent);\n        i = parent;\n    }\n}\n```\n\n**예시: 최대 힙에 95 삽입**\n```\n초기:        삽입 95:       Heapify Up:\n   100          100            100\n   / \\          / \\            / \\\n  80  90       80  90         95  90\n / \\          / \\  /        / \\  /\n50  60       50  60 95     50  60 80\n\n// 95가 부모 80보다 크므로 교환\n```\n\n---\n\n### 2. 삭제 (Extract Max/Min) - O(log n)\n\n```java\nint extractMax() {\n    if (heap.isEmpty()) throw new Exception();\n    \n    // 1. 루트 저장 (반환값)\n    int max = heap.get(0);\n    \n    // 2. 마지막 원소를 루트로\n    int last = heap.remove(heap.size() - 1);\n    if (heap.isEmpty()) return max;\n    \n    heap.set(0, last);\n    \n    // 3. Heapify Down (하향 조정)\n    int i = 0;\n    while (true) {\n        int left = 2 * i + 1;\n        int right = 2 * i + 2;\n        int largest = i;\n        \n        if (left < heap.size() && heap.get(left) > heap.get(largest)) {\n            largest = left;\n        }\n        if (right < heap.size() && heap.get(right) > heap.get(largest)) {\n            largest = right;\n        }\n        \n        if (largest == i) break;  // 힙 조건 만족\n        \n        swap(i, largest);\n        i = largest;\n    }\n    \n    return max;\n}\n```\n\n**예시: 최댓값 삭제**\n```\n초기:           마지막→루트:    Heapify Down:\n    100             60             90\n   /   \\           / \\            / \\\n  80    90        80  90         80  70\n / \\   / \\       / \\  / \\       / \\  /\n50  60 70 40    50  X 70 40    50  60 40\n\n// 60 < 90이므로 교환\n// 60 < 70이므로 교환\n```\n\n---\n\n### 3. Peek (최댓값/최솟값 조회) - O(1)\n\n```java\nint peek() {\n    return heap.get(0);  // 루트\n}\n```\n\n---\n\n## 힙의 시간복잡도\n\n| 연산 | 시간복잡도 | 이유 |\n|------|-----------|------|\n| Insert | O(log n) | Heapify Up (트리 높이) |\n| Extract Max/Min | O(log n) | Heapify Down (트리 높이) |\n| Peek | O(1) | 루트 접근 |\n| Build Heap | O(n) | Bottom-up 구성 |\n| Search | O(n) | 순서 없음, 전체 탐색 |\n\n---\n\n## 힙 vs BST\n\n| 특성 | Heap | BST |\n|------|------|-----|\n| 구조 | 완전 이진트리 | 이진트리 |\n| 순서 | 부분 순서 (부모-자식만) | 전체 순서 (왼쪽 < 현재 < 오른쪽) |\n| 최댓값 찾기 | O(1) | O(log n) ~ O(n) |\n| 검색 | O(n) | O(log n) ~ O(n) |\n| 삽입 | O(log n) | O(log n) ~ O(n) |\n| 삭제 | O(log n) | O(log n) ~ O(n) |\n| 배열 구현 | 쉬움 | 어려움 |\n| 사용 사례 | 우선순위 큐, 힙 정렬 | 정렬된 데이터, 검색 |\n\n---\n\n## 힙의 활용\n\n### 1. 우선순위 큐 (Priority Queue)\n\n```java\nPriorityQueue<Integer> pq = new PriorityQueue<>();  // Min Heap\npq.add(5);\npq.add(3);\npq.add(7);\npq.poll();  // 3 (최솟값)\n\n// Max Heap\nPriorityQueue<Integer> maxPQ = new PriorityQueue<>(Collections.reverseOrder());\n```\n\n### 2. 힙 정렬 (Heap Sort)\n\n```java\nvoid heapSort(int[] arr) {\n    // 1. Build Heap: O(n)\n    buildMaxHeap(arr);\n    \n    // 2. Extract Max 반복: O(n log n)\n    for (int i = arr.length - 1; i > 0; i--) {\n        swap(arr, 0, i);  // 최댓값을 뒤로\n        heapify(arr, 0, i);  // 남은 부분 Heapify\n    }\n}\n\n// 시간: O(n log n)\n// 공간: O(1) (in-place)\n```\n\n### 3. K번째 최댓값/최솟값\n\n```java\n// K번째 최솟값\nPriorityQueue<Integer> maxHeap = new PriorityQueue<>(Collections.reverseOrder());\nfor (int num : nums) {\n    maxHeap.add(num);\n    if (maxHeap.size() > k) {\n        maxHeap.poll();  // 큰 값 제거\n    }\n}\nreturn maxHeap.peek();  // K번째 최솟값\n```\n\n### 4. 중앙값 찾기\n\n```java\n// 두 개의 힙 사용\nPriorityQueue<Integer> maxHeap = new PriorityQueue<>(Collections.reverseOrder());  // 작은 쪽 절반\nPriorityQueue<Integer> minHeap = new PriorityQueue<>();  // 큰 쪽 절반\n\n// 중앙값 = maxHeap의 루트 (또는 두 루트의 평균)\n```\n\n---\n\n## Java 구현\n\n```java\nimport java.util.PriorityQueue;\n\n// Min Heap (기본)\nPriorityQueue<Integer> minHeap = new PriorityQueue<>();\n\n// Max Heap\nPriorityQueue<Integer> maxHeap = new PriorityQueue<>(\n    (a, b) -> b - a\n);\n\n// 사용자 정의 비교\nPriorityQueue<Task> pq = new PriorityQueue<>(\n    (a, b) -> a.priority - b.priority\n);\n```\n\n---\n\n## 결론\n\n**힙의 장점:**\n- 최댓값/최솟값 빠른 접근 (O(1))\n- 삽입/삭제 효율적 (O(log n))\n- 배열로 구현 가능 (메모리 효율)\n\n**힙의 단점:**\n- 검색 느림 (O(n))\n- 정렬되지 않음 (부분 순서만)\n\n**사용 시기:**\n- 우선순위 큐 필요 시\n- 최댓값/최솟값 반복 조회\n- 정렬 (힙 정렬)",
      "type": "essay",
      "tags": [
        "힙",
        "Heap",
        "우선순위 큐",
        "자료구조"
      ]
    },
    {
      "question": "힙을 배열로 구현한다고 가정하면, 어떻게 값을 저장할 수 있을까요?",
      "answer": "## 힙의 배열 구현\n\n**핵심: 완전 이진트리는 배열로 표현 가능**\n\n---\n\n## 인덱스 매핑 규칙\n\n**부모-자식 관계:**\n\n```\n노드 인덱스: i (0-based)\n\n왼쪽 자식: 2*i + 1\n오른쪽 자식: 2*i + 2\n부모: (i - 1) / 2\n```\n\n**예시 (최대 힙):**\n\n```\n트리 형태:          배열 인덱스:\n      100 (0)           0\n     /   \\            /   \\\n   80(1)  90(2)      1     2\n  / \\    / \\        / \\   / \\\n50  60  70 40      3   4 5   6\n(3)(4) (5)(6)\n\n배열:\nindex: 0   1   2   3   4   5   6\nvalue: [100, 80, 90, 50, 60, 70, 40]\n\n관계:\n- 100의 왼쪽 자식: 2*0+1 = 1 → 80\n- 100의 오른쪽 자식: 2*0+2 = 2 → 90\n- 80의 부모: (1-1)/2 = 0 → 100\n- 50의 부모: (3-1)/2 = 1 → 80\n```\n\n---\n\n## Java 구현\n\n### 최대 힙 (Max Heap)\n\n```java\nclass MaxHeap {\n    private List<Integer> heap = new ArrayList<>();\n    \n    // 부모 인덱스\n    private int parent(int i) {\n        return (i - 1) / 2;\n    }\n    \n    // 왼쪽 자식 인덱스\n    private int left(int i) {\n        return 2 * i + 1;\n    }\n    \n    // 오른쪽 자식 인덱스\n    private int right(int i) {\n        return 2 * i + 2;\n    }\n    \n    // 교환\n    private void swap(int i, int j) {\n        int temp = heap.get(i);\n        heap.set(i, heap.get(j));\n        heap.set(j, temp);\n    }\n    \n    // 삽입: O(log n)\n    public void insert(int value) {\n        heap.add(value);  // 맨 끝에 추가\n        heapifyUp(heap.size() - 1);\n    }\n    \n    // 상향 조정\n    private void heapifyUp(int i) {\n        while (i > 0 && heap.get(i) > heap.get(parent(i))) {\n            swap(i, parent(i));\n            i = parent(i);\n        }\n    }\n    \n    // 최댓값 추출: O(log n)\n    public int extractMax() {\n        if (heap.isEmpty()) {\n            throw new NoSuchElementException(\"Heap is empty\");\n        }\n        \n        int max = heap.get(0);  // 루트\n        int last = heap.remove(heap.size() - 1);  // 마지막 원소\n        \n        if (!heap.isEmpty()) {\n            heap.set(0, last);  // 마지막 원소를 루트로\n            heapifyDown(0);\n        }\n        \n        return max;\n    }\n    \n    // 하향 조정\n    private void heapifyDown(int i) {\n        int maxIndex = i;\n        int l = left(i);\n        int r = right(i);\n        \n        // 왼쪽 자식과 비교\n        if (l < heap.size() && heap.get(l) > heap.get(maxIndex)) {\n            maxIndex = l;\n        }\n        \n        // 오른쪽 자식과 비교\n        if (r < heap.size() && heap.get(r) > heap.get(maxIndex)) {\n            maxIndex = r;\n        }\n        \n        // 교환 필요 시\n        if (i != maxIndex) {\n            swap(i, maxIndex);\n            heapifyDown(maxIndex);  // 재귀\n        }\n    }\n    \n    // 최댓값 조회: O(1)\n    public int peek() {\n        if (heap.isEmpty()) {\n            throw new NoSuchElementException(\"Heap is empty\");\n        }\n        return heap.get(0);\n    }\n    \n    // 크기\n    public int size() {\n        return heap.size();\n    }\n}\n```\n\n---\n\n## 동작 예시\n\n### 삽입 과정 (95 삽입)\n\n```\n초기 배열: [100, 80, 90, 50, 60, 70, 40]\n\n트리:\n      100\n     /   \\\n   80     90\n  / \\    / \\\n 50  60 70  40\n\nStep 1: 맨 끝에 추가\n배열: [100, 80, 90, 50, 60, 70, 40, 95]\nindex: 7\n\n      100\n     /   \\\n   80     90\n  / \\    / \\\n 50  60 70  40\n/\n95\n\nStep 2: Heapify Up\n95 > 80 (parent(7) = 3) → 교환\n배열: [100, 95, 90, 50, 60, 70, 40, 80]\nindex: 1\n\n      100\n     /   \\\n   95     90\n  / \\    / \\\n 50  60 70  40\n          \\\n          80\n\nStep 3: 계속 Heapify Up\n95 < 100 → 종료\n\n최종 배열: [100, 95, 90, 50, 60, 70, 40, 80]\n```\n\n---\n\n### 삭제 과정 (최댓값 추출)\n\n```\n초기 배열: [100, 80, 90, 50, 60, 70, 40]\n\nStep 1: 루트 저장 (100)\nStep 2: 마지막 원소(40)를 루트로\n배열: [40, 80, 90, 50, 60, 70]\n\n      40\n     /  \\\n   80    90\n  / \\   /\n 50  60 70\n\nStep 3: Heapify Down\n40 < 90 (right child) → 교환\n배열: [90, 80, 40, 50, 60, 70]\n\n      90\n     /  \\\n   80    40\n  / \\   /\n 50  60 70\n\nStep 4: 계속 Heapify Down\n40 < 70 (right child) → 교환\n배열: [90, 80, 70, 50, 60, 40]\n\n      90\n     /  \\\n   80    70\n  / \\   /\n 50  60 40\n\n종료 (40이 리프)\n반환값: 100\n```\n\n---\n\n## 1-based 인덱스 (대안)\n\n**일부 구현은 1-based 사용 (수식 간결):**\n\n```java\n노드 인덱스: i (1-based, index 0 사용 안 함)\n\n왼쪽 자식: 2*i\n오른쪽 자식: 2*i + 1\n부모: i / 2\n\n배열:\nindex: 0   1   2   3   4   5   6   7\nvalue: [X, 100, 80, 90, 50, 60, 70, 40]\n              ↑ 루트\n\n// 수식이 더 간단\n```\n\n---\n\n## Build Heap: O(n)\n\n**배열을 힙으로 변환:**\n\n```java\nvoid buildHeap(int[] arr) {\n    heap = new ArrayList<>();\n    for (int val : arr) {\n        heap.add(val);\n    }\n    \n    // 마지막 부모부터 Heapify Down\n    for (int i = heap.size() / 2 - 1; i >= 0; i--) {\n        heapifyDown(i);\n    }\n}\n```\n\n**예시:**\n```\n초기 배열: [10, 20, 15, 30, 40]\n\n트리:\n      10\n     /  \\\n   20    15\n  / \\\n 30  40\n\n마지막 부모: i = (5/2 - 1) = 1\n\nStep 1: heapifyDown(1) → 20과 40 교환\n      10\n     /  \\\n   40    15\n  / \\\n 30  20\n\nStep 2: heapifyDown(0) → 10과 40 교환\n      40\n     /  \\\n   10    15\n  / \\\n 30  20\n\nStep 3: heapifyDown(0) 계속 → 10과 30 교환\n      40\n     /  \\\n   30    15\n  / \\\n 10  20\n\n최종 배열: [40, 30, 15, 10, 20]\n```\n\n**시간복잡도:** O(n)\n- 각 레벨의 노드 수와 Heapify 비용이 역비례\n- 리프(n/2개): O(0)\n- 레벨 h-1(n/4개): O(1)\n- 레벨 h-2(n/8개): O(2)\n- ...\n- 루트(1개): O(log n)\n\n---\n\n## 배열 vs 포인터 구현\n\n| 특성 | 배열 | 포인터 |\n|------|------|--------|\n| 구현 복잡도 | 간단 | 복잡 |\n| 메모리 | O(n) | O(n) + 포인터 오버헤드 |\n| 캐시 효율 | 높음 (연속 메모리) | 낮음 (흩어진 메모리) |\n| 인덱스 계산 | 산술 연산 | 포인터 따라가기 |\n| 리사이징 | 필요 시 O(n) | 불필요 |\n| 사용 | 일반적 | 거의 없음 |\n\n**결론: 힙은 거의 항상 배열로 구현**\n\n---\n\n## JavaScript 예시\n\n```javascript\nclass MaxHeap {\n    constructor() {\n        this.heap = [];\n    }\n    \n    parent(i) { return Math.floor((i - 1) / 2); }\n    left(i) { return 2 * i + 1; }\n    right(i) { return 2 * i + 2; }\n    \n    insert(val) {\n        this.heap.push(val);\n        this.heapifyUp(this.heap.length - 1);\n    }\n    \n    heapifyUp(i) {\n        while (i > 0 && this.heap[i] > this.heap[this.parent(i)]) {\n            [this.heap[i], this.heap[this.parent(i)]] = \n            [this.heap[this.parent(i)], this.heap[i]];\n            i = this.parent(i);\n        }\n    }\n    \n    extractMax() {\n        if (this.heap.length === 0) return null;\n        \n        const max = this.heap[0];\n        const last = this.heap.pop();\n        \n        if (this.heap.length > 0) {\n            this.heap[0] = last;\n            this.heapifyDown(0);\n        }\n        \n        return max;\n    }\n    \n    heapifyDown(i) {\n        let maxIdx = i;\n        const l = this.left(i);\n        const r = this.right(i);\n        \n        if (l < this.heap.length && this.heap[l] > this.heap[maxIdx]) {\n            maxIdx = l;\n        }\n        if (r < this.heap.length && this.heap[r] > this.heap[maxIdx]) {\n            maxIdx = r;\n        }\n        \n        if (i !== maxIdx) {\n            [this.heap[i], this.heap[maxIdx]] = \n            [this.heap[maxIdx], this.heap[i]];\n            this.heapifyDown(maxIdx);\n        }\n    }\n}\n```",
      "type": "essay",
      "tags": [
        "힙",
        "배열",
        "구현",
        "인덱싱"
      ]
    },
    {
      "question": "힙의 삽입, 삭제 방식에 대해 설명하고, 왜 이진탐색트리와 달리 편향이 발생하지 않는지 설명해 주세요.",
      "answer": "## 힙의 삽입과 삭제\n\n### 삽입 (Insert) - O(log n)\n\n**알고리즘:**\n1. 새 값을 맨 끝(완전 이진트리 유지)에 추가\n2. Heapify Up (부모와 비교하며 올라감)\n\n```java\nvoid insert(int value) {\n    // 1. 맨 끝에 추가\n    heap.add(value);\n    \n    // 2. Heapify Up\n    int i = heap.size() - 1;\n    while (i > 0) {\n        int parent = (i - 1) / 2;\n        \n        if (heap.get(i) <= heap.get(parent)) {\n            break;  // 힙 조건 만족\n        }\n        \n        swap(i, parent);\n        i = parent;\n    }\n}\n```\n\n**예시: 최대 힙에 95 삽입**\n```\nStep 1: 맨 끝에 추가\n      100              [100, 80, 90, 50, 60, 70, 40, 95]\n     /   \\                                           ↑\n   80     90                                      여기 추가\n  / \\    / \\\n 50  60 70  40\n/\n95\n\nStep 2: 95 > 50 (부모) → 교환\n      100\n     /   \\\n   80     90\n  / \\    / \\\n 95  60 70  40\n/\n50\n\nStep 3: 95 > 80 (부모) → 교환\n      100\n     /   \\\n   95     90\n  / \\    / \\\n 80  60 70  40\n/\n50\n\nStep 4: 95 < 100 (부모) → 종료\n최종: [100, 95, 90, 80, 60, 70, 40, 50]\n```\n\n**핵심: 항상 맨 끝에 추가 → 완전 이진트리 유지**\n\n---\n\n### 삭제 (Extract Max) - O(log n)\n\n**알고리즘:**\n1. 루트(최댓값/최솟값) 제거\n2. 마지막 원소를 루트로 이동\n3. Heapify Down (자식과 비교하며 내려감)\n\n```java\nint extractMax() {\n    int max = heap.get(0);  // 루트 저장\n    \n    // 마지막 원소를 루트로\n    int last = heap.remove(heap.size() - 1);\n    if (heap.isEmpty()) return max;\n    \n    heap.set(0, last);\n    \n    // Heapify Down\n    int i = 0;\n    while (true) {\n        int left = 2 * i + 1;\n        int right = 2 * i + 2;\n        int largest = i;\n        \n        if (left < heap.size() && heap.get(left) > heap.get(largest)) {\n            largest = left;\n        }\n        if (right < heap.size() && heap.get(right) > heap.get(largest)) {\n            largest = right;\n        }\n        \n        if (largest == i) break;\n        \n        swap(i, largest);\n        i = largest;\n    }\n    \n    return max;\n}\n```\n\n**예시: 최댓값 삭제**\n```\nStep 1: 루트(100) 제거, 마지막(40)을 루트로\n      40               [40, 80, 90, 50, 60, 70]\n     /  \\\n   80    90\n  / \\   /\n 50  60 70\n\nStep 2: 40 < 90 (오른쪽 자식, 최대) → 교환\n      90\n     /  \\\n   80    40\n  / \\   /\n 50  60 70\n\nStep 3: 40 < 70 (오른쪽 자식) → 교환\n      90\n     /  \\\n   80    70\n  / \\   /\n 50  60 40\n\nStep 4: 40이 리프 → 종료\n최종: [90, 80, 70, 50, 60, 40]\n반환: 100\n```\n\n**핵심: 마지막 원소를 사용 → 완전 이진트리 유지**\n\n---\n\n## 왜 힙은 편향이 발생하지 않는가?\n\n### 1. 완전 이진트리 강제\n\n**힙:**\n```java\n// 항상 맨 끝에 추가\ninsert(1);\ninsert(2);\ninsert(3);\ninsert(4);\ninsert(5);\n\n결과 (최대 힙):\n       5\n     /   \\\n    4     3\n   / \\\n  1   2\n\n// 완전 이진트리 형태 유지\n// 높이: log₂(5) = 2.32 → 3\n```\n\n**BST (비교):**\n```java\n// 삽입 위치가 값에 따라 결정\ninsert(1);\ninsert(2);\ninsert(3);\ninsert(4);\ninsert(5);\n\n결과:\n1\n \\\n  2\n   \\\n    3\n     \\\n      4\n       \\\n        5\n\n// 편향 발생!\n// 높이: 5\n```\n\n**차이점:**\n- **힙**: 삽입 위치가 값과 무관 (항상 맨 끝)\n- **BST**: 삽입 위치가 값에 따라 결정\n\n---\n\n### 2. 삽입 순서와 무관\n\n**힙은 어떤 순서로 삽입해도 완전 이진트리:**\n\n```\n오름차순 삽입 [1,2,3,4,5]:\n       5\n     /   \\\n    4     3\n   / \\\n  1   2\n높이: 3\n\n내림차순 삽입 [5,4,3,2,1]:\n       5\n     /   \\\n    4     3\n   / \\\n  2   1\n높이: 3\n\n랜덤 삽입 [3,1,4,5,2]:\n       5\n     /   \\\n    3     4\n   / \\\n  1   2\n높이: 3\n\n// 모두 높이 ≈ log n!\n// 트리 모양만 다를 뿐, 높이는 동일\n```\n\n**BST (비교):**\n```\n오름차순: 높이 5 (편향)\n내림차순: 높이 5 (편향)\n랜덤: 높이 2~5 (운에 따라)\n```\n\n---\n\n### 3. 레벨별 채우기 방식\n\n**힙의 삽입 규칙:**\n```\n삽입 순서: A, B, C, D, E, F, G\n\nStep 1: A 삽입\n   A\n\nStep 2: B 삽입 (왼쪽부터)\n   A\n  /\n B\n\nStep 3: C 삽입 (왼쪽 끝)\n   A\n  / \\\n B   C\n\nStep 4: D 삽입 (다음 레벨, 왼쪽부터)\n   A\n  / \\\n B   C\n/\nD\n\nStep 5-7: E, F, G 삽입\n      A\n    /   \\\n   B     C\n  / \\   / \\\n D   E F   G\n\n// 레벨 0: 1개 (2^0)\n// 레벨 1: 2개 (2^1)\n// 레벨 2: 4개 (2^2)\n// → 완전 이진트리\n```\n\n**높이 보장:**\n```\nn개 노드 → 높이 = ⌊log₂(n)⌋\n\nn = 7 → h = 2\nn = 15 → h = 3\nn = 100 → h = 6\n\n// 항상 최소 높이 유지\n```\n\n---\n\n### 4. 삭제도 균형 유지\n\n**힙:**\n```java\n// 항상 마지막 원소 사용\nextractMax();  // 마지막 → 루트\n\n삭제 전: [100, 80, 90, 50, 60, 70, 40]\n         100\n        /   \\\n      80     90\n     / \\    / \\\n    50 60  70 40\n\n삭제 후: [90, 80, 70, 50, 60, 40]\n         90\n        /  \\\n      80    70\n     / \\   /\n    50 60 40\n\n// 여전히 완전 이진트리\n// 높이: log(6) ≈ 2\n```\n\n**BST (비교):**\n```\n삭제 전:    삭제(100):\n   100         80\n  /   \\       /  \\\n 80    90    50   90\n/  \\          \\     \\\n50  60         60   110\n    \\\n     110\n\n// 삭제 후 균형 보장 없음\n// 편향 가능\n```\n\n---\n\n## 힙 vs BST 비교표\n\n| 특성 | Heap | BST |\n|------|------|-----|\n| 삽입 위치 | 항상 맨 끝 | 값에 따라 결정 |\n| 트리 형태 | 완전 이진트리 강제 | 형태 보장 없음 |\n| 높이 | 항상 log n | 최악 n (편향 시) |\n| 정렬 의존성 | 없음 | 있음 (정렬 시 편향) |\n| 균형 유지 | 자동 | 없음 (BBST 필요) |\n| 삽입 순서 영향 | 없음 | 큼 |\n\n---\n\n## 배열 인덱스로 보는 균형\n\n**힙 (배열 구현):**\n```java\n삽입 순서: 1, 2, 3, 4, 5\n\n배열: [5, 4, 3, 2, 1]\nindex: 0  1  2  3  4\n\n트리:\n       5 (0)\n      / \\\n    4(1) 3(2)\n   / \\\n  2(3) 1(4)\n\n// 인덱스 0~4 순서대로 채워짐\n// 빈 공간 없음 → 완전 이진트리\n```\n\n**BST (배열 구현 어려움):**\n```\n삽입 순서: 1, 2, 3, 4, 5\n\n배열: [1, _, 2, _, _, _, 3, ..., 5]\n       ↑    ↑          ↑        ↑\n      root  ?         ?       편향\n\n// 빈 공간 많음\n// 배열 크기 = 2^h (낭비)\n```\n\n---\n\n## 결론\n\n**힙이 편향되지 않는 이유:**\n\n1. **완전 이진트리 강제**\n   - 맨 끝에만 삽입\n   - 레벨별로 왼쪽부터 채움\n\n2. **삽입 순서 무관**\n   - 정렬 여부와 관계없이 균형\n   - 값이 아닌 위치 기반\n\n3. **높이 보장**\n   - 항상 O(log n)\n   - 최소 높이 유지\n\n4. **자동 균형**\n   - Heapify만으로 균형\n   - 회전 불필요\n\n**BST의 편향 이유:**\n\n1. **값 기반 삽입**\n   - 정렬된 데이터 → 편향\n\n2. **형태 보장 없음**\n   - 균형 트리 아님\n\n3. **BBST 필요**\n   - AVL, Red-Black Tree로 해결\n\n**사용 시기:**\n- **힙**: 최댓값/최솟값 반복 조회, 우선순위 큐\n- **BST**: 정렬된 데이터, 범위 쿼리, 검색",
      "type": "essay",
      "tags": [
        "힙",
        "삽입",
        "삭제",
        "편향",
        "완전 이진트리"
      ]
    },
    {
      "question": "힙 정렬의 시간복잡도는 어떻게 되나요? Stable 한가요?",
      "answer": "## 힙 정렬 (Heap Sort)\n\n### 시간복잡도\n\n**전체: O(n log n)**\n\n**단계별 분석:**\n\n1. **Build Heap: O(n)**\n2. **Extract Max 반복 (n번): O(n log n)**\n\n---\n\n## 힙 정렬 구현\n\n```java\nvoid heapSort(int[] arr) {\n    int n = arr.length;\n    \n    // 1. Build Max Heap: O(n)\n    for (int i = n / 2 - 1; i >= 0; i--) {\n        heapify(arr, n, i);\n    }\n    \n    // 2. Extract Max 반복: O(n log n)\n    for (int i = n - 1; i > 0; i--) {\n        // 루트(최댓값)와 마지막 원소 교환\n        swap(arr, 0, i);\n        \n        // 남은 부분에 대해 Heapify\n        heapify(arr, i, 0);  // O(log n)\n    }\n}\n\nvoid heapify(int[] arr, int n, int i) {\n    int largest = i;\n    int left = 2 * i + 1;\n    int right = 2 * i + 2;\n    \n    if (left < n && arr[left] > arr[largest]) {\n        largest = left;\n    }\n    if (right < n && arr[right] > arr[largest]) {\n        largest = right;\n    }\n    \n    if (largest != i) {\n        swap(arr, i, largest);\n        heapify(arr, n, largest);  // 재귀\n    }\n}\n\nvoid swap(int[] arr, int i, int j) {\n    int temp = arr[i];\n    arr[i] = arr[j];\n    arr[j] = temp;\n}\n```\n\n---\n\n## 동작 과정 예시\n\n```\n초기 배열: [4, 10, 3, 5, 1]\n\nStep 1: Build Max Heap\n초기:   4\n       / \\\n     10   3\n     / \\\n    5   1\n\nHeapify(1): 10 > 5, 10 > 1 → 변화 없음\nHeapify(0): 4 < 10 → 교환\n\n결과:  10\n       / \\\n      5   3\n     / \\\n    4   1\n\n배열: [10, 5, 3, 4, 1]\n\n---\n\nStep 2: Extract Max 반복\n\ni=4: [10, 5, 3, 4, 1]\n     루트(10)와 마지막(1) 교환\n     [1, 5, 3, 4 | 10]\n     Heapify(0): [5, 4, 3, 1 | 10]\n\ni=3: [5, 4, 3, 1 | 10]\n     루트(5)와 마지막(1) 교환\n     [1, 4, 3 | 5, 10]\n     Heapify(0): [4, 1, 3 | 5, 10]\n\ni=2: [4, 1, 3 | 5, 10]\n     루트(4)와 마지막(3) 교환\n     [3, 1 | 4, 5, 10]\n     Heapify(0): [3, 1 | 4, 5, 10]\n\ni=1: [3, 1 | 4, 5, 10]\n     루트(3)와 마지막(1) 교환\n     [1 | 3, 4, 5, 10]\n\n최종 정렬: [1, 3, 4, 5, 10]\n```\n\n---\n\n## 시간복잡도 증명\n\n### Build Heap: O(n)\n\n**각 레벨의 비용:**\n\n```\n높이 h = log n\n\n레벨 h (리프):      n/2 노드, 이동 0번\n레벨 h-1:          n/4 노드, 이동 1번\n레벨 h-2:          n/8 노드, 이동 2번\n...\n레벨 0 (루트):      1 노드,   이동 h번\n\n총 비용:\nT = n/2 * 0 + n/4 * 1 + n/8 * 2 + ... + 1 * log n\n  = n * (1/4 + 2/8 + 3/16 + ...)\n  = n * Σ(i/2^(i+1))  (i=0 to ∞)\n  = n * 1/2  // 수렴\n  = O(n)\n```\n\n### Extract Max: O(n log n)\n\n```\nn번 반복 * Heapify O(log n)\n= O(n log n)\n```\n\n**전체:**\n```\nBuild Heap + Extract Max\n= O(n) + O(n log n)\n= O(n log n)\n```\n\n---\n\n## Stable한가? → 아니오! (Unstable)\n\n**Stable Sort:**\n- 같은 값의 상대적 순서가 유지됨\n\n**힙 정렬은 Unstable:**\n\n**예시:**\n```\n초기 배열: [3a, 3b, 2, 1]\n// a, b는 같은 값의 순서 구분\n\nBuild Heap (Max Heap):\n      3a\n     /  \\\n   3b    2\n   /\n  1\n\n배열: [3a, 3b, 2, 1]\n\nExtract Max:\n1) [3a, 3b, 2, 1] → 3a와 1 교환\n   [1, 3b, 2 | 3a]\n   Heapify: [3b, 1, 2 | 3a]\n\n2) [3b, 1, 2 | 3a] → 3b와 2 교환\n   [2, 1 | 3b, 3a]  ← 3b가 3a보다 앞!\n   Heapify: [2, 1 | 3b, 3a]\n\n3) [2, 1 | 3b, 3a] → 2와 1 교환\n   [1 | 2, 3b, 3a]\n\n최종: [1, 2, 3b, 3a]\n//        ↑   ↑\n//     순서 바뀜! (원래 3a가 먼저)\n```\n\n**왜 Unstable?**\n\n1. **Heap 구성 시 교환**: 같은 값도 위치 바뀜\n2. **Extract 시 교환**: 루트와 마지막 원소 교환\n\n---\n\n## 힙 정렬 vs 다른 정렬\n\n### 시간복잡도 비교\n\n| 정렬 | 최선 | 평균 | 최악 | 공간 | Stable |\n|------|------|------|------|------|--------|\n| 힙 정렬 | O(n log n) | O(n log n) | O(n log n) | O(1) | ❌ |\n| 병합 정렬 | O(n log n) | O(n log n) | O(n log n) | O(n) | ✅ |\n| 퀵 정렬 | O(n log n) | O(n log n) | O(n²) | O(log n) | ❌ |\n| 삽입 정렬 | O(n) | O(n²) | O(n²) | O(1) | ✅ |\n\n---\n\n### 장단점\n\n**장점:**\n1. **보장된 O(n log n)**: 최악도 O(n log n)\n2. **In-place**: 추가 메모리 O(1)\n3. **간단한 구현**: 힙 연산만 이해하면 됨\n\n**단점:**\n1. **Unstable**: 같은 값의 순서 바뀜\n2. **캐시 비효율**: 비연속 접근\n3. **실전 느림**: 평균적으로 퀵 정렬보다 느림\n\n---\n\n## 성능 비교 (실제 벤치마크)\n\n```\n100만 개 정렬:\n\n퀵 정렬:    50ms   (빠름, 캐시 효율적)\n병합 정렬:  80ms   (안정적, O(n) 메모리)\n힙 정렬:    120ms  (느림, 캐시 미스)\n```\n\n**왜 힙 정렬이 느릴까?**\n\n```\nHeapify 과정에서 비연속 접근:\n\n배열: [10, 5, 3, 4, 1]\nindex:  0  1  2  3  4\n\nHeapify(0):\n- 인덱스 0 접근\n- 인덱스 1 접근 (2*0+1)\n- 인덱스 2 접근 (2*0+2)\n- 인덱스 4 접근 (재귀)\n\n// 띄엄띄엄 접근 → 캐시 미스\n```\n\n---\n\n## 사용 사례\n\n**힙 정렬 사용:**\n- 메모리 제한 심함 (O(1) 필요)\n- 최악 성능 보장 필요\n- Stable 필요 없음\n\n**다른 정렬 사용:**\n- **퀵 정렬**: 일반적 경우 (가장 빠름)\n- **병합 정렬**: Stable 필요 시\n- **삽입 정렬**: 거의 정렬된 데이터\n\n---\n\n## Java 예시\n\n```java\nimport java.util.Arrays;\n\npublic class HeapSortExample {\n    public static void main(String[] args) {\n        int[] arr = {12, 11, 13, 5, 6, 7};\n        \n        System.out.println(\"Original: \" + Arrays.toString(arr));\n        heapSort(arr);\n        System.out.println(\"Sorted: \" + Arrays.toString(arr));\n    }\n    \n    static void heapSort(int[] arr) {\n        int n = arr.length;\n        \n        // Build heap\n        for (int i = n / 2 - 1; i >= 0; i--)\n            heapify(arr, n, i);\n        \n        // Extract elements\n        for (int i = n - 1; i > 0; i--) {\n            int temp = arr[0];\n            arr[0] = arr[i];\n            arr[i] = temp;\n            \n            heapify(arr, i, 0);\n        }\n    }\n    \n    static void heapify(int[] arr, int n, int i) {\n        int largest = i;\n        int l = 2 * i + 1;\n        int r = 2 * i + 2;\n        \n        if (l < n && arr[l] > arr[largest])\n            largest = l;\n        \n        if (r < n && arr[r] > arr[largest])\n            largest = r;\n        \n        if (largest != i) {\n            int swap = arr[i];\n            arr[i] = arr[largest];\n            arr[largest] = swap;\n            \n            heapify(arr, n, largest);\n        }\n    }\n}\n```\n\n---\n\n## 결론\n\n**시간복잡도:**\n- **모든 경우: O(n log n)** (최선, 평균, 최악)\n\n**Stable:**\n- **아니오 (Unstable)**\n- 같은 값의 순서 보장 안 됨\n\n**사용:**\n- 메모리 제한 + 최악 성능 보장 필요 시\n- 실전에서는 퀵 정렬/병합 정렬 선호",
      "type": "essay",
      "tags": [
        "힙 정렬",
        "Heap Sort",
        "시간복잡도",
        "Stable"
      ]
    },
    {
      "question": "BBST (Balanced Binary Search Tree) 와, 그 종류에 대해 설명해 주세요.",
      "answer": "## BBST (Balanced Binary Search Tree)\n\n**정의:**  \n자동으로 **높이 균형을 유지**하는 이진탐색트리. 모든 연산이 **O(log n) 보장**됩니다.\n\n**필요성:**\n- 일반 BST: 편향 시 O(n) → 성능 저하\n- BBST: 자동 균형 → 항상 O(log n)\n\n---\n\n## 주요 BBST 종류\n\n### 1. AVL Tree (1962)\n\n**발명자:** Adelson-Velsky & Landis\n\n**균형 조건:**\n```\n모든 노드의 좌우 서브트리 높이 차이 ≤ 1\n\nBalance Factor (BF) = height(left) - height(right)\nBF ∈ {-1, 0, 1}\n```\n\n**예시:**\n```\n✅ 균형 (AVL):\n       4\n      / \\\n     2   6\n    / \\   \\\n   1   3   7\n\nBF(4) = 2 - 1 = 1 ✓\nBF(2) = 0 - 0 = 0 ✓\nBF(6) = 0 - 1 = -1 ✓\n\n❌ 불균형:\n       4\n      / \\\n     2   6\n    /     \\\n   1       7\n  /         \\\n 0           8\n\nBF(4) = 3 - 2 = 1 ✓\nBF(2) = 2 - 0 = 2 ✗  (위반!)\n```\n\n**회전 종류:**\n\n1. **LL (Left-Left) → Right Rotation**\n2. **RR (Right-Right) → Left Rotation**\n3. **LR (Left-Right) → Left + Right Rotation**\n4. **RL (Right-Left) → Right + Left Rotation**\n\n**장점:**\n- 엄격한 균형 → 검색 가장 빠름\n- 높이 보장: h ≤ 1.44 log n\n\n**단점:**\n- 삽입/삭제 시 회전 많음\n- 구현 복잡\n\n---\n\n### 2. Red-Black Tree (1972)\n\n**균형 조건:**\n```\n1. 모든 노드는 Red 또는 Black\n2. 루트는 Black\n3. 모든 리프(NULL)는 Black\n4. Red 노드의 자식은 모두 Black (연속 Red 금지)\n5. 모든 경로의 Black 노드 개수 동일\n```\n\n**예시:**\n```\n       B(10)\n      /     \\\n   R(5)    R(15)\n   /  \\    /   \\\n B(3) B(7) B(12) B(20)\n\nBlack Height = 2\n```\n\n**장점:**\n- AVL보다 느슨한 균형 → 삽입/삭제 빠름\n- 회전 최대 3번\n- 실용적 (Java, C++ STL 사용)\n\n**단점:**\n- 구현 가장 복잡\n- 검색은 AVL보다 느림\n\n**높이:** h ≤ 2 log(n+1)\n\n---\n\n### 3. B-Tree (1970)\n\n**특징:**\n- **다진 트리** (자식 2개 이상)\n- 디스크 기반 자료구조\n- 데이터베이스, 파일 시스템 사용\n\n**구조 (2-3-4 Tree = 4차 B-Tree):**\n```\n노드당 키 1~3개, 자식 2~4개\n\n      [10, 20]\n     /    |    \\\n  [5]  [12,15] [25,30]\n  / \\   / | \\   / | \\\n```\n\n**균형 조건:**\n- 모든 리프가 같은 레벨\n- 최소 차수 유지\n\n**장점:**\n- 디스크 I/O 최소화\n- 큰 데이터 처리 효율적\n\n**단점:**\n- 메모리 오버헤드\n- 구현 복잡\n\n---\n\n### 4. Splay Tree (1985)\n\n**특징:**\n- **자가 조정 (Self-adjusting)**\n- 최근 접근 노드를 루트로 이동 (Splaying)\n\n**동작:**\n```\n검색 시마다 해당 노드를 루트로 회전\n\n검색(3):\n       5              3\n      / \\            / \\\n     3   7    →     1   5\n    / \\                / \\\n   1   4              4   7\n\n// 3이 루트로 이동\n```\n\n**장점:**\n- 캐시 효과 (자주 쓰는 데이터 빠름)\n- 구현 간단 (색깔/BF 불필요)\n- Amortized O(log n)\n\n**단점:**\n- 최악 O(n) (단일 연산)\n- 균형 보장 안 됨\n\n---\n\n### 5. Treap (Tree + Heap)\n\n**특징:**\n- BST (값 기준) + Heap (우선순위 기준)\n- 랜덤 우선순위로 균형 유지\n\n**구조:**\n```\nclass TreapNode {\n    int key;        // BST 기준\n    int priority;   // Heap 기준 (랜덤)\n    TreapNode left, right;\n}\n```\n\n**예시:**\n```\n      5(90)        // (key, priority)\n     /     \\\n  3(50)   8(70)\n  /         \\\n1(30)      10(60)\n\n// Key: BST 순서\n// Priority: Max Heap\n```\n\n**장점:**\n- 구현 간단\n- 확률적 균형 (기대값 O(log n))\n\n**단점:**\n- 최악 보장 없음\n- 난수 생성 비용\n\n---\n\n## BBST 비교표\n\n| 트리 | 균형 기준 | 높이 | 회전 (삽입) | 회전 (삭제) | 검색 | 사용 |\n|------|-----------|------|-------------|-------------|------|------|\n| AVL | \\|BF\\| ≤ 1 | 1.44 log n | 최대 2회 | 최대 log n | ★★★★★ | 검색 많음 |\n| Red-Black | 5가지 규칙 | 2 log n | 최대 2회 | 최대 3회 | ★★★★ | 범용 (STL) |\n| B-Tree | 레벨 동일 | log_m n | - | - | ★★★ | 데이터베이스 |\n| Splay | 없음 | - | - | - | ★★★ | 캐시 효과 |\n| Treap | 랜덤 우선순위 | ~log n | 기대값 | 기대값 | ★★★ | 간단 구현 |\n\n---\n\n## 시간복잡도 비교\n\n| 연산 | 일반 BST (평균) | 일반 BST (최악) | BBST |\n|------|----------------|----------------|------|\n| 검색 | O(log n) | O(n) | O(log n) |\n| 삽입 | O(log n) | O(n) | O(log n) |\n| 삭제 | O(log n) | O(n) | O(log n) |\n\n---\n\n## 언어별 BBST 구현\n\n**Java:**\n```java\n// Red-Black Tree\nTreeMap<Integer, String> map = new TreeMap<>();\nTreeSet<Integer> set = new TreeSet<>();\n```\n\n**C++:**\n```cpp\n// Red-Black Tree\nstd::map<int, string> map;\nstd::set<int> set;\n```\n\n**Python:**\n```python\n# 기본 라이브러리 없음\n# sortedcontainers 패키지 사용\nfrom sortedcontainers import SortedDict, SortedSet\n\nsd = SortedDict()\nss = SortedSet()\n```\n\n**JavaScript:**\n```javascript\n// 기본 라이브러리 없음\n// 직접 구현 또는 라이브러리 사용\n```\n\n---\n\n## 실전 사용 가이드\n\n**AVL Tree 사용:**\n- 검색이 압도적으로 많음\n- 삽입/삭제 거의 없음\n- 데이터 크기 고정\n\n**Red-Black Tree 사용:**\n- 검색, 삽입, 삭제 고루 발생\n- 범용 목적\n- 대부분의 경우 (Java/C++ 기본)\n\n**B-Tree 사용:**\n- 디스크 기반 저장\n- 대용량 데이터\n- 데이터베이스 인덱스\n\n**Splay Tree 사용:**\n- 접근 패턴 편향\n- 캐시 효과 필요\n- 간단한 구현 선호\n\n---\n\n## 결론\n\n**BBST가 필요한 이유:**\n- 일반 BST의 편향 문제 해결\n- 안정적인 O(log n) 보장\n- 실용적인 성능\n\n**가장 많이 사용:**\n- **Red-Black Tree** (Java TreeMap, C++ std::map)\n- 삽입/삭제/검색 균형 잡힌 성능\n- 구현 복잡하지만 라이브러리 제공",
      "type": "essay",
      "tags": [
        "BBST",
        "균형 이진탐색트리",
        "AVL",
        "Red-Black Tree",
        "B-Tree"
      ]
    },
    {
      "question": "Red Black Tree는 어떻게 균형을 유지할 수 있을까요?",
      "answer": "## Red-Black Tree 균형 유지 메커니즘\n\n### 5가지 성질 (Properties)\n\n```\n1. 모든 노드는 Red 또는 Black\n2. 루트는 항상 Black\n3. 모든 리프(NULL)는 Black\n4. Red 노드의 자식은 반드시 Black (연속 Red 금지)\n5. 모든 경로의 Black 노드 개수 동일 (Black Height)\n```\n\n**예시:**\n```\n        B(10)              Black Height = 2\n       /     \\\n    R(5)     R(15)\n    /  \\     /   \\\n  B(3) B(7) B(12) B(20)\n\n경로별 Black 노드 개수:\n10 → 3:   B(10) → B(3) = 2 ✓\n10 → 7:   B(10) → B(7) = 2 ✓\n10 → 12:  B(10) → B(12) = 2 ✓\n10 → 20:  B(10) → B(20) = 2 ✓\n```\n\n---\n\n## 삽입 (Insert)\n\n**기본 전략:**\n1. BST 방식으로 삽입 (위치 찾기)\n2. 새 노드를 **Red**로 삽입\n3. 위반 확인 및 수정\n\n**왜 Red로 삽입?**\n- Black으로 삽입하면 성질 5 위반 (Black Height 증가)\n- Red로 삽입하면 성질 4만 확인하면 됨\n\n---\n\n### Case 분석\n\n**Case 1: 부모가 Black**\n```\n     B(10)\n    /\n  B(5)     ← 부모\n  /\nR(3)      ← 새 노드\n\n// 위반 없음 → 종료\n```\n\n**Case 2: 부모와 삼촌 모두 Red**\n```\n      B(10)         →       R(10)     ← Recolor\n     /     \\                /    \\\n  R(5)     R(15)         B(5)   B(15)\n  /                      /\nR(3) ← 새 노드          R(3)\n\n작업:\n1. 부모 → Black\n2. 삼촌 → Black\n3. 조부모 → Red\n4. 조부모에서 재귀적으로 확인\n```\n\n**Case 3: 부모 Red, 삼촌 Black (LL 패턴)**\n```\n      B(10)                B(5)\n     /     \\      →       /    \\\n  R(5)     B(15)       R(3)   R(10)\n  /                             \\\nR(3)                            B(15)\n\n작업:\n1. 조부모(10) 기준 Right Rotation\n2. 부모(5) → Black\n3. 조부모(10) → Red\n```\n\n**Case 4: 부모 Red, 삼촌 Black (LR 패턴)**\n```\n      B(10)              B(10)             B(7)\n     /     \\            /     \\           /    \\\n  R(5)     B(15)  →  R(7)   B(15)  →  R(5)   R(10)\n    \\                /                          \\\nR(7)              R(5)                         B(15)\n\n작업:\n1. 부모(5) 기준 Left Rotation → Case 3로 변환\n2. Case 3 처리\n```\n\n---\n\n## 삽입 예시 (상세)\n\n```\n빈 트리에 [10, 5, 15, 3, 7] 순서로 삽입\n\nStep 1: 10 삽입\n   B(10)   // 루트는 Black\n\nStep 2: 5 삽입 (Red)\n     B(10)\n    /\n  R(5)     // 부모 Black → OK\n\nStep 3: 15 삽입 (Red)\n     B(10)\n    /    \\\n  R(5)   R(15)  // 부모 Black → OK\n\nStep 4: 3 삽입 (Red)\n       B(10)\n      /    \\\n   R(5)   R(15)\n   /\nR(3)\n\n// 부모(5) Red, 삼촌(15) Red → Case 2\n// Recolor:\n\n       R(10)  ← Red (조부모)\n      /    \\\n   B(5)   B(15)  ← Black (부모, 삼촌)\n   /\nR(3)\n\n// 루트가 Red → Black으로 변경:\n\n       B(10)\n      /    \\\n   B(5)   B(15)\n   /\nR(3)\n\nStep 5: 7 삽입 (Red)\n       B(10)\n      /    \\\n   B(5)   B(15)\n   /  \\\nR(3)  R(7)  // 부모 Black → OK\n\n최종 트리:\n       B(10)              Black Height = 2\n      /    \\\n   B(5)   B(15)\n   /  \\\nR(3)  R(7)\n```\n\n---\n\n## 균형 유지 핵심 원리\n\n**1. Black Height 불변:**\n- 모든 경로의 Black 노드 개수 동일\n- 트리 높이를 log 수준으로 제한\n\n**2. Red 제약:**\n- 연속 Red 금지 → 높이 2배 이하 제한\n- Black 사이에만 Red 삽입 가능\n\n**3. Recoloring + Rotation:**\n- 위반 시 색 변경 또는 회전\n- 지역적 수정 (O(1) 회전)\n- 최악 O(log n) 상승 (Recolor)\n\n**4. 루트는 항상 Black:**\n- Black Height 일관성 유지\n- 삽입 후 Red 루트 → Black 변경\n\n---\n\n## 시간복잡도\n\n**높이:**\n```\nh ≤ 2 log₂(n + 1)\n\n증명:\n- Black Height = bh\n- 최소 노드 수 (모든 Black): 2^bh - 1\n- 최대 높이 (Black-Red 교대): 2*bh\n- n ≥ 2^bh - 1\n- bh ≤ log₂(n + 1)\n- h ≤ 2 log₂(n + 1)\n```\n\n**연산:**\n- 검색: O(log n)\n- 삽입: O(log n) + 최대 2번 회전\n- 삭제: O(log n) + 최대 3번 회전\n\n---\n\n## 결론\n\n**Red-Black Tree 균형 유지:**\n\n1. **5가지 성질** 강제\n2. **Black Height** 일정 유지\n3. **Recoloring + Rotation**으로 수정\n4. **O(log n) 높이** 보장\n\n**장점:**\n- 삽입/삭제 시 회전 적음 (최대 2-3번)\n- AVL보다 구현 효율적\n- 실용적 성능\n\n**사용:**\n- Java TreeMap, TreeSet\n- C++ std::map, std::set\n- Linux 커널 (CFS 스케줄러)",
      "type": "essay",
      "tags": [
        "Red-Black Tree",
        "균형",
        "회전",
        "Recoloring"
      ]
    },
    {
      "question": "Red Black Tree의 주요 성질 4가지에 대해 설명해 주세요.",
      "answer": "## Red-Black Tree의 5가지 성질\n\n> 질문은 \"4가지\"이지만, Red-Black Tree는 **5가지 성질**을 가집니다.\n\n---\n\n### 성질 1: 색 제약\n\n**모든 노드는 Red 또는 Black**\n\n```java\nclass Node {\n    int key;\n    boolean color;  // RED(true) 또는 BLACK(false)\n    Node left, right, parent;\n}\n```\n\n**의미:**\n- 이진 상태로 단순화\n- 추가 메모리 최소화 (1 bit)\n\n---\n\n### 성질 2: 루트 제약\n\n**루트는 항상 Black**\n\n```\n✅ 올바른 트리:\n   B(10)\n  /    \\\nR(5)  R(15)\n\n❌ 잘못된 트리:\n   R(10)  ← 루트가 Red (위반!)\n  /    \\\nR(5)  R(15)\n```\n\n**이유:**\n- Black Height 일관성 유지\n- 경로별 Black 개수 계산 기준점\n\n---\n\n### 성질 3: 리프 제약\n\n**모든 리프(NULL 노드)는 Black**\n\n```\n실제 트리:\n       B(10)\n      /    \\\n   R(5)   B(15)\n   /  \\\n  NULL NULL\n\nNULL 포함 (개념적):\n       B(10)\n      /    \\\n   R(5)   B(15)\n   /  \\   /  \\\n  B  B   B   B  ← 모든 NULL은 Black\n```\n\n**의미:**\n- 경로 계산 시 일관성\n- Black Height 정의에 필요\n\n---\n\n### 성질 4: Red 노드 제약 ⭐ (핵심)\n\n**Red 노드의 자식은 반드시 Black**\n\n= **연속된 Red 노드 금지**\n\n```\n✅ 올바른 트리:\n       B(10)\n      /    \\\n   R(5)   R(15)\n   /  \\   /  \\\n  B(3) B(7) B(12) B(20)\n\n// Red 노드(5, 15)의 자식은 모두 Black ✓\n\n❌ 잘못된 트리:\n       B(10)\n      /    \\\n   R(5)   R(15)\n   /  \\      \\\n  R(3) B(7)  R(20)  ← Red(15) → Red(20) 위반!\n```\n\n**왜 중요한가?**\n\n이 성질이 **높이를 제한**합니다:\n\n```\n최악의 경로 (Black-Red 교대):\nB → R → B → R → B → R → ...\n\nBlack 노드가 bh개라면\n최대 경로 길이 = 2*bh\n\n따라서 높이 h ≤ 2 log₂(n+1)\n```\n\n---\n\n### 성질 5: Black Height 제약 ⭐ (핵심)\n\n**모든 노드에서 리프까지의 모든 경로는 같은 수의 Black 노드를 포함**\n\n= **Black Height 일정**\n\n```\n예시 트리:\n         B(10)              Black Height (bh)\n        /    \\\n     R(5)    R(15)\n     /  \\    /   \\\n  B(3) B(7) B(12) B(20)\n\n경로별 Black 노드:\n10 → 3:   B(10) → B(3) = 2 ✓\n10 → 7:   B(10) → B(7) = 2 ✓\n10 → 12:  B(10) → B(12) = 2 ✓\n10 → 20:  B(10) → B(20) = 2 ✓\n\n모두 같음!\n```\n\n**Black Height 정의:**\n```\nbh(node) = 해당 노드에서 리프까지 경로의 Black 노드 개수\n           (자기 자신 제외)\n```\n\n**왜 중요한가?**\n\n이 성질이 **균형을 보장**합니다:\n\n```\nBlack Height가 bh인 서브트리:\n- 최소 노드 수: 2^bh - 1 (모든 노드 Black)\n- 최대 높이: 2*bh (Black-Red 교대)\n\n전체 노드 n개:\nn ≥ 2^bh - 1\nbh ≤ log₂(n + 1)\nh ≤ 2 log₂(n + 1)\n\n→ O(log n) 보장!\n```\n\n---\n\n## 5가지 성질의 관계\n\n```\n성질 1: 색 정의 (기본)\n        ↓\n성질 2: 루트 Black (기준점)\n        ↓\n성질 3: 리프 Black (경로 끝)\n        ↓\n성질 4: Red 연속 금지 ──→ 높이 제한 (h ≤ 2bh)\n        ↓\n성질 5: Black Height 일정 ──→ 균형 보장 (h ≤ 2 log n)\n```\n\n---\n\n## 성질들의 역할 정리\n\n| 성질 | 역할 | 보장하는 것 |\n|------|------|-------------|\n| 1 | 노드 타입 정의 | 구조 단순화 |\n| 2 | 루트 기준점 | Black Height 일관성 |\n| 3 | 리프 기준점 | 경로 계산 일관성 |\n| 4 | Red 연속 금지 | **높이 제한 (h ≤ 2bh)** |\n| 5 | Black Height 일정 | **균형 보장 (h ≤ 2 log n)** |\n\n---\n\n## 결론\n\n**Red-Black Tree의 5가지 성질:**\n\n1. **색 제약**: Red 또는 Black\n2. **루트 Black**: 기준점\n3. **리프 Black**: 경로 끝\n4. **Red 연속 금지**: 높이 제한 ⭐\n5. **Black Height 일정**: 균형 보장 ⭐\n\n**핵심:**\n- 성질 4 + 5 = O(log n) 보장\n- 성질 4: 높이를 Black Height의 2배 이하로 제한\n- 성질 5: Black Height를 log n으로 제한\n\n**결과:**\n```\nh ≤ 2 log₂(n + 1)\n→ 모든 연산 O(log n) 보장\n```",
      "type": "essay",
      "tags": [
        "Red-Black Tree",
        "성질",
        "균형",
        "Black Height"
      ]
    },
    {
      "question": "2-3-4 Tree, AVL Tree 등의 다른 BBST 가 있음에도, 왜 Red Black Tree가 많이 사용될까요?",
      "answer": "## Red-Black Tree vs 다른 BBST\n\n### 주요 BBST 비교\n\n| 특성 | AVL Tree | Red-Black Tree | 2-3-4 Tree | B-Tree |\n|------|----------|----------------|------------|--------|\n| 균형 조건 | \\|BF\\| ≤ 1 | 5가지 성질 | 노드당 2-4 자식 | 노드당 t~2t 자식 |\n| 높이 | 1.44 log n | 2 log n | 1.44 log n | logₜ n |\n| 삽입 회전 | 최대 2회 | 최대 2회 | 0회 (Split) | 0회 (Split) |\n| 삭제 회전 | 최대 log n | 최대 3회 | 0회 (Merge) | 0회 (Merge) |\n| 검색 속도 | ★★★★★ | ★★★★ | ★★★ | ★★ |\n| 삽입 속도 | ★★★ | ★★★★ | ★★★★ | ★★★ |\n| 삭제 속도 | ★★ | ★★★★ | ★★★★ | ★★★ |\n| 구현 복잡도 | 중간 | 복잡 | 중간 | 복잡 |\n| 메모리 | 작음 | 작음 | 중간 | 큼 |\n| 사용 | 검색 많음 | 범용 | 교육용 | 데이터베이스 |\n\n---\n\n## Red-Black Tree가 많이 사용되는 이유\n\n### 1. 삽입/삭제 성능 우수\n\n**AVL Tree의 문제:**\n\n```\nAVL 삭제 시 최악의 경우:\n\n삭제 후 (불균형 전파):\n       4                3\n      / \\              / \\\n     2   6            2   6\n    / \\   \\   →      /     \\\n   1   3   7        1       7\n  /                          \\\n 0                            8\n\nBF(2) = 2 (위반)\nBF(4) = -1 → 회전 필요\n...\n// 루트까지 회전 전파 가능 → O(log n) 회전\n```\n\n**Red-Black Tree:**\n\n```\n삭제 시 최대 3번 회전으로 종료\n\n삭제 후:\n      B(10)\n     /    \\\n  B(5)   B(15)  → 최대 3번 회전으로 균형 복구\n  /\nB(3)\n\n// 상수 시간 회전 → 예측 가능한 성능\n```\n\n**비교:**\n\n```java\n// 100만 번 삽입+삭제\n\nAVL Tree:     280ms  (회전 많음)\nRed-Black:    180ms  (회전 적음)\n```\n\n---\n\n### 2. 구현의 실용성\n\n**2-3-4 Tree의 문제:**\n\n```java\nclass Node234 {\n    int[] keys = new int[3];     // 최대 3개 키\n    Node234[] children = new Node234[4];  // 최대 4개 자식\n    int keyCount;  // 실제 키 개수\n}\n\n// 문제점:\n// 1. 가변 크기 노드 → 메모리 낭비\n// 2. 배열 관리 복잡\n// 3. 노드 타입이 여러 개 (2-노드, 3-노드, 4-노드)\n```\n\n**Red-Black Tree:**\n\n```java\nclass Node {\n    int key;           // 고정 크기\n    boolean color;     // 1 bit 추가\n    Node left, right, parent;\n}\n\n// 장점:\n// 1. 고정 크기 노드 → 메모리 효율\n// 2. 단순한 구조 → 캐시 친화적\n// 3. 이진 트리 연산 재사용 가능\n```\n\n**메모리 비교:**\n\n```\n노드당 메모리 (64비트 시스템):\n\nAVL:        24 bytes (key + 2 포인터 + height)\nRed-Black:  25 bytes (key + 3 포인터 + color)\n2-3-4:      ~80 bytes (3 keys + 4 포인터 + count)\nB-Tree:     100+ bytes (가변)\n\n// Red-Black이 가장 효율적\n```\n\n---\n\n### 3. 균형 vs 성능 트레이드오프\n\n**AVL Tree:**\n- 엄격한 균형 (h ≤ 1.44 log n)\n- 검색 최적화\n- 삽입/삭제 느림\n\n**Red-Black Tree:**\n- 느슨한 균형 (h ≤ 2 log n)\n- 삽입/삭제 최적화\n- 검색도 충분히 빠름\n\n**실제 성능 차이:**\n\n```\n100만 노드 검색 비교:\n\nAVL:        평균 20회 비교\nRed-Black:  평균 22회 비교\n\n// 10% 차이 - 실전에서 무시 가능\n```\n\n**삽입/삭제 비교:**\n\n```\n100만 번 삽입:\n\nAVL:        평균 1.5 회전/삽입\nRed-Black:  평균 0.5 회전/삽입\n\n// 3배 차이 - 유의미함\n```\n\n---\n\n### 4. 산업 표준\n\n**주요 라이브러리 사용:**\n\n**Java:**\n```java\n// TreeMap, TreeSet 내부 구현\npublic class TreeMap<K,V> {\n    private static class Entry<K,V> {\n        K key;\n        V value;\n        Entry<K,V> left, right, parent;\n        boolean color = BLACK;  // Red-Black\n    }\n}\n```\n\n**C++ STL:**\n```cpp\n// std::map, std::set 내부 구현\ntemplate<typename Key, typename Value>\nclass map {\n    struct Node {\n        Key key;\n        Value value;\n        Node *left, *right, *parent;\n        bool color;  // Red-Black\n    };\n};\n```\n\n**Linux 커널:**\n```c\n// rbtree.h - 완전 균형 스케줄러 (CFS)\nstruct rb_node {\n    unsigned long rb_parent_color;  // 부모 포인터 + 색 (1 bit)\n    struct rb_node *rb_right;\n    struct rb_node *rb_left;\n};\n```\n\n**이유:**\n- 검증된 안정성\n- 풍부한 레퍼런스\n- 최적화된 구현\n\n---\n\n### 5. 캐시 효율성\n\n**메모리 레이아웃:**\n\n```\nRed-Black Tree 노드:\n[key][color][left][right][parent]\n 4B    1B     8B    8B     8B   = 29 bytes\n\n// 연속 메모리, 캐시 라인 적중률 높음\n\n2-3-4 Tree 노드:\n[key1][key2][key3][child0][child1][child2][child3][count]\n  4B    4B    4B     8B      8B      8B      8B     4B  = 48 bytes\n\n// 크고, 낭비 많음\n```\n\n**L1 캐시 적중률:**\n```\nRed-Black:  85%\n2-3-4:      70%\nB-Tree:     60%\n```\n\n---\n\n## 언제 다른 BBST 사용?\n\n**AVL Tree 사용:**\n```\n- 검색이 95% 이상\n- 삽입/삭제 거의 없음\n- 데이터 크기 고정\n\n예: 사전 (Dictionary), 읽기 전용 데이터\n```\n\n**B-Tree/B+ Tree 사용:**\n```\n- 디스크 기반 저장\n- 대용량 데이터\n- 블록 단위 I/O\n\n예: 데이터베이스 인덱스, 파일 시스템\n```\n\n**2-3-4 Tree 사용:**\n```\n- 교육 목적\n- Red-Black 이해를 위한 도구\n\n실전에서는 거의 사용 안 함\n```\n\n---\n\n## 실전 성능 벤치마크\n\n```java\n// 100만 노드, 랜덤 삽입+검색+삭제\n\n결과:\n\nAVL Tree:\n  삽입: 350ms\n  검색: 180ms  ★\n  삭제: 420ms\n  총합: 950ms\n\nRed-Black Tree:\n  삽입: 280ms  ★\n  검색: 200ms\n  삭제: 290ms  ★\n  총합: 770ms  ★ (최고)\n\n2-3-4 Tree:\n  삽입: 450ms\n  검색: 250ms\n  삭제: 480ms\n  총합: 1180ms\n\n// Red-Black이 전체적으로 균형 잡힌 성능\n```\n\n---\n\n## 결론\n\n**Red-Black Tree가 가장 많이 사용되는 이유:**\n\n1. **삽입/삭제 효율**: 최대 2-3번 회전 (AVL은 O(log n))\n2. **메모리 효율**: 고정 크기 노드, 1 bit 색 정보만 추가\n3. **균형 vs 성능**: 느슨한 균형으로 실용적 성능\n4. **산업 표준**: Java, C++, Linux에서 사용\n5. **구현 단순**: 이진 트리 구조 재사용\n6. **예측 가능**: 상수 회전, 안정적 성능\n7. **캐시 효율**: 작고 연속적인 메모리 레이아웃\n\n**요약:**\n```\nAVL:        검색 최적화 (검색 >> 삽입/삭제)\nRed-Black:  범용 목적 (균형 잡힌 성능) ★\nB-Tree:     디스크 기반 (데이터베이스)\n2-3-4:      교육용 (실전 거의 없음)\n\n→ 대부분의 경우 Red-Black Tree 사용\n```",
      "type": "essay",
      "tags": [
        "Red-Black Tree",
        "AVL Tree",
        "BBST",
        "성능 비교"
      ]
    },
    {
      "question": "정렬 알고리즘에 대해 설명해 주세요.",
      "answer": "## 정렬 알고리즘 (Sorting Algorithms)\n\n**정의:** 데이터를 특정 순서(오름차순/내림차순)로 배열하는 알고리즘\n\n---\n\n## 주요 정렬 알고리즘\n\n### 1. 버블 정렬 (Bubble Sort)\n\n**개념:** 인접한 두 원소를 비교하여 교환\n\n```java\nvoid bubbleSort(int[] arr) {\n    int n = arr.length;\n    for (int i = 0; i < n - 1; i++) {\n        for (int j = 0; j < n - i - 1; j++) {\n            if (arr[j] > arr[j + 1]) {\n                swap(arr, j, j + 1);\n            }\n        }\n    }\n}\n```\n\n**시간복잡도:**\n- 최선: O(n) (이미 정렬됨)\n- 평균/최악: O(n²)\n\n**공간복잡도:** O(1)\n**Stable:** ✅\n\n---\n\n### 2. 선택 정렬 (Selection Sort)\n\n**개념:** 최솟값을 찾아 맨 앞과 교환\n\n```java\nvoid selectionSort(int[] arr) {\n    int n = arr.length;\n    for (int i = 0; i < n - 1; i++) {\n        int minIdx = i;\n        for (int j = i + 1; j < n; j++) {\n            if (arr[j] < arr[minIdx]) {\n                minIdx = j;\n            }\n        }\n        swap(arr, i, minIdx);\n    }\n}\n```\n\n**시간복잡도:** O(n²) (모든 경우)\n**공간복잡도:** O(1)\n**Stable:** ❌\n\n---\n\n### 3. 삽입 정렬 (Insertion Sort)\n\n**개념:** 현재 원소를 정렬된 부분에 삽입\n\n```java\nvoid insertionSort(int[] arr) {\n    int n = arr.length;\n    for (int i = 1; i < n; i++) {\n        int key = arr[i];\n        int j = i - 1;\n\n        while (j >= 0 && arr[j] > key) {\n            arr[j + 1] = arr[j];\n            j--;\n        }\n        arr[j + 1] = key;\n    }\n}\n```\n\n**시간복잡도:**\n- 최선: O(n) (이미 정렬됨)\n- 평균/최악: O(n²)\n\n**공간복잡도:** O(1)\n**Stable:** ✅\n\n---\n\n### 4. 병합 정렬 (Merge Sort)\n\n**개념:** 분할 정복 (Divide and Conquer)\n\n```java\nvoid mergeSort(int[] arr, int left, int right) {\n    if (left < right) {\n        int mid = left + (right - left) / 2;\n\n        mergeSort(arr, left, mid);\n        mergeSort(arr, mid + 1, right);\n        merge(arr, left, mid, right);\n    }\n}\n\nvoid merge(int[] arr, int left, int mid, int right) {\n    int n1 = mid - left + 1;\n    int n2 = right - mid;\n\n    int[] L = new int[n1];\n    int[] R = new int[n2];\n\n    System.arraycopy(arr, left, L, 0, n1);\n    System.arraycopy(arr, mid + 1, R, 0, n2);\n\n    int i = 0, j = 0, k = left;\n\n    while (i < n1 && j < n2) {\n        if (L[i] <= R[j]) {\n            arr[k++] = L[i++];\n        } else {\n            arr[k++] = R[j++];\n        }\n    }\n\n    while (i < n1) arr[k++] = L[i++];\n    while (j < n2) arr[k++] = R[j++];\n}\n```\n\n**시간복잡도:** O(n log n) (모든 경우)\n**공간복잡도:** O(n)\n**Stable:** ✅\n\n---\n\n### 5. 퀵 정렬 (Quick Sort)\n\n**개념:** 피벗 기준 분할\n\n```java\nvoid quickSort(int[] arr, int low, int high) {\n    if (low < high) {\n        int pi = partition(arr, low, high);\n\n        quickSort(arr, low, pi - 1);\n        quickSort(arr, pi + 1, high);\n    }\n}\n\nint partition(int[] arr, int low, int high) {\n    int pivot = arr[high];\n    int i = low - 1;\n\n    for (int j = low; j < high; j++) {\n        if (arr[j] < pivot) {\n            i++;\n            swap(arr, i, j);\n        }\n    }\n\n    swap(arr, i + 1, high);\n    return i + 1;\n}\n```\n\n**시간복잡도:**\n- 최선/평균: O(n log n)\n- 최악: O(n²) (이미 정렬됨)\n\n**공간복잡도:** O(log n) (재귀 스택)\n**Stable:** ❌\n\n---\n\n### 6. 힙 정렬 (Heap Sort)\n\n```java\nvoid heapSort(int[] arr) {\n    int n = arr.length;\n\n    // Build heap\n    for (int i = n / 2 - 1; i >= 0; i--)\n        heapify(arr, n, i);\n\n    // Extract elements\n    for (int i = n - 1; i > 0; i--) {\n        swap(arr, 0, i);\n        heapify(arr, i, 0);\n    }\n}\n```\n\n**시간복잡도:** O(n log n) (모든 경우)\n**공간복잡도:** O(1)\n**Stable:** ❌\n\n---\n\n### 7. 계수 정렬 (Counting Sort)\n\n**개념:** 값의 빈도수 세기\n\n```java\nvoid countingSort(int[] arr) {\n    int max = Arrays.stream(arr).max().getAsInt();\n    int[] count = new int[max + 1];\n\n    // 빈도수 세기\n    for (int num : arr) {\n        count[num]++;\n    }\n\n    // 누적합\n    for (int i = 1; i <= max; i++) {\n        count[i] += count[i - 1];\n    }\n\n    // 정렬\n    int[] output = new int[arr.length];\n    for (int i = arr.length - 1; i >= 0; i--) {\n        output[count[arr[i]] - 1] = arr[i];\n        count[arr[i]]--;\n    }\n\n    System.arraycopy(output, 0, arr, 0, arr.length);\n}\n```\n\n**시간복잡도:** O(n + k) (k = 최댓값)\n**공간복잡도:** O(n + k)\n**Stable:** ✅\n\n---\n\n### 8. 기수 정렬 (Radix Sort)\n\n**개념:** 자릿수별로 정렬\n\n```java\nvoid radixSort(int[] arr) {\n    int max = Arrays.stream(arr).max().getAsInt();\n\n    for (int exp = 1; max / exp > 0; exp *= 10) {\n        countingSortByDigit(arr, exp);\n    }\n}\n\nvoid countingSortByDigit(int[] arr, int exp) {\n    int[] output = new int[arr.length];\n    int[] count = new int[10];\n\n    for (int num : arr) {\n        count[(num / exp) % 10]++;\n    }\n\n    for (int i = 1; i < 10; i++) {\n        count[i] += count[i - 1];\n    }\n\n    for (int i = arr.length - 1; i >= 0; i--) {\n        int digit = (arr[i] / exp) % 10;\n        output[count[digit] - 1] = arr[i];\n        count[digit]--;\n    }\n\n    System.arraycopy(output, 0, arr, 0, arr.length);\n}\n```\n\n**시간복잡도:** O(d * (n + k)) (d = 자릿수)\n**공간복잡도:** O(n + k)\n**Stable:** ✅\n\n---\n\n## 정렬 알고리즘 비교\n\n| 알고리즘 | 최선 | 평균 | 최악 | 공간 | Stable | 특징 |\n|---------|------|------|------|------|--------|------|\n| Bubble | O(n) | O(n²) | O(n²) | O(1) | ✅ | 단순, 느림 |\n| Selection | O(n²) | O(n²) | O(n²) | O(1) | ❌ | 교환 적음 |\n| Insertion | O(n) | O(n²) | O(n²) | O(1) | ✅ | 거의 정렬된 데이터 빠름 |\n| Merge | O(n log n) | O(n log n) | O(n log n) | O(n) | ✅ | 안정적, 메모리 사용 |\n| Quick | O(n log n) | O(n log n) | O(n²) | O(log n) | ❌ | 평균 가장 빠름 |\n| Heap | O(n log n) | O(n log n) | O(n log n) | O(1) | ❌ | In-place |\n| Counting | O(n+k) | O(n+k) | O(n+k) | O(n+k) | ✅ | 정수 전용 |\n| Radix | O(d(n+k)) | O(d(n+k)) | O(d(n+k)) | O(n+k) | ✅ | 정수/문자열 |\n\n---\n\n## 언어별 기본 정렬\n\n**Java:**\n```java\nArrays.sort(arr);  // Dual-Pivot Quick Sort (원시 타입)\nCollections.sort(list);  // TimSort (객체)\n```\n\n**Python:**\n```python\narr.sort()  # TimSort (Stable)\nsorted(arr)  # TimSort (새 리스트 반환)\n```\n\n**JavaScript:**\n```javascript\narr.sort((a, b) => a - b);  // TimSort 또는 Quick Sort (엔진마다 다름)\n```\n\n**C++:**\n```cpp\nstd::sort(arr.begin(), arr.end());  // IntroSort (Quick + Heap + Insertion)\nstd::stable_sort(arr.begin(), arr.end());  // Merge Sort\n```\n\n---\n\n## 선택 기준\n\n**1. 작은 데이터 (n < 50):**\n- **Insertion Sort** (단순, 빠름)\n\n**2. 일반적인 경우:**\n- **Quick Sort** (평균 최고 성능)\n- **Merge Sort** (Stable 필요 시)\n\n**3. 최악 보장:**\n- **Heap Sort** (O(n log n) 보장, In-place)\n\n**4. 정수 범위 작음:**\n- **Counting Sort** (O(n))\n- **Radix Sort** (O(d*n))\n\n**5. 거의 정렬됨:**\n- **Insertion Sort** (O(n))\n- **Tim Sort** (Merge + Insertion 혼합)\n\n---\n\n## 실전 예시\n\n```java\n// Java의 Arrays.sort() 내부 동작\n\npublic static void sort(int[] arr) {\n    // n < 47: Insertion Sort\n    // 47 ≤ n < 286: Dual-Pivot Quick Sort\n    // n ≥ 286: Merge Sort (일부 정렬된 경우)\n}\n```\n\n---\n\n## 결론\n\n**정렬 알고리즘 선택:**\n\n1. **범용**: Quick Sort\n2. **안정성**: Merge Sort\n3. **메모리 제약**: Heap Sort\n4. **작은 데이터**: Insertion Sort\n5. **정수**: Counting/Radix Sort\n\n**대부분의 경우:**\n- 언어 기본 정렬 사용 (최적화됨)\n- 특수한 요구사항 시에만 직접 구현",
      "type": "essay",
      "tags": [
        "정렬",
        "알고리즘",
        "시간복잡도",
        "Sorting"
      ]
    },
    {
      "question": "Quick Sort와 Merge Sort를 비교해 주세요.",
      "answer": "## Quick Sort vs Merge Sort\n\n---\n\n## 기본 개념\n\n### Quick Sort (퀵 정렬)\n\n**전략:** 분할 정복 (Partition)\n\n```\n1. 피벗 선택\n2. 피벗보다 작은 것은 왼쪽, 큰 것은 오른쪽 배치\n3. 재귀적으로 정렬\n\n    [5, 2, 9, 1, 7, 6]\n    피벗 = 6\n\n    [5, 2, 1] [6] [9, 7]\n       ↓            ↓\n    재귀 정렬    재귀 정렬\n```\n\n### Merge Sort (병합 정렬)\n\n**전략:** 분할 정복 (Divide & Merge)\n\n```\n1. 배열을 반으로 나눔\n2. 재귀적으로 정렬\n3. 정렬된 두 부분을 병합\n\n    [5, 2, 9, 1]\n       ↓\n    [5, 2] [9, 1]\n       ↓      ↓\n    [5][2] [9][1]\n       ↓      ↓\n    [2, 5] [1, 9]\n       ↓\n    [1, 2, 5, 9]\n```\n\n---\n\n## 상세 비교\n\n### 1. 시간복잡도\n\n| 경우 | Quick Sort | Merge Sort |\n|------|------------|------------|\n| 최선 | O(n log n) | O(n log n) |\n| 평균 | O(n log n) | O(n log n) |\n| 최악 | **O(n²)** | O(n log n) |\n\n**Quick Sort 최악:**\n```\n이미 정렬된 배열 + 첫 원소를 피벗으로:\n\n[1, 2, 3, 4, 5]\n피벗 = 1\n[_] [1] [2, 3, 4, 5]  ← 불균형!\n         ↓\n      피벗 = 2\n      [_] [2] [3, 4, 5]\n               ↓\n            O(n²) 발생\n```\n\n**Merge Sort는 항상 균등 분할:**\n```\n[1, 2, 3, 4]\n   ↓\n[1, 2] [3, 4]  ← 항상 반으로\n```\n\n---\n\n### 2. 공간복잡도\n\n**Quick Sort:** O(log n)\n- In-place 정렬 (추가 배열 불필요)\n- 재귀 스택만 사용\n\n**Merge Sort:** O(n)\n- 병합을 위한 임시 배열 필요\n- 메모리 오버헤드\n\n```java\n// Merge Sort 공간 사용\nvoid merge(int[] arr, int left, int mid, int right) {\n    int[] temp = new int[right - left + 1];  // O(n) 추가 메모리\n    // ...\n}\n```\n\n---\n\n### 3. Stability (안정성)\n\n**Quick Sort:** Unstable\n```\n초기: [3a, 2, 3b]\n피벗 = 3b\n결과: [2, 3b, 3a]  ← 순서 바뀜!\n```\n\n**Merge Sort:** Stable\n```\n초기: [3a, 2, 3b]\n분할: [3a, 2] [3b]\n병합: [2, 3a, 3b]  ← 순서 유지!\n```\n\n---\n\n### 4. 실제 성능\n\n**평균적으로 Quick Sort가 더 빠름!**\n\n```java\n// 100만 개 정렬 벤치마크\n\nQuick Sort:  80ms   ★ (빠름)\nMerge Sort:  120ms\n\n왜?\n1. 캐시 효율: In-place → 메모리 접근 연속\n2. 상수 계수: 단순한 비교/교환\n3. 분기 예측: 피벗 비교가 효율적\n```\n\n**Merge Sort가 빠른 경우:**\n```\n1. 최악 성능 보장 필요\n2. Stable 정렬 필요\n3. 링크드 리스트 정렬 (O(1) 병합)\n```\n\n---\n\n### 5. 구현 복잡도\n\n**Quick Sort (간단):**\n\n```java\nvoid quickSort(int[] arr, int low, int high) {\n    if (low < high) {\n        int pi = partition(arr, low, high);\n        quickSort(arr, low, pi - 1);\n        quickSort(arr, pi + 1, high);\n    }\n}\n\nint partition(int[] arr, int low, int high) {\n    int pivot = arr[high];\n    int i = low - 1;\n\n    for (int j = low; j < high; j++) {\n        if (arr[j] < pivot) {\n            swap(arr, ++i, j);\n        }\n    }\n    swap(arr, i + 1, high);\n    return i + 1;\n}\n```\n\n**Merge Sort (복잡):**\n\n```java\nvoid mergeSort(int[] arr, int left, int right) {\n    if (left < right) {\n        int mid = left + (right - left) / 2;\n        mergeSort(arr, left, mid);\n        mergeSort(arr, mid + 1, right);\n        merge(arr, left, mid, right);\n    }\n}\n\nvoid merge(int[] arr, int left, int mid, int right) {\n    // 임시 배열 생성\n    // 병합 로직 (10줄 이상)\n    // ...\n}\n```\n\n---\n\n## 장단점 비교\n\n### Quick Sort\n\n**장점:**\n- 평균 가장 빠름\n- In-place (메모리 효율)\n- 캐시 친화적\n- 구현 간단\n\n**단점:**\n- 최악 O(n²)\n- Unstable\n- 재귀 깊이 (스택 오버플로 가능)\n\n### Merge Sort\n\n**장점:**\n- 최악도 O(n log n) 보장\n- Stable\n- 병렬화 쉬움\n- 예측 가능한 성능\n\n**단점:**\n- O(n) 추가 메모리\n- 상수 계수 큼\n- 작은 데이터에 비효율\n\n---\n\n## 최적화 기법\n\n### Quick Sort 최적화\n\n**1. 랜덤 피벗:**\n```java\nint randomPivot = low + random.nextInt(high - low + 1);\nswap(arr, randomPivot, high);\n```\n\n**2. 중앙값 피벗 (Median of Three):**\n```java\nint mid = low + (high - low) / 2;\nif (arr[mid] < arr[low]) swap(arr, low, mid);\nif (arr[high] < arr[low]) swap(arr, low, high);\nif (arr[mid] < arr[high]) swap(arr, mid, high);\n// arr[high] = 중앙값\n```\n\n**3. Hybrid (IntroSort):**\n```java\nvoid introSort(int[] arr, int depth) {\n    if (depth == 0) {\n        heapSort(arr);  // Quick이 느리면 Heap으로 전환\n    } else {\n        quickSort(arr, depth - 1);\n    }\n}\n```\n\n### Merge Sort 최적화\n\n**1. 작은 배열 → Insertion Sort:**\n```java\nvoid mergeSort(int[] arr, int left, int right) {\n    if (right - left < 10) {\n        insertionSort(arr, left, right);  // 작으면 Insertion\n    } else {\n        // Merge Sort\n    }\n}\n```\n\n**2. In-place Merge (복잡하지만 메모리 절약):**\n```java\n// 추가 배열 없이 병합 (구현 복잡)\n```\n\n---\n\n## 언어별 선택\n\n**Java:**\n```java\n// 원시 타입: Dual-Pivot Quick Sort\nArrays.sort(int[] arr);\n\n// 객체: TimSort (Merge + Insertion)\nCollections.sort(List<T> list);\n```\n\n**Python:**\n```python\n# TimSort (Merge + Insertion, Stable)\narr.sort()\n```\n\n**C++:**\n```cpp\n// IntroSort (Quick + Heap + Insertion)\nstd::sort(arr.begin(), arr.end());\n\n// Stable이 필요하면:\nstd::stable_sort(arr.begin(), arr.end());  // Merge Sort\n```\n\n---\n\n## 사용 시나리오\n\n### Quick Sort 사용\n\n```\n✅ 일반적인 경우 (평균 최고 성능)\n✅ 메모리 제약 있음\n✅ Stable 불필요\n✅ 캐시 효율 중요\n\n예: 대부분의 정렬 작업\n```\n\n### Merge Sort 사용\n\n```\n✅ 최악 성능 보장 필요\n✅ Stable 필요 (같은 값 순서 유지)\n✅ 병렬 처리\n✅ 링크드 리스트 정렬\n\n예: 외부 정렬, 데이터베이스 정렬\n```\n\n---\n\n## 실전 성능 비교\n\n```java\n// 100만 개 랜덤 데이터\n\nQuick Sort:\n  평균: 80ms\n  최악: 8000ms (정렬된 데이터)\n\nMerge Sort:\n  평균: 120ms\n  최악: 120ms  ← 일정!\n\n// 거의 정렬된 데이터\n\nQuick Sort: 5000ms (O(n²) 발생)\nMerge Sort: 120ms\n\n// 랜덤 데이터 + 피벗 최적화\n\nQuick Sort (랜덤 피벗): 75ms  ★\nMerge Sort: 120ms\n```\n\n---\n\n## 하이브리드 접근 (TimSort)\n\n**Python/Java의 TimSort:**\n\n```\n1. 작은 부분 (< 64): Insertion Sort\n2. Run(연속 정렬 부분) 찾기\n3. Run들을 Merge Sort로 병합\n\n장점:\n- 평균 O(n log n)\n- 최선 O(n) (이미 정렬됨)\n- Stable\n- 실전 데이터에 최적화\n```\n\n---\n\n## 결론\n\n**Quick Sort:**\n- **평균 최고 성능**\n- 일반적으로 선호\n- 피벗 선택 중요\n\n**Merge Sort:**\n- **안정적이고 예측 가능**\n- Stable 필요 시\n- 최악 보장 필요 시\n\n**실전:**\n```\n대부분: Quick Sort (최적화 버전)\n특수: Merge Sort (Stable, 최악 보장)\n최고: TimSort/IntroSort (하이브리드)\n```\n\n**추천:**\n```\n언어 기본 정렬 사용 (이미 최적화됨)\n특별한 요구사항이 없으면 Arrays.sort() 등 사용\n```",
      "type": "essay",
      "tags": [
        "Quick Sort",
        "Merge Sort",
        "정렬",
        "비교"
      ]
    },
    {
      "question": "Quick Sort에서 O(N^2)이 걸리는 예시를 들고, 이를 개선할 수 있는 방법에 대해 설명해 주세요.",
      "answer": "## Quick Sort O(N²) 발생 상황\n\n### 최악의 경우: 불균형 분할\n\n**발생 조건:**\n- 피벗이 항상 최솟값 또는 최댓값일 때\n- 매번 한쪽으로만 분할\n\n---\n\n## 예시 1: 이미 정렬된 배열 + 마지막 원소 피벗\n\n```java\nint[] arr = {1, 2, 3, 4, 5};\n// 피벗을 항상 마지막 원소로 선택\n\npartition(arr, 0, 4):\n  피벗 = 5\n  [1, 2, 3, 4] | 5 |  ← 불균형!\n\npartition(arr, 0, 3):\n  피벗 = 4\n  [1, 2, 3] | 4 |\n\npartition(arr, 0, 2):\n  피벗 = 3\n  [1, 2] | 3 |\n\npartition(arr, 0, 1):\n  피벗 = 2\n  [1] | 2 |\n\npartition(arr, 0, 0):\n  [1]  ← 종료\n```\n\n**재귀 트리:**\n```\n        [1,2,3,4,5]     ← n\n             |\n        [1,2,3,4]       ← n-1\n             |\n        [1,2,3]         ← n-2\n             |\n        [1,2]           ← n-3\n             |\n        [1]             ← n-4\n\n깊이: n\n각 레벨 비용: O(n)\n총 비용: O(n²)\n```\n\n---\n\n## 예시 2: 역순 정렬 + 첫 원소 피벗\n\n```java\nint[] arr = {5, 4, 3, 2, 1};\n// 피벗을 항상 첫 원소로 선택\n\npartition(arr, 0, 4):\n  피벗 = 5\n  | 5 | [4, 3, 2, 1]  ← 불균형!\n\npartition(arr, 0, 3):\n  피벗 = 4\n  | 4 | [3, 2, 1]\n\n// 동일하게 O(n²)\n```\n\n---\n\n## 예시 3: 동일한 값들\n\n```java\nint[] arr = {5, 5, 5, 5, 5};\n// 피벗 = 5\n\npartition(arr, 0, 4):\n  // 모든 원소가 피벗과 같음\n  // 한쪽으로 몰림\n\n  결과: [] | 5 | [5, 5, 5, 5]  ← O(n²)\n```\n\n---\n\n## 시간복잡도 증명\n\n```\nT(n) = T(0) + T(n-1) + O(n)\n     = T(n-1) + O(n)\n     = T(n-2) + O(n-1) + O(n)\n     = ...\n     = O(n) + O(n-1) + ... + O(1)\n     = O(n²)\n```\n\n---\n\n## 개선 방법\n\n### 1. 랜덤 피벗 선택\n\n**개념:** 피벗을 랜덤하게 선택\n\n```java\nimport java.util.Random;\n\nRandom random = new Random();\n\nint partition(int[] arr, int low, int high) {\n    // 랜덤 인덱스 선택\n    int randomIndex = low + random.nextInt(high - low + 1);\n\n    // 랜덤 원소를 마지막으로 이동\n    swap(arr, randomIndex, high);\n\n    // 기존 partition 로직\n    int pivot = arr[high];\n    int i = low - 1;\n\n    for (int j = low; j < high; j++) {\n        if (arr[j] < pivot) {\n            swap(arr, ++i, j);\n        }\n    }\n    swap(arr, i + 1, high);\n    return i + 1;\n}\n```\n\n**효과:**\n```\n정렬된 배열 [1, 2, 3, 4, 5]:\n\n랜덤 피벗 = 3\n[1, 2] | 3 | [4, 5]  ← 균형!\n\n기대 시간복잡도: O(n log n)\n최악은 여전히 O(n²)이지만 확률 낮음 (1/n!)\n```\n\n---\n\n### 2. Median of Three (중앙값)\n\n**개념:** 첫, 중간, 끝 원소의 중앙값을 피벗으로\n\n```java\nint medianOfThree(int[] arr, int low, int high) {\n    int mid = low + (high - low) / 2;\n\n    // 정렬: arr[low] <= arr[mid] <= arr[high]\n    if (arr[mid] < arr[low])\n        swap(arr, low, mid);\n    if (arr[high] < arr[low])\n        swap(arr, low, high);\n    if (arr[mid] < arr[high])\n        swap(arr, mid, high);\n\n    // arr[high]가 중앙값\n    return high;\n}\n\nvoid quickSort(int[] arr, int low, int high) {\n    if (low < high) {\n        int pivotIdx = medianOfThree(arr, low, high);\n        swap(arr, pivotIdx, high);  // 피벗을 끝으로\n\n        int pi = partition(arr, low, high);\n        quickSort(arr, low, pi - 1);\n        quickSort(arr, pi + 1, high);\n    }\n}\n```\n\n**효과:**\n```\n배열: [1, 2, 3, 4, 5]\nlow = 1, mid = 3, high = 5\n\n중앙값 = 3 (피벗)\n[1, 2] | 3 | [4, 5]  ← 균형!\n\n정렬된 배열에서도 O(n log n)\n```\n\n---\n\n### 3. Three-Way Partitioning (3-Way 분할)\n\n**개념:** 피벗보다 작음, 같음, 큼으로 3분할\n\n```java\nvoid quickSort3Way(int[] arr, int low, int high) {\n    if (low >= high) return;\n\n    int lt = low, gt = high;\n    int pivot = arr[low];\n    int i = low + 1;\n\n    while (i <= gt) {\n        if (arr[i] < pivot) {\n            swap(arr, lt++, i++);\n        } else if (arr[i] > pivot) {\n            swap(arr, i, gt--);\n        } else {\n            i++;  // arr[i] == pivot\n        }\n    }\n\n    // [< pivot] [== pivot] [> pivot]\n    //     lt        i        gt\n\n    quickSort3Way(arr, low, lt - 1);\n    quickSort3Way(arr, gt + 1, high);\n}\n```\n\n**동작 예시:**\n```\n배열: [5, 5, 5, 5, 5]\n피벗 = 5\n\n분할 후:\n[] [5, 5, 5, 5, 5] []  ← 같은 값은 재귀 안 함!\n\n시간: O(n) (단일 패스)\n\n일반 Quick Sort: O(n²)\n3-Way: O(n)  ← 중복 많을 때 효율적!\n```\n\n**효과:**\n- 중복 값이 많을 때 매우 효율적\n- 동일 값은 재귀에서 제외\n\n---\n\n### 4. IntroSort (하이브리드)\n\n**개념:** Quick Sort + Heap Sort 조합\n\n```java\nvoid introSort(int[] arr, int low, int high, int maxDepth) {\n    if (high - low < 16) {\n        insertionSort(arr, low, high);  // 작으면 Insertion\n        return;\n    }\n\n    if (maxDepth == 0) {\n        heapSort(arr, low, high);  // 깊이 초과 → Heap Sort\n        return;\n    }\n\n    // Quick Sort\n    int pi = partition(arr, low, high);\n    introSort(arr, low, pi - 1, maxDepth - 1);\n    introSort(arr, pi + 1, high, maxDepth - 1);\n}\n\nvoid introSort(int[] arr) {\n    int maxDepth = 2 * (int)(Math.log(arr.length) / Math.log(2));\n    introSort(arr, 0, arr.length - 1, maxDepth);\n}\n```\n\n**장점:**\n```\n일반적: Quick Sort (빠름)\n최악 발생: Heap Sort로 전환 (O(n log n) 보장)\n\n최악 시간복잡도: O(n log n) 보장!\n```\n\n---\n\n### 5. Tail Call 최적화\n\n**개념:** 한쪽만 재귀, 다른 쪽은 반복문\n\n```java\nvoid quickSortOptimized(int[] arr, int low, int high) {\n    while (low < high) {\n        int pi = partition(arr, low, high);\n\n        // 작은 쪽을 재귀\n        if (pi - low < high - pi) {\n            quickSortOptimized(arr, low, pi - 1);\n            low = pi + 1;  // 큰 쪽은 반복문\n        } else {\n            quickSortOptimized(arr, pi + 1, high);\n            high = pi - 1;\n        }\n    }\n}\n```\n\n**효과:**\n- 재귀 깊이를 O(log n)으로 제한\n- 스택 오버플로 방지\n\n---\n\n## 방법별 비교\n\n| 방법 | 최악 | 구현 | 효과 |\n|------|------|------|------|\n| 랜덤 피벗 | O(n²)* | 간단 | 확률적 개선 |\n| Median of Three | O(n log n)** | 간단 | 정렬 데이터 개선 |\n| 3-Way Partition | O(n log n) | 중간 | 중복 많을 때 ★ |\n| IntroSort | O(n log n) | 복잡 | 최악 보장 ★ |\n| Tail Call | 재귀 깊이 감소 | 중간 | 스택 오버플로 방지 |\n\n*실질적으로 거의 발생 안 함\n**특정 패턴에서는 여전히 O(n²)\n\n---\n\n## 실전 벤치마크\n\n```java\n// 100만 개, 이미 정렬된 데이터\n\n기본 Quick Sort:        8000ms  (O(n²))\n랜덤 피벗:              75ms    (O(n log n))\nMedian of Three:        80ms\n3-Way Partition:        70ms    (중복 있으면 더 빠름)\nIntroSort:              85ms\n\n// 중복 많은 데이터 (50% 동일)\n\n기본 Quick Sort:        5000ms\n3-Way Partition:        60ms    ★ (압도적)\n```\n\n---\n\n## C++ STL의 std::sort\n\n```cpp\n// IntroSort 사용\ntemplate<typename Iter>\nvoid sort(Iter first, Iter last) {\n    if (last - first > 16) {\n        // Quick Sort (Median of Three)\n        // 깊이 초과 시 Heap Sort\n    } else {\n        // Insertion Sort\n    }\n}\n\n// 최악 O(n log n) 보장!\n```\n\n---\n\n## 결론\n\n**Quick Sort O(n²) 발생:**\n1. 정렬된 데이터 + 고정 피벗\n2. 역순 데이터 + 고정 피벗\n3. 중복 값 많음\n\n**개선 방법:**\n\n**간단하고 효과적:**\n1. **랜덤 피벗** (가장 간단)\n2. **Median of Three** (정렬 데이터 대응)\n\n**완벽한 해결:**\n3. **3-Way Partition** (중복 많을 때)\n4. **IntroSort** (최악 보장, C++ STL 방식)\n\n**권장:**\n```java\n// 일반적: 랜덤 피벗 또는 Median of Three\n// 중복 많음: 3-Way Partition\n// 최악 보장: IntroSort\n// 실전: 언어 기본 정렬 (이미 최적화됨)\n```",
      "type": "essay",
      "tags": [
        "Quick Sort",
        "시간복잡도",
        "최적화",
        "O(N²)"
      ]
    },
    {
      "question": "Stable Sort가 무엇이고, 어떤 정렬 알고리즘이 Stable 한지 설명해 주세요.",
      "answer": "## Stable Sort (안정 정렬)\n\n**정의:**\n**같은 값의 상대적 순서가 정렬 후에도 유지**되는 정렬\n\n---\n\n## Stable의 의미\n\n### 예시\n\n```\n초기 데이터: [(3, a), (1, b), (3, c), (2, d)]\n// (값, 원래 순서)\n\nStable Sort 결과:\n[(1, b), (2, d), (3, a), (3, c)]\n                   ↑       ↑\n            원래 순서 유지! (a가 c보다 먼저)\n\nUnstable Sort 결과:\n[(1, b), (2, d), (3, c), (3, a)]\n                   ↑       ↑\n            순서 바뀜! (c가 a보다 먼저)\n```\n\n---\n\n## 왜 Stable이 중요한가?\n\n### 실전 예시: 학생 성적 정렬\n\n```java\nclass Student {\n    String name;\n    int score;\n    int enrollmentOrder;  // 입학 순서\n}\n\nStudent[] students = {\n    {\"Alice\", 85, 1},\n    {\"Bob\", 90, 2},\n    {\"Charlie\", 85, 3},\n    {\"David\", 90, 4}\n};\n\n// 1단계: 점수로 정렬 (Stable)\n결과: [Alice(85, 1), Charlie(85, 3), Bob(90, 2), David(90, 4)]\n\n// 2단계: 같은 점수 내에서 입학 순서 유지됨!\n// 만약 Unstable이었다면:\n결과: [Charlie(85, 3), Alice(85, 1), ...]  ← 순서 엉망\n```\n\n---\n\n## Stable 여부 판별\n\n### Stable한 알고리즘\n\n**1. Bubble Sort ✅**\n\n```java\nvoid bubbleSort(int[] arr) {\n    for (int i = 0; i < n - 1; i++) {\n        for (int j = 0; j < n - i - 1; j++) {\n            if (arr[j] > arr[j + 1]) {  // > (not >=)\n                swap(arr, j, j + 1);\n            }\n        }\n    }\n}\n\n// 같은 값은 교환 안 함 → Stable\n```\n\n**예시:**\n```\n[3a, 1, 3b]\n\ni=0, j=0: 3a > 1 → [1, 3a, 3b]\ni=0, j=1: 3a > 3b? No (같으면 교환 안 함)\n\n결과: [1, 3a, 3b]  ← 순서 유지!\n```\n\n---\n\n**2. Insertion Sort ✅**\n\n```java\nvoid insertionSort(int[] arr) {\n    for (int i = 1; i < n; i++) {\n        int key = arr[i];\n        int j = i - 1;\n\n        while (j >= 0 && arr[j] > key) {  // > (not >=)\n            arr[j + 1] = arr[j];\n            j--;\n        }\n        arr[j + 1] = key;\n    }\n}\n\n// 같은 값보다 뒤에 삽입 → Stable\n```\n\n**예시:**\n```\n[3a, 1, 3b]\n\ni=1: key=1, 3a > 1 → [1, 3a, 3b]\ni=2: key=3b, 3a > 3b? No → 그대로\n\n결과: [1, 3a, 3b]  ← Stable\n```\n\n---\n\n**3. Merge Sort ✅**\n\n```java\nvoid merge(int[] arr, int left, int mid, int right) {\n    // ...\n\n    while (i < n1 && j < n2) {\n        if (L[i] <= R[j]) {  // <= (같으면 왼쪽 먼저)\n            arr[k++] = L[i++];\n        } else {\n            arr[k++] = R[j++];\n        }\n    }\n}\n\n// 같으면 왼쪽(앞쪽) 먼저 선택 → Stable\n```\n\n**예시:**\n```\n초기: [3a, 1, 3b]\n\n분할: [3a, 1] [3b]\n\n정렬: [1, 3a] [3b]\n\n병합:\n  L=[1, 3a], R=[3b]\n  1 < 3b → [1]\n  3a <= 3b → [1, 3a]  ← 같으면 왼쪽 먼저\n\n결과: [1, 3a, 3b]  ← Stable!\n```\n\n---\n\n**4. Counting Sort ✅**\n\n```java\nvoid countingSort(int[] arr) {\n    int[] count = new int[max + 1];\n    int[] output = new int[n];\n\n    // 빈도수\n    for (int num : arr) count[num]++;\n\n    // 누적합\n    for (int i = 1; i <= max; i++) {\n        count[i] += count[i - 1];\n    }\n\n    // 뒤에서부터 배치 (핵심!)\n    for (int i = n - 1; i >= 0; i--) {\n        output[count[arr[i]] - 1] = arr[i];\n        count[arr[i]]--;\n    }\n}\n\n// 뒤에서부터 배치 → 상대 순서 유지 → Stable\n```\n\n---\n\n**5. Radix Sort ✅**\n\n```\nCounting Sort를 반복 → Stable\n```\n\n---\n\n**6. Tim Sort ✅**\n\n```\nMerge Sort + Insertion Sort → 둘 다 Stable → Stable\n```\n\n---\n\n### Unstable한 알고리즘\n\n**1. Selection Sort ❌**\n\n```java\nvoid selectionSort(int[] arr) {\n    for (int i = 0; i < n - 1; i++) {\n        int minIdx = i;\n        for (int j = i + 1; j < n; j++) {\n            if (arr[j] < arr[minIdx]) {\n                minIdx = j;\n            }\n        }\n        swap(arr, i, minIdx);  // 먼 거리 교환 → 순서 깨짐\n    }\n}\n```\n\n**왜 Unstable?**\n```\n[3a, 2, 3b, 1]\n\ni=0: minIdx=3 (1)\nswap(0, 3) → [1, 2, 3b, 3a]\n                   ↑    ↑\n               순서 바뀜!\n```\n\n---\n\n**2. Quick Sort ❌**\n\n```java\nint partition(int[] arr, int low, int high) {\n    int pivot = arr[high];\n    int i = low - 1;\n\n    for (int j = low; j < high; j++) {\n        if (arr[j] < pivot) {\n            swap(arr, ++i, j);  // 교환으로 순서 깨짐\n        }\n    }\n    swap(arr, i + 1, high);\n    return i + 1;\n}\n```\n\n**왜 Unstable?**\n```\n[3a, 2, 3b, 1]\n피벗 = 1\n\npartition 후:\n[1, 2, 3b, 3a]  ← 3a와 3b 순서 바뀜\n```\n\n---\n\n**3. Heap Sort ❌**\n\n```java\nvoid heapSort(int[] arr) {\n    buildHeap(arr);\n\n    for (int i = n - 1; i > 0; i--) {\n        swap(arr, 0, i);  // 루트와 끝 교환 → 순서 깨짐\n        heapify(arr, i, 0);\n    }\n}\n```\n\n**왜 Unstable?**\n```\n[3a, 1, 3b]\n\nBuild Heap:\n      3a\n     /  \\\n   1    3b\n\nExtract Max: 3a와 3b 교환\n[3b, 1, 3a]  ← 순서 바뀜\n```\n\n---\n\n## Stable 여부 정리\n\n| 알고리즘 | Stable | 이유 |\n|---------|--------|------|\n| Bubble Sort | ✅ | 인접 비교, 같으면 교환 안 함 |\n| Insertion Sort | ✅ | 같은 값 뒤에 삽입 |\n| Merge Sort | ✅ | 같으면 왼쪽 먼저 선택 |\n| Counting Sort | ✅ | 뒤에서부터 배치 |\n| Radix Sort | ✅ | Counting Sort 기반 |\n| Tim Sort | ✅ | Merge + Insertion |\n| **Selection Sort** | ❌ | 먼 거리 교환 |\n| **Quick Sort** | ❌ | Partition 시 교환 |\n| **Heap Sort** | ❌ | 힙 구조 유지 중 교환 |\n\n---\n\n## Unstable을 Stable하게 만들기\n\n### 방법: 원래 인덱스 함께 저장\n\n```java\nclass Item implements Comparable<Item> {\n    int value;\n    int index;  // 원래 위치\n\n    @Override\n    public int compareTo(Item o) {\n        if (this.value != o.value) {\n            return this.value - o.value;\n        }\n        return this.index - o.index;  // 같으면 인덱스로 비교\n    }\n}\n\n// Quick Sort에도 Stable처럼 동작\nItem[] items = new Item[n];\nfor (int i = 0; i < n; i++) {\n    items[i] = new Item(arr[i], i);\n}\n\nArrays.sort(items);  // Quick Sort지만 Stable처럼\n```\n\n**단점:**\n- 추가 메모리 (인덱스 저장)\n- 비교 연산 증가\n\n---\n\n## 언어별 기본 정렬\n\n| 언어 | 정렬 함수 | 알고리즘 | Stable |\n|------|----------|---------|--------|\n| Java (원시) | Arrays.sort() | Dual-Pivot Quick | ❌ |\n| Java (객체) | Collections.sort() | Tim Sort | ✅ |\n| Python | list.sort() | Tim Sort | ✅ |\n| JavaScript | Array.sort() | Tim Sort | ✅* |\n| C++ | std::sort() | Intro Sort | ❌ |\n| C++ | std::stable_sort() | Merge Sort | ✅ |\n\n*엔진마다 다름, V8은 Tim Sort\n\n---\n\n## 실전 사용\n\n### Stable이 필요한 경우\n\n```java\n// 1. 다단계 정렬\nstudents.sort(Comparator.comparing(Student::getName));  // 1차: 이름\nstudents.sort(Comparator.comparing(Student::getScore)); // 2차: 점수\n// 같은 점수 내에서 이름 순서 유지됨!\n\n// 2. 동점자 처리\nranks.sort((a, b) -> {\n    if (a.score != b.score) return b.score - a.score;\n    return 0;  // 같으면 원래 순서 유지 (Stable 필요)\n});\n```\n\n### Stable 불필요한 경우\n\n```java\n// 단순 정렬\nint[] arr = {5, 2, 8, 1, 9};\nArrays.sort(arr);  // Quick Sort (빠름)\n\n// 같은 값 없음\n// 순서 상관없음\n```\n\n---\n\n## 성능 비교\n\n```java\n// 100만 개 정렬\n\nQuick Sort (Unstable):     80ms   ★\nMerge Sort (Stable):       120ms\nTim Sort (Stable):         110ms  ★★ (실전 데이터)\n\n// Stable이 필요하면:\nTim Sort (최고) > Merge Sort > Bubble/Insertion (느림)\n```\n\n---\n\n## 결론\n\n**Stable Sort:**\n- 같은 값의 순서 유지\n- 다단계 정렬, 동점자 처리 필요 시\n\n**Stable 알고리즘:**\n- Merge Sort, Tim Sort (추천)\n- Bubble, Insertion (느림)\n- Counting, Radix (정수)\n\n**Unstable 알고리즘:**\n- Quick Sort, Heap Sort (빠름)\n- Selection Sort\n\n**실전:**\n```\nStable 필요: Collections.sort() (Java), sorted() (Python)\nStable 불필요: Arrays.sort() (Java 원시 타입)\n중요: 언어 기본 정렬 사용 (이미 최적화됨)\n```",
      "type": "essay",
      "tags": [
        "Stable Sort",
        "정렬",
        "알고리즘",
        "안정성"
      ]
    },
    {
      "question": "Merge Sort를 재귀를 사용하지 않고 구현할 수 있을까요?",
      "answer": "## 비재귀 Merge Sort (Iterative Merge Sort)\n\n**답:** 네, **Bottom-Up 방식**으로 가능합니다!\n\n---\n\n## 재귀 vs 반복 비교\n\n### 재귀 방식 (Top-Down)\n\n```java\nvoid mergeSortRecursive(int[] arr, int left, int right) {\n    if (left < right) {\n        int mid = left + (right - left) / 2;\n\n        mergeSortRecursive(arr, left, mid);      // 왼쪽 재귀\n        mergeSortRecursive(arr, mid + 1, right); // 오른쪽 재귀\n        merge(arr, left, mid, right);\n    }\n}\n\n동작:\n[8, 4, 2, 1]\n     ↓ (분할)\n[8, 4]  [2, 1]\n  ↓       ↓\n[8][4] [2][1]\n  ↓       ↓ (병합)\n[4, 8]  [1, 2]\n     ↓\n[1, 2, 4, 8]\n```\n\n### 반복 방식 (Bottom-Up)\n\n```java\nvoid mergeSortIterative(int[] arr) {\n    int n = arr.length;\n\n    // 크기를 1, 2, 4, 8, ... 로 증가\n    for (int size = 1; size < n; size *= 2) {\n        // 각 크기별로 병합\n        for (int left = 0; left < n - size; left += 2 * size) {\n            int mid = left + size - 1;\n            int right = Math.min(left + 2 * size - 1, n - 1);\n\n            merge(arr, left, mid, right);\n        }\n    }\n}\n\n동작:\n[8, 4, 2, 1]\n\nsize=1:\n  [8][4] → [4, 8]\n  [2][1] → [1, 2]\n  결과: [4, 8, 1, 2]\n\nsize=2:\n  [4, 8][1, 2] → [1, 2, 4, 8]\n  결과: [1, 2, 4, 8]\n```\n\n---\n\n## 완전한 구현\n\n```java\npublic class IterativeMergeSort {\n\n    public static void mergeSort(int[] arr) {\n        int n = arr.length;\n        int[] temp = new int[n];  // 임시 배열\n\n        // 크기: 1, 2, 4, 8, ...\n        for (int size = 1; size < n; size *= 2) {\n\n            // 각 크기의 부분 배열들을 병합\n            for (int left = 0; left < n - size; left += 2 * size) {\n                int mid = left + size - 1;\n                int right = Math.min(left + 2 * size - 1, n - 1);\n\n                merge(arr, temp, left, mid, right);\n            }\n        }\n    }\n\n    private static void merge(int[] arr, int[] temp,\n                             int left, int mid, int right) {\n        // 임시 배열에 복사\n        for (int i = left; i <= right; i++) {\n            temp[i] = arr[i];\n        }\n\n        int i = left;       // 왼쪽 부분 시작\n        int j = mid + 1;    // 오른쪽 부분 시작\n        int k = left;       // 병합 위치\n\n        // 병합\n        while (i <= mid && j <= right) {\n            if (temp[i] <= temp[j]) {\n                arr[k++] = temp[i++];\n            } else {\n                arr[k++] = temp[j++];\n            }\n        }\n\n        // 남은 원소 복사\n        while (i <= mid) {\n            arr[k++] = temp[i++];\n        }\n\n        while (j <= right) {\n            arr[k++] = temp[j++];\n        }\n    }\n\n    public static void main(String[] args) {\n        int[] arr = {8, 4, 2, 1, 7, 3, 5, 6};\n\n        System.out.println(\"Original: \" + Arrays.toString(arr));\n        mergeSort(arr);\n        System.out.println(\"Sorted: \" + Arrays.toString(arr));\n    }\n}\n```\n\n---\n\n## 동작 과정 상세\n\n### 예시: [8, 4, 2, 1, 7, 3]\n\n```\n초기: [8, 4, 2, 1, 7, 3]\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nsize = 1 (1개씩 병합):\n\nleft=0: [8, 4] → [4, 8]\nleft=2: [2, 1] → [1, 2]\nleft=4: [7, 3] → [3, 7]\n\n결과: [4, 8, 1, 2, 3, 7]\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nsize = 2 (2개씩 병합):\n\nleft=0: [4, 8][1, 2] → [1, 2, 4, 8]\nleft=4: [3, 7]만 (병합 안 함)\n\n결과: [1, 2, 4, 8, 3, 7]\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\nsize = 4 (4개씩 병합):\n\nleft=0: [1, 2, 4, 8][3, 7] → [1, 2, 3, 4, 7, 8]\n\n최종: [1, 2, 3, 4, 7, 8]\n```\n\n---\n\n## 인덱스 계산 상세\n\n```java\nfor (int size = 1; size < n; size *= 2) {\n    // size = 1: 1개씩\n    // size = 2: 2개씩\n    // size = 4: 4개씩\n    // ...\n\n    for (int left = 0; left < n - size; left += 2 * size) {\n        // left: 왼쪽 시작\n        // left += 2*size: 다음 그룹으로 (왼쪽 + 오른쪽)\n\n        int mid = left + size - 1;\n        // mid: 왼쪽 끝 = left + (size - 1)\n\n        int right = Math.min(left + 2 * size - 1, n - 1);\n        // right: 오른쪽 끝 (배열 끝 초과 방지)\n\n        merge(arr, temp, left, mid, right);\n    }\n}\n```\n\n**예시: n=8, size=2**\n```\nleft=0: [0, 1][2, 3] → mid=1, right=3\nleft=4: [4, 5][6, 7] → mid=5, right=7\nleft=8: 종료 (left >= n - size)\n```\n\n---\n\n## 메모리 최적화 버전\n\n**문제:** 매번 임시 배열 할당하면 비효율\n\n**해결:** 두 배열 번갈아 사용\n\n```java\npublic static void mergeSortOptimized(int[] arr) {\n    int n = arr.length;\n    int[] src = arr;\n    int[] dst = new int[n];\n\n    for (int size = 1; size < n; size *= 2) {\n        for (int left = 0; left < n - size; left += 2 * size) {\n            int mid = left + size - 1;\n            int right = Math.min(left + 2 * size - 1, n - 1);\n\n            mergeAB(src, dst, left, mid, right);\n        }\n\n        // src ↔ dst 교환\n        int[] temp = src;\n        src = dst;\n        dst = temp;\n    }\n\n    // 최종 결과가 src에 있으면 arr로 복사\n    if (src != arr) {\n        System.arraycopy(src, 0, arr, 0, n);\n    }\n}\n\nprivate static void mergeAB(int[] src, int[] dst,\n                            int left, int mid, int right) {\n    int i = left, j = mid + 1, k = left;\n\n    while (i <= mid && j <= right) {\n        if (src[i] <= src[j]) {\n            dst[k++] = src[i++];\n        } else {\n            dst[k++] = src[j++];\n        }\n    }\n\n    while (i <= mid) dst[k++] = src[i++];\n    while (j <= right) dst[k++] = src[j++];\n\n    // 병합 안 된 부분 복사\n    for (int m = 0; m < left; m++) dst[m] = src[m];\n    for (int m = right + 1; m < src.length; m++) dst[m] = src[m];\n}\n```\n\n---\n\n## 재귀 vs 반복 비교\n\n| 특성 | 재귀 (Top-Down) | 반복 (Bottom-Up) |\n|------|----------------|-----------------|\n| 구현 | 간결 | 복잡 |\n| 스택 | O(log n) | O(1) |\n| 캐시 | 좋음 (작은 배열) | 나쁨 (큰 배열) |\n| 속도 | 약간 느림 | 약간 빠름 |\n| 오버헤드 | 함수 호출 | 없음 |\n| 스택 오버플로 | 가능 | 없음 |\n\n---\n\n## 성능 비교\n\n```java\n// 100만 개 정렬\n\n재귀 Merge Sort:    120ms\n반복 Merge Sort:    115ms  ← 약간 빠름\n\n// 1억 개 (큰 데이터)\n\n재귀:  15000ms\n반복:  14000ms\n\n// 차이 미미 (5~10%)\n```\n\n---\n\n## 링크드 리스트 버전\n\n**링크드 리스트는 Bottom-Up이 더 자연스러움**\n\n```java\nclass ListNode {\n    int val;\n    ListNode next;\n}\n\npublic ListNode mergeSortList(ListNode head) {\n    if (head == null || head.next == null) return head;\n\n    // 길이 계산\n    int length = getLength(head);\n\n    ListNode dummy = new ListNode(0);\n    dummy.next = head;\n\n    // 크기: 1, 2, 4, 8, ...\n    for (int size = 1; size < length; size *= 2) {\n        ListNode prev = dummy;\n        ListNode curr = dummy.next;\n\n        while (curr != null) {\n            // 왼쪽 부분 (size개)\n            ListNode left = curr;\n            ListNode right = split(left, size);\n\n            // 오른쪽 부분 (size개)\n            curr = split(right, size);\n\n            // 병합\n            prev = merge(left, right, prev);\n        }\n    }\n\n    return dummy.next;\n}\n\nprivate ListNode split(ListNode head, int size) {\n    for (int i = 1; head != null && i < size; i++) {\n        head = head.next;\n    }\n\n    if (head == null) return null;\n\n    ListNode next = head.next;\n    head.next = null;\n    return next;\n}\n\nprivate ListNode merge(ListNode l1, ListNode l2, ListNode prev) {\n    ListNode curr = prev;\n\n    while (l1 != null && l2 != null) {\n        if (l1.val <= l2.val) {\n            curr.next = l1;\n            l1 = l1.next;\n        } else {\n            curr.next = l2;\n            l2 = l2.next;\n        }\n        curr = curr.next;\n    }\n\n    curr.next = (l1 != null) ? l1 : l2;\n\n    while (curr.next != null) {\n        curr = curr.next;\n    }\n\n    return curr;\n}\n```\n\n---\n\n## 장단점\n\n### 재귀 방식 장점\n\n1. **코드 간결**: 이해하기 쉬움\n2. **캐시 효율**: 작은 배열 먼저 처리\n3. **직관적**: 분할 정복 개념 명확\n\n### 재귀 방식 단점\n\n1. **스택 오버플로**: 큰 데이터 위험\n2. **함수 호출 오버헤드**: 약간 느림\n\n### 반복 방식 장점\n\n1. **스택 사용 없음**: O(1) 공간\n2. **스택 오버플로 없음**: 안전\n3. **약간 빠름**: 함수 호출 없음\n\n### 반복 방식 단점\n\n1. **코드 복잡**: 인덱스 계산 어려움\n2. **캐시 비효율**: 큰 배열부터 순차 접근\n3. **디버깅 어려움**\n\n---\n\n## 언제 사용?\n\n**재귀 사용:**\n```\n- 일반적인 경우 (코드 간결)\n- 작은~중간 데이터\n- 가독성 중요\n```\n\n**반복 사용:**\n```\n- 매우 큰 데이터 (스택 오버플로 방지)\n- 임베디드 시스템 (스택 제한)\n- 함수 호출 최소화 필요\n- 링크드 리스트\n```\n\n---\n\n## 실전 코드\n\n```java\n// 대부분: 재귀 사용 (간결)\npublic static void mergeSort(int[] arr) {\n    mergeSortHelper(arr, 0, arr.length - 1);\n}\n\n// 특수: 반복 사용 (안전)\npublic static void mergeSortSafe(int[] arr) {\n    mergeSortIterative(arr);\n}\n```\n\n---\n\n## 결론\n\n**반복 Merge Sort 가능:**\n- ✅ Bottom-Up 방식\n- ✅ O(1) 스택 공간\n- ✅ 스택 오버플로 없음\n- ✅ 약간 더 빠름\n\n**선택:**\n```\n일반적: 재귀 (간결, 읽기 쉬움)\n특수: 반복 (안전, 큰 데이터)\n\n실전: 언어 기본 정렬 사용 (이미 최적화)\n```\n\n**핵심:**\n```\n재귀 = Top-Down (위에서 아래로 분할)\n반복 = Bottom-Up (아래에서 위로 병합)\n\n둘 다 O(n log n), O(n) 공간\n차이는 스택 사용 여부\n```",
      "type": "essay",
      "tags": [
        "Merge Sort",
        "반복",
        "재귀",
        "Bottom-Up"
      ]
    },
    {
      "question": "Radix Sort에 대해 설명해 주세요.",
      "answer": "## Radix Sort (기수 정렬)\n\n**정의:** 자릿수별로 정렬하는 비교 기반이 아닌 정렬 알고리즘\n\n**핵심 아이디어:**\n- 숫자의 각 자릿수(1의 자리, 10의 자리, ...)를 기준으로 정렬\n- Counting Sort를 반복 사용\n\n---\n\n## 동작 원리\n\n### LSD (Least Significant Digit) 방식\n\n**1의 자리부터 시작 → 가장 높은 자릿수까지**\n\n```\n초기: [170, 45, 75, 90, 802, 24, 2, 66]\n\nStep 1: 1의 자리로 정렬\n[170, 90, 802, 2, 24, 45, 75, 66]\n//     0   0    2  2   4   5   5   6\n\nStep 2: 10의 자리로 정렬\n[802, 2, 24, 45, 66, 170, 75, 90]\n//  0  0   2   4   6    7   7   9\n\nStep 3: 100의 자리로 정렬\n[2, 24, 45, 66, 75, 90, 170, 802]\n// 0   0   0   0   0   0    1    8\n\n최종 정렬 완료!\n```\n\n---\n\n## 구현 (Java)\n\n```java\npublic class RadixSort {\n    \n    public static void radixSort(int[] arr) {\n        // 최댓값 찾기\n        int max = getMax(arr);\n        \n        // 각 자릿수별로 Counting Sort\n        for (int exp = 1; max / exp > 0; exp *= 10) {\n            countingSortByDigit(arr, exp);\n        }\n    }\n    \n    private static void countingSortByDigit(int[] arr, int exp) {\n        int n = arr.length;\n        int[] output = new int[n];\n        int[] count = new int[10];  // 0~9\n        \n        // 빈도수 세기\n        for (int i = 0; i < n; i++) {\n            int digit = (arr[i] / exp) % 10;\n            count[digit]++;\n        }\n        \n        // 누적합\n        for (int i = 1; i < 10; i++) {\n            count[i] += count[i - 1];\n        }\n        \n        // 뒤에서부터 배치 (Stable 유지)\n        for (int i = n - 1; i >= 0; i--) {\n            int digit = (arr[i] / exp) % 10;\n            output[count[digit] - 1] = arr[i];\n            count[digit]--;\n        }\n        \n        // 결과 복사\n        System.arraycopy(output, 0, arr, 0, n);\n    }\n    \n    private static int getMax(int[] arr) {\n        int max = arr[0];\n        for (int num : arr) {\n            if (num > max) max = num;\n        }\n        return max;\n    }\n}\n```\n\n---\n\n## 시간복잡도\n\n**O(d * (n + k))**\n\n- d = 자릿수 (최댓값의 자릿수)\n- n = 원소 개수\n- k = 기수 (보통 10)\n\n**예시:**\n```\n배열: [170, 45, 75, 90, 802, 24, 2, 66]\nn = 8\nmax = 802 → d = 3 (자릿수)\nk = 10 (0~9)\n\n시간: O(3 * (8 + 10)) = O(54)\n비교 정렬(O(n log n)): O(8 * 3) = O(24)\n\n// d가 작으면 Radix Sort가 빠름!\n```\n\n---\n\n## 공간복잡도\n\n**O(n + k)**\n\n- output 배열: O(n)\n- count 배열: O(k)\n\n---\n\n## MSD (Most Significant Digit) 방식\n\n**가장 높은 자릿수부터 시작 → 1의 자리까지**\n\n```\n초기: [170, 45, 75, 90, 802, 24, 2, 66]\n\nStep 1: 100의 자리로 분할\n[45, 75, 90, 24, 2, 66] (0xx)\n[170] (1xx)\n[802] (8xx)\n\nStep 2: 각 그룹 내에서 10의 자리로 분할\n[2] (00x)\n[24] (02x)\n[45] (04x)\n...\n\n// 재귀적으로 처리\n```\n\n**특징:**\n- 재귀 사용\n- 중간에 종료 가능 (자릿수 차이 큼)\n- LSD보다 복잡\n\n---\n\n## LSD vs MSD\n\n| 특성 | LSD | MSD |\n|------|-----|-----|\n| 구현 | 간단 (반복) | 복잡 (재귀) |\n| Stable | ✅ | ✅ (구현 주의) |\n| 조기 종료 | ❌ | ✅ |\n| 메모리 | O(n+k) | O(n+k) + 재귀 스택 |\n| 사용 | 정수 정렬 | 문자열 정렬 |\n\n---\n\n## Radix Sort 장단점\n\n### 장점\n\n1. **빠름**: O(d*n), d가 작으면 O(n)\n2. **Stable**: 순서 유지\n3. **비교 없음**: 비교 기반 하한선 O(n log n) 초과 가능\n\n### 단점\n\n1. **정수/문자열 전용**: 일반 객체 불가\n2. **메모리**: O(n+k) 추가 공간\n3. **자릿수 의존**: d가 크면 느림\n4. **음수 처리**: 별도 로직 필요\n\n---\n\n## 음수 처리\n\n```java\npublic static void radixSortWithNegative(int[] arr) {\n    // 양수/음수 분리\n    List<Integer> negative = new ArrayList<>();\n    List<Integer> positive = new ArrayList<>();\n    \n    for (int num : arr) {\n        if (num < 0) {\n            negative.add(-num);  // 절댓값\n        } else {\n            positive.add(num);\n        }\n    }\n    \n    // 각각 Radix Sort\n    int[] negArr = negative.stream().mapToInt(i->i).toArray();\n    int[] posArr = positive.stream().mapToInt(i->i).toArray();\n    \n    radixSort(negArr);\n    radixSort(posArr);\n    \n    // 합치기: 음수(역순) + 양수\n    int idx = 0;\n    for (int i = negArr.length - 1; i >= 0; i--) {\n        arr[idx++] = -negArr[i];\n    }\n    for (int num : posArr) {\n        arr[idx++] = num;\n    }\n}\n```\n\n---\n\n## 문자열 Radix Sort\n\n```java\npublic static void radixSortStrings(String[] arr) {\n    int maxLen = getMaxLength(arr);\n    \n    // MSD 방식 (높은 자리부터)\n    for (int pos = maxLen - 1; pos >= 0; pos--) {\n        countingSortByChar(arr, pos);\n    }\n}\n\nprivate static void countingSortByChar(String[] arr, int pos) {\n    int n = arr.length;\n    String[] output = new String[n];\n    int[] count = new int[256];  // ASCII\n    \n    for (String s : arr) {\n        int ch = (pos < s.length()) ? s.charAt(pos) : 0;\n        count[ch]++;\n    }\n    \n    for (int i = 1; i < 256; i++) {\n        count[i] += count[i - 1];\n    }\n    \n    for (int i = n - 1; i >= 0; i--) {\n        int ch = (pos < arr[i].length()) ? arr[i].charAt(pos) : 0;\n        output[count[ch] - 1] = arr[i];\n        count[ch]--;\n    }\n    \n    System.arraycopy(output, 0, arr, 0, n);\n}\n```\n\n---\n\n## 성능 비교\n\n```java\n// 100만 개 정수 (0~9999)\n\nRadix Sort:       50ms   ★ (빠름)\nQuick Sort:       80ms\nMerge Sort:       120ms\n\n// 100만 개 정수 (0~999,999,999)\n\nRadix Sort:       150ms  (d=9)\nQuick Sort:       75ms   ★ (역전!)\n\n// d가 크면 비교 정렬이 더 빠를 수 있음\n```\n\n---\n\n## 언제 사용?\n\n**Radix Sort 사용:**\n```\n✅ 정수 또는 문자열\n✅ 자릿수 작음 (d ≤ log n)\n✅ 범위 제한됨\n✅ Stable 필요\n\n예: IP 주소 정렬, 학번 정렬, 우편번호 정렬\n```\n\n**비교 정렬 사용:**\n```\n✅ 일반 객체\n✅ 자릿수 큼 (d > log n)\n✅ 메모리 제약\n\n예: 일반적인 정렬\n```\n\n---\n\n## 결론\n\n**Radix Sort:**\n- 자릿수별 정렬\n- O(d * (n + k))\n- 정수/문자열 전용\n- d가 작으면 O(n) 가능\n- Stable, 비교 없음\n\n**사용:**\n```\nd ≤ log n: Radix Sort (빠름)\nd > log n: Quick/Merge Sort (더 빠름)\n```",
      "type": "essay",
      "tags": [
        "Radix Sort",
        "기수 정렬",
        "Counting Sort",
        "정렬"
      ]
    },
    {
      "question": "Bubble, Selection, Insertion Sort의 속도를 비교해 주세요.",
      "answer": "## Bubble, Selection, Insertion Sort 비교\n\n### 시간복잡도 요약\n\n| 알고리즘 | 최선 | 평균 | 최악 |\n|---------|------|------|------|\n| Bubble | O(n) | O(n²) | O(n²) |\n| Selection | O(n²) | O(n²) | O(n²) |\n| Insertion | **O(n)** | O(n²) | O(n²) |\n\n---\n\n## 랜덤 데이터 성능 비교\n\n```java\n// 10,000개 랜덤 데이터 정렬\n\nBubble Sort:      850ms\nSelection Sort:   550ms   ★ (가장 빠름)\nInsertion Sort:   450ms   ★★ (가장 빠름)\n\n왜 Insertion이 가장 빠를까?\n- 평균적으로 절반만 비교\n- 조기 종료 가능\n- 캐시 효율적\n```\n\n**이유 분석:**\n\n**Insertion Sort:**\n```java\n// 평균 n/2개 비교\nfor (int i = 1; i < n; i++) {\n    int key = arr[i];\n    int j = i - 1;\n    \n    // 평균 i/2 번 반복\n    while (j >= 0 && arr[j] > key) {\n        arr[j + 1] = arr[j];\n        j--;\n    }\n    // ...\n}\n// 평균 비교: n * n/4 = n²/4\n```\n\n**Selection Sort:**\n```java\n// 항상 n(n-1)/2 번 비교\nfor (int i = 0; i < n - 1; i++) {\n    int minIdx = i;\n    for (int j = i + 1; j < n; j++) {  // 항상 끝까지\n        if (arr[j] < arr[minIdx]) {\n            minIdx = j;\n        }\n    }\n    swap(arr, i, minIdx);\n}\n// 비교: n²/2\n```\n\n**Bubble Sort:**\n```java\n// 최악 n(n-1)/2 번 교환\nfor (int i = 0; i < n - 1; i++) {\n    for (int j = 0; j < n - i - 1; j++) {\n        if (arr[j] > arr[j + 1]) {\n            swap(arr, j, j + 1);  // 교환 많음\n        }\n    }\n}\n// 비교: n²/2, 교환: n²/4 (평균)\n```\n\n---\n\n## 정렬된 데이터 (최선)\n\n```java\n// 10,000개 이미 정렬된 데이터\n\nBubble Sort (최적화):  10ms   ★★\nSelection Sort:         550ms  (변화 없음)\nInsertion Sort:         5ms    ★★★ (압도적)\n\n// Insertion이 압도적으로 빠름!\n```\n\n**Insertion Sort (최선 O(n)):**\n```java\n[1, 2, 3, 4, 5]  // 이미 정렬됨\n\ni=1: key=2, 1 < 2 → 교환 없음\ni=2: key=3, 2 < 3 → 교환 없음\ni=3: key=4, 3 < 4 → 교환 없음\n...\n\n// 각 원소당 1번 비교만!\n// 총 n번 비교 → O(n)\n```\n\n**Selection Sort (항상 O(n²)):**\n```java\n[1, 2, 3, 4, 5]\n\ni=0: 1~4에서 최솟값 찾기 (4번 비교)\ni=1: 2~4에서 최솟값 찾기 (3번 비교)\n...\n\n// 정렬 여부와 무관하게 항상 n²/2 비교\n```\n\n**Bubble Sort (최적화 시 O(n)):**\n```java\nboolean swapped;\nfor (int i = 0; i < n - 1; i++) {\n    swapped = false;\n    for (int j = 0; j < n - i - 1; j++) {\n        if (arr[j] > arr[j + 1]) {\n            swap(arr, j, j + 1);\n            swapped = true;\n        }\n    }\n    if (!swapped) break;  // 교환 없으면 종료\n}\n\n// 정렬됨 → 첫 패스에서 종료 → O(n)\n```\n\n---\n\n## 역순 데이터 (최악)\n\n```java\n// 10,000개 역순 데이터\n\nBubble Sort:      1200ms  (최악)\nSelection Sort:   550ms   ★ (변화 없음)\nInsertion Sort:   900ms\n\n// Selection이 가장 안정적\n```\n\n---\n\n## 교환 횟수 비교\n\n**랜덤 데이터:**\n\n```\nBubble Sort:      평균 n²/4 교환\nSelection Sort:   항상 n 교환     ★ (최소)\nInsertion Sort:   평균 n²/4 이동\n```\n\n**Selection Sort 장점:**\n```java\n// 항상 n번만 교환 (최솟값을 찾아 한 번만)\nfor (int i = 0; i < n - 1; i++) {\n    int minIdx = findMin(arr, i, n);\n    swap(arr, i, minIdx);  // 딱 1번!\n}\n\n// 교환 비용이 큰 경우 유리\n// 예: 큰 객체, 디스크 I/O\n```\n\n---\n\n## 메모리 사용\n\n**모두 O(1) - In-place**\n\n```\nBubble:    O(1)\nSelection: O(1)\nInsertion: O(1)\n\n// 추가 메모리 없음\n// temp 변수만 사용\n```\n\n---\n\n## Stable 여부\n\n| 알고리즘 | Stable | 이유 |\n|---------|--------|------|\n| Bubble | ✅ | 같으면 교환 안 함 |\n| Selection | ❌ | 먼 거리 교환 |\n| Insertion | ✅ | 같은 값 뒤에 삽입 |\n\n---\n\n## 캐시 효율성\n\n**Insertion Sort > Bubble Sort > Selection Sort**\n\n**Insertion:**\n```java\n// 연속된 메모리 접근\nwhile (j >= 0 && arr[j] > key) {\n    arr[j + 1] = arr[j];  // j, j+1 연속\n    j--;\n}\n// 캐시 친화적\n```\n\n**Selection:**\n```java\n// 전체 배열 스캔\nfor (int j = i + 1; j < n; j++) {\n    // 멀리 떨어진 원소 접근\n}\n// 캐시 미스 많음\n```\n\n---\n\n## 실전 벤치마크\n\n```java\n// 다양한 크기 비교\n\nn=100:\n  Insertion: 0.1ms  ★\n  Selection: 0.15ms\n  Bubble:    0.2ms\n\nn=1,000:\n  Insertion: 5ms    ★\n  Selection: 10ms\n  Bubble:    15ms\n\nn=10,000:\n  Insertion: 450ms  ★\n  Selection: 550ms\n  Bubble:    850ms\n\nn=100,000:\n  Insertion: 45s\n  Selection: 55s\n  Bubble:    85s\n\n// Insertion이 항상 가장 빠름 (랜덤 데이터)\n```\n\n---\n\n## 언제 사용?\n\n**Insertion Sort:**\n```\n✅ 작은 데이터 (n < 50)\n✅ 거의 정렬됨\n✅ 온라인 정렬 (실시간 추가)\n✅ 일반적으로 가장 빠름\n\n사용 예:\n- Tim Sort의 일부\n- Intro Sort의 일부\n- 작은 부분 배열 정렬\n```\n\n**Selection Sort:**\n```\n✅ 교환 비용 큼\n✅ 메모리 제약 극심\n✅ 단순 구현\n\n사용 예:\n- 큰 객체 정렬 (교환 최소화)\n- 교육용\n```\n\n**Bubble Sort:**\n```\n✅ 거의 정렬됨 (최적화 버전)\n✅ 교육용\n\n실전: 거의 사용 안 함\n```\n\n---\n\n## 최종 순위\n\n### 랜덤 데이터\n```\n1. Insertion Sort  ★★★\n2. Selection Sort  ★★\n3. Bubble Sort     ★\n```\n\n### 정렬된 데이터\n```\n1. Insertion Sort  ★★★ (O(n))\n2. Bubble (최적화) ★★  (O(n))\n3. Selection Sort  ★   (O(n²))\n```\n\n### 역순 데이터\n```\n1. Selection Sort  ★★ (안정적)\n2. Insertion Sort  ★\n3. Bubble Sort     ★ (최악)\n```\n\n### 교환 비용 큼\n```\n1. Selection Sort  ★★★ (n번만)\n2. Insertion Sort  ★\n3. Bubble Sort     ★\n```\n\n---\n\n## 결론\n\n**일반적:**\n```\nInsertion Sort > Selection Sort > Bubble Sort\n\n이유:\n- 평균 비교 적음\n- 캐시 효율적\n- 거의 정렬된 데이터 빠름\n```\n\n**실전:**\n```\nn < 10:      그냥 정렬 (차이 미미)\n10 ≤ n < 50: Insertion Sort\nn ≥ 50:      Quick/Merge Sort\n\nBubble Sort: 교육용 외 사용 안 함\n```\n\n**하이브리드 정렬:**\n```java\nvoid sort(int[] arr, int low, int high) {\n    if (high - low < 10) {\n        insertionSort(arr, low, high);  // 작으면 Insertion\n    } else {\n        quickSort(arr, low, high);      // 크면 Quick\n    }\n}\n\n// Tim Sort, Intro Sort 등에서 사용\n```",
      "type": "essay",
      "tags": [
        "Bubble Sort",
        "Selection Sort",
        "Insertion Sort",
        "성능 비교"
      ]
    },
    {
      "question": "값이 거의 정렬되어 있거나, 아예 정렬되어 있다면, 위 세 알고리즘의 성능 비교 결과는 달라질까요?",
      "answer": "## 거의 정렬된/정렬된 데이터에서의 성능 변화\n\n**네, 크게 달라집니다!**\n\n---\n\n## 정렬된 데이터 [1, 2, 3, 4, 5]\n\n### Insertion Sort: O(n) ★★★\n\n```java\nfor (int i = 1; i < n; i++) {\n    int key = arr[i];\n    int j = i - 1;\n    \n    // arr[j] < key 이므로 while 바로 종료\n    while (j >= 0 && arr[j] > key) {  // 진입 안 함\n        arr[j + 1] = arr[j];\n        j--;\n    }\n    arr[j + 1] = key;\n}\n\n// 각 원소당 1번 비교 → 총 n번\n// 시간: O(n)\n```\n\n**결과: 5ms (100배 빠름!)**\n\n---\n\n### Bubble Sort (최적화): O(n) ★★\n\n```java\nboolean swapped;\nfor (int i = 0; i < n - 1; i++) {\n    swapped = false;\n    for (int j = 0; j < n - i - 1; j++) {\n        if (arr[j] > arr[j + 1]) {\n            swap(arr, j, j + 1);\n            swapped = true;\n        }\n    }\n    if (!swapped) break;  // 첫 패스에서 종료!\n}\n\n// 첫 패스: n-1번 비교, 교환 없음 → 종료\n// 시간: O(n)\n```\n\n**결과: 10ms (80배 빠름!)**\n\n---\n\n### Selection Sort: O(n²) ★ (변화 없음)\n\n```java\nfor (int i = 0; i < n - 1; i++) {\n    int minIdx = i;\n    for (int j = i + 1; j < n; j++) {  // 항상 끝까지 스캔\n        if (arr[j] < arr[minIdx]) {\n            minIdx = j;\n        }\n    }\n    swap(arr, i, minIdx);\n}\n\n// 정렬 여부와 무관하게 항상 n²/2 비교\n// 시간: O(n²)\n```\n\n**결과: 550ms (변화 없음)**\n\n---\n\n## 거의 정렬된 데이터 [1, 2, 4, 3, 5]\n\n### Insertion Sort: ~O(n) ★★★\n\n```\ni=1: 2 → 위치 맞음 (1번 비교)\ni=2: 4 → 위치 맞음 (1번 비교)\ni=3: 3 → 4와 비교 후 이동 (2번 비교)\ni=4: 5 → 위치 맞음 (1번 비교)\n\n총 비교: 5번\n시간: O(n + k)  (k = 역전 쌍 개수)\n```\n\n**결과: 10ms (매우 빠름)**\n\n---\n\n### Bubble Sort (최적화): ~O(n) ★★\n\n```\n첫 패스:\n  [1, 2, 4, 3, 5]\n  → [1, 2, 3, 4, 5]  (교환 1번)\n  \n두 번째 패스:\n  교환 없음 → 종료\n\n총 비교: ~2n\n시간: O(n)\n```\n\n**결과: 20ms (빠름)**\n\n---\n\n### Selection Sort: O(n²) (변화 없음)\n\n**결과: 550ms (그대로)**\n\n---\n\n## 성능 비교표\n\n### 랜덤 데이터 (10,000개)\n\n| 알고리즘 | 시간 | 순위 |\n|---------|------|------|\n| Insertion | 450ms | 1위 |\n| Selection | 550ms | 2위 |\n| Bubble | 850ms | 3위 |\n\n### 정렬된 데이터 (10,000개)\n\n| 알고리즘 | 시간 | 변화 | 순위 |\n|---------|------|------|------|\n| Insertion | **5ms** | 90배↓ | 1위 ★★★ |\n| Bubble (최적화) | **10ms** | 85배↓ | 2위 ★★ |\n| Selection | **550ms** | 변화없음 | 3위 |\n\n### 거의 정렬 (10,000개, 100개 역전)\n\n| 알고리즘 | 시간 | 순위 |\n|---------|------|------|\n| Insertion | **15ms** | 1위 ★★★ |\n| Bubble (최적화) | **50ms** | 2위 ★★ |\n| Selection | **550ms** | 3위 |\n\n---\n\n## 왜 Insertion이 가장 빠를까?\n\n**적응형 (Adaptive) 알고리즘:**\n\n```java\n// 정렬 정도에 따라 성능 변화\n\n완전 정렬: O(n)         ← 최선\n거의 정렬: O(n + k)     ← k = 역전 쌍\n랜덤:      O(n²/4)      ← 평균\n역순:      O(n²)        ← 최악\n\n// 데이터 상태를 \"감지\"하고 빠르게 처리\n```\n\n**Selection은 비적응형:**\n\n```java\n// 항상 모든 원소 비교\n// 데이터 상태와 무관\n\n모든 경우: O(n²/2)  ← 일정\n```\n\n---\n\n## 실전 활용\n\n### Tim Sort (Python, Java)\n\n```python\ndef timsort(arr):\n    # 1. Run(정렬된 부분) 찾기\n    runs = find_runs(arr)  # 이미 정렬된 부분 활용\n    \n    # 2. 작은 Run은 Insertion Sort\n    for run in runs:\n        if len(run) < 64:\n            insertion_sort(run)  # Insertion 사용!\n    \n    # 3. Run들을 Merge\n    return merge_runs(runs)\n\n# 거의 정렬된 데이터: O(n)\n# 랜덤 데이터: O(n log n)\n```\n\n---\n\n## 온라인 정렬 (실시간 추가)\n\n**Insertion Sort가 최적:**\n\n```java\nList<Integer> sorted = new ArrayList<>();\n\nvoid addNumber(int num) {\n    // Insertion Sort 로직\n    int i = sorted.size() - 1;\n    sorted.add(num);\n    \n    while (i >= 0 && sorted.get(i) > sorted.get(i + 1)) {\n        swap(sorted, i, i + 1);\n        i--;\n    }\n}\n\n// 이미 정렬된 상태 유지\n// 새 원소 추가: 평균 O(n/2), 최선 O(1)\n```\n\n---\n\n## 결론\n\n**거의 정렬/정렬된 데이터:**\n\n```\n1. Insertion Sort: O(n) ★★★ (압도적)\n2. Bubble (최적화): O(n) ★★\n3. Selection Sort: O(n²) ★ (느림)\n\n차이: 100배 이상!\n```\n\n**Insertion Sort 우수한 이유:**\n- 적응형 알고리즘\n- 조기 종료 가능\n- 정렬 정도 감지\n\n**Selection Sort 문제:**\n- 항상 전체 스캔\n- 데이터 상태 무시\n\n**실전 활용:**\n- 거의 정렬: Insertion Sort\n- 랜덤: Quick/Merge Sort\n- 하이브리드: Tim Sort, Intro Sort",
      "type": "essay",
      "tags": [
        "정렬",
        "적응형 알고리즘",
        "Insertion Sort",
        "성능"
      ]
    },
    {
      "question": "본인이 사용하고 있는 언어에선, 어떤 정렬 알고리즘을 사용하여 정렬 함수를 제공하고 있을까요?",
      "answer": "## 언어별 정렬 알고리즘\n\n### Java\n\n**1. Arrays.sort() - 원시 타입**\n\n```java\nint[] arr = {5, 2, 8, 1};\nArrays.sort(arr);\n\n// 알고리즘: Dual-Pivot Quick Sort\n// 시간: O(n log n) 평균, O(n²) 최악\n// Stable: ❌\n```\n\n**Dual-Pivot Quick Sort:**\n- 두 개의 피벗 사용\n- 일반 Quick Sort보다 5-10% 빠름\n- Java 7부터 사용\n\n**2. Arrays.sort() / Collections.sort() - 객체**\n\n```java\nInteger[] arr = {5, 2, 8, 1};\nArrays.sort(arr);\n\n// 알고리즘: TimSort\n// 시간: O(n log n) 최악\n// Stable: ✅\n```\n\n---\n\n### Python\n\n```python\narr = [5, 2, 8, 1]\narr.sort()  # In-place\nsorted_arr = sorted(arr)  # 새 리스트\n\n# 알고리즘: TimSort\n# 시간: O(n log n) 최악, O(n) 최선\n# Stable: ✅\n```\n\n**TimSort 특징:**\n- Merge Sort + Insertion Sort\n- 실전 데이터에 최적화\n- Python 2.3+ 사용\n\n---\n\n### JavaScript\n\n```javascript\nconst arr = [5, 2, 8, 1];\narr.sort((a, b) => a - b);\n\n// V8 엔진 (Chrome, Node.js): TimSort\n// SpiderMonkey (Firefox): Merge Sort\n// JavaScriptCore (Safari): 다양한 알고리즘\n// Stable: ✅ (ES2019+)\n```\n\n---\n\n### C++\n\n**1. std::sort() - Unstable**\n\n```cpp\nstd::vector<int> arr = {5, 2, 8, 1};\nstd::sort(arr.begin(), arr.end());\n\n// 알고리즘: IntroSort\n// 시간: O(n log n) 보장\n// Stable: ❌\n```\n\n**IntroSort = Quick + Heap + Insertion:**\n```cpp\n1. Quick Sort 시작\n2. 재귀 깊이 > 2*log(n): Heap Sort로 전환\n3. 부분 크기 < 16: Insertion Sort\n\n→ 최악 O(n log n) 보장\n```\n\n**2. std::stable_sort() - Stable**\n\n```cpp\nstd::stable_sort(arr.begin(), arr.end());\n\n// 알고리즘: Merge Sort\n// 시간: O(n log n)\n// Stable: ✅\n```\n\n---\n\n### Go\n\n```go\nimport \"sort\"\n\narr := []int{5, 2, 8, 1}\nsort.Ints(arr)\n\n// 알고리즘: Pattern-defeating Quick Sort (pdqsort)\n// 시간: O(n log n)\n// Stable: ❌\n\n// Stable 버전:\nsort.SliceStable(arr, func(i, j int) bool {\n    return arr[i] < arr[j]\n})\n// 알고리즘: Stable Sort (구현 비공개)\n```\n\n---\n\n### Rust\n\n```rust\nlet mut arr = vec![5, 2, 8, 1];\narr.sort();  // Unstable\narr.sort_stable();  // Stable\n\n// sort(): Pattern-defeating Quick Sort (pdqsort)\n// sort_stable(): TimSort\n```\n\n---\n\n## 알고리즘별 비교\n\n| 언어 | 기본 정렬 | 알고리즘 | Stable | 최악 |\n|------|----------|---------|--------|------|\n| Java (원시) | Arrays.sort() | Dual-Pivot Quick | ❌ | O(n²) |\n| Java (객체) | Collections.sort() | TimSort | ✅ | O(n log n) |\n| Python | sort() | TimSort | ✅ | O(n log n) |\n| JavaScript | sort() | TimSort (V8) | ✅ | O(n log n) |\n| C++ | std::sort() | IntroSort | ❌ | O(n log n) |\n| C++ | std::stable_sort() | Merge Sort | ✅ | O(n log n) |\n| Go | sort.Ints() | pdqsort | ❌ | O(n log n) |\n| Rust | sort() | pdqsort | ❌ | O(n log n) |\n| Rust | sort_stable() | TimSort | ✅ | O(n log n) |\n\n---\n\n## TimSort 상세\n\n**개발:** Tim Peters (Python 개발자), 2002년\n\n**알고리즘:**\n```\n1. Run 찾기 (정렬된 부분)\n   - 오름차순/내림차순 Run 탐지\n   - 최소 길이 32\n\n2. 작은 Run은 Insertion Sort\n   - Run < 32: Insertion으로 확장\n\n3. Run들을 Merge Sort로 병합\n   - Galloping mode (한쪽이 계속 작으면 최적화)\n\n4. 스택 기반 병합 전략\n```\n\n**성능:**\n```\n최선: O(n) (이미 정렬)\n평균: O(n log n)\n최악: O(n log n)\n공간: O(n)\n```\n\n---\n\n## IntroSort 상세\n\n**개발:** David Musser, 1997년\n\n**알고리즘:**\n```cpp\nvoid introsort(arr, depth_limit) {\n    if (size < 16) {\n        insertion_sort(arr);  // 작으면 Insertion\n        return;\n    }\n    \n    if (depth_limit == 0) {\n        heapsort(arr);  // 재귀 깊이 초과 → Heap\n        return;\n    }\n    \n    pivot = median_of_three(arr);\n    partition(arr, pivot);\n    introsort(left, depth_limit - 1);\n    introsort(right, depth_limit - 1);\n}\n\ndepth_limit = 2 * log₂(n)\n```\n\n**장점:**\n- Quick Sort 평균 성능\n- 최악 O(n log n) 보장\n- In-place (O(log n) 스택)\n\n---\n\n## Pattern-defeating Quicksort (pdqsort)\n\n**개발:** Orson Peters, 2015년\n\n**특징:**\n- Quick Sort 기반\n- 패턴 감지 (정렬됨, 역순, 동일 값)\n- 패턴 발견 시 최적화\n- Heap Sort로 폴백\n\n**성능:**\n- 평균: Quick Sort 수준\n- 최악: O(n log n) 보장\n- 실전: IntroSort보다 빠름\n\n---\n\n## 선택 가이드\n\n**Stable 필요:**\n```\nJava: Collections.sort()\nPython: sort()\nC++: std::stable_sort()\nRust: sort_stable()\n```\n\n**최고 성능:**\n```\nJava (원시): Arrays.sort() (Dual-Pivot Quick)\nC++: std::sort() (IntroSort)\nGo/Rust: sort() (pdqsort)\n```\n\n**거의 정렬:**\n```\nPython: sort() (TimSort)\nJava (객체): Collections.sort() (TimSort)\n```\n\n---\n\n## 결론\n\n**현대 언어 트렌드:**\n- Stable: TimSort\n- Unstable: IntroSort, pdqsort\n- 모두 O(n log n) 최악 보장\n\n**추천:**\n```\n언어 기본 정렬 사용\n→ 이미 최적화됨\n→ 특수 케이스 처리됨\n→ 충분히 빠름\n```",
      "type": "essay",
      "tags": [
        "정렬 알고리즘",
        "Tim Sort",
        "IntroSort",
        "언어별 구현"
      ]
    },
    {
      "question": "정렬해야 하는 데이터는 50G 인데, 메모리가 4G라면, 어떤 방식으로 정렬을 진행할 수 있을까요?",
      "answer": "## 외부 정렬 (External Sorting)\n\n**문제:** 데이터(50G) > 메모리(4G)\n\n**해결:** 외부 정렬 (디스크 사용)\n\n---\n\n## 외부 병합 정렬 (External Merge Sort)\n\n### 알고리즘\n\n**Phase 1: 초기 Run 생성**\n\n```\n1. 4G씩 메모리에 로드\n2. 메모리 내에서 정렬 (Quick Sort)\n3. 정렬된 Run을 디스크에 저장\n4. 반복\n\n50G / 4G = 13개 Run 생성\n\nRun 0: [정렬된 4G 데이터]\nRun 1: [정렬된 4G 데이터]\n...\nRun 12: [정렬된 2G 데이터]\n```\n\n**Phase 2: K-Way Merge**\n\n```\n1. K개 Run을 동시에 읽기\n2. 최솟값을 찾아 출력\n3. 반복\n\nK = 메모리 / (Run당 버퍼 크기)\n```\n\n---\n\n### 상세 구현\n\n```java\npublic class ExternalSort {\n    private static final int MEMORY_SIZE = 4 * 1024 * 1024 * 1024;  // 4G\n    private static final int BUFFER_SIZE = 100 * 1024 * 1024;  // 100MB\n    \n    public void sort(String inputFile, String outputFile) {\n        // Phase 1: 초기 Run 생성\n        List<String> runs = createInitialRuns(inputFile);\n        \n        // Phase 2: Merge\n        mergeRuns(runs, outputFile);\n    }\n    \n    private List<String> createInitialRuns(String inputFile) {\n        List<String> runs = new ArrayList<>();\n        List<Integer> buffer = new ArrayList<>();\n        \n        try (BufferedReader br = new BufferedReader(new FileReader(inputFile))) {\n            String line;\n            int runIndex = 0;\n            \n            while ((line = br.readLine()) != null) {\n                buffer.add(Integer.parseInt(line));\n                \n                // 버퍼가 꽉 차면\n                if (buffer.size() * 4 >= MEMORY_SIZE) {\n                    // 정렬하고 디스크에 저장\n                    Collections.sort(buffer);\n                    String runFile = \"run_\" + runIndex++ + \".tmp\";\n                    writeRun(buffer, runFile);\n                    runs.add(runFile);\n                    buffer.clear();\n                }\n            }\n            \n            // 남은 데이터 처리\n            if (!buffer.isEmpty()) {\n                Collections.sort(buffer);\n                String runFile = \"run_\" + runIndex + \".tmp\";\n                writeRun(buffer, runFile);\n                runs.add(runFile);\n            }\n        }\n        \n        return runs;\n    }\n    \n    private void mergeRuns(List<String> runs, String outputFile) {\n        int K = MEMORY_SIZE / BUFFER_SIZE;  // 동시에 읽을 Run 개수\n        \n        while (runs.size() > 1) {\n            List<String> newRuns = new ArrayList<>();\n            \n            // K개씩 병합\n            for (int i = 0; i < runs.size(); i += K) {\n                int end = Math.min(i + K, runs.size());\n                List<String> toMerge = runs.subList(i, end);\n                String merged = kWayMerge(toMerge);\n                newRuns.add(merged);\n            }\n            \n            runs = newRuns;\n        }\n        \n        // 최종 결과\n        Files.move(Paths.get(runs.get(0)), Paths.get(outputFile));\n    }\n    \n    private String kWayMerge(List<String> runs) {\n        PriorityQueue<RunIterator> pq = new PriorityQueue<>(\n            Comparator.comparingInt(r -> r.current)\n        );\n        \n        // 각 Run에서 BufferedReader 생성\n        List<BufferedReader> readers = new ArrayList<>();\n        for (String run : runs) {\n            BufferedReader br = new BufferedReader(new FileReader(run));\n            readers.add(br);\n            RunIterator iter = new RunIterator(br);\n            if (iter.hasNext()) {\n                pq.offer(iter);\n            }\n        }\n        \n        // 병합된 Run 생성\n        String outputRun = \"merged_\" + System.currentTimeMillis() + \".tmp\";\n        BufferedWriter bw = new BufferedWriter(new FileWriter(outputRun));\n        \n        while (!pq.isEmpty()) {\n            RunIterator min = pq.poll();\n            bw.write(String.valueOf(min.current));\n            bw.newLine();\n            \n            if (min.hasNext()) {\n                pq.offer(min);\n            }\n        }\n        \n        bw.close();\n        \n        // 원본 Run 삭제\n        for (String run : runs) {\n            new File(run).delete();\n        }\n        \n        return outputRun;\n    }\n    \n    static class RunIterator {\n        BufferedReader reader;\n        int current;\n        \n        RunIterator(BufferedReader reader) {\n            this.reader = reader;\n            readNext();\n        }\n        \n        boolean hasNext() {\n            return current != -1;\n        }\n        \n        void readNext() {\n            try {\n                String line = reader.readLine();\n                current = (line != null) ? Integer.parseInt(line) : -1;\n            } catch (IOException e) {\n                current = -1;\n            }\n        }\n    }\n}\n```\n\n---\n\n## 시간/공간 복잡도\n\n**시간복잡도: O(n log n)**\n\n```\nPhase 1: O(n log n)\n  - 각 Run 정렬: O(m log m), m = 4G\n  - Run 개수: 13\n  - 총: O(n log m) ≈ O(n log n)\n\nPhase 2: O(n log K)\n  - K-Way Merge\n  - K = 메모리 / 버퍼 크기\n  - log K 패스\n\n전체: O(n log n)\n```\n\n**공간복잡도: O(메모리 크기)**\n\n---\n\n## I/O 최적화\n\n**1. 버퍼링**\n```java\nBufferedReader (100MB 버퍼)\nBufferedWriter (100MB 버퍼)\n\n→ 디스크 I/O 횟수 감소\n```\n\n**2. 멀티스레드**\n```java\n// Phase 1: 병렬 Run 생성\nExecutorService executor = Executors.newFixedThreadPool(4);\nfor (chunk : chunks) {\n    executor.submit(() -> sortAndWrite(chunk));\n}\n\n// I/O 대기 시간 동안 다른 Run 처리\n```\n\n**3. Replacement Selection**\n```\n초기 Run을 더 크게 생성\n평균 2배 크기 Run\n→ Merge 패스 감소\n```\n\n---\n\n## 실전 시스템\n\n**Hadoop MapReduce:**\n```\nMap: 데이터 분할 + 정렬\nShuffle: 네트워크 전송\nReduce: 병합\n\n대규모 분산 정렬\n```\n\n**데이터베이스:**\n```sql\nSELECT * FROM large_table ORDER BY column;\n\n-- 내부적으로 External Sort 사용\n-- 임시 파일 생성 (temp tablespace)\n```\n\n---\n\n## 결론\n\n**외부 정렬:**\n- 데이터 > 메모리 → 디스크 사용\n- External Merge Sort\n- O(n log n) 시간\n- 실전: Hadoop, DBMS",
      "type": "essay",
      "tags": [
        "외부 정렬",
        "External Sort",
        "대용량 데이터",
        "Merge Sort"
      ]
    },
    {
      "question": "그래프 자료구조에 대해 설명하고, 이를 구현할 수 있는 두 방법에 대해 설명해 주세요.",
      "answer": "## 그래프 (Graph)\n\n**정의:** 정점(Vertex)과 간선(Edge)으로 구성된 자료구조\n\n```\n정점: 노드, 객체\n간선: 정점 간의 연결\n\nG = (V, E)\nV = 정점 집합\nE = 간선 집합\n```\n\n**예시:**\n```\n    1 --- 2\n    |     |\n    3 --- 4\n\nV = {1, 2, 3, 4}\nE = {(1,2), (1,3), (2,4), (3,4)}\n```\n\n---\n\n## 그래프 종류\n\n**1. 무방향 그래프 (Undirected)**\n```\nA --- B\n\n간선에 방향 없음\n(A,B) = (B,A)\n```\n\n**2. 방향 그래프 (Directed)**\n```\nA → B\n\n간선에 방향 있음\n(A,B) ≠ (B,A)\n```\n\n**3. 가중치 그래프 (Weighted)**\n```\nA --5-- B\n\n간선에 가중치(비용)\n```\n\n---\n\n## 구현 방법\n\n### 1. 인접 행렬 (Adjacency Matrix)\n\n**2차원 배열 사용**\n\n```java\nint[][] adjMatrix = new int[V][V];\n\n// 간선 (i, j) 추가\nadjMatrix[i][j] = 1;  // 무방향: adjMatrix[j][i] = 1도\n\n// 가중치 그래프\nadjMatrix[i][j] = weight;\n```\n\n**예시:**\n```\n그래프:\n    0 --- 1\n    |     |\n    2 --- 3\n\n인접 행렬:\n    0  1  2  3\n0 [ 0  1  1  0 ]\n1 [ 1  0  0  1 ]\n2 [ 1  0  0  1 ]\n3 [ 0  1  1  0 ]\n\nadjMatrix[0][1] = 1  // 0-1 간선\nadjMatrix[1][0] = 1  // 무방향\n```\n\n**장점:**\n- 간선 확인: O(1)\n- 구현 간단\n- 밀집 그래프에 효율적\n\n**단점:**\n- 공간: O(V²)\n- 모든 간선 순회: O(V²)\n- 희소 그래프 비효율\n\n---\n\n### 2. 인접 리스트 (Adjacency List)\n\n**배열 + 연결 리스트**\n\n```java\nList<List<Integer>> adjList = new ArrayList<>();\n\n// 초기화\nfor (int i = 0; i < V; i++) {\n    adjList.add(new ArrayList<>());\n}\n\n// 간선 (i, j) 추가\nadjList.get(i).add(j);\nadjList.get(j).add(i);  // 무방향\n\n// 가중치 그래프\nList<List<Pair<Integer, Integer>>> adjList;  // (정점, 가중치)\nadjList.get(i).add(new Pair<>(j, weight));\n```\n\n**예시:**\n```\n그래프:\n    0 --- 1\n    |     |\n    2 --- 3\n\n인접 리스트:\n0 → [1, 2]\n1 → [0, 3]\n2 → [0, 3]\n3 → [1, 2]\n```\n\n**장점:**\n- 공간: O(V + E)\n- 모든 간선 순회: O(V + E)\n- 희소 그래프 효율적\n\n**단점:**\n- 간선 확인: O(degree(v))\n- 구현 복잡\n\n---\n\n## 완전한 구현\n\n**인접 행렬:**\n```java\nclass GraphMatrix {\n    private int V;\n    private int[][] adjMatrix;\n    \n    public GraphMatrix(int V) {\n        this.V = V;\n        adjMatrix = new int[V][V];\n    }\n    \n    public void addEdge(int i, int j) {\n        adjMatrix[i][j] = 1;\n        adjMatrix[j][i] = 1;  // 무방향\n    }\n    \n    public boolean hasEdge(int i, int j) {\n        return adjMatrix[i][j] == 1;\n    }\n    \n    public List<Integer> getNeighbors(int v) {\n        List<Integer> neighbors = new ArrayList<>();\n        for (int i = 0; i < V; i++) {\n            if (adjMatrix[v][i] == 1) {\n                neighbors.add(i);\n            }\n        }\n        return neighbors;\n    }\n}\n```\n\n**인접 리스트:**\n```java\nclass GraphList {\n    private int V;\n    private List<List<Integer>> adjList;\n    \n    public GraphList(int V) {\n        this.V = V;\n        adjList = new ArrayList<>();\n        for (int i = 0; i < V; i++) {\n            adjList.add(new ArrayList<>());\n        }\n    }\n    \n    public void addEdge(int i, int j) {\n        adjList.get(i).add(j);\n        adjList.get(j).add(i);  // 무방향\n    }\n    \n    public boolean hasEdge(int i, int j) {\n        return adjList.get(i).contains(j);\n    }\n    \n    public List<Integer> getNeighbors(int v) {\n        return adjList.get(v);\n    }\n}\n```\n\n---\n\n## 언제 사용?\n\n**인접 행렬:**\n```\n✅ 밀집 그래프 (E ≈ V²)\n✅ 간선 확인 빈번\n✅ V가 작음\n\n예: 완전 그래프, 작은 그래프\n```\n\n**인접 리스트:**\n```\n✅ 희소 그래프 (E << V²)\n✅ 모든 간선 순회\n✅ V가 큼\n\n예: 소셜 네트워크, 도로망\n```\n\n---\n\n## 결론\n\n**그래프:**\n- 정점 + 간선\n- 네트워크, 관계 표현\n\n**구현:**\n1. 인접 행렬: O(V²) 공간, O(1) 간선 확인\n2. 인접 리스트: O(V+E) 공간, O(degree) 간선 확인\n\n**선택:**\n- 밀집: 행렬\n- 희소: 리스트",
      "type": "essay",
      "tags": [
        "그래프",
        "인접 행렬",
        "인접 리스트",
        "Graph"
      ]
    },
    {
      "question": "각 방법에 대해, \"두 정점이 연결되었는지\" 확인하는 시간복잡도와 \"한 정점에 연결된 모든 정점을 찾는\" 시간복잡도, 그리고 공간복잡도를 비교해 주세요.",
      "answer": "## 인접 행렬 vs 인접 리스트 복잡도 비교\n\n### 1. 간선 확인 (i와 j가 연결?)\n\n**인접 행렬: O(1)**\n```java\nboolean hasEdge(int i, int j) {\n    return adjMatrix[i][j] == 1;  // 배열 접근 O(1)\n}\n```\n\n**인접 리스트: O(degree(i))**\n```java\nboolean hasEdge(int i, int j) {\n    return adjList.get(i).contains(j);  // 리스트 순회\n}\n// 최악: O(V) (완전 그래프)\n// 평균: O(E/V) (degree)\n```\n\n---\n\n### 2. 모든 인접 정점 찾기\n\n**인접 행렬: O(V)**\n```java\nList<Integer> getNeighbors(int v) {\n    List<Integer> neighbors = new ArrayList<>();\n    for (int i = 0; i < V; i++) {  // O(V)\n        if (adjMatrix[v][i] == 1) {\n            neighbors.add(i);\n        }\n    }\n    return neighbors;\n}\n```\n\n**인접 리스트: O(degree(v))**\n```java\nList<Integer> getNeighbors(int v) {\n    return adjList.get(v);  // O(1) + degree(v)\n}\n```\n\n---\n\n### 3. 공간복잡도\n\n**인접 행렬: O(V²)**\n```java\nint[][] adjMatrix = new int[V][V];\n// V x V 배열\n// 간선 유무와 무관하게 V² 공간\n```\n\n**인접 리스트: O(V + E)**\n```java\nList<List<Integer>> adjList;  // V개 리스트\n// 각 리스트의 총 크기 = E (간선 수)\n// 무방향: 2E (양방향 저장)\n```\n\n---\n\n## 비교표\n\n| 연산 | 인접 행렬 | 인접 리스트 |\n|------|----------|------------|\n| **간선 확인** | **O(1)** ★ | O(degree) |\n| **모든 인접 정점** | O(V) | **O(degree)** ★ |\n| **모든 간선 순회** | O(V²) | **O(V + E)** ★ |\n| **정점 추가** | O(V²)* | O(1) |\n| **간선 추가** | O(1) | O(1) |\n| **간선 삭제** | O(1) | O(degree) |\n| **공간** | O(V²) | **O(V + E)** ★ |\n\n*새 행/열 추가 필요\n\n---\n\n## 구체적 예시\n\n### 희소 그래프 (Sparse)\n\n```\nV = 1,000\nE = 3,000\n\n인접 행렬:\n  공간: 1000² = 1,000,000\n  모든 간선: O(1,000,000)\n  \n인접 리스트:\n  공간: 1000 + 3000 = 4,000 ★\n  모든 간선: O(4,000) ★\n\n→ 리스트가 250배 효율적!\n```\n\n### 밀집 그래프 (Dense)\n\n```\nV = 100\nE = 4,950 (거의 완전 그래프)\n\n인접 행렬:\n  공간: 100² = 10,000\n  간선 확인: O(1) ★\n  \n인접 리스트:\n  공간: 100 + 4,950 = 5,050\n  간선 확인: O(50) (평균 degree)\n\n→ 행렬이 간선 확인 빠름\n```\n\n---\n\n## 실전 성능\n\n```java\n// V=10,000, E=50,000 (희소)\n\n간선 확인 100만 번:\n  행렬: 10ms   ★\n  리스트: 250ms\n\n모든 간선 순회:\n  행렬: 1000ms\n  리스트: 50ms  ★\n\n메모리:\n  행렬: 400MB\n  리스트: 0.4MB  ★\n```\n\n---\n\n## 알고리즘별 선호\n\n### DFS/BFS (인접 리스트 선호)\n\n```java\nvoid BFS(int start) {\n    Queue<Integer> q = new LinkedList<>();\n    q.offer(start);\n    \n    while (!q.isEmpty()) {\n        int v = q.poll();\n        \n        // 인접 리스트: O(degree(v))\n        for (int neighbor : adjList.get(v)) {\n            q.offer(neighbor);\n        }\n        \n        // 인접 행렬: O(V)\n        for (int i = 0; i < V; i++) {\n            if (adjMatrix[v][i] == 1) {\n                q.offer(i);\n            }\n        }\n    }\n}\n\n// 리스트: O(V + E)\n// 행렬: O(V²)\n```\n\n### Floyd-Warshall (인접 행렬 선호)\n\n```java\n// 모든 쌍 최단경로\nfor (int k = 0; k < V; k++) {\n    for (int i = 0; i < V; i++) {\n        for (int j = 0; j < V; j++) {\n            dist[i][j] = min(dist[i][j], \n                            dist[i][k] + dist[k][j]);\n        }\n    }\n}\n\n// 행렬 사용 필수: O(V³)\n```\n\n---\n\n## 결론\n\n**인접 행렬:**\n- 간선 확인: O(1) ★\n- 공간: O(V²)\n- 사용: 밀집 그래프, 간선 확인 빈번\n\n**인접 리스트:**\n- 인접 정점: O(degree) ★\n- 공간: O(V + E) ★\n- 사용: 희소 그래프, 순회 알고리즘\n\n**선택 기준:**\n```\nE ≈ V²:      행렬\nE << V²:     리스트 (대부분)\n간선 확인:    행렬\nDFS/BFS:    리스트\n```",
      "type": "essay",
      "tags": [
        "그래프",
        "시간복잡도",
        "인접 행렬",
        "인접 리스트"
      ]
    },
    {
      "question": "정점의 개수가 N개, 간선의 개수가 N^3 개라면, 어떤 방식으로 구현하는 것이 효율적일까요?",
      "answer": "## N개 정점, N³개 간선\n\n**답: 인접 행렬 사용**\n\n---\n\n## 이유\n\n### 공간복잡도\n\n**인접 리스트: O(V + E) = O(N + N³) = O(N³)**\n\n```java\n각 정점마다 N² 개 간선 (평균)\nList<List<Integer>> adjList;  // N개 리스트\n각 리스트 크기 합: N³\n\n총 공간: O(N³)\n```\n\n**인접 행렬: O(V²) = O(N²)**\n\n```java\nint[][] adjMatrix = new int[N][N];\n\n총 공간: O(N²)  ★ (훨씬 작음!)\n```\n\n**비교:**\n```\nN = 100:\n\n리스트: O(100³) = 1,000,000\n행렬:   O(100²) = 10,000  ★ (100배 작음)\n\nN = 1000:\n\n리스트: O(10⁹)\n행렬:   O(10⁶)  ★ (1000배 작음)\n```\n\n---\n\n### 밀집 그래프\n\n**정의:**\n```\n밀집 그래프: E ≈ V²\n\nE = N³\nV² = N²\n\nE/V² = N³/N² = N\n\n→ 매우 밀집! (N배 초과)\n```\n\n**특징:**\n- 거의 모든 정점 쌍이 연결\n- 행렬의 대부분 원소가 1\n\n---\n\n### 연산 성능\n\n**간선 확인: 행렬 우세**\n\n```java\n// 행렬: O(1)\nadjMatrix[i][j];  \n\n// 리스트: O(N²) (평균 degree)\nadjList.get(i).contains(j);  // 느림\n```\n\n**모든 간선 순회:**\n\n```java\n// 행렬: O(N²)\nfor (int i = 0; i < N; i++) {\n    for (int j = 0; j < N; j++) {\n        if (adjMatrix[i][j] == 1) {\n            // ...\n        }\n    }\n}\n\n// 리스트: O(N + N³) = O(N³)  \nfor (int i = 0; i < N; i++) {\n    for (int neighbor : adjList.get(i)) {\n        // ...\n    }\n}\n\n→ 행렬이 N배 빠름!\n```\n\n---\n\n## 실전 예시\n\n```java\nN = 100\nE = 1,000,000 (= 100³)\n\n// 인접 행렬\nint[][] adjMatrix = new int[100][100];\n메모리: 10,000 * 4 bytes = 40KB  ★\n\n// 인접 리스트\nList<List<Integer>> adjList;\n평균 degree: 10,000\n메모리: 100 + 1,000,000 = ~4MB\n\n→ 행렬이 100배 메모리 절약!\n```\n\n---\n\n## 알고리즘 선택\n\n**BFS/DFS: 여전히 행렬이 나음**\n\n```java\nvoid BFS(int start) {\n    // 행렬: O(N²)\n    for (int i = 0; i < N; i++) {\n        for (int j = 0; j < N; j++) {\n            if (adjMatrix[i][j] == 1) {\n                // ...\n            }\n        }\n    }\n    \n    // 리스트: O(N + N³) = O(N³)\n    for (int i = 0; i < N; i++) {\n        for (int neighbor : adjList.get(i)) {  // 평균 N² 개\n            // ...\n        }\n    }\n}\n\n→ 행렬이 N배 빠름\n```\n\n---\n\n## 결론\n\n**E = N³ → 인접 행렬 사용**\n\n**이유:**\n1. 공간: O(N²) vs O(N³) → N배 절약\n2. 밀집 그래프 → 행렬 적합\n3. 간선 확인: O(1)\n4. 순회: O(N²) vs O(N³)\n\n**일반 규칙:**\n```\nE > V²:  행렬 (밀집)\nE ≈ V²:  행렬\nE << V²: 리스트 (희소)\n```",
      "type": "essay",
      "tags": [
        "그래프",
        "인접 행렬",
        "밀집 그래프",
        "공간복잡도"
      ]
    },
    {
      "question": "사이클이 없는 그래프는 모두 트리인가요? 그렇지 않다면, 예시를 들어주세요.",
      "answer": "## 사이클 없는 그래프 ≠ 트리\n\n**답: 아니오**\n\n---\n\n## 트리 조건\n\n**트리 = 사이클 없음 + 연결됨**\n\n```\n1. 사이클 없음 (Acyclic)\n2. 연결 그래프 (Connected)\n3. V개 정점 → V-1개 간선\n```\n\n---\n\n## 반례: Forest (숲)\n\n### 예시 1: 분리된 트리들\n\n```\n    1        4\n   / \\        \\\n  2   3        5\n\n정점: 5개\n간선: 3개\n사이클: 없음 ✓\n연결: 아니오 ✗ (1-2-3과 4-5가 분리)\n\n→ 트리 아님! (Forest)\n```\n\n### 예시 2: 단일 정점들\n\n```\n1    2    3    4\n\n정점: 4개\n간선: 0개\n사이클: 없음 ✓\n연결: 아니오 ✗\n\n→ 트리 아님! (4개 고립 정점)\n```\n\n---\n\n## 사이클 없는 그래프 종류\n\n### 1. Tree (트리)\n\n```\n    1\n   / \\\n  2   3\n / \\   \\\n4   5   6\n\n사이클: 없음 ✓\n연결: 됨 ✓\n간선: V-1 = 5 ✓\n\n→ 트리 ✓\n```\n\n### 2. Forest (숲)\n\n```\n  1       4\n /  \\    /  \\\n2    3  5    6\n\n사이클: 없음 ✓\n연결: 안 됨 ✗\n컴포넌트: 2개\n\n→ 트리 아님 (트리의 집합)\n```\n\n### 3. DAG (Directed Acyclic Graph)\n\n```\n  1 → 2\n  ↓   ↓\n  3 → 4\n\n방향 그래프\n사이클: 없음 ✓\n연결: 됨 (방향 무시 시)\n\n→ 트리 아님 (방향 때문)\n```\n\n---\n\n## 트리 판별\n\n```java\nboolean isTree(Graph g) {\n    // 1. 연결 확인\n    if (!isConnected(g)) {\n        return false;  // Forest\n    }\n    \n    // 2. 사이클 확인\n    if (hasCycle(g)) {\n        return false;\n    }\n    \n    // 3. 간선 개수 확인\n    if (g.edges() != g.vertices() - 1) {\n        return false;\n    }\n    \n    return true;\n}\n\nboolean isConnected(Graph g) {\n    // BFS/DFS로 모든 정점 방문 가능한지\n    boolean[] visited = new boolean[g.V];\n    dfs(0, visited);\n    \n    for (boolean v : visited) {\n        if (!v) return false;\n    }\n    return true;\n}\n```\n\n---\n\n## 개수 관계\n\n**트리:**\n```\nV개 정점 → V-1개 간선\n\nV=5 → E=4\n```\n\n**Forest:**\n```\nk개 트리 → V-k개 간선\n\nV=10, k=3 → E=7\n```\n\n**DAG:**\n```\n간선 개수 제한 없음\n\nV=4 → E는 0~6 가능\n```\n\n---\n\n## 실전 예시\n\n**파일 시스템:**\n```\n/\n├── home\n│   ├── user1\n│   └── user2\n└── var\n    └── log\n\n→ Tree (단일 루트, 연결됨)\n```\n\n**Unix 프로세스:**\n```\ninit (PID 1)\n├── systemd\n│   └── sshd\n└── login\n\n// 고아 프로세스 발생 시:\n\ninit          orphan\n├── sshd\n\n→ Forest (분리된 프로세스들)\n```\n\n---\n\n## 결론\n\n**사이클 없음 ≠ 트리**\n\n```\n사이클 없는 그래프:\n1. Tree (연결됨)\n2. Forest (분리됨)\n3. DAG (방향)\n\n트리 = 사이클 없음 + 연결됨 + V-1 간선\n```\n\n**판별:**\n```\n1. 연결 확인\n2. 사이클 확인\n3. 간선 개수 확인\n\n모두 만족 → 트리\n```",
      "type": "essay",
      "tags": [
        "그래프",
        "트리",
        "Forest",
        "DAG"
      ]
    },
    {
      "question": "그래프에서, 최단거리를 구하는 방법에 대해 설명해 주세요.",
      "answer": "## 그래프 최단거리 알고리즘\n\n---\n\n## 1. BFS (가중치 없음)\n\n**조건:** 모든 간선 가중치 = 1\n\n```java\nint bfs(int start, int end) {\n    Queue<Integer> q = new LinkedList<>();\n    int[] dist = new int[V];\n    Arrays.fill(dist, -1);\n    \n    q.offer(start);\n    dist[start] = 0;\n    \n    while (!q.isEmpty()) {\n        int v = q.poll();\n        \n        for (int next : graph[v]) {\n            if (dist[next] == -1) {\n                dist[next] = dist[v] + 1;\n                q.offer(next);\n            }\n        }\n    }\n    \n    return dist[end];\n}\n\n// 시간: O(V + E)\n```\n\n---\n\n## 2. 다익스트라 (Dijkstra)\n\n**조건:** 양수 가중치\n\n```java\nint[] dijkstra(int start) {\n    int[] dist = new int[V];\n    Arrays.fill(dist, Integer.MAX_VALUE);\n    dist[start] = 0;\n    \n    PriorityQueue<int[]> pq = new PriorityQueue<>(\n        Comparator.comparingInt(a -> a[1])\n    );\n    pq.offer(new int[]{start, 0});\n    \n    while (!pq.isEmpty()) {\n        int[] curr = pq.poll();\n        int v = curr[0];\n        int d = curr[1];\n        \n        if (d > dist[v]) continue;\n        \n        for (Edge e : graph[v]) {\n            int next = e.to;\n            int cost = dist[v] + e.weight;\n            \n            if (cost < dist[next]) {\n                dist[next] = cost;\n                pq.offer(new int[]{next, cost});\n            }\n        }\n    }\n    \n    return dist;\n}\n\n// 시간: O((V + E) log V)\n```\n\n---\n\n## 3. 벨만-포드 (Bellman-Ford)\n\n**조건:** 음수 가중치 허용\n\n```java\nint[] bellmanFord(int start) {\n    int[] dist = new int[V];\n    Arrays.fill(dist, Integer.MAX_VALUE);\n    dist[start] = 0;\n    \n    // V-1번 반복\n    for (int i = 0; i < V - 1; i++) {\n        for (Edge e : edges) {\n            if (dist[e.from] != Integer.MAX_VALUE &&\n                dist[e.from] + e.weight < dist[e.to]) {\n                dist[e.to] = dist[e.from] + e.weight;\n            }\n        }\n    }\n    \n    // 음수 사이클 검사\n    for (Edge e : edges) {\n        if (dist[e.from] + e.weight < dist[e.to]) {\n            throw new Exception(\"음수 사이클 존재\");\n        }\n    }\n    \n    return dist;\n}\n\n// 시간: O(VE)\n```\n\n---\n\n## 4. 플로이드-워셜 (Floyd-Warshall)\n\n**조건:** 모든 쌍 최단거리\n\n```java\nint[][] floydWarshall() {\n    int[][] dist = new int[V][V];\n    \n    // 초기화\n    for (int i = 0; i < V; i++) {\n        Arrays.fill(dist[i], Integer.MAX_VALUE);\n        dist[i][i] = 0;\n    }\n    \n    for (Edge e : edges) {\n        dist[e.from][e.to] = e.weight;\n    }\n    \n    // DP\n    for (int k = 0; k < V; k++) {\n        for (int i = 0; i < V; i++) {\n            for (int j = 0; j < V; j++) {\n                if (dist[i][k] != Integer.MAX_VALUE &&\n                    dist[k][j] != Integer.MAX_VALUE) {\n                    dist[i][j] = Math.min(dist[i][j],\n                                         dist[i][k] + dist[k][j]);\n                }\n            }\n        }\n    }\n    \n    return dist;\n}\n\n// 시간: O(V³)\n```\n\n---\n\n## 알고리즘 비교\n\n| 알고리즘 | 시간 | 가중치 | 음수 | 모든 쌍 |\n|---------|------|--------|------|--------|\n| BFS | O(V+E) | 없음/1 | - | ❌ |\n| Dijkstra | O((V+E)logV) | 양수 | ❌ | ❌ |\n| Bellman-Ford | O(VE) | 있음 | ✅ | ❌ |\n| Floyd-Warshall | O(V³) | 있음 | ✅ | ✅ |\n\n---\n\n## 선택 가이드\n\n```\n가중치 없음:         BFS\n양수 가중치:         Dijkstra\n음수 가중치:         Bellman-Ford\n모든 쌍 최단거리:    Floyd-Warshall\n```\n\n---\n\n## 결론\n\n**최단거리 알고리즘:**\n1. BFS: 가중치 없음\n2. Dijkstra: 양수 가중치\n3. Bellman-Ford: 음수 허용\n4. Floyd-Warshall: 모든 쌍",
      "type": "essay",
      "tags": [
        "최단거리",
        "Dijkstra",
        "BFS",
        "Bellman-Ford",
        "Floyd-Warshall"
      ]
    }
  ]
}